				 *** Text Processing using NLTK *** 


============================ Sentence 1 =============================

Big Data Analytics: A Literature Review   Perspective  Sarah Al-Shiakhli  Information Security, master's level (120 credits)   2019  Luleå University of Technology   Department of Computer Science, Electrical and Space Engineering    Abstract   Big data is currently a buzzword in both academia and industry, with the term being used to   describe a broad domain of concepts, ranging from extracting data from outside sources, storing   and managing it, to processing such data with analytical techniques and tools. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', ':', 'A', 'Literature', 'Review', 'Perspective', 'Sarah', 'Al-Shiakhli', 'Information', 'Security', ',', 'master', "'s", 'level', '(', '120', 'credits', ')', '2019', 'Luleå', 'University', 'Technology', 'Department', 'Computer', 'Science', ',', 'Electrical', 'Space', 'Engineering', 'Abstract', 'Big', 'data', 'currently', 'buzzword', 'academia', 'industry', ',', 'term', 'used', 'describe', 'broad', 'domain', 'concepts', ',', 'ranging', 'extracting', 'data', 'outside', 'sources', ',', 'storing', 'managing', ',', 'processing', 'data', 'analytical', 'techniques', 'tools', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', ':'), (':', 'A'), ('A', 'Literature'), ('Literature', 'Review'), ('Review', 'Perspective'), ('Perspective', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', 'Information'), ('Information', 'Security'), ('Security', ','), (',', 'master'), ('master', "'s"), ("'s", 'level'), ('level', '('), ('(', '120'), ('120', 'credits'), ('credits', ')'), (')', '2019'), ('2019', 'Luleå'), ('Luleå', 'University'), ('University', 'Technology'), ('Technology', 'Department'), ('Department', 'Computer'), ('Computer', 'Science'), ('Science', ','), (',', 'Electrical'), ('Electrical', 'Space'), ('Space', 'Engineering'), ('Engineering', 'Abstract'), ('Abstract', 'Big'), ('Big', 'data'), ('data', 'currently'), ('currently', 'buzzword'), ('buzzword', 'academia'), ('academia', 'industry'), ('industry', ','), (',', 'term'), ('term', 'used'), ('used', 'describe'), ('describe', 'broad'), ('broad', 'domain'), ('domain', 'concepts'), ('concepts', ','), (',', 'ranging'), ('ranging', 'extracting'), ('extracting', 'data'), ('data', 'outside'), ('outside', 'sources'), ('sources', ','), (',', 'storing'), ('storing', 'managing'), ('managing', ','), (',', 'processing'), ('processing', 'data'), ('data', 'analytical'), ('analytical', 'techniques'), ('techniques', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', ':'), ('Analytics', ':', 'A'), (':', 'A', 'Literature'), ('A', 'Literature', 'Review'), ('Literature', 'Review', 'Perspective'), ('Review', 'Perspective', 'Sarah'), ('Perspective', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', 'Information'), ('Al-Shiakhli', 'Information', 'Security'), ('Information', 'Security', ','), ('Security', ',', 'master'), (',', 'master', "'s"), ('master', "'s", 'level'), ("'s", 'level', '('), ('level', '(', '120'), ('(', '120', 'credits'), ('120', 'credits', ')'), ('credits', ')', '2019'), (')', '2019', 'Luleå'), ('2019', 'Luleå', 'University'), ('Luleå', 'University', 'Technology'), ('University', 'Technology', 'Department'), ('Technology', 'Department', 'Computer'), ('Department', 'Computer', 'Science'), ('Computer', 'Science', ','), ('Science', ',', 'Electrical'), (',', 'Electrical', 'Space'), ('Electrical', 'Space', 'Engineering'), ('Space', 'Engineering', 'Abstract'), ('Engineering', 'Abstract', 'Big'), ('Abstract', 'Big', 'data'), ('Big', 'data', 'currently'), ('data', 'currently', 'buzzword'), ('currently', 'buzzword', 'academia'), ('buzzword', 'academia', 'industry'), ('academia', 'industry', ','), ('industry', ',', 'term'), (',', 'term', 'used'), ('term', 'used', 'describe'), ('used', 'describe', 'broad'), ('describe', 'broad', 'domain'), ('broad', 'domain', 'concepts'), ('domain', 'concepts', ','), ('concepts', ',', 'ranging'), (',', 'ranging', 'extracting'), ('ranging', 'extracting', 'data'), ('extracting', 'data', 'outside'), ('data', 'outside', 'sources'), ('outside', 'sources', ','), ('sources', ',', 'storing'), (',', 'storing', 'managing'), ('storing', 'managing', ','), ('managing', ',', 'processing'), (',', 'processing', 'data'), ('processing', 'data', 'analytical'), ('data', 'analytical', 'techniques'), ('analytical', 'techniques', 'tools'), ('techniques', 'tools', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS'), (':', ':'), ('A', 'DT'), ('Literature', 'NNP'), ('Review', 'NNP'), ('Perspective', 'NNP'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('Information', 'NNP'), ('Security', 'NNP'), (',', ','), ('master', 'NN'), ("'s", 'POS'), ('level', 'NN'), ('(', '('), ('120', 'CD'), ('credits', 'NNS'), (')', ')'), ('2019', 'CD'), ('Luleå', 'NNP'), ('University', 'NNP'), ('Technology', 'NNP'), ('Department', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), (',', ','), ('Electrical', 'JJ'), ('Space', 'NNP'), ('Engineering', 'NNP'), ('Abstract', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('currently', 'RB'), ('buzzword', 'VBP'), ('academia', 'NN'), ('industry', 'NN'), (',', ','), ('term', 'NN'), ('used', 'VBN'), ('describe', 'NN'), ('broad', 'JJ'), ('domain', 'NN'), ('concepts', 'NNS'), (',', ','), ('ranging', 'VBG'), ('extracting', 'VBG'), ('data', 'NNS'), ('outside', 'JJ'), ('sources', 'NNS'), (',', ','), ('storing', 'VBG'), ('managing', 'NN'), (',', ','), ('processing', 'VBG'), ('data', 'NNS'), ('analytical', 'JJ'), ('techniques', 'NNS'), ('tools', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP Analytics/NNS)
  :/:
  (NP
    A/DT
    Literature/NNP
    Review/NNP
    Perspective/NNP
    Sarah/NNP
    Al-Shiakhli/NNP
    Information/NNP
    Security/NNP)
  ,/,
  (NP master/NN)
  's/POS
  (NP level/NN)
  (/(
  120/CD
  (NP credits/NNS)
  )/)
  2019/CD
  (NP
    Luleå/NNP
    University/NNP
    Technology/NNP
    Department/NNP
    Computer/NNP
    Science/NNP)
  ,/,
  (NP
    Electrical/JJ
    Space/NNP
    Engineering/NNP
    Abstract/NNP
    Big/NNP
    data/NNS)
  currently/RB
  buzzword/VBP
  (NP academia/NN industry/NN)
  ,/,
  (NP term/NN)
  used/VBN
  (NP describe/NN)
  (NP broad/JJ domain/NN concepts/NNS)
  ,/,
  ranging/VBG
  extracting/VBG
  (NP data/NNS)
  (NP outside/JJ sources/NNS)
  ,/,
  storing/VBG
  (NP managing/NN)
  ,/,
  processing/VBG
  (NP data/NNS)
  (NP analytical/JJ techniques/NNS tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics', 'A Literature Review Perspective Sarah Al-Shiakhli Information Security', 'master', 'level', 'credits', 'Luleå University Technology Department Computer Science', 'Electrical Space Engineering Abstract Big data', 'academia industry', 'term', 'describe', 'broad domain concepts', 'data', 'outside sources', 'managing', 'data', 'analytical techniques tools']

>> Named Entities are: 
 [('ORGANIZATION', 'Literature Review'), ('PERSON', 'Sarah'), ('ORGANIZATION', 'Luleå University Technology Department Computer Science'), ('ORGANIZATION', 'Electrical Space')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Literature', 'literatur'), ('Review', 'review'), ('Perspective', 'perspect'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('Information', 'inform'), ('Security', 'secur'), (',', ','), ('master', 'master'), ("'s", "'s"), ('level', 'level'), ('(', '('), ('120', '120'), ('credits', 'credit'), (')', ')'), ('2019', '2019'), ('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineering', 'engin'), ('Abstract', 'abstract'), ('Big', 'big'), ('data', 'data'), ('currently', 'current'), ('buzzword', 'buzzword'), ('academia', 'academia'), ('industry', 'industri'), (',', ','), ('term', 'term'), ('used', 'use'), ('describe', 'describ'), ('broad', 'broad'), ('domain', 'domain'), ('concepts', 'concept'), (',', ','), ('ranging', 'rang'), ('extracting', 'extract'), ('data', 'data'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ','), ('storing', 'store'), ('managing', 'manag'), (',', ','), ('processing', 'process'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Literature', 'literatur'), ('Review', 'review'), ('Perspective', 'perspect'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('Information', 'inform'), ('Security', 'secur'), (',', ','), ('master', 'master'), ("'s", "'s"), ('level', 'level'), ('(', '('), ('120', '120'), ('credits', 'credit'), (')', ')'), ('2019', '2019'), ('Luleå', 'luleå'), ('University', 'univers'), ('Technology', 'technolog'), ('Department', 'depart'), ('Computer', 'comput'), ('Science', 'scienc'), (',', ','), ('Electrical', 'electr'), ('Space', 'space'), ('Engineering', 'engin'), ('Abstract', 'abstract'), ('Big', 'big'), ('data', 'data'), ('currently', 'current'), ('buzzword', 'buzzword'), ('academia', 'academia'), ('industry', 'industri'), (',', ','), ('term', 'term'), ('used', 'use'), ('describe', 'describ'), ('broad', 'broad'), ('domain', 'domain'), ('concepts', 'concept'), (',', ','), ('ranging', 'rang'), ('extracting', 'extract'), ('data', 'data'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ','), ('storing', 'store'), ('managing', 'manag'), (',', ','), ('processing', 'process'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), (':', ':'), ('A', 'A'), ('Literature', 'Literature'), ('Review', 'Review'), ('Perspective', 'Perspective'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('Information', 'Information'), ('Security', 'Security'), (',', ','), ('master', 'master'), ("'s", "'s"), ('level', 'level'), ('(', '('), ('120', '120'), ('credits', 'credit'), (')', ')'), ('2019', '2019'), ('Luleå', 'Luleå'), ('University', 'University'), ('Technology', 'Technology'), ('Department', 'Department'), ('Computer', 'Computer'), ('Science', 'Science'), (',', ','), ('Electrical', 'Electrical'), ('Space', 'Space'), ('Engineering', 'Engineering'), ('Abstract', 'Abstract'), ('Big', 'Big'), ('data', 'data'), ('currently', 'currently'), ('buzzword', 'buzzword'), ('academia', 'academia'), ('industry', 'industry'), (',', ','), ('term', 'term'), ('used', 'used'), ('describe', 'describe'), ('broad', 'broad'), ('domain', 'domain'), ('concepts', 'concept'), (',', ','), ('ranging', 'ranging'), ('extracting', 'extracting'), ('data', 'data'), ('outside', 'outside'), ('sources', 'source'), (',', ','), ('storing', 'storing'), ('managing', 'managing'), (',', ','), ('processing', 'processing'), ('data', 'data'), ('analytical', 'analytical'), ('techniques', 'technique'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 2 =============================

This thesis work thus aims to provide a review of current big data analytics concepts in an attempt   to highlight big data analytics’ importance to decision making. 


>> Tokens are: 
 ['This', 'thesis', 'work', 'thus', 'aims', 'provide', 'review', 'current', 'big', 'data', 'analytics', 'concepts', 'attempt', 'highlight', 'big', 'data', 'analytics', '’', 'importance', 'decision', 'making', '.']

>> Bigrams are: 
 [('This', 'thesis'), ('thesis', 'work'), ('work', 'thus'), ('thus', 'aims'), ('aims', 'provide'), ('provide', 'review'), ('review', 'current'), ('current', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'concepts'), ('concepts', 'attempt'), ('attempt', 'highlight'), ('highlight', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '’'), ('’', 'importance'), ('importance', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('This', 'thesis', 'work'), ('thesis', 'work', 'thus'), ('work', 'thus', 'aims'), ('thus', 'aims', 'provide'), ('aims', 'provide', 'review'), ('provide', 'review', 'current'), ('review', 'current', 'big'), ('current', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'concepts'), ('analytics', 'concepts', 'attempt'), ('concepts', 'attempt', 'highlight'), ('attempt', 'highlight', 'big'), ('highlight', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '’'), ('analytics', '’', 'importance'), ('’', 'importance', 'decision'), ('importance', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('thesis', 'NN'), ('work', 'NN'), ('thus', 'RB'), ('aims', 'VBZ'), ('provide', 'VB'), ('review', 'NN'), ('current', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('concepts', 'NNS'), ('attempt', 'VBP'), ('highlight', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('’', 'JJ'), ('importance', 'NN'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

 (S
  (NP This/DT thesis/NN work/NN)
  thus/RB
  aims/VBZ
  provide/VB
  (NP review/NN)
  (NP current/JJ big/JJ data/NN analytics/NNS concepts/NNS)
  attempt/VBP
  highlight/RB
  (NP big/JJ data/NNS analytics/NNS)
  (NP ’/JJ importance/NN decision/NN making/NN)
  ./.) 


>> Noun Phrases are: 
 ['This thesis work', 'review', 'current big data analytics concepts', 'big data analytics', '’ importance decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thesis', 'thesi'), ('work', 'work'), ('thus', 'thu'), ('aims', 'aim'), ('provide', 'provid'), ('review', 'review'), ('current', 'current'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('concepts', 'concept'), ('attempt', 'attempt'), ('highlight', 'highlight'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’'), ('importance', 'import'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thesis', 'thesi'), ('work', 'work'), ('thus', 'thus'), ('aims', 'aim'), ('provide', 'provid'), ('review', 'review'), ('current', 'current'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('concepts', 'concept'), ('attempt', 'attempt'), ('highlight', 'highlight'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’'), ('importance', 'import'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('thesis', 'thesis'), ('work', 'work'), ('thus', 'thus'), ('aims', 'aim'), ('provide', 'provide'), ('review', 'review'), ('current', 'current'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('concepts', 'concept'), ('attempt', 'attempt'), ('highlight', 'highlight'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('’', '’'), ('importance', 'importance'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



============================ Sentence 3 =============================

Due to the rapid increase in interest in big data and its importance to academia, industry, and   society, solutions to handling data and extracting knowledge from datasets need to be developed   and provided with some urgency to allow decision makers to gain valuable insights from the varied   and rapidly changing data they now have access to. 


>> Tokens are: 
 ['Due', 'rapid', 'increase', 'interest', 'big', 'data', 'importance', 'academia', ',', 'industry', ',', 'society', ',', 'solutions', 'handling', 'data', 'extracting', 'knowledge', 'datasets', 'need', 'developed', 'provided', 'urgency', 'allow', 'decision', 'makers', 'gain', 'valuable', 'insights', 'varied', 'rapidly', 'changing', 'data', 'access', '.']

>> Bigrams are: 
 [('Due', 'rapid'), ('rapid', 'increase'), ('increase', 'interest'), ('interest', 'big'), ('big', 'data'), ('data', 'importance'), ('importance', 'academia'), ('academia', ','), (',', 'industry'), ('industry', ','), (',', 'society'), ('society', ','), (',', 'solutions'), ('solutions', 'handling'), ('handling', 'data'), ('data', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'datasets'), ('datasets', 'need'), ('need', 'developed'), ('developed', 'provided'), ('provided', 'urgency'), ('urgency', 'allow'), ('allow', 'decision'), ('decision', 'makers'), ('makers', 'gain'), ('gain', 'valuable'), ('valuable', 'insights'), ('insights', 'varied'), ('varied', 'rapidly'), ('rapidly', 'changing'), ('changing', 'data'), ('data', 'access'), ('access', '.')]

>> Trigrams are: 
 [('Due', 'rapid', 'increase'), ('rapid', 'increase', 'interest'), ('increase', 'interest', 'big'), ('interest', 'big', 'data'), ('big', 'data', 'importance'), ('data', 'importance', 'academia'), ('importance', 'academia', ','), ('academia', ',', 'industry'), (',', 'industry', ','), ('industry', ',', 'society'), (',', 'society', ','), ('society', ',', 'solutions'), (',', 'solutions', 'handling'), ('solutions', 'handling', 'data'), ('handling', 'data', 'extracting'), ('data', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'datasets'), ('knowledge', 'datasets', 'need'), ('datasets', 'need', 'developed'), ('need', 'developed', 'provided'), ('developed', 'provided', 'urgency'), ('provided', 'urgency', 'allow'), ('urgency', 'allow', 'decision'), ('allow', 'decision', 'makers'), ('decision', 'makers', 'gain'), ('makers', 'gain', 'valuable'), ('gain', 'valuable', 'insights'), ('valuable', 'insights', 'varied'), ('insights', 'varied', 'rapidly'), ('varied', 'rapidly', 'changing'), ('rapidly', 'changing', 'data'), ('changing', 'data', 'access'), ('data', 'access', '.')]

>> POS Tags are: 
 [('Due', 'JJ'), ('rapid', 'JJ'), ('increase', 'NN'), ('interest', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('importance', 'NN'), ('academia', 'NN'), (',', ','), ('industry', 'NN'), (',', ','), ('society', 'NN'), (',', ','), ('solutions', 'NNS'), ('handling', 'VBG'), ('data', 'NNS'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('datasets', 'NNS'), ('need', 'VBP'), ('developed', 'VBN'), ('provided', 'JJ'), ('urgency', 'NN'), ('allow', 'JJ'), ('decision', 'NN'), ('makers', 'NNS'), ('gain', 'VBP'), ('valuable', 'JJ'), ('insights', 'NNS'), ('varied', 'VBD'), ('rapidly', 'RB'), ('changing', 'VBG'), ('data', 'NNS'), ('access', 'NN'), ('.', '.')]

 (S
  (NP Due/JJ rapid/JJ increase/NN interest/NN)
  (NP big/JJ data/NNS importance/NN academia/NN)
  ,/,
  (NP industry/NN)
  ,/,
  (NP society/NN)
  ,/,
  (NP solutions/NNS)
  handling/VBG
  (NP data/NNS)
  extracting/VBG
  (NP knowledge/NN datasets/NNS)
  need/VBP
  developed/VBN
  (NP provided/JJ urgency/NN)
  (NP allow/JJ decision/NN makers/NNS)
  gain/VBP
  (NP valuable/JJ insights/NNS)
  varied/VBD
  rapidly/RB
  changing/VBG
  (NP data/NNS access/NN)
  ./.) 


>> Noun Phrases are: 
 ['Due rapid increase interest', 'big data importance academia', 'industry', 'society', 'solutions', 'data', 'knowledge datasets', 'provided urgency', 'allow decision makers', 'valuable insights', 'data access']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('rapid', 'rapid'), ('increase', 'increas'), ('interest', 'interest'), ('big', 'big'), ('data', 'data'), ('importance', 'import'), ('academia', 'academia'), (',', ','), ('industry', 'industri'), (',', ','), ('society', 'societi'), (',', ','), ('solutions', 'solut'), ('handling', 'handl'), ('data', 'data'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('need', 'need'), ('developed', 'develop'), ('provided', 'provid'), ('urgency', 'urgenc'), ('allow', 'allow'), ('decision', 'decis'), ('makers', 'maker'), ('gain', 'gain'), ('valuable', 'valuabl'), ('insights', 'insight'), ('varied', 'vari'), ('rapidly', 'rapidli'), ('changing', 'chang'), ('data', 'data'), ('access', 'access'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('rapid', 'rapid'), ('increase', 'increas'), ('interest', 'interest'), ('big', 'big'), ('data', 'data'), ('importance', 'import'), ('academia', 'academia'), (',', ','), ('industry', 'industri'), (',', ','), ('society', 'societi'), (',', ','), ('solutions', 'solut'), ('handling', 'handl'), ('data', 'data'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('need', 'need'), ('developed', 'develop'), ('provided', 'provid'), ('urgency', 'urgenc'), ('allow', 'allow'), ('decision', 'decis'), ('makers', 'maker'), ('gain', 'gain'), ('valuable', 'valuabl'), ('insights', 'insight'), ('varied', 'vari'), ('rapidly', 'rapid'), ('changing', 'chang'), ('data', 'data'), ('access', 'access'), ('.', '.')]

>> Lemmatization: 
 [('Due', 'Due'), ('rapid', 'rapid'), ('increase', 'increase'), ('interest', 'interest'), ('big', 'big'), ('data', 'data'), ('importance', 'importance'), ('academia', 'academia'), (',', ','), ('industry', 'industry'), (',', ','), ('society', 'society'), (',', ','), ('solutions', 'solution'), ('handling', 'handling'), ('data', 'data'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('datasets', 'datasets'), ('need', 'need'), ('developed', 'developed'), ('provided', 'provided'), ('urgency', 'urgency'), ('allow', 'allow'), ('decision', 'decision'), ('makers', 'maker'), ('gain', 'gain'), ('valuable', 'valuable'), ('insights', 'insight'), ('varied', 'varied'), ('rapidly', 'rapidly'), ('changing', 'changing'), ('data', 'data'), ('access', 'access'), ('.', '.')]



============================ Sentence 4 =============================

Many companies are using big data analytics   to analyse the massive quantities of data they have, with the results influencing their decision   making. 


>> Tokens are: 
 ['Many', 'companies', 'using', 'big', 'data', 'analytics', 'analyse', 'massive', 'quantities', 'data', ',', 'results', 'influencing', 'decision', 'making', '.']

>> Bigrams are: 
 [('Many', 'companies'), ('companies', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'analyse'), ('analyse', 'massive'), ('massive', 'quantities'), ('quantities', 'data'), ('data', ','), (',', 'results'), ('results', 'influencing'), ('influencing', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('Many', 'companies', 'using'), ('companies', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'analyse'), ('analytics', 'analyse', 'massive'), ('analyse', 'massive', 'quantities'), ('massive', 'quantities', 'data'), ('quantities', 'data', ','), ('data', ',', 'results'), (',', 'results', 'influencing'), ('results', 'influencing', 'decision'), ('influencing', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('companies', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('analyse', 'VBP'), ('massive', 'JJ'), ('quantities', 'NNS'), ('data', 'NNS'), (',', ','), ('results', 'NNS'), ('influencing', 'VBG'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

 (S
  (NP Many/JJ companies/NNS)
  using/VBG
  (NP big/JJ data/NNS analytics/NNS)
  analyse/VBP
  (NP massive/JJ quantities/NNS data/NNS)
  ,/,
  (NP results/NNS)
  influencing/VBG
  (NP decision/NN making/NN)
  ./.) 


>> Noun Phrases are: 
 ['Many companies', 'big data analytics', 'massive quantities data', 'results', 'decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('companies', 'compani'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('analyse', 'analys'), ('massive', 'massiv'), ('quantities', 'quantiti'), ('data', 'data'), (',', ','), ('results', 'result'), ('influencing', 'influenc'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('companies', 'compani'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('analyse', 'analys'), ('massive', 'massiv'), ('quantities', 'quantiti'), ('data', 'data'), (',', ','), ('results', 'result'), ('influencing', 'influenc'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('companies', 'company'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('analyse', 'analyse'), ('massive', 'massive'), ('quantities', 'quantity'), ('data', 'data'), (',', ','), ('results', 'result'), ('influencing', 'influencing'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



============================ Sentence 5 =============================

Many studies have shown the benefits of using big data in various sectors, and in this   thesis work, various big data analytical techniques and tools are discussed to allow analysis of the   application of big data analytics in several different domains. 


>> Tokens are: 
 ['Many', 'studies', 'shown', 'benefits', 'using', 'big', 'data', 'various', 'sectors', ',', 'thesis', 'work', ',', 'various', 'big', 'data', 'analytical', 'techniques', 'tools', 'discussed', 'allow', 'analysis', 'application', 'big', 'data', 'analytics', 'several', 'different', 'domains', '.']

>> Bigrams are: 
 [('Many', 'studies'), ('studies', 'shown'), ('shown', 'benefits'), ('benefits', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'various'), ('various', 'sectors'), ('sectors', ','), (',', 'thesis'), ('thesis', 'work'), ('work', ','), (',', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'analytical'), ('analytical', 'techniques'), ('techniques', 'tools'), ('tools', 'discussed'), ('discussed', 'allow'), ('allow', 'analysis'), ('analysis', 'application'), ('application', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'several'), ('several', 'different'), ('different', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('Many', 'studies', 'shown'), ('studies', 'shown', 'benefits'), ('shown', 'benefits', 'using'), ('benefits', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'various'), ('data', 'various', 'sectors'), ('various', 'sectors', ','), ('sectors', ',', 'thesis'), (',', 'thesis', 'work'), ('thesis', 'work', ','), ('work', ',', 'various'), (',', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'analytical'), ('data', 'analytical', 'techniques'), ('analytical', 'techniques', 'tools'), ('techniques', 'tools', 'discussed'), ('tools', 'discussed', 'allow'), ('discussed', 'allow', 'analysis'), ('allow', 'analysis', 'application'), ('analysis', 'application', 'big'), ('application', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'several'), ('analytics', 'several', 'different'), ('several', 'different', 'domains'), ('different', 'domains', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('studies', 'NNS'), ('shown', 'VBN'), ('benefits', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('various', 'JJ'), ('sectors', 'NNS'), (',', ','), ('thesis', 'NN'), ('work', 'NN'), (',', ','), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytical', 'JJ'), ('techniques', 'NNS'), ('tools', 'NNS'), ('discussed', 'VBD'), ('allow', 'JJ'), ('analysis', 'NN'), ('application', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('several', 'JJ'), ('different', 'JJ'), ('domains', 'NNS'), ('.', '.')]

 (S
  (NP Many/JJ studies/NNS)
  shown/VBN
  (NP benefits/NNS)
  using/VBG
  (NP big/JJ data/NNS)
  (NP various/JJ sectors/NNS)
  ,/,
  (NP thesis/NN work/NN)
  ,/,
  (NP various/JJ big/JJ data/NNS)
  (NP analytical/JJ techniques/NNS tools/NNS)
  discussed/VBD
  (NP allow/JJ analysis/NN application/NN)
  (NP big/JJ data/NNS analytics/NNS)
  (NP several/JJ different/JJ domains/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Many studies', 'benefits', 'big data', 'various sectors', 'thesis work', 'various big data', 'analytical techniques tools', 'allow analysis application', 'big data analytics', 'several different domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('studies', 'studi'), ('shown', 'shown'), ('benefits', 'benefit'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('various', 'variou'), ('sectors', 'sector'), (',', ','), ('thesis', 'thesi'), ('work', 'work'), (',', ','), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('discussed', 'discuss'), ('allow', 'allow'), ('analysis', 'analysi'), ('application', 'applic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('several', 'sever'), ('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('studies', 'studi'), ('shown', 'shown'), ('benefits', 'benefit'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('various', 'various'), ('sectors', 'sector'), (',', ','), ('thesis', 'thesi'), ('work', 'work'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('techniques', 'techniqu'), ('tools', 'tool'), ('discussed', 'discuss'), ('allow', 'allow'), ('analysis', 'analysi'), ('application', 'applic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('several', 'sever'), ('different', 'differ'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('studies', 'study'), ('shown', 'shown'), ('benefits', 'benefit'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('various', 'various'), ('sectors', 'sector'), (',', ','), ('thesis', 'thesis'), ('work', 'work'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analytical', 'analytical'), ('techniques', 'technique'), ('tools', 'tool'), ('discussed', 'discussed'), ('allow', 'allow'), ('analysis', 'analysis'), ('application', 'application'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('several', 'several'), ('different', 'different'), ('domains', 'domain'), ('.', '.')]



============================ Sentence 6 =============================

Keywords: Literature review, big data, big data analytics and tools, decision making, big data   applications. 


>> Tokens are: 
 ['Keywords', ':', 'Literature', 'review', ',', 'big', 'data', ',', 'big', 'data', 'analytics', 'tools', ',', 'decision', 'making', ',', 'big', 'data', 'applications', '.']

>> Bigrams are: 
 [('Keywords', ':'), (':', 'Literature'), ('Literature', 'review'), ('review', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', ','), (',', 'decision'), ('decision', 'making'), ('making', ','), (',', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('Keywords', ':', 'Literature'), (':', 'Literature', 'review'), ('Literature', 'review', ','), ('review', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', ','), ('tools', ',', 'decision'), (',', 'decision', 'making'), ('decision', 'making', ','), ('making', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', '.')]

>> POS Tags are: 
 [('Keywords', 'NNS'), (':', ':'), ('Literature', 'NNP'), ('review', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), (',', ','), ('decision', 'NN'), ('making', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('applications', 'NNS'), ('.', '.')]

 (S
  (NP Keywords/NNS)
  :/:
  (NP Literature/NNP review/NN)
  ,/,
  (NP big/JJ data/NNS)
  ,/,
  (NP big/JJ data/NNS analytics/NNS tools/NNS)
  ,/,
  (NP decision/NN making/NN)
  ,/,
  (NP big/JJ data/NN applications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Keywords', 'Literature review', 'big data', 'big data analytics tools', 'decision making', 'big data applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), (',', ','), ('decision', 'decis'), ('making', 'make'), (',', ','), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Keywords', 'keyword'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), (',', ','), ('decision', 'decis'), ('making', 'make'), (',', ','), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('Keywords', 'Keywords'), (':', ':'), ('Literature', 'Literature'), ('review', 'review'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), (',', ','), ('decision', 'decision'), ('making', 'making'), (',', ','), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('.', '.')]



============================ Sentence 7 =============================

Sarah Al-Shiakhli   ii      Contents   Abstract ............................................................................................................................................ i   Contents .......................................................................................................................................... ii   1. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', 'ii', 'Contents', 'Abstract', '............................................................................................................................................', 'Contents', '..........................................................................................................................................', 'ii', '1', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', 'ii'), ('ii', 'Contents'), ('Contents', 'Abstract'), ('Abstract', '............................................................................................................................................'), ('............................................................................................................................................', 'Contents'), ('Contents', '..........................................................................................................................................'), ('..........................................................................................................................................', 'ii'), ('ii', '1'), ('1', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', 'ii'), ('Al-Shiakhli', 'ii', 'Contents'), ('ii', 'Contents', 'Abstract'), ('Contents', 'Abstract', '............................................................................................................................................'), ('Abstract', '............................................................................................................................................', 'Contents'), ('............................................................................................................................................', 'Contents', '..........................................................................................................................................'), ('Contents', '..........................................................................................................................................', 'ii'), ('..........................................................................................................................................', 'ii', '1'), ('ii', '1', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('ii', 'NN'), ('Contents', 'NNP'), ('Abstract', 'NNP'), ('............................................................................................................................................', 'NNP'), ('Contents', 'NNP'), ('..........................................................................................................................................', 'NNP'), ('ii', 'VBZ'), ('1', 'CD'), ('.', '.')]

 (S
  (NP
    Sarah/NNP
    Al-Shiakhli/NNP
    ii/NN
    Contents/NNP
    Abstract/NNP
    ............................................................................................................................................/NNP
    Contents/NNP
    ........................................................................................................................................../NNP)
  ii/VBZ
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli ii Contents Abstract ............................................................................................................................................ Contents ..........................................................................................................................................']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'Contents Abstract')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('ii', 'ii'), ('Contents', 'content'), ('Abstract', 'abstract'), ('............................................................................................................................................', '............................................................................................................................................'), ('Contents', 'content'), ('..........................................................................................................................................', '..........................................................................................................................................'), ('ii', 'ii'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('ii', 'ii'), ('Contents', 'content'), ('Abstract', 'abstract'), ('............................................................................................................................................', '............................................................................................................................................'), ('Contents', 'content'), ('..........................................................................................................................................', '..........................................................................................................................................'), ('ii', 'ii'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('ii', 'ii'), ('Contents', 'Contents'), ('Abstract', 'Abstract'), ('............................................................................................................................................', '............................................................................................................................................'), ('Contents', 'Contents'), ('..........................................................................................................................................', '..........................................................................................................................................'), ('ii', 'ii'), ('1', '1'), ('.', '.')]



============================ Sentence 8 =============================

Introduction ............................................................................................................................. 1   2. 


>> Tokens are: 
 ['Introduction', '.............................................................................................................................', '1', '2', '.']

>> Bigrams are: 
 [('Introduction', '.............................................................................................................................'), ('.............................................................................................................................', '1'), ('1', '2'), ('2', '.')]

>> Trigrams are: 
 [('Introduction', '.............................................................................................................................', '1'), ('.............................................................................................................................', '1', '2'), ('1', '2', '.')]

>> POS Tags are: 
 [('Introduction', 'NN'), ('.............................................................................................................................', 'VBD'), ('1', 'CD'), ('2', 'CD'), ('.', '.')]

 (S
  (NP Introduction/NN)
  ............................................................................................................................./VBD
  1/CD
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['Introduction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct'), ('.............................................................................................................................', '.............................................................................................................................'), ('1', '1'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct'), ('.............................................................................................................................', '.............................................................................................................................'), ('1', '1'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Introduction', 'Introduction'), ('.............................................................................................................................', '.............................................................................................................................'), ('1', '1'), ('2', '2'), ('.', '.')]



============================ Sentence 9 =============================

Research Question ................................................................................................................... 2   3. 


>> Tokens are: 
 ['Research', 'Question', '...................................................................................................................', '2', '3', '.']

>> Bigrams are: 
 [('Research', 'Question'), ('Question', '...................................................................................................................'), ('...................................................................................................................', '2'), ('2', '3'), ('3', '.')]

>> Trigrams are: 
 [('Research', 'Question', '...................................................................................................................'), ('Question', '...................................................................................................................', '2'), ('...................................................................................................................', '2', '3'), ('2', '3', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Question', 'NNP'), ('...................................................................................................................', 'VBD'), ('2', 'CD'), ('3', 'CD'), ('.', '.')]

 (S
  (NP Research/NNP Question/NNP)
  .................................................................................................................../VBD
  2/CD
  3/CD
  ./.) 


>> Noun Phrases are: 
 ['Research Question']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Question', 'question'), ('...................................................................................................................', '...................................................................................................................'), ('2', '2'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Question', 'question'), ('...................................................................................................................', '...................................................................................................................'), ('2', '2'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Question', 'Question'), ('...................................................................................................................', '...................................................................................................................'), ('2', '2'), ('3', '3'), ('.', '.')]



============================ Sentence 10 =============================

Research Method ..................................................................................................................... 3   4. 


>> Tokens are: 
 ['Research', 'Method', '.....................................................................................................................', '3', '4', '.']

>> Bigrams are: 
 [('Research', 'Method'), ('Method', '.....................................................................................................................'), ('.....................................................................................................................', '3'), ('3', '4'), ('4', '.')]

>> Trigrams are: 
 [('Research', 'Method', '.....................................................................................................................'), ('Method', '.....................................................................................................................', '3'), ('.....................................................................................................................', '3', '4'), ('3', '4', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Method', 'NNP'), ('.....................................................................................................................', 'VBD'), ('3', 'CD'), ('4', 'CD'), ('.', '.')]

 (S
  (NP Research/NNP Method/NNP)
  ...................................................................................................................../VBD
  3/CD
  4/CD
  ./.) 


>> Noun Phrases are: 
 ['Research Method']

>> Named Entities are: 
 [('PERSON', 'Method')] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Method', 'method'), ('.....................................................................................................................', '.....................................................................................................................'), ('3', '3'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Method', 'method'), ('.....................................................................................................................', '.....................................................................................................................'), ('3', '3'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Method', 'Method'), ('.....................................................................................................................', '.....................................................................................................................'), ('3', '3'), ('4', '4'), ('.', '.')]



============================ Sentence 11 =============================

Scope delimitation and risks .................................................................................................... 7   5. 


>> Tokens are: 
 ['Scope', 'delimitation', 'risks', '....................................................................................................', '7', '5', '.']

>> Bigrams are: 
 [('Scope', 'delimitation'), ('delimitation', 'risks'), ('risks', '....................................................................................................'), ('....................................................................................................', '7'), ('7', '5'), ('5', '.')]

>> Trigrams are: 
 [('Scope', 'delimitation', 'risks'), ('delimitation', 'risks', '....................................................................................................'), ('risks', '....................................................................................................', '7'), ('....................................................................................................', '7', '5'), ('7', '5', '.')]

>> POS Tags are: 
 [('Scope', 'NNP'), ('delimitation', 'NN'), ('risks', 'NNS'), ('....................................................................................................', 'VBP'), ('7', 'CD'), ('5', 'CD'), ('.', '.')]

 (S
  (NP Scope/NNP delimitation/NN risks/NNS)
  ..................................................................................................../VBP
  7/CD
  5/CD
  ./.) 


>> Noun Phrases are: 
 ['Scope delimitation risks']

>> Named Entities are: 
 [('GPE', 'Scope')] 

>> Stemming using Porter Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk'), ('....................................................................................................', '....................................................................................................'), ('7', '7'), ('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk'), ('....................................................................................................', '....................................................................................................'), ('7', '7'), ('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('Scope', 'Scope'), ('delimitation', 'delimitation'), ('risks', 'risk'), ('....................................................................................................', '....................................................................................................'), ('7', '7'), ('5', '5'), ('.', '.')]



============================ Sentence 12 =============================

What is “big data”? 


>> Tokens are: 
 ['What', '“', 'big', 'data', '”', '?']

>> Bigrams are: 
 [('What', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', '?')]

>> Trigrams are: 
 [('What', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('“', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('?', '.')]

 (S What/WP “/VBZ (NP big/JJ data/NNS ”/NN) ?/.) 


>> Noun Phrases are: 
 ['big data ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]



============================ Sentence 13 =============================

.................................................................................................................. 8   6. 


>> Tokens are: 
 ['..................................................................................................................', '8', '6', '.']

>> Bigrams are: 
 [('..................................................................................................................', '8'), ('8', '6'), ('6', '.')]

>> Trigrams are: 
 [('..................................................................................................................', '8', '6'), ('8', '6', '.')]

>> POS Tags are: 
 [('..................................................................................................................', 'RB'), ('8', 'CD'), ('6', 'CD'), ('.', '.')]

 (S
  ................................................................................................................../RB
  8/CD
  6/CD
  ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('..................................................................................................................', '..................................................................................................................'), ('8', '8'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('..................................................................................................................', '..................................................................................................................'), ('8', '8'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('..................................................................................................................', '..................................................................................................................'), ('8', '8'), ('6', '6'), ('.', '.')]



============================ Sentence 14 =============================

Big data characteristics .......................................................................................................... 15   7. 


>> Tokens are: 
 ['Big', 'data', 'characteristics', '..........................................................................................................', '15', '7', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'characteristics'), ('characteristics', '..........................................................................................................'), ('..........................................................................................................', '15'), ('15', '7'), ('7', '.')]

>> Trigrams are: 
 [('Big', 'data', 'characteristics'), ('data', 'characteristics', '..........................................................................................................'), ('characteristics', '..........................................................................................................', '15'), ('..........................................................................................................', '15', '7'), ('15', '7', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('characteristics', 'NNS'), ('..........................................................................................................', 'VBP'), ('15', 'CD'), ('7', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS characteristics/NNS)
  ........................................................................................................../VBP
  15/CD
  7/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data characteristics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('..........................................................................................................', '..........................................................................................................'), ('15', '15'), ('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('..........................................................................................................', '..........................................................................................................'), ('15', '15'), ('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('characteristics', 'characteristic'), ('..........................................................................................................', '..........................................................................................................'), ('15', '15'), ('7', '7'), ('.', '.')]



============================ Sentence 15 =============================

Big data analytics (BDA): tools and methods ....................................................................... 18   7.1. 


>> Tokens are: 
 ['Big', 'data', 'analytics', '(', 'BDA', ')', ':', 'tools', 'methods', '.......................................................................', '18', '7.1', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', '('), ('(', 'BDA'), ('BDA', ')'), (')', ':'), (':', 'tools'), ('tools', 'methods'), ('methods', '.......................................................................'), ('.......................................................................', '18'), ('18', '7.1'), ('7.1', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', '('), ('analytics', '(', 'BDA'), ('(', 'BDA', ')'), ('BDA', ')', ':'), (')', ':', 'tools'), (':', 'tools', 'methods'), ('tools', 'methods', '.......................................................................'), ('methods', '.......................................................................', '18'), ('.......................................................................', '18', '7.1'), ('18', '7.1', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('(', '('), ('BDA', 'NNP'), (')', ')'), (':', ':'), ('tools', 'NNS'), ('methods', 'NNS'), ('.......................................................................', 'VBP'), ('18', 'CD'), ('7.1', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  (/(
  (NP BDA/NNP)
  )/)
  :/:
  (NP tools/NNS methods/NNS)
  ......................................................................./VBP
  18/CD
  7.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'BDA', 'tools methods']

>> Named Entities are: 
 [('ORGANIZATION', 'BDA')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('.......................................................................', '.......................................................................'), ('18', '18'), ('7.1', '7.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('.......................................................................', '.......................................................................'), ('18', '18'), ('7.1', '7.1'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('(', '('), ('BDA', 'BDA'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('.......................................................................', '.......................................................................'), ('18', '18'), ('7.1', '7.1'), ('.', '.')]



============================ Sentence 16 =============================

Big data storage and management .................................................................................. 18   7.2. 


>> Tokens are: 
 ['Big', 'data', 'storage', 'management', '..................................................................................', '18', '7.2', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'storage'), ('storage', 'management'), ('management', '..................................................................................'), ('..................................................................................', '18'), ('18', '7.2'), ('7.2', '.')]

>> Trigrams are: 
 [('Big', 'data', 'storage'), ('data', 'storage', 'management'), ('storage', 'management', '..................................................................................'), ('management', '..................................................................................', '18'), ('..................................................................................', '18', '7.2'), ('18', '7.2', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), ('management', 'NN'), ('..................................................................................', 'VBD'), ('18', 'CD'), ('7.2', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS storage/NN management/NN)
  ................................................................................../VBD
  18/CD
  7.2/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data storage management']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('..................................................................................', '..................................................................................'), ('18', '18'), ('7.2', '7.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('..................................................................................', '..................................................................................'), ('18', '18'), ('7.2', '7.2'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('storage', 'storage'), ('management', 'management'), ('..................................................................................', '..................................................................................'), ('18', '18'), ('7.2', '7.2'), ('.', '.')]



============================ Sentence 17 =============================

Big data analytics processing ......................................................................................... 19   7.3. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'processing', '.........................................................................................', '19', '7.3', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'processing'), ('processing', '.........................................................................................'), ('.........................................................................................', '19'), ('19', '7.3'), ('7.3', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'processing'), ('analytics', 'processing', '.........................................................................................'), ('processing', '.........................................................................................', '19'), ('.........................................................................................', '19', '7.3'), ('19', '7.3', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('processing', 'VBG'), ('.........................................................................................', 'JJ'), ('19', 'CD'), ('7.3', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  processing/VBG
  ........................................................................................./JJ
  19/CD
  7.3/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('.........................................................................................', '.........................................................................................'), ('19', '19'), ('7.3', '7.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('.........................................................................................', '.........................................................................................'), ('19', '19'), ('7.3', '7.3'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('processing', 'processing'), ('.........................................................................................', '.........................................................................................'), ('19', '19'), ('7.3', '7.3'), ('.', '.')]



============================ Sentence 18 =============================

Big data analytics ........................................................................................................... 20   7.1.1. 


>> Tokens are: 
 ['Big', 'data', 'analytics', '...........................................................................................................', '20', '7.1.1', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', '...........................................................................................................'), ('...........................................................................................................', '20'), ('20', '7.1.1'), ('7.1.1', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', '...........................................................................................................'), ('analytics', '...........................................................................................................', '20'), ('...........................................................................................................', '20', '7.1.1'), ('20', '7.1.1', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('...........................................................................................................', 'VBP'), ('20', 'CD'), ('7.1.1', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  .........................................................................................................../VBP
  20/CD
  7.1.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('...........................................................................................................', '...........................................................................................................'), ('20', '20'), ('7.1.1', '7.1.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('...........................................................................................................', '...........................................................................................................'), ('20', '20'), ('7.1.1', '7.1.1'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('...........................................................................................................', '...........................................................................................................'), ('20', '20'), ('7.1.1', '7.1.1'), ('.', '.')]



============================ Sentence 19 =============================

Supervised techniques ............................................................................................. 22   7.1.2. 


>> Tokens are: 
 ['Supervised', 'techniques', '.............................................................................................', '22', '7.1.2', '.']

>> Bigrams are: 
 [('Supervised', 'techniques'), ('techniques', '.............................................................................................'), ('.............................................................................................', '22'), ('22', '7.1.2'), ('7.1.2', '.')]

>> Trigrams are: 
 [('Supervised', 'techniques', '.............................................................................................'), ('techniques', '.............................................................................................', '22'), ('.............................................................................................', '22', '7.1.2'), ('22', '7.1.2', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('techniques', 'NNS'), ('.............................................................................................', 'VBP'), ('22', 'CD'), ('7.1.2', 'CD'), ('.', '.')]

 (S
  Supervised/VBN
  (NP techniques/NNS)
  ............................................................................................./VBP
  22/CD
  7.1.2/CD
  ./.) 


>> Noun Phrases are: 
 ['techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu'), ('.............................................................................................', '.............................................................................................'), ('22', '22'), ('7.1.2', '7.1.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu'), ('.............................................................................................', '.............................................................................................'), ('22', '22'), ('7.1.2', '7.1.2'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('techniques', 'technique'), ('.............................................................................................', '.............................................................................................'), ('22', '22'), ('7.1.2', '7.1.2'), ('.', '.')]



============================ Sentence 20 =============================

Un-supervised techniques ....................................................................................... 24   7.1.3. 


>> Tokens are: 
 ['Un-supervised', 'techniques', '.......................................................................................', '24', '7.1.3', '.']

>> Bigrams are: 
 [('Un-supervised', 'techniques'), ('techniques', '.......................................................................................'), ('.......................................................................................', '24'), ('24', '7.1.3'), ('7.1.3', '.')]

>> Trigrams are: 
 [('Un-supervised', 'techniques', '.......................................................................................'), ('techniques', '.......................................................................................', '24'), ('.......................................................................................', '24', '7.1.3'), ('24', '7.1.3', '.')]

>> POS Tags are: 
 [('Un-supervised', 'JJ'), ('techniques', 'NNS'), ('.......................................................................................', 'VBP'), ('24', 'CD'), ('7.1.3', 'CD'), ('.', '.')]

 (S
  (NP Un-supervised/JJ techniques/NNS)
  ......................................................................................./VBP
  24/CD
  7.1.3/CD
  ./.) 


>> Noun Phrases are: 
 ['Un-supervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu'), ('.......................................................................................', '.......................................................................................'), ('24', '24'), ('7.1.3', '7.1.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu'), ('.......................................................................................', '.......................................................................................'), ('24', '24'), ('7.1.3', '7.1.3'), ('.', '.')]

>> Lemmatization: 
 [('Un-supervised', 'Un-supervised'), ('techniques', 'technique'), ('.......................................................................................', '.......................................................................................'), ('24', '24'), ('7.1.3', '7.1.3'), ('.', '.')]



============================ Sentence 21 =============================

Semi-supervised techniques .................................................................................... 24   7.1.4. 


>> Tokens are: 
 ['Semi-supervised', 'techniques', '....................................................................................', '24', '7.1.4', '.']

>> Bigrams are: 
 [('Semi-supervised', 'techniques'), ('techniques', '....................................................................................'), ('....................................................................................', '24'), ('24', '7.1.4'), ('7.1.4', '.')]

>> Trigrams are: 
 [('Semi-supervised', 'techniques', '....................................................................................'), ('techniques', '....................................................................................', '24'), ('....................................................................................', '24', '7.1.4'), ('24', '7.1.4', '.')]

>> POS Tags are: 
 [('Semi-supervised', 'JJ'), ('techniques', 'NNS'), ('....................................................................................', 'VBP'), ('24', 'CD'), ('7.1.4', 'CD'), ('.', '.')]

 (S
  (NP Semi-supervised/JJ techniques/NNS)
  ..................................................................................../VBP
  24/CD
  7.1.4/CD
  ./.) 


>> Noun Phrases are: 
 ['Semi-supervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu'), ('....................................................................................', '....................................................................................'), ('24', '24'), ('7.1.4', '7.1.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu'), ('....................................................................................', '....................................................................................'), ('24', '24'), ('7.1.4', '7.1.4'), ('.', '.')]

>> Lemmatization: 
 [('Semi-supervised', 'Semi-supervised'), ('techniques', 'technique'), ('....................................................................................', '....................................................................................'), ('24', '24'), ('7.1.4', '7.1.4'), ('.', '.')]



============================ Sentence 22 =============================

Reinforcement learning (RL) .................................................................................. 25   7.4. 


>> Tokens are: 
 ['Reinforcement', 'learning', '(', 'RL', ')', '..................................................................................', '25', '7.4', '.']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', '('), ('(', 'RL'), ('RL', ')'), (')', '..................................................................................'), ('..................................................................................', '25'), ('25', '7.4'), ('7.4', '.')]

>> Trigrams are: 
 [('Reinforcement', 'learning', '('), ('learning', '(', 'RL'), ('(', 'RL', ')'), ('RL', ')', '..................................................................................'), (')', '..................................................................................', '25'), ('..................................................................................', '25', '7.4'), ('25', '7.4', '.')]

>> POS Tags are: 
 [('Reinforcement', 'NN'), ('learning', 'NN'), ('(', '('), ('RL', 'NNP'), (')', ')'), ('..................................................................................', 'VBD'), ('25', 'CD'), ('7.4', 'CD'), ('.', '.')]

 (S
  (NP Reinforcement/NN learning/NN)
  (/(
  (NP RL/NNP)
  )/)
  ................................................................................../VBD
  25/CD
  7.4/CD
  ./.) 


>> Noun Phrases are: 
 ['Reinforcement learning', 'RL']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')'), ('..................................................................................', '..................................................................................'), ('25', '25'), ('7.4', '7.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')'), ('..................................................................................', '..................................................................................'), ('25', '25'), ('7.4', '7.4'), ('.', '.')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('(', '('), ('RL', 'RL'), (')', ')'), ('..................................................................................', '..................................................................................'), ('25', '25'), ('7.4', '7.4'), ('.', '.')]



============================ Sentence 23 =============================

Analytics techniques ...................................................................................................... 26   7.5. 


>> Tokens are: 
 ['Analytics', 'techniques', '......................................................................................................', '26', '7.5', '.']

>> Bigrams are: 
 [('Analytics', 'techniques'), ('techniques', '......................................................................................................'), ('......................................................................................................', '26'), ('26', '7.5'), ('7.5', '.')]

>> Trigrams are: 
 [('Analytics', 'techniques', '......................................................................................................'), ('techniques', '......................................................................................................', '26'), ('......................................................................................................', '26', '7.5'), ('26', '7.5', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('techniques', 'NNS'), ('......................................................................................................', 'VBP'), ('26', 'CD'), ('7.5', 'CD'), ('.', '.')]

 (S
  (NP Analytics/NNS techniques/NNS)
  ....................................................................................................../VBP
  26/CD
  7.5/CD
  ./.) 


>> Noun Phrases are: 
 ['Analytics techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu'), ('......................................................................................................', '......................................................................................................'), ('26', '26'), ('7.5', '7.5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu'), ('......................................................................................................', '......................................................................................................'), ('26', '26'), ('7.5', '7.5'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('techniques', 'technique'), ('......................................................................................................', '......................................................................................................'), ('26', '26'), ('7.5', '7.5'), ('.', '.')]



============================ Sentence 24 =============================

Big data platforms and tools .......................................................................................... 30   8. 


>> Tokens are: 
 ['Big', 'data', 'platforms', 'tools', '..........................................................................................', '30', '8', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', '..........................................................................................'), ('..........................................................................................', '30'), ('30', '8'), ('8', '.')]

>> Trigrams are: 
 [('Big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', '..........................................................................................'), ('tools', '..........................................................................................', '30'), ('..........................................................................................', '30', '8'), ('30', '8', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'NNS'), ('..........................................................................................', 'VBD'), ('30', 'CD'), ('8', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS platforms/NNS tools/NNS)
  ........................................................................................../VBD
  30/CD
  8/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data platforms tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('..........................................................................................', '..........................................................................................'), ('30', '30'), ('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('..........................................................................................', '..........................................................................................'), ('30', '30'), ('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('..........................................................................................', '..........................................................................................'), ('30', '30'), ('8', '8'), ('.', '.')]



============================ Sentence 25 =============================

Big Data Analytics and Decision Making ............................................................................. 34   9. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Decision', 'Making', '.............................................................................', '34', '9', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Decision'), ('Decision', 'Making'), ('Making', '.............................................................................'), ('.............................................................................', '34'), ('34', '9'), ('9', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Decision'), ('Analytics', 'Decision', 'Making'), ('Decision', 'Making', '.............................................................................'), ('Making', '.............................................................................', '34'), ('.............................................................................', '34', '9'), ('34', '9', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('.............................................................................', 'VBD'), ('34', 'CD'), ('9', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP Analytics/NNP Decision/NNP Making/NNP)
  ............................................................................./VBD
  34/CD
  9/CD
  ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics Decision Making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make'), ('.............................................................................', '.............................................................................'), ('34', '34'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make'), ('.............................................................................', '.............................................................................'), ('34', '34'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Decision', 'Decision'), ('Making', 'Making'), ('.............................................................................', '.............................................................................'), ('34', '34'), ('9', '9'), ('.', '.')]



============================ Sentence 26 =============================

Big data analytics challenges ................................................................................................. 37   9.1. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'challenges', '.................................................................................................', '37', '9.1', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', '.................................................................................................'), ('.................................................................................................', '37'), ('37', '9.1'), ('9.1', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', '.................................................................................................'), ('challenges', '.................................................................................................', '37'), ('.................................................................................................', '37', '9.1'), ('37', '9.1', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('.................................................................................................', 'VBP'), ('37', 'CD'), ('9.1', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS challenges/NNS)
  ................................................................................................./VBP
  37/CD
  9.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('.................................................................................................', '.................................................................................................'), ('37', '37'), ('9.1', '9.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('.................................................................................................', '.................................................................................................'), ('37', '37'), ('9.1', '9.1'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('.................................................................................................', '.................................................................................................'), ('37', '37'), ('9.1', '9.1'), ('.', '.')]



============================ Sentence 27 =============================

Data Security issues ....................................................................................................... 37   9.2. 


>> Tokens are: 
 ['Data', 'Security', 'issues', '.......................................................................................................', '37', '9.2', '.']

>> Bigrams are: 
 [('Data', 'Security'), ('Security', 'issues'), ('issues', '.......................................................................................................'), ('.......................................................................................................', '37'), ('37', '9.2'), ('9.2', '.')]

>> Trigrams are: 
 [('Data', 'Security', 'issues'), ('Security', 'issues', '.......................................................................................................'), ('issues', '.......................................................................................................', '37'), ('.......................................................................................................', '37', '9.2'), ('37', '9.2', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Security', 'NNP'), ('issues', 'NNS'), ('.......................................................................................................', 'VBP'), ('37', 'CD'), ('9.2', 'CD'), ('.', '.')]

 (S
  (NP Data/NNP Security/NNP issues/NNS)
  ......................................................................................................./VBP
  37/CD
  9.2/CD
  ./.) 


>> Noun Phrases are: 
 ['Data Security issues']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu'), ('.......................................................................................................', '.......................................................................................................'), ('37', '37'), ('9.2', '9.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu'), ('.......................................................................................................', '.......................................................................................................'), ('37', '37'), ('9.2', '9.2'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Security', 'Security'), ('issues', 'issue'), ('.......................................................................................................', '.......................................................................................................'), ('37', '37'), ('9.2', '9.2'), ('.', '.')]



============================ Sentence 28 =============================

Data privacy issues ......................................................................................................... 39   9.3. 


>> Tokens are: 
 ['Data', 'privacy', 'issues', '.........................................................................................................', '39', '9.3', '.']

>> Bigrams are: 
 [('Data', 'privacy'), ('privacy', 'issues'), ('issues', '.........................................................................................................'), ('.........................................................................................................', '39'), ('39', '9.3'), ('9.3', '.')]

>> Trigrams are: 
 [('Data', 'privacy', 'issues'), ('privacy', 'issues', '.........................................................................................................'), ('issues', '.........................................................................................................', '39'), ('.........................................................................................................', '39', '9.3'), ('39', '9.3', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('privacy', 'NN'), ('issues', 'NNS'), ('.........................................................................................................', 'VBP'), ('39', 'CD'), ('9.3', 'CD'), ('.', '.')]

 (S
  (NP Data/NNP privacy/NN issues/NNS)
  ........................................................................................................./VBP
  39/CD
  9.3/CD
  ./.) 


>> Noun Phrases are: 
 ['Data privacy issues']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu'), ('.........................................................................................................', '.........................................................................................................'), ('39', '39'), ('9.3', '9.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu'), ('.........................................................................................................', '.........................................................................................................'), ('39', '39'), ('9.3', '9.3'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('privacy', 'privacy'), ('issues', 'issue'), ('.........................................................................................................', '.........................................................................................................'), ('39', '39'), ('9.3', '9.3'), ('.', '.')]



============================ Sentence 29 =============================

Data storage, data capture and quality of data ............................................................... 39   9.4. 


>> Tokens are: 
 ['Data', 'storage', ',', 'data', 'capture', 'quality', 'data', '...............................................................', '39', '9.4', '.']

>> Bigrams are: 
 [('Data', 'storage'), ('storage', ','), (',', 'data'), ('data', 'capture'), ('capture', 'quality'), ('quality', 'data'), ('data', '...............................................................'), ('...............................................................', '39'), ('39', '9.4'), ('9.4', '.')]

>> Trigrams are: 
 [('Data', 'storage', ','), ('storage', ',', 'data'), (',', 'data', 'capture'), ('data', 'capture', 'quality'), ('capture', 'quality', 'data'), ('quality', 'data', '...............................................................'), ('data', '...............................................................', '39'), ('...............................................................', '39', '9.4'), ('39', '9.4', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('storage', 'NN'), (',', ','), ('data', 'NNS'), ('capture', 'VBP'), ('quality', 'NN'), ('data', 'NNS'), ('...............................................................', 'VBD'), ('39', 'CD'), ('9.4', 'CD'), ('.', '.')]

 (S
  (NP Data/NNP storage/NN)
  ,/,
  (NP data/NNS)
  capture/VBP
  (NP quality/NN data/NNS)
  .............................................................../VBD
  39/CD
  9.4/CD
  ./.) 


>> Noun Phrases are: 
 ['Data storage', 'data', 'quality data']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data'), ('...............................................................', '...............................................................'), ('39', '39'), ('9.4', '9.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data'), ('...............................................................', '...............................................................'), ('39', '39'), ('9.4', '9.4'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('storage', 'storage'), (',', ','), ('data', 'data'), ('capture', 'capture'), ('quality', 'quality'), ('data', 'data'), ('...............................................................', '...............................................................'), ('39', '39'), ('9.4', '9.4'), ('.', '.')]



============================ Sentence 30 =============================

Challenges in data analysis and visualisation ................................................................ 40   10. 


>> Tokens are: 
 ['Challenges', 'data', 'analysis', 'visualisation', '................................................................', '40', '10', '.']

>> Bigrams are: 
 [('Challenges', 'data'), ('data', 'analysis'), ('analysis', 'visualisation'), ('visualisation', '................................................................'), ('................................................................', '40'), ('40', '10'), ('10', '.')]

>> Trigrams are: 
 [('Challenges', 'data', 'analysis'), ('data', 'analysis', 'visualisation'), ('analysis', 'visualisation', '................................................................'), ('visualisation', '................................................................', '40'), ('................................................................', '40', '10'), ('40', '10', '.')]

>> POS Tags are: 
 [('Challenges', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('visualisation', 'NN'), ('................................................................', 'VBD'), ('40', 'CD'), ('10', 'CD'), ('.', '.')]

 (S
  (NP Challenges/NNS data/NNS analysis/NN visualisation/NN)
  ................................................................/VBD
  40/CD
  10/CD
  ./.) 


>> Noun Phrases are: 
 ['Challenges data analysis visualisation']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis'), ('................................................................', '................................................................'), ('40', '40'), ('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis'), ('................................................................', '................................................................'), ('40', '40'), ('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('Challenges', 'Challenges'), ('data', 'data'), ('analysis', 'analysis'), ('visualisation', 'visualisation'), ('................................................................', '................................................................'), ('40', '40'), ('10', '10'), ('.', '.')]



============================ Sentence 31 =============================

Big data analytics applications........................................................................................... 42   10.1. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'applications', '...........................................................................................', '42', '10.1', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', '...........................................................................................'), ('...........................................................................................', '42'), ('42', '10.1'), ('10.1', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', '...........................................................................................'), ('applications', '...........................................................................................', '42'), ('...........................................................................................', '42', '10.1'), ('42', '10.1', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('...........................................................................................', 'VBP'), ('42', 'CD'), ('10.1', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS applications/NNS)
  .........................................................................................../VBP
  42/CD
  10.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('...........................................................................................', '...........................................................................................'), ('42', '42'), ('10.1', '10.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('...........................................................................................', '...........................................................................................'), ('42', '42'), ('10.1', '10.1'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('...........................................................................................', '...........................................................................................'), ('42', '42'), ('10.1', '10.1'), ('.', '.')]



============================ Sentence 32 =============================

Healthcare ................................................................................................................... 43   10.2. 


>> Tokens are: 
 ['Healthcare', '...................................................................................................................', '43', '10.2', '.']

>> Bigrams are: 
 [('Healthcare', '...................................................................................................................'), ('...................................................................................................................', '43'), ('43', '10.2'), ('10.2', '.')]

>> Trigrams are: 
 [('Healthcare', '...................................................................................................................', '43'), ('...................................................................................................................', '43', '10.2'), ('43', '10.2', '.')]

>> POS Tags are: 
 [('Healthcare', 'NNP'), ('...................................................................................................................', 'VBZ'), ('43', 'CD'), ('10.2', 'CD'), ('.', '.')]

 (S
  (NP Healthcare/NNP)
  .................................................................................................................../VBZ
  43/CD
  10.2/CD
  ./.) 


>> Noun Phrases are: 
 ['Healthcare']

>> Named Entities are: 
 [('GPE', 'Healthcare')] 

>> Stemming using Porter Stemmer: 
 [('Healthcare', 'healthcar'), ('...................................................................................................................', '...................................................................................................................'), ('43', '43'), ('10.2', '10.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Healthcare', 'healthcar'), ('...................................................................................................................', '...................................................................................................................'), ('43', '43'), ('10.2', '10.2'), ('.', '.')]

>> Lemmatization: 
 [('Healthcare', 'Healthcare'), ('...................................................................................................................', '...................................................................................................................'), ('43', '43'), ('10.2', '10.2'), ('.', '.')]



============================ Sentence 33 =============================

Banking ....................................................................................................................... 43   10.3. 


>> Tokens are: 
 ['Banking', '.......................................................................................................................', '43', '10.3', '.']

>> Bigrams are: 
 [('Banking', '.......................................................................................................................'), ('.......................................................................................................................', '43'), ('43', '10.3'), ('10.3', '.')]

>> Trigrams are: 
 [('Banking', '.......................................................................................................................', '43'), ('.......................................................................................................................', '43', '10.3'), ('43', '10.3', '.')]

>> POS Tags are: 
 [('Banking', 'NN'), ('.......................................................................................................................', 'VBZ'), ('43', 'CD'), ('10.3', 'CD'), ('.', '.')]

 (S
  (NP Banking/NN)
  ......................................................................................................................./VBZ
  43/CD
  10.3/CD
  ./.) 


>> Noun Phrases are: 
 ['Banking']

>> Named Entities are: 
 [('GPE', 'Banking')] 

>> Stemming using Porter Stemmer: 
 [('Banking', 'bank'), ('.......................................................................................................................', '.......................................................................................................................'), ('43', '43'), ('10.3', '10.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Banking', 'bank'), ('.......................................................................................................................', '.......................................................................................................................'), ('43', '43'), ('10.3', '10.3'), ('.', '.')]

>> Lemmatization: 
 [('Banking', 'Banking'), ('.......................................................................................................................', '.......................................................................................................................'), ('43', '43'), ('10.3', '10.3'), ('.', '.')]



============================ Sentence 34 =============================

Retail ........................................................................................................................... 44   10.4. 


>> Tokens are: 
 ['Retail', '...........................................................................................................................', '44', '10.4', '.']

>> Bigrams are: 
 [('Retail', '...........................................................................................................................'), ('...........................................................................................................................', '44'), ('44', '10.4'), ('10.4', '.')]

>> Trigrams are: 
 [('Retail', '...........................................................................................................................', '44'), ('...........................................................................................................................', '44', '10.4'), ('44', '10.4', '.')]

>> POS Tags are: 
 [('Retail', 'JJ'), ('...........................................................................................................................', 'NN'), ('44', 'CD'), ('10.4', 'CD'), ('.', '.')]

 (S
  (NP
    Retail/JJ
    .........................................................................................................................../NN)
  44/CD
  10.4/CD
  ./.) 


>> Noun Phrases are: 
 ['Retail ...........................................................................................................................']

>> Named Entities are: 
 [('GPE', 'Retail')] 

>> Stemming using Porter Stemmer: 
 [('Retail', 'retail'), ('...........................................................................................................................', '...........................................................................................................................'), ('44', '44'), ('10.4', '10.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Retail', 'retail'), ('...........................................................................................................................', '...........................................................................................................................'), ('44', '44'), ('10.4', '10.4'), ('.', '.')]

>> Lemmatization: 
 [('Retail', 'Retail'), ('...........................................................................................................................', '...........................................................................................................................'), ('44', '44'), ('10.4', '10.4'), ('.', '.')]



============================ Sentence 35 =============================

Telecommunications ................................................................................................... 45   11. 


>> Tokens are: 
 ['Telecommunications', '...................................................................................................', '45', '11', '.']

>> Bigrams are: 
 [('Telecommunications', '...................................................................................................'), ('...................................................................................................', '45'), ('45', '11'), ('11', '.')]

>> Trigrams are: 
 [('Telecommunications', '...................................................................................................', '45'), ('...................................................................................................', '45', '11'), ('45', '11', '.')]

>> POS Tags are: 
 [('Telecommunications', 'NNS'), ('...................................................................................................', 'VBP'), ('45', 'CD'), ('11', 'CD'), ('.', '.')]

 (S
  (NP Telecommunications/NNS)
  .................................................................................................../VBP
  45/CD
  11/CD
  ./.) 


>> Noun Phrases are: 
 ['Telecommunications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Telecommunications', 'telecommun'), ('...................................................................................................', '...................................................................................................'), ('45', '45'), ('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Telecommunications', 'telecommun'), ('...................................................................................................', '...................................................................................................'), ('45', '45'), ('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('Telecommunications', 'Telecommunications'), ('...................................................................................................', '...................................................................................................'), ('45', '45'), ('11', '11'), ('.', '.')]



============================ Sentence 36 =============================

Implications of research ..................................................................................................... 45   12. 


>> Tokens are: 
 ['Implications', 'research', '.....................................................................................................', '45', '12', '.']

>> Bigrams are: 
 [('Implications', 'research'), ('research', '.....................................................................................................'), ('.....................................................................................................', '45'), ('45', '12'), ('12', '.')]

>> Trigrams are: 
 [('Implications', 'research', '.....................................................................................................'), ('research', '.....................................................................................................', '45'), ('.....................................................................................................', '45', '12'), ('45', '12', '.')]

>> POS Tags are: 
 [('Implications', 'NNS'), ('research', 'NN'), ('.....................................................................................................', 'VBP'), ('45', 'CD'), ('12', 'CD'), ('.', '.')]

 (S
  (NP Implications/NNS research/NN)
  ...................................................................................................../VBP
  45/CD
  12/CD
  ./.) 


>> Noun Phrases are: 
 ['Implications research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Implications', 'implic'), ('research', 'research'), ('.....................................................................................................', '.....................................................................................................'), ('45', '45'), ('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Implications', 'implic'), ('research', 'research'), ('.....................................................................................................', '.....................................................................................................'), ('45', '45'), ('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('Implications', 'Implications'), ('research', 'research'), ('.....................................................................................................', '.....................................................................................................'), ('45', '45'), ('12', '12'), ('.', '.')]



============================ Sentence 37 =============================

Conclusion and Future Research ....................................................................................... 46   13. 


>> Tokens are: 
 ['Conclusion', 'Future', 'Research', '.......................................................................................', '46', '13', '.']

>> Bigrams are: 
 [('Conclusion', 'Future'), ('Future', 'Research'), ('Research', '.......................................................................................'), ('.......................................................................................', '46'), ('46', '13'), ('13', '.')]

>> Trigrams are: 
 [('Conclusion', 'Future', 'Research'), ('Future', 'Research', '.......................................................................................'), ('Research', '.......................................................................................', '46'), ('.......................................................................................', '46', '13'), ('46', '13', '.')]

>> POS Tags are: 
 [('Conclusion', 'NNP'), ('Future', 'NNP'), ('Research', 'NNP'), ('.......................................................................................', 'VBD'), ('46', 'CD'), ('13', 'CD'), ('.', '.')]

 (S
  (NP Conclusion/NNP Future/NNP Research/NNP)
  ......................................................................................./VBD
  46/CD
  13/CD
  ./.) 


>> Noun Phrases are: 
 ['Conclusion Future Research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research'), ('.......................................................................................', '.......................................................................................'), ('46', '46'), ('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research'), ('.......................................................................................', '.......................................................................................'), ('46', '46'), ('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('Conclusion', 'Conclusion'), ('Future', 'Future'), ('Research', 'Research'), ('.......................................................................................', '.......................................................................................'), ('46', '46'), ('13', '13'), ('.', '.')]



============================ Sentence 38 =============================

References .......................................................................................................................... 47     Sarah Al-Shiakhli   1      1. 


>> Tokens are: 
 ['References', '..........................................................................................................................', '47', 'Sarah', 'Al-Shiakhli', '1', '1', '.']

>> Bigrams are: 
 [('References', '..........................................................................................................................'), ('..........................................................................................................................', '47'), ('47', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '1'), ('1', '1'), ('1', '.')]

>> Trigrams are: 
 [('References', '..........................................................................................................................', '47'), ('..........................................................................................................................', '47', 'Sarah'), ('47', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '1'), ('Al-Shiakhli', '1', '1'), ('1', '1', '.')]

>> POS Tags are: 
 [('References', 'NNS'), ('..........................................................................................................................', 'VBP'), ('47', 'CD'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('1', 'CD'), ('1', 'CD'), ('.', '.')]

 (S
  (NP References/NNS)
  ........................................................................................................................../VBP
  47/CD
  (NP Sarah/NNP Al-Shiakhli/NNP)
  1/CD
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['References', 'Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('References', 'refer'), ('..........................................................................................................................', '..........................................................................................................................'), ('47', '47'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('1', '1'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('References', 'refer'), ('..........................................................................................................................', '..........................................................................................................................'), ('47', '47'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('1', '1'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('References', 'References'), ('..........................................................................................................................', '..........................................................................................................................'), ('47', '47'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('1', '1'), ('1', '1'), ('.', '.')]



============================ Sentence 39 =============================

Introduction    Big data refers to datasets which are both large in size and high in variety and velocity of data,   characteristics which make it difficult for them to be handled using traditional techniques and tools   (Constantiou, I.D. 


>> Tokens are: 
 ['Introduction', 'Big', 'data', 'refers', 'datasets', 'large', 'size', 'high', 'variety', 'velocity', 'data', ',', 'characteristics', 'make', 'difficult', 'handled', 'using', 'traditional', 'techniques', 'tools', '(', 'Constantiou', ',', 'I.D', '.']

>> Bigrams are: 
 [('Introduction', 'Big'), ('Big', 'data'), ('data', 'refers'), ('refers', 'datasets'), ('datasets', 'large'), ('large', 'size'), ('size', 'high'), ('high', 'variety'), ('variety', 'velocity'), ('velocity', 'data'), ('data', ','), (',', 'characteristics'), ('characteristics', 'make'), ('make', 'difficult'), ('difficult', 'handled'), ('handled', 'using'), ('using', 'traditional'), ('traditional', 'techniques'), ('techniques', 'tools'), ('tools', '('), ('(', 'Constantiou'), ('Constantiou', ','), (',', 'I.D'), ('I.D', '.')]

>> Trigrams are: 
 [('Introduction', 'Big', 'data'), ('Big', 'data', 'refers'), ('data', 'refers', 'datasets'), ('refers', 'datasets', 'large'), ('datasets', 'large', 'size'), ('large', 'size', 'high'), ('size', 'high', 'variety'), ('high', 'variety', 'velocity'), ('variety', 'velocity', 'data'), ('velocity', 'data', ','), ('data', ',', 'characteristics'), (',', 'characteristics', 'make'), ('characteristics', 'make', 'difficult'), ('make', 'difficult', 'handled'), ('difficult', 'handled', 'using'), ('handled', 'using', 'traditional'), ('using', 'traditional', 'techniques'), ('traditional', 'techniques', 'tools'), ('techniques', 'tools', '('), ('tools', '(', 'Constantiou'), ('(', 'Constantiou', ','), ('Constantiou', ',', 'I.D'), (',', 'I.D', '.')]

>> POS Tags are: 
 [('Introduction', 'NN'), ('Big', 'NNP'), ('data', 'NN'), ('refers', 'NNS'), ('datasets', 'NNS'), ('large', 'JJ'), ('size', 'NN'), ('high', 'JJ'), ('variety', 'NN'), ('velocity', 'NN'), ('data', 'NNS'), (',', ','), ('characteristics', 'NNS'), ('make', 'VBP'), ('difficult', 'JJ'), ('handled', 'VBN'), ('using', 'VBG'), ('traditional', 'JJ'), ('techniques', 'NNS'), ('tools', 'NNS'), ('(', '('), ('Constantiou', 'NNP'), (',', ','), ('I.D', 'NNP'), ('.', '.')]

 (S
  (NP Introduction/NN Big/NNP data/NN refers/NNS datasets/NNS)
  (NP large/JJ size/NN)
  (NP high/JJ variety/NN velocity/NN data/NNS)
  ,/,
  (NP characteristics/NNS)
  make/VBP
  difficult/JJ
  handled/VBN
  using/VBG
  (NP traditional/JJ techniques/NNS tools/NNS)
  (/(
  (NP Constantiou/NNP)
  ,/,
  (NP I.D/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Introduction Big data refers datasets', 'large size', 'high variety velocity data', 'characteristics', 'traditional techniques tools', 'Constantiou', 'I.D']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('Introduction', 'introduct'), ('Big', 'big'), ('data', 'data'), ('refers', 'refer'), ('datasets', 'dataset'), ('large', 'larg'), ('size', 'size'), ('high', 'high'), ('variety', 'varieti'), ('velocity', 'veloc'), ('data', 'data'), (',', ','), ('characteristics', 'characterist'), ('make', 'make'), ('difficult', 'difficult'), ('handled', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('techniques', 'techniqu'), ('tools', 'tool'), ('(', '('), ('Constantiou', 'constanti'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Introduction', 'introduct'), ('Big', 'big'), ('data', 'data'), ('refers', 'refer'), ('datasets', 'dataset'), ('large', 'larg'), ('size', 'size'), ('high', 'high'), ('variety', 'varieti'), ('velocity', 'veloc'), ('data', 'data'), (',', ','), ('characteristics', 'characterist'), ('make', 'make'), ('difficult', 'difficult'), ('handled', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('techniques', 'techniqu'), ('tools', 'tool'), ('(', '('), ('Constantiou', 'constantiou'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Lemmatization: 
 [('Introduction', 'Introduction'), ('Big', 'Big'), ('data', 'data'), ('refers', 'refers'), ('datasets', 'datasets'), ('large', 'large'), ('size', 'size'), ('high', 'high'), ('variety', 'variety'), ('velocity', 'velocity'), ('data', 'data'), (',', ','), ('characteristics', 'characteristic'), ('make', 'make'), ('difficult', 'difficult'), ('handled', 'handled'), ('using', 'using'), ('traditional', 'traditional'), ('techniques', 'technique'), ('tools', 'tool'), ('(', '('), ('Constantiou', 'Constantiou'), (',', ','), ('I.D', 'I.D'), ('.', '.')]



============================ Sentence 40 =============================

and Kallinikos, J., 2015). 


>> Tokens are: 
 ['Kallinikos', ',', 'J.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Kallinikos', ','), (',', 'J.'), ('J.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Kallinikos', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Kallinikos', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S (NP Kallinikos/NNP) ,/, (NP J./NNP) ,/, 2015/CD )/) ./.) 


>> Noun Phrases are: 
 ['Kallinikos', 'J.']

>> Named Entities are: 
 [('GPE', 'Kallinikos')] 

>> Stemming using Porter Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Kallinikos', 'Kallinikos'), (',', ','), ('J.', 'J.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 41 =============================

This has generated a need for research into and   provision of solutions to handle and extract knowledge from such datasets. 


>> Tokens are: 
 ['This', 'generated', 'need', 'research', 'provision', 'solutions', 'handle', 'extract', 'knowledge', 'datasets', '.']

>> Bigrams are: 
 [('This', 'generated'), ('generated', 'need'), ('need', 'research'), ('research', 'provision'), ('provision', 'solutions'), ('solutions', 'handle'), ('handle', 'extract'), ('extract', 'knowledge'), ('knowledge', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('This', 'generated', 'need'), ('generated', 'need', 'research'), ('need', 'research', 'provision'), ('research', 'provision', 'solutions'), ('provision', 'solutions', 'handle'), ('solutions', 'handle', 'extract'), ('handle', 'extract', 'knowledge'), ('extract', 'knowledge', 'datasets'), ('knowledge', 'datasets', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('generated', 'VBD'), ('need', 'MD'), ('research', 'NN'), ('provision', 'NN'), ('solutions', 'NNS'), ('handle', 'VBP'), ('extract', 'JJ'), ('knowledge', 'NN'), ('datasets', 'NNS'), ('.', '.')]

 (S
  This/DT
  generated/VBD
  need/MD
  (NP research/NN provision/NN solutions/NNS)
  handle/VBP
  (NP extract/JJ knowledge/NN datasets/NNS)
  ./.) 


>> Noun Phrases are: 
 ['research provision solutions', 'extract knowledge datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('generated', 'gener'), ('need', 'need'), ('research', 'research'), ('provision', 'provis'), ('solutions', 'solut'), ('handle', 'handl'), ('extract', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('generated', 'generat'), ('need', 'need'), ('research', 'research'), ('provision', 'provis'), ('solutions', 'solut'), ('handle', 'handl'), ('extract', 'extract'), ('knowledge', 'knowledg'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('generated', 'generated'), ('need', 'need'), ('research', 'research'), ('provision', 'provision'), ('solutions', 'solution'), ('handle', 'handle'), ('extract', 'extract'), ('knowledge', 'knowledge'), ('datasets', 'datasets'), ('.', '.')]



============================ Sentence 42 =============================

Due to the large   quantities of data involved, multiple technologies and frameworks have been created in order to   provide additional storage capacity and real-time analysis. 


>> Tokens are: 
 ['Due', 'large', 'quantities', 'data', 'involved', ',', 'multiple', 'technologies', 'frameworks', 'created', 'order', 'provide', 'additional', 'storage', 'capacity', 'real-time', 'analysis', '.']

>> Bigrams are: 
 [('Due', 'large'), ('large', 'quantities'), ('quantities', 'data'), ('data', 'involved'), ('involved', ','), (',', 'multiple'), ('multiple', 'technologies'), ('technologies', 'frameworks'), ('frameworks', 'created'), ('created', 'order'), ('order', 'provide'), ('provide', 'additional'), ('additional', 'storage'), ('storage', 'capacity'), ('capacity', 'real-time'), ('real-time', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Due', 'large', 'quantities'), ('large', 'quantities', 'data'), ('quantities', 'data', 'involved'), ('data', 'involved', ','), ('involved', ',', 'multiple'), (',', 'multiple', 'technologies'), ('multiple', 'technologies', 'frameworks'), ('technologies', 'frameworks', 'created'), ('frameworks', 'created', 'order'), ('created', 'order', 'provide'), ('order', 'provide', 'additional'), ('provide', 'additional', 'storage'), ('additional', 'storage', 'capacity'), ('storage', 'capacity', 'real-time'), ('capacity', 'real-time', 'analysis'), ('real-time', 'analysis', '.')]

>> POS Tags are: 
 [('Due', 'JJ'), ('large', 'JJ'), ('quantities', 'NNS'), ('data', 'NNS'), ('involved', 'VBN'), (',', ','), ('multiple', 'JJ'), ('technologies', 'NNS'), ('frameworks', 'NNS'), ('created', 'VBD'), ('order', 'NN'), ('provide', 'VBP'), ('additional', 'JJ'), ('storage', 'NN'), ('capacity', 'NN'), ('real-time', 'JJ'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP Due/JJ large/JJ quantities/NNS data/NNS)
  involved/VBN
  ,/,
  (NP multiple/JJ technologies/NNS frameworks/NNS)
  created/VBD
  (NP order/NN)
  provide/VBP
  (NP additional/JJ storage/NN capacity/NN)
  (NP real-time/JJ analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['Due large quantities data', 'multiple technologies frameworks', 'order', 'additional storage capacity', 'real-time analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('involved', 'involv'), (',', ','), ('multiple', 'multipl'), ('technologies', 'technolog'), ('frameworks', 'framework'), ('created', 'creat'), ('order', 'order'), ('provide', 'provid'), ('additional', 'addit'), ('storage', 'storag'), ('capacity', 'capac'), ('real-time', 'real-tim'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('involved', 'involv'), (',', ','), ('multiple', 'multipl'), ('technologies', 'technolog'), ('frameworks', 'framework'), ('created', 'creat'), ('order', 'order'), ('provide', 'provid'), ('additional', 'addit'), ('storage', 'storag'), ('capacity', 'capac'), ('real-time', 'real-tim'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Due', 'Due'), ('large', 'large'), ('quantities', 'quantity'), ('data', 'data'), ('involved', 'involved'), (',', ','), ('multiple', 'multiple'), ('technologies', 'technology'), ('frameworks', 'framework'), ('created', 'created'), ('order', 'order'), ('provide', 'provide'), ('additional', 'additional'), ('storage', 'storage'), ('capacity', 'capacity'), ('real-time', 'real-time'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 43 =============================

Many models, programs, software,   hardware, and technologies have thus been designed specifically for extracting knowledge from   big data (Oussous et al., 2018), as the extensive but rapidly changing data from daily transactions,   customer interactions, and social networks has the potential to provide decision makers with   valuable insights (Provost and Fawcett, 2013; Elgendy and Elragal, 2014; Elgendy and Elragal,   2016). 


>> Tokens are: 
 ['Many', 'models', ',', 'programs', ',', 'software', ',', 'hardware', ',', 'technologies', 'thus', 'designed', 'specifically', 'extracting', 'knowledge', 'big', 'data', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', ',', 'extensive', 'rapidly', 'changing', 'data', 'daily', 'transactions', ',', 'customer', 'interactions', ',', 'social', 'networks', 'potential', 'provide', 'decision', 'makers', 'valuable', 'insights', '(', 'Provost', 'Fawcett', ',', '2013', ';', 'Elgendy', 'Elragal', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Many', 'models'), ('models', ','), (',', 'programs'), ('programs', ','), (',', 'software'), ('software', ','), (',', 'hardware'), ('hardware', ','), (',', 'technologies'), ('technologies', 'thus'), ('thus', 'designed'), ('designed', 'specifically'), ('specifically', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'big'), ('big', 'data'), ('data', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', ','), (',', 'extensive'), ('extensive', 'rapidly'), ('rapidly', 'changing'), ('changing', 'data'), ('data', 'daily'), ('daily', 'transactions'), ('transactions', ','), (',', 'customer'), ('customer', 'interactions'), ('interactions', ','), (',', 'social'), ('social', 'networks'), ('networks', 'potential'), ('potential', 'provide'), ('provide', 'decision'), ('decision', 'makers'), ('makers', 'valuable'), ('valuable', 'insights'), ('insights', '('), ('(', 'Provost'), ('Provost', 'Fawcett'), ('Fawcett', ','), (',', '2013'), ('2013', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Many', 'models', ','), ('models', ',', 'programs'), (',', 'programs', ','), ('programs', ',', 'software'), (',', 'software', ','), ('software', ',', 'hardware'), (',', 'hardware', ','), ('hardware', ',', 'technologies'), (',', 'technologies', 'thus'), ('technologies', 'thus', 'designed'), ('thus', 'designed', 'specifically'), ('designed', 'specifically', 'extracting'), ('specifically', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'big'), ('knowledge', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', ','), (')', ',', 'extensive'), (',', 'extensive', 'rapidly'), ('extensive', 'rapidly', 'changing'), ('rapidly', 'changing', 'data'), ('changing', 'data', 'daily'), ('data', 'daily', 'transactions'), ('daily', 'transactions', ','), ('transactions', ',', 'customer'), (',', 'customer', 'interactions'), ('customer', 'interactions', ','), ('interactions', ',', 'social'), (',', 'social', 'networks'), ('social', 'networks', 'potential'), ('networks', 'potential', 'provide'), ('potential', 'provide', 'decision'), ('provide', 'decision', 'makers'), ('decision', 'makers', 'valuable'), ('makers', 'valuable', 'insights'), ('valuable', 'insights', '('), ('insights', '(', 'Provost'), ('(', 'Provost', 'Fawcett'), ('Provost', 'Fawcett', ','), ('Fawcett', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('models', 'NNS'), (',', ','), ('programs', 'NNS'), (',', ','), ('software', 'NN'), (',', ','), ('hardware', 'NN'), (',', ','), ('technologies', 'NNS'), ('thus', 'RB'), ('designed', 'VBN'), ('specifically', 'RB'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Oussous', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), (',', ','), ('extensive', 'JJ'), ('rapidly', 'RB'), ('changing', 'VBG'), ('data', 'NNS'), ('daily', 'JJ'), ('transactions', 'NNS'), (',', ','), ('customer', 'NN'), ('interactions', 'NNS'), (',', ','), ('social', 'JJ'), ('networks', 'NNS'), ('potential', 'JJ'), ('provide', 'JJ'), ('decision', 'NN'), ('makers', 'NNS'), ('valuable', 'JJ'), ('insights', 'NNS'), ('(', '('), ('Provost', 'NNP'), ('Fawcett', 'NNP'), (',', ','), ('2013', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Many/JJ models/NNS)
  ,/,
  (NP programs/NNS)
  ,/,
  (NP software/NN)
  ,/,
  (NP hardware/NN)
  ,/,
  (NP technologies/NNS)
  thus/RB
  designed/VBN
  specifically/RB
  extracting/VBG
  (NP knowledge/NN)
  (NP big/JJ data/NNS)
  (/(
  (NP Oussous/JJ et/NN al./NN)
  ,/,
  2018/CD
  )/)
  ,/,
  extensive/JJ
  rapidly/RB
  changing/VBG
  (NP data/NNS)
  (NP daily/JJ transactions/NNS)
  ,/,
  (NP customer/NN interactions/NNS)
  ,/,
  (NP social/JJ networks/NNS)
  (NP potential/JJ provide/JJ decision/NN makers/NNS)
  (NP valuable/JJ insights/NNS)
  (/(
  (NP Provost/NNP Fawcett/NNP)
  ,/,
  2013/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Many models', 'programs', 'software', 'hardware', 'technologies', 'knowledge', 'big data', 'Oussous et al.', 'data', 'daily transactions', 'customer interactions', 'social networks', 'potential provide decision makers', 'valuable insights', 'Provost Fawcett', 'Elgendy Elragal', 'Elgendy Elragal']

>> Named Entities are: 
 [('ORGANIZATION', 'Oussous'), ('ORGANIZATION', 'Provost Fawcett'), ('PERSON', 'Elgendy Elragal'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('models', 'model'), (',', ','), ('programs', 'program'), (',', ','), ('software', 'softwar'), (',', ','), ('hardware', 'hardwar'), (',', ','), ('technologies', 'technolog'), ('thus', 'thu'), ('designed', 'design'), ('specifically', 'specif'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('extensive', 'extens'), ('rapidly', 'rapidli'), ('changing', 'chang'), ('data', 'data'), ('daily', 'daili'), ('transactions', 'transact'), (',', ','), ('customer', 'custom'), ('interactions', 'interact'), (',', ','), ('social', 'social'), ('networks', 'network'), ('potential', 'potenti'), ('provide', 'provid'), ('decision', 'decis'), ('makers', 'maker'), ('valuable', 'valuabl'), ('insights', 'insight'), ('(', '('), ('Provost', 'provost'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('models', 'model'), (',', ','), ('programs', 'program'), (',', ','), ('software', 'softwar'), (',', ','), ('hardware', 'hardwar'), (',', ','), ('technologies', 'technolog'), ('thus', 'thus'), ('designed', 'design'), ('specifically', 'specif'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('extensive', 'extens'), ('rapidly', 'rapid'), ('changing', 'chang'), ('data', 'data'), ('daily', 'daili'), ('transactions', 'transact'), (',', ','), ('customer', 'custom'), ('interactions', 'interact'), (',', ','), ('social', 'social'), ('networks', 'network'), ('potential', 'potenti'), ('provide', 'provid'), ('decision', 'decis'), ('makers', 'maker'), ('valuable', 'valuabl'), ('insights', 'insight'), ('(', '('), ('Provost', 'provost'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('models', 'model'), (',', ','), ('programs', 'program'), (',', ','), ('software', 'software'), (',', ','), ('hardware', 'hardware'), (',', ','), ('technologies', 'technology'), ('thus', 'thus'), ('designed', 'designed'), ('specifically', 'specifically'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('extensive', 'extensive'), ('rapidly', 'rapidly'), ('changing', 'changing'), ('data', 'data'), ('daily', 'daily'), ('transactions', 'transaction'), (',', ','), ('customer', 'customer'), ('interactions', 'interaction'), (',', ','), ('social', 'social'), ('networks', 'network'), ('potential', 'potential'), ('provide', 'provide'), ('decision', 'decision'), ('makers', 'maker'), ('valuable', 'valuable'), ('insights', 'insight'), ('(', '('), ('Provost', 'Provost'), ('Fawcett', 'Fawcett'), (',', ','), ('2013', '2013'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 44 =============================

Big data analytics have already been extensively researched in academia; however, some industrial   advances and new technologies have mainly been discussed in industry papers thus far (Elgendy   and Elragal, 2014; Elragal and Klischewski, 2017). 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'already', 'extensively', 'researched', 'academia', ';', 'however', ',', 'industrial', 'advances', 'new', 'technologies', 'mainly', 'discussed', 'industry', 'papers', 'thus', 'far', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Elragal', 'Klischewski', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'already'), ('already', 'extensively'), ('extensively', 'researched'), ('researched', 'academia'), ('academia', ';'), (';', 'however'), ('however', ','), (',', 'industrial'), ('industrial', 'advances'), ('advances', 'new'), ('new', 'technologies'), ('technologies', 'mainly'), ('mainly', 'discussed'), ('discussed', 'industry'), ('industry', 'papers'), ('papers', 'thus'), ('thus', 'far'), ('far', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elragal'), ('Elragal', 'Klischewski'), ('Klischewski', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'already'), ('analytics', 'already', 'extensively'), ('already', 'extensively', 'researched'), ('extensively', 'researched', 'academia'), ('researched', 'academia', ';'), ('academia', ';', 'however'), (';', 'however', ','), ('however', ',', 'industrial'), (',', 'industrial', 'advances'), ('industrial', 'advances', 'new'), ('advances', 'new', 'technologies'), ('new', 'technologies', 'mainly'), ('technologies', 'mainly', 'discussed'), ('mainly', 'discussed', 'industry'), ('discussed', 'industry', 'papers'), ('industry', 'papers', 'thus'), ('papers', 'thus', 'far'), ('thus', 'far', '('), ('far', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elragal'), (';', 'Elragal', 'Klischewski'), ('Elragal', 'Klischewski', ','), ('Klischewski', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('already', 'RB'), ('extensively', 'RB'), ('researched', 'JJ'), ('academia', 'NN'), (';', ':'), ('however', 'RB'), (',', ','), ('industrial', 'JJ'), ('advances', 'NNS'), ('new', 'JJ'), ('technologies', 'NNS'), ('mainly', 'RB'), ('discussed', 'VBD'), ('industry', 'NN'), ('papers', 'NNS'), ('thus', 'RB'), ('far', 'RB'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elragal', 'NNP'), ('Klischewski', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  already/RB
  extensively/RB
  (NP researched/JJ academia/NN)
  ;/:
  however/RB
  ,/,
  (NP industrial/JJ advances/NNS)
  (NP new/JJ technologies/NNS)
  mainly/RB
  discussed/VBD
  (NP industry/NN papers/NNS)
  thus/RB
  far/RB
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elragal/NNP Klischewski/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'researched academia', 'industrial advances', 'new technologies', 'industry papers', 'Elgendy Elragal', 'Elragal Klischewski']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Elragal Klischewski')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi'), ('extensively', 'extens'), ('researched', 'research'), ('academia', 'academia'), (';', ';'), ('however', 'howev'), (',', ','), ('industrial', 'industri'), ('advances', 'advanc'), ('new', 'new'), ('technologies', 'technolog'), ('mainly', 'mainli'), ('discussed', 'discuss'), ('industry', 'industri'), ('papers', 'paper'), ('thus', 'thu'), ('far', 'far'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi'), ('extensively', 'extens'), ('researched', 'research'), ('academia', 'academia'), (';', ';'), ('however', 'howev'), (',', ','), ('industrial', 'industri'), ('advances', 'advanc'), ('new', 'new'), ('technologies', 'technolog'), ('mainly', 'main'), ('discussed', 'discuss'), ('industry', 'industri'), ('papers', 'paper'), ('thus', 'thus'), ('far', 'far'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('already', 'already'), ('extensively', 'extensively'), ('researched', 'researched'), ('academia', 'academia'), (';', ';'), ('however', 'however'), (',', ','), ('industrial', 'industrial'), ('advances', 'advance'), ('new', 'new'), ('technologies', 'technology'), ('mainly', 'mainly'), ('discussed', 'discussed'), ('industry', 'industry'), ('papers', 'paper'), ('thus', 'thus'), ('far', 'far'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'Elragal'), ('Klischewski', 'Klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 45 =============================

The link between research in academia and   industry may be best understood when summarised and reviewed critically, and as a literature   review represents the foundation for any further research in information systems, it may be   regarded either as a part of such research or as research itself. 


>> Tokens are: 
 ['The', 'link', 'research', 'academia', 'industry', 'may', 'best', 'understood', 'summarised', 'reviewed', 'critically', ',', 'literature', 'review', 'represents', 'foundation', 'research', 'information', 'systems', ',', 'may', 'regarded', 'either', 'part', 'research', 'research', '.']

>> Bigrams are: 
 [('The', 'link'), ('link', 'research'), ('research', 'academia'), ('academia', 'industry'), ('industry', 'may'), ('may', 'best'), ('best', 'understood'), ('understood', 'summarised'), ('summarised', 'reviewed'), ('reviewed', 'critically'), ('critically', ','), (',', 'literature'), ('literature', 'review'), ('review', 'represents'), ('represents', 'foundation'), ('foundation', 'research'), ('research', 'information'), ('information', 'systems'), ('systems', ','), (',', 'may'), ('may', 'regarded'), ('regarded', 'either'), ('either', 'part'), ('part', 'research'), ('research', 'research'), ('research', '.')]

>> Trigrams are: 
 [('The', 'link', 'research'), ('link', 'research', 'academia'), ('research', 'academia', 'industry'), ('academia', 'industry', 'may'), ('industry', 'may', 'best'), ('may', 'best', 'understood'), ('best', 'understood', 'summarised'), ('understood', 'summarised', 'reviewed'), ('summarised', 'reviewed', 'critically'), ('reviewed', 'critically', ','), ('critically', ',', 'literature'), (',', 'literature', 'review'), ('literature', 'review', 'represents'), ('review', 'represents', 'foundation'), ('represents', 'foundation', 'research'), ('foundation', 'research', 'information'), ('research', 'information', 'systems'), ('information', 'systems', ','), ('systems', ',', 'may'), (',', 'may', 'regarded'), ('may', 'regarded', 'either'), ('regarded', 'either', 'part'), ('either', 'part', 'research'), ('part', 'research', 'research'), ('research', 'research', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('link', 'NN'), ('research', 'NN'), ('academia', 'NN'), ('industry', 'NN'), ('may', 'MD'), ('best', 'VB'), ('understood', 'NN'), ('summarised', 'VBN'), ('reviewed', 'VBN'), ('critically', 'RB'), (',', ','), ('literature', 'NN'), ('review', 'NN'), ('represents', 'VBZ'), ('foundation', 'JJ'), ('research', 'NN'), ('information', 'NN'), ('systems', 'NNS'), (',', ','), ('may', 'MD'), ('regarded', 'VB'), ('either', 'CC'), ('part', 'NN'), ('research', 'NN'), ('research', 'NN'), ('.', '.')]

 (S
  (NP The/DT link/NN research/NN academia/NN industry/NN)
  may/MD
  best/VB
  (NP understood/NN)
  summarised/VBN
  reviewed/VBN
  critically/RB
  ,/,
  (NP literature/NN review/NN)
  represents/VBZ
  (NP foundation/JJ research/NN information/NN systems/NNS)
  ,/,
  may/MD
  regarded/VB
  either/CC
  (NP part/NN research/NN research/NN)
  ./.) 


>> Noun Phrases are: 
 ['The link research academia industry', 'understood', 'literature review', 'foundation research information systems', 'part research research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('link', 'link'), ('research', 'research'), ('academia', 'academia'), ('industry', 'industri'), ('may', 'may'), ('best', 'best'), ('understood', 'understood'), ('summarised', 'summaris'), ('reviewed', 'review'), ('critically', 'critic'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('represents', 'repres'), ('foundation', 'foundat'), ('research', 'research'), ('information', 'inform'), ('systems', 'system'), (',', ','), ('may', 'may'), ('regarded', 'regard'), ('either', 'either'), ('part', 'part'), ('research', 'research'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('link', 'link'), ('research', 'research'), ('academia', 'academia'), ('industry', 'industri'), ('may', 'may'), ('best', 'best'), ('understood', 'understood'), ('summarised', 'summaris'), ('reviewed', 'review'), ('critically', 'critic'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('represents', 'repres'), ('foundation', 'foundat'), ('research', 'research'), ('information', 'inform'), ('systems', 'system'), (',', ','), ('may', 'may'), ('regarded', 'regard'), ('either', 'either'), ('part', 'part'), ('research', 'research'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('link', 'link'), ('research', 'research'), ('academia', 'academia'), ('industry', 'industry'), ('may', 'may'), ('best', 'best'), ('understood', 'understood'), ('summarised', 'summarised'), ('reviewed', 'reviewed'), ('critically', 'critically'), (',', ','), ('literature', 'literature'), ('review', 'review'), ('represents', 'represents'), ('foundation', 'foundation'), ('research', 'research'), ('information', 'information'), ('systems', 'system'), (',', ','), ('may', 'may'), ('regarded', 'regarded'), ('either', 'either'), ('part', 'part'), ('research', 'research'), ('research', 'research'), ('.', '.')]



============================ Sentence 46 =============================

However, this requires more than a   literature summary, as it must show the relationship between different publications and identify   relationships between ideas and practice. 


>> Tokens are: 
 ['However', ',', 'requires', 'literature', 'summary', ',', 'must', 'show', 'relationship', 'different', 'publications', 'identify', 'relationships', 'ideas', 'practice', '.']

>> Bigrams are: 
 [('However', ','), (',', 'requires'), ('requires', 'literature'), ('literature', 'summary'), ('summary', ','), (',', 'must'), ('must', 'show'), ('show', 'relationship'), ('relationship', 'different'), ('different', 'publications'), ('publications', 'identify'), ('identify', 'relationships'), ('relationships', 'ideas'), ('ideas', 'practice'), ('practice', '.')]

>> Trigrams are: 
 [('However', ',', 'requires'), (',', 'requires', 'literature'), ('requires', 'literature', 'summary'), ('literature', 'summary', ','), ('summary', ',', 'must'), (',', 'must', 'show'), ('must', 'show', 'relationship'), ('show', 'relationship', 'different'), ('relationship', 'different', 'publications'), ('different', 'publications', 'identify'), ('publications', 'identify', 'relationships'), ('identify', 'relationships', 'ideas'), ('relationships', 'ideas', 'practice'), ('ideas', 'practice', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('requires', 'VBZ'), ('literature', 'JJ'), ('summary', 'JJ'), (',', ','), ('must', 'MD'), ('show', 'VB'), ('relationship', 'NN'), ('different', 'JJ'), ('publications', 'NNS'), ('identify', 'VBP'), ('relationships', 'NNS'), ('ideas', 'NNS'), ('practice', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  requires/VBZ
  literature/JJ
  summary/JJ
  ,/,
  must/MD
  show/VB
  (NP relationship/NN)
  (NP different/JJ publications/NNS)
  identify/VBP
  (NP relationships/NNS ideas/NNS practice/NN)
  ./.) 


>> Noun Phrases are: 
 ['relationship', 'different publications', 'relationships ideas practice']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('requires', 'requir'), ('literature', 'literatur'), ('summary', 'summari'), (',', ','), ('must', 'must'), ('show', 'show'), ('relationship', 'relationship'), ('different', 'differ'), ('publications', 'public'), ('identify', 'identifi'), ('relationships', 'relationship'), ('ideas', 'idea'), ('practice', 'practic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('requires', 'requir'), ('literature', 'literatur'), ('summary', 'summari'), (',', ','), ('must', 'must'), ('show', 'show'), ('relationship', 'relationship'), ('different', 'differ'), ('publications', 'public'), ('identify', 'identifi'), ('relationships', 'relationship'), ('ideas', 'idea'), ('practice', 'practic'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('requires', 'requires'), ('literature', 'literature'), ('summary', 'summary'), (',', ','), ('must', 'must'), ('show', 'show'), ('relationship', 'relationship'), ('different', 'different'), ('publications', 'publication'), ('identify', 'identify'), ('relationships', 'relationship'), ('ideas', 'idea'), ('practice', 'practice'), ('.', '.')]



============================ Sentence 47 =============================

An effective literature review provides the reader with state-of-the-art reporting on a specific topic   and also identifies any gaps in the current state of knowledge of that topic. 


>> Tokens are: 
 ['An', 'effective', 'literature', 'review', 'provides', 'reader', 'state-of-the-art', 'reporting', 'specific', 'topic', 'also', 'identifies', 'gaps', 'current', 'state', 'knowledge', 'topic', '.']

>> Bigrams are: 
 [('An', 'effective'), ('effective', 'literature'), ('literature', 'review'), ('review', 'provides'), ('provides', 'reader'), ('reader', 'state-of-the-art'), ('state-of-the-art', 'reporting'), ('reporting', 'specific'), ('specific', 'topic'), ('topic', 'also'), ('also', 'identifies'), ('identifies', 'gaps'), ('gaps', 'current'), ('current', 'state'), ('state', 'knowledge'), ('knowledge', 'topic'), ('topic', '.')]

>> Trigrams are: 
 [('An', 'effective', 'literature'), ('effective', 'literature', 'review'), ('literature', 'review', 'provides'), ('review', 'provides', 'reader'), ('provides', 'reader', 'state-of-the-art'), ('reader', 'state-of-the-art', 'reporting'), ('state-of-the-art', 'reporting', 'specific'), ('reporting', 'specific', 'topic'), ('specific', 'topic', 'also'), ('topic', 'also', 'identifies'), ('also', 'identifies', 'gaps'), ('identifies', 'gaps', 'current'), ('gaps', 'current', 'state'), ('current', 'state', 'knowledge'), ('state', 'knowledge', 'topic'), ('knowledge', 'topic', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('effective', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('provides', 'VBZ'), ('reader', 'JJR'), ('state-of-the-art', 'JJ'), ('reporting', 'NN'), ('specific', 'JJ'), ('topic', 'NN'), ('also', 'RB'), ('identifies', 'VBZ'), ('gaps', 'NNS'), ('current', 'JJ'), ('state', 'NN'), ('knowledge', 'NN'), ('topic', 'NN'), ('.', '.')]

 (S
  (NP An/DT effective/JJ literature/NN review/NN)
  provides/VBZ
  reader/JJR
  (NP state-of-the-art/JJ reporting/NN)
  (NP specific/JJ topic/NN)
  also/RB
  identifies/VBZ
  (NP gaps/NNS)
  (NP current/JJ state/NN knowledge/NN topic/NN)
  ./.) 


>> Noun Phrases are: 
 ['An effective literature review', 'state-of-the-art reporting', 'specific topic', 'gaps', 'current state knowledge topic']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('provides', 'provid'), ('reader', 'reader'), ('state-of-the-art', 'state-of-the-art'), ('reporting', 'report'), ('specific', 'specif'), ('topic', 'topic'), ('also', 'also'), ('identifies', 'identifi'), ('gaps', 'gap'), ('current', 'current'), ('state', 'state'), ('knowledge', 'knowledg'), ('topic', 'topic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('provides', 'provid'), ('reader', 'reader'), ('state-of-the-art', 'state-of-the-art'), ('reporting', 'report'), ('specific', 'specif'), ('topic', 'topic'), ('also', 'also'), ('identifies', 'identifi'), ('gaps', 'gap'), ('current', 'current'), ('state', 'state'), ('knowledge', 'knowledg'), ('topic', 'topic'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('effective', 'effective'), ('literature', 'literature'), ('review', 'review'), ('provides', 'provides'), ('reader', 'reader'), ('state-of-the-art', 'state-of-the-art'), ('reporting', 'reporting'), ('specific', 'specific'), ('topic', 'topic'), ('also', 'also'), ('identifies', 'identifies'), ('gaps', 'gap'), ('current', 'current'), ('state', 'state'), ('knowledge', 'knowledge'), ('topic', 'topic'), ('.', '.')]



============================ Sentence 48 =============================

Literature reviews have   played a decisive role in scholarship, particularly where scientists are looking for the new   knowledge created by explaining and combining existing knowledge processes. 


>> Tokens are: 
 ['Literature', 'reviews', 'played', 'decisive', 'role', 'scholarship', ',', 'particularly', 'scientists', 'looking', 'new', 'knowledge', 'created', 'explaining', 'combining', 'existing', 'knowledge', 'processes', '.']

>> Bigrams are: 
 [('Literature', 'reviews'), ('reviews', 'played'), ('played', 'decisive'), ('decisive', 'role'), ('role', 'scholarship'), ('scholarship', ','), (',', 'particularly'), ('particularly', 'scientists'), ('scientists', 'looking'), ('looking', 'new'), ('new', 'knowledge'), ('knowledge', 'created'), ('created', 'explaining'), ('explaining', 'combining'), ('combining', 'existing'), ('existing', 'knowledge'), ('knowledge', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('Literature', 'reviews', 'played'), ('reviews', 'played', 'decisive'), ('played', 'decisive', 'role'), ('decisive', 'role', 'scholarship'), ('role', 'scholarship', ','), ('scholarship', ',', 'particularly'), (',', 'particularly', 'scientists'), ('particularly', 'scientists', 'looking'), ('scientists', 'looking', 'new'), ('looking', 'new', 'knowledge'), ('new', 'knowledge', 'created'), ('knowledge', 'created', 'explaining'), ('created', 'explaining', 'combining'), ('explaining', 'combining', 'existing'), ('combining', 'existing', 'knowledge'), ('existing', 'knowledge', 'processes'), ('knowledge', 'processes', '.')]

>> POS Tags are: 
 [('Literature', 'NNP'), ('reviews', 'VBZ'), ('played', 'VBN'), ('decisive', 'JJ'), ('role', 'NN'), ('scholarship', 'NN'), (',', ','), ('particularly', 'RB'), ('scientists', 'NNS'), ('looking', 'VBG'), ('new', 'JJ'), ('knowledge', 'NN'), ('created', 'VBD'), ('explaining', 'VBG'), ('combining', 'VBG'), ('existing', 'VBG'), ('knowledge', 'NN'), ('processes', 'NNS'), ('.', '.')]

 (S
  (NP Literature/NNP)
  reviews/VBZ
  played/VBN
  (NP decisive/JJ role/NN scholarship/NN)
  ,/,
  particularly/RB
  (NP scientists/NNS)
  looking/VBG
  (NP new/JJ knowledge/NN)
  created/VBD
  explaining/VBG
  combining/VBG
  existing/VBG
  (NP knowledge/NN processes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Literature', 'decisive role scholarship', 'scientists', 'new knowledge', 'knowledge processes']

>> Named Entities are: 
 [('GPE', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Literature', 'literatur'), ('reviews', 'review'), ('played', 'play'), ('decisive', 'decis'), ('role', 'role'), ('scholarship', 'scholarship'), (',', ','), ('particularly', 'particularli'), ('scientists', 'scientist'), ('looking', 'look'), ('new', 'new'), ('knowledge', 'knowledg'), ('created', 'creat'), ('explaining', 'explain'), ('combining', 'combin'), ('existing', 'exist'), ('knowledge', 'knowledg'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Literature', 'literatur'), ('reviews', 'review'), ('played', 'play'), ('decisive', 'decis'), ('role', 'role'), ('scholarship', 'scholarship'), (',', ','), ('particularly', 'particular'), ('scientists', 'scientist'), ('looking', 'look'), ('new', 'new'), ('knowledge', 'knowledg'), ('created', 'creat'), ('explaining', 'explain'), ('combining', 'combin'), ('existing', 'exist'), ('knowledge', 'knowledg'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Literature', 'Literature'), ('reviews', 'review'), ('played', 'played'), ('decisive', 'decisive'), ('role', 'role'), ('scholarship', 'scholarship'), (',', ','), ('particularly', 'particularly'), ('scientists', 'scientist'), ('looking', 'looking'), ('new', 'new'), ('knowledge', 'knowledge'), ('created', 'created'), ('explaining', 'explaining'), ('combining', 'combining'), ('existing', 'existing'), ('knowledge', 'knowledge'), ('processes', 'process'), ('.', '.')]



============================ Sentence 49 =============================

The literature   search process used determines the quality of a literature review (Webster and Watson, 2002), and   the literature review writing goal is to reconstruct available knowledge in a specific domain,   offering access to subsequent literature analysis. 


>> Tokens are: 
 ['The', 'literature', 'search', 'process', 'used', 'determines', 'quality', 'literature', 'review', '(', 'Webster', 'Watson', ',', '2002', ')', ',', 'literature', 'review', 'writing', 'goal', 'reconstruct', 'available', 'knowledge', 'specific', 'domain', ',', 'offering', 'access', 'subsequent', 'literature', 'analysis', '.']

>> Bigrams are: 
 [('The', 'literature'), ('literature', 'search'), ('search', 'process'), ('process', 'used'), ('used', 'determines'), ('determines', 'quality'), ('quality', 'literature'), ('literature', 'review'), ('review', '('), ('(', 'Webster'), ('Webster', 'Watson'), ('Watson', ','), (',', '2002'), ('2002', ')'), (')', ','), (',', 'literature'), ('literature', 'review'), ('review', 'writing'), ('writing', 'goal'), ('goal', 'reconstruct'), ('reconstruct', 'available'), ('available', 'knowledge'), ('knowledge', 'specific'), ('specific', 'domain'), ('domain', ','), (',', 'offering'), ('offering', 'access'), ('access', 'subsequent'), ('subsequent', 'literature'), ('literature', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('The', 'literature', 'search'), ('literature', 'search', 'process'), ('search', 'process', 'used'), ('process', 'used', 'determines'), ('used', 'determines', 'quality'), ('determines', 'quality', 'literature'), ('quality', 'literature', 'review'), ('literature', 'review', '('), ('review', '(', 'Webster'), ('(', 'Webster', 'Watson'), ('Webster', 'Watson', ','), ('Watson', ',', '2002'), (',', '2002', ')'), ('2002', ')', ','), (')', ',', 'literature'), (',', 'literature', 'review'), ('literature', 'review', 'writing'), ('review', 'writing', 'goal'), ('writing', 'goal', 'reconstruct'), ('goal', 'reconstruct', 'available'), ('reconstruct', 'available', 'knowledge'), ('available', 'knowledge', 'specific'), ('knowledge', 'specific', 'domain'), ('specific', 'domain', ','), ('domain', ',', 'offering'), (',', 'offering', 'access'), ('offering', 'access', 'subsequent'), ('access', 'subsequent', 'literature'), ('subsequent', 'literature', 'analysis'), ('literature', 'analysis', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('literature', 'NN'), ('search', 'NN'), ('process', 'NN'), ('used', 'VBN'), ('determines', 'NNS'), ('quality', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('(', '('), ('Webster', 'NNP'), ('Watson', 'NNP'), (',', ','), ('2002', 'CD'), (')', ')'), (',', ','), ('literature', 'JJ'), ('review', 'NN'), ('writing', 'VBG'), ('goal', 'NN'), ('reconstruct', 'NN'), ('available', 'JJ'), ('knowledge', 'NN'), ('specific', 'JJ'), ('domain', 'NN'), (',', ','), ('offering', 'VBG'), ('access', 'NN'), ('subsequent', 'JJ'), ('literature', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP The/DT literature/NN search/NN process/NN)
  used/VBN
  (NP determines/NNS)
  (NP quality/JJ literature/NN review/NN)
  (/(
  (NP Webster/NNP Watson/NNP)
  ,/,
  2002/CD
  )/)
  ,/,
  (NP literature/JJ review/NN)
  writing/VBG
  (NP goal/NN reconstruct/NN)
  (NP available/JJ knowledge/NN)
  (NP specific/JJ domain/NN)
  ,/,
  offering/VBG
  (NP access/NN)
  (NP subsequent/JJ literature/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['The literature search process', 'determines', 'quality literature review', 'Webster Watson', 'literature review', 'goal reconstruct', 'available knowledge', 'specific domain', 'access', 'subsequent literature analysis']

>> Named Entities are: 
 [('PERSON', 'Webster Watson')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('used', 'use'), ('determines', 'determin'), ('quality', 'qualiti'), ('literature', 'literatur'), ('review', 'review'), ('(', '('), ('Webster', 'webster'), ('Watson', 'watson'), (',', ','), ('2002', '2002'), (')', ')'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('writing', 'write'), ('goal', 'goal'), ('reconstruct', 'reconstruct'), ('available', 'avail'), ('knowledge', 'knowledg'), ('specific', 'specif'), ('domain', 'domain'), (',', ','), ('offering', 'offer'), ('access', 'access'), ('subsequent', 'subsequ'), ('literature', 'literatur'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('used', 'use'), ('determines', 'determin'), ('quality', 'qualiti'), ('literature', 'literatur'), ('review', 'review'), ('(', '('), ('Webster', 'webster'), ('Watson', 'watson'), (',', ','), ('2002', '2002'), (')', ')'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('writing', 'write'), ('goal', 'goal'), ('reconstruct', 'reconstruct'), ('available', 'avail'), ('knowledge', 'knowledg'), ('specific', 'specif'), ('domain', 'domain'), (',', ','), ('offering', 'offer'), ('access', 'access'), ('subsequent', 'subsequ'), ('literature', 'literatur'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('literature', 'literature'), ('search', 'search'), ('process', 'process'), ('used', 'used'), ('determines', 'determines'), ('quality', 'quality'), ('literature', 'literature'), ('review', 'review'), ('(', '('), ('Webster', 'Webster'), ('Watson', 'Watson'), (',', ','), ('2002', '2002'), (')', ')'), (',', ','), ('literature', 'literature'), ('review', 'review'), ('writing', 'writing'), ('goal', 'goal'), ('reconstruct', 'reconstruct'), ('available', 'available'), ('knowledge', 'knowledge'), ('specific', 'specific'), ('domain', 'domain'), (',', ','), ('offering', 'offering'), ('access', 'access'), ('subsequent', 'subsequent'), ('literature', 'literature'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 50 =============================

The process should thus be described   comprehensively, allowing the reader can assess the knowledge available within the relevant field   in order to use the results in further research (Vom Brocke, J. et al., 2009). 


>> Tokens are: 
 ['The', 'process', 'thus', 'described', 'comprehensively', ',', 'allowing', 'reader', 'assess', 'knowledge', 'available', 'within', 'relevant', 'field', 'order', 'use', 'results', 'research', '(', 'Vom', 'Brocke', ',', 'J.', 'et', 'al.', ',', '2009', ')', '.']

>> Bigrams are: 
 [('The', 'process'), ('process', 'thus'), ('thus', 'described'), ('described', 'comprehensively'), ('comprehensively', ','), (',', 'allowing'), ('allowing', 'reader'), ('reader', 'assess'), ('assess', 'knowledge'), ('knowledge', 'available'), ('available', 'within'), ('within', 'relevant'), ('relevant', 'field'), ('field', 'order'), ('order', 'use'), ('use', 'results'), ('results', 'research'), ('research', '('), ('(', 'Vom'), ('Vom', 'Brocke'), ('Brocke', ','), (',', 'J.'), ('J.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'process', 'thus'), ('process', 'thus', 'described'), ('thus', 'described', 'comprehensively'), ('described', 'comprehensively', ','), ('comprehensively', ',', 'allowing'), (',', 'allowing', 'reader'), ('allowing', 'reader', 'assess'), ('reader', 'assess', 'knowledge'), ('assess', 'knowledge', 'available'), ('knowledge', 'available', 'within'), ('available', 'within', 'relevant'), ('within', 'relevant', 'field'), ('relevant', 'field', 'order'), ('field', 'order', 'use'), ('order', 'use', 'results'), ('use', 'results', 'research'), ('results', 'research', '('), ('research', '(', 'Vom'), ('(', 'Vom', 'Brocke'), ('Vom', 'Brocke', ','), ('Brocke', ',', 'J.'), (',', 'J.', 'et'), ('J.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2009'), (',', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('thus', 'RB'), ('described', 'VBN'), ('comprehensively', 'RB'), (',', ','), ('allowing', 'VBG'), ('reader', 'JJR'), ('assess', 'NN'), ('knowledge', 'NN'), ('available', 'JJ'), ('within', 'IN'), ('relevant', 'JJ'), ('field', 'NN'), ('order', 'NN'), ('use', 'NN'), ('results', 'NNS'), ('research', 'NN'), ('(', '('), ('Vom', 'NNP'), ('Brocke', 'NNP'), (',', ','), ('J.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2009', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT process/NN)
  thus/RB
  described/VBN
  comprehensively/RB
  ,/,
  allowing/VBG
  reader/JJR
  (NP assess/NN knowledge/NN)
  available/JJ
  within/IN
  (NP relevant/JJ field/NN order/NN use/NN results/NNS research/NN)
  (/(
  (NP Vom/NNP Brocke/NNP)
  ,/,
  (NP J./NNP)
  et/FW
  (NP al./NN)
  ,/,
  2009/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The process', 'assess knowledge', 'relevant field order use results research', 'Vom Brocke', 'J.', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('thus', 'thu'), ('described', 'describ'), ('comprehensively', 'comprehens'), (',', ','), ('allowing', 'allow'), ('reader', 'reader'), ('assess', 'assess'), ('knowledge', 'knowledg'), ('available', 'avail'), ('within', 'within'), ('relevant', 'relev'), ('field', 'field'), ('order', 'order'), ('use', 'use'), ('results', 'result'), ('research', 'research'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('thus', 'thus'), ('described', 'describ'), ('comprehensively', 'comprehens'), (',', ','), ('allowing', 'allow'), ('reader', 'reader'), ('assess', 'assess'), ('knowledge', 'knowledg'), ('available', 'avail'), ('within', 'within'), ('relevant', 'relev'), ('field', 'field'), ('order', 'order'), ('use', 'use'), ('results', 'result'), ('research', 'research'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('thus', 'thus'), ('described', 'described'), ('comprehensively', 'comprehensively'), (',', ','), ('allowing', 'allowing'), ('reader', 'reader'), ('assess', 'ass'), ('knowledge', 'knowledge'), ('available', 'available'), ('within', 'within'), ('relevant', 'relevant'), ('field', 'field'), ('order', 'order'), ('use', 'use'), ('results', 'result'), ('research', 'research'), ('(', '('), ('Vom', 'Vom'), ('Brocke', 'Brocke'), (',', ','), ('J.', 'J.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('.', '.')]



============================ Sentence 51 =============================

This thesis aims to present a literature review of work on big data analytics, a pertinent   contemporary topic which has been of importance since 2010 as one of the top technologies   suggested to solve multiple academic, industrial, and societal problems. 


>> Tokens are: 
 ['This', 'thesis', 'aims', 'present', 'literature', 'review', 'work', 'big', 'data', 'analytics', ',', 'pertinent', 'contemporary', 'topic', 'importance', 'since', '2010', 'one', 'top', 'technologies', 'suggested', 'solve', 'multiple', 'academic', ',', 'industrial', ',', 'societal', 'problems', '.']

>> Bigrams are: 
 [('This', 'thesis'), ('thesis', 'aims'), ('aims', 'present'), ('present', 'literature'), ('literature', 'review'), ('review', 'work'), ('work', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'pertinent'), ('pertinent', 'contemporary'), ('contemporary', 'topic'), ('topic', 'importance'), ('importance', 'since'), ('since', '2010'), ('2010', 'one'), ('one', 'top'), ('top', 'technologies'), ('technologies', 'suggested'), ('suggested', 'solve'), ('solve', 'multiple'), ('multiple', 'academic'), ('academic', ','), (',', 'industrial'), ('industrial', ','), (',', 'societal'), ('societal', 'problems'), ('problems', '.')]

>> Trigrams are: 
 [('This', 'thesis', 'aims'), ('thesis', 'aims', 'present'), ('aims', 'present', 'literature'), ('present', 'literature', 'review'), ('literature', 'review', 'work'), ('review', 'work', 'big'), ('work', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'pertinent'), (',', 'pertinent', 'contemporary'), ('pertinent', 'contemporary', 'topic'), ('contemporary', 'topic', 'importance'), ('topic', 'importance', 'since'), ('importance', 'since', '2010'), ('since', '2010', 'one'), ('2010', 'one', 'top'), ('one', 'top', 'technologies'), ('top', 'technologies', 'suggested'), ('technologies', 'suggested', 'solve'), ('suggested', 'solve', 'multiple'), ('solve', 'multiple', 'academic'), ('multiple', 'academic', ','), ('academic', ',', 'industrial'), (',', 'industrial', ','), ('industrial', ',', 'societal'), (',', 'societal', 'problems'), ('societal', 'problems', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('thesis', 'NN'), ('aims', 'VBZ'), ('present', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('work', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('pertinent', 'JJ'), ('contemporary', 'JJ'), ('topic', 'NN'), ('importance', 'NN'), ('since', 'IN'), ('2010', 'CD'), ('one', 'CD'), ('top', 'NN'), ('technologies', 'NNS'), ('suggested', 'VBD'), ('solve', 'JJ'), ('multiple', 'JJ'), ('academic', 'JJ'), (',', ','), ('industrial', 'JJ'), (',', ','), ('societal', 'JJ'), ('problems', 'NNS'), ('.', '.')]

 (S
  (NP This/DT thesis/NN)
  aims/VBZ
  (NP present/JJ literature/NN review/NN work/NN)
  (NP big/JJ data/NNS analytics/NNS)
  ,/,
  (NP pertinent/JJ contemporary/JJ topic/NN importance/NN)
  since/IN
  2010/CD
  one/CD
  (NP top/NN technologies/NNS)
  suggested/VBD
  solve/JJ
  multiple/JJ
  academic/JJ
  ,/,
  industrial/JJ
  ,/,
  (NP societal/JJ problems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This thesis', 'present literature review work', 'big data analytics', 'pertinent contemporary topic importance', 'top technologies', 'societal problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thesis', 'thesi'), ('aims', 'aim'), ('present', 'present'), ('literature', 'literatur'), ('review', 'review'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('pertinent', 'pertin'), ('contemporary', 'contemporari'), ('topic', 'topic'), ('importance', 'import'), ('since', 'sinc'), ('2010', '2010'), ('one', 'one'), ('top', 'top'), ('technologies', 'technolog'), ('suggested', 'suggest'), ('solve', 'solv'), ('multiple', 'multipl'), ('academic', 'academ'), (',', ','), ('industrial', 'industri'), (',', ','), ('societal', 'societ'), ('problems', 'problem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thesis', 'thesi'), ('aims', 'aim'), ('present', 'present'), ('literature', 'literatur'), ('review', 'review'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('pertinent', 'pertin'), ('contemporary', 'contemporari'), ('topic', 'topic'), ('importance', 'import'), ('since', 'sinc'), ('2010', '2010'), ('one', 'one'), ('top', 'top'), ('technologies', 'technolog'), ('suggested', 'suggest'), ('solve', 'solv'), ('multiple', 'multipl'), ('academic', 'academ'), (',', ','), ('industrial', 'industri'), (',', ','), ('societal', 'societ'), ('problems', 'problem'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('thesis', 'thesis'), ('aims', 'aim'), ('present', 'present'), ('literature', 'literature'), ('review', 'review'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('pertinent', 'pertinent'), ('contemporary', 'contemporary'), ('topic', 'topic'), ('importance', 'importance'), ('since', 'since'), ('2010', '2010'), ('one', 'one'), ('top', 'top'), ('technologies', 'technology'), ('suggested', 'suggested'), ('solve', 'solve'), ('multiple', 'multiple'), ('academic', 'academic'), (',', ','), ('industrial', 'industrial'), (',', ','), ('societal', 'societal'), ('problems', 'problem'), ('.', '.')]



============================ Sentence 52 =============================

In addition, this work   explains and analyses different analytic methods and tools that have been applied to big data. 


>> Tokens are: 
 ['In', 'addition', ',', 'work', 'explains', 'analyses', 'different', 'analytic', 'methods', 'tools', 'applied', 'big', 'data', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'work'), ('work', 'explains'), ('explains', 'analyses'), ('analyses', 'different'), ('different', 'analytic'), ('analytic', 'methods'), ('methods', 'tools'), ('tools', 'applied'), ('applied', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'work'), (',', 'work', 'explains'), ('work', 'explains', 'analyses'), ('explains', 'analyses', 'different'), ('analyses', 'different', 'analytic'), ('different', 'analytic', 'methods'), ('analytic', 'methods', 'tools'), ('methods', 'tools', 'applied'), ('tools', 'applied', 'big'), ('applied', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('work', 'NN'), ('explains', 'NNS'), ('analyses', 'VBZ'), ('different', 'JJ'), ('analytic', 'JJ'), ('methods', 'NNS'), ('tools', 'NNS'), ('applied', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP addition/NN)
  ,/,
  (NP work/NN explains/NNS)
  analyses/VBZ
  (NP different/JJ analytic/JJ methods/NNS tools/NNS)
  applied/VBD
  (NP big/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['addition', 'work explains', 'different analytic methods tools', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('work', 'work'), ('explains', 'explain'), ('analyses', 'analys'), ('different', 'differ'), ('analytic', 'analyt'), ('methods', 'method'), ('tools', 'tool'), ('applied', 'appli'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('work', 'work'), ('explains', 'explain'), ('analyses', 'analys'), ('different', 'differ'), ('analytic', 'analyt'), ('methods', 'method'), ('tools', 'tool'), ('applied', 'appli'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('work', 'work'), ('explains', 'explains'), ('analyses', 'analysis'), ('different', 'different'), ('analytic', 'analytic'), ('methods', 'method'), ('tools', 'tool'), ('applied', 'applied'), ('big', 'big'), ('data', 'data'), ('.', '.')]



============================ Sentence 53 =============================

Recently, the focus has been on big data in the research and industrial domains, which has been   reflected in the sheer number of papers, conferences, and white papers discussing big data analytic   tools, methods, and applications that have been published. 


>> Tokens are: 
 ['Recently', ',', 'focus', 'big', 'data', 'research', 'industrial', 'domains', ',', 'reflected', 'sheer', 'number', 'papers', ',', 'conferences', ',', 'white', 'papers', 'discussing', 'big', 'data', 'analytic', 'tools', ',', 'methods', ',', 'applications', 'published', '.']

>> Bigrams are: 
 [('Recently', ','), (',', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'research'), ('research', 'industrial'), ('industrial', 'domains'), ('domains', ','), (',', 'reflected'), ('reflected', 'sheer'), ('sheer', 'number'), ('number', 'papers'), ('papers', ','), (',', 'conferences'), ('conferences', ','), (',', 'white'), ('white', 'papers'), ('papers', 'discussing'), ('discussing', 'big'), ('big', 'data'), ('data', 'analytic'), ('analytic', 'tools'), ('tools', ','), (',', 'methods'), ('methods', ','), (',', 'applications'), ('applications', 'published'), ('published', '.')]

>> Trigrams are: 
 [('Recently', ',', 'focus'), (',', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'research'), ('data', 'research', 'industrial'), ('research', 'industrial', 'domains'), ('industrial', 'domains', ','), ('domains', ',', 'reflected'), (',', 'reflected', 'sheer'), ('reflected', 'sheer', 'number'), ('sheer', 'number', 'papers'), ('number', 'papers', ','), ('papers', ',', 'conferences'), (',', 'conferences', ','), ('conferences', ',', 'white'), (',', 'white', 'papers'), ('white', 'papers', 'discussing'), ('papers', 'discussing', 'big'), ('discussing', 'big', 'data'), ('big', 'data', 'analytic'), ('data', 'analytic', 'tools'), ('analytic', 'tools', ','), ('tools', ',', 'methods'), (',', 'methods', ','), ('methods', ',', 'applications'), (',', 'applications', 'published'), ('applications', 'published', '.')]

>> POS Tags are: 
 [('Recently', 'RB'), (',', ','), ('focus', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('research', 'NN'), ('industrial', 'JJ'), ('domains', 'NNS'), (',', ','), ('reflected', 'VBD'), ('sheer', 'NN'), ('number', 'NN'), ('papers', 'NNS'), (',', ','), ('conferences', 'NNS'), (',', ','), ('white', 'JJ'), ('papers', 'NNS'), ('discussing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytic', 'JJ'), ('tools', 'NNS'), (',', ','), ('methods', 'NNS'), (',', ','), ('applications', 'NNS'), ('published', 'VBD'), ('.', '.')]

 (S
  Recently/RB
  ,/,
  (NP focus/NN)
  (NP big/JJ data/NNS research/NN)
  (NP industrial/JJ domains/NNS)
  ,/,
  reflected/VBD
  (NP sheer/NN number/NN papers/NNS)
  ,/,
  (NP conferences/NNS)
  ,/,
  (NP white/JJ papers/NNS)
  discussing/VBG
  (NP big/JJ data/NNS)
  (NP analytic/JJ tools/NNS)
  ,/,
  (NP methods/NNS)
  ,/,
  (NP applications/NNS)
  published/VBD
  ./.) 


>> Noun Phrases are: 
 ['focus', 'big data research', 'industrial domains', 'sheer number papers', 'conferences', 'white papers', 'big data', 'analytic tools', 'methods', 'applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Recently', 'recent'), (',', ','), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('industrial', 'industri'), ('domains', 'domain'), (',', ','), ('reflected', 'reflect'), ('sheer', 'sheer'), ('number', 'number'), ('papers', 'paper'), (',', ','), ('conferences', 'confer'), (',', ','), ('white', 'white'), ('papers', 'paper'), ('discussing', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('applications', 'applic'), ('published', 'publish'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recently', 'recent'), (',', ','), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('industrial', 'industri'), ('domains', 'domain'), (',', ','), ('reflected', 'reflect'), ('sheer', 'sheer'), ('number', 'number'), ('papers', 'paper'), (',', ','), ('conferences', 'confer'), (',', ','), ('white', 'white'), ('papers', 'paper'), ('discussing', 'discuss'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('applications', 'applic'), ('published', 'publish'), ('.', '.')]

>> Lemmatization: 
 [('Recently', 'Recently'), (',', ','), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('industrial', 'industrial'), ('domains', 'domain'), (',', ','), ('reflected', 'reflected'), ('sheer', 'sheer'), ('number', 'number'), ('papers', 'paper'), (',', ','), ('conferences', 'conference'), (',', ','), ('white', 'white'), ('papers', 'paper'), ('discussing', 'discussing'), ('big', 'big'), ('data', 'data'), ('analytic', 'analytic'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('applications', 'application'), ('published', 'published'), ('.', '.')]



============================ Sentence 54 =============================

In writing this literature review, the   same procedure was followed as in most commonly used literature reviews in information systems,   such as Vom Brocke et al. 


>> Tokens are: 
 ['In', 'writing', 'literature', 'review', ',', 'procedure', 'followed', 'commonly', 'used', 'literature', 'reviews', 'information', 'systems', ',', 'Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('In', 'writing'), ('writing', 'literature'), ('literature', 'review'), ('review', ','), (',', 'procedure'), ('procedure', 'followed'), ('followed', 'commonly'), ('commonly', 'used'), ('used', 'literature'), ('literature', 'reviews'), ('reviews', 'information'), ('information', 'systems'), ('systems', ','), (',', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('In', 'writing', 'literature'), ('writing', 'literature', 'review'), ('literature', 'review', ','), ('review', ',', 'procedure'), (',', 'procedure', 'followed'), ('procedure', 'followed', 'commonly'), ('followed', 'commonly', 'used'), ('commonly', 'used', 'literature'), ('used', 'literature', 'reviews'), ('literature', 'reviews', 'information'), ('reviews', 'information', 'systems'), ('information', 'systems', ','), ('systems', ',', 'Vom'), (',', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('writing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), (',', ','), ('procedure', 'NN'), ('followed', 'VBD'), ('commonly', 'RB'), ('used', 'VBN'), ('literature', 'NN'), ('reviews', 'VBZ'), ('information', 'NN'), ('systems', 'NNS'), (',', ','), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  In/IN
  writing/VBG
  (NP literature/NN review/NN)
  ,/,
  (NP procedure/NN)
  followed/VBD
  commonly/RB
  used/VBN
  (NP literature/NN)
  reviews/VBZ
  (NP information/NN systems/NNS)
  ,/,
  (NP Vom/NNP Brocke/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['literature review', 'procedure', 'literature', 'information systems', 'Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('writing', 'write'), ('literature', 'literatur'), ('review', 'review'), (',', ','), ('procedure', 'procedur'), ('followed', 'follow'), ('commonly', 'commonli'), ('used', 'use'), ('literature', 'literatur'), ('reviews', 'review'), ('information', 'inform'), ('systems', 'system'), (',', ','), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('writing', 'write'), ('literature', 'literatur'), ('review', 'review'), (',', ','), ('procedure', 'procedur'), ('followed', 'follow'), ('commonly', 'common'), ('used', 'use'), ('literature', 'literatur'), ('reviews', 'review'), ('information', 'inform'), ('systems', 'system'), (',', ','), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('writing', 'writing'), ('literature', 'literature'), ('review', 'review'), (',', ','), ('procedure', 'procedure'), ('followed', 'followed'), ('commonly', 'commonly'), ('used', 'used'), ('literature', 'literature'), ('reviews', 'review'), ('information', 'information'), ('systems', 'system'), (',', ','), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 55 =============================

(2009). 


>> Tokens are: 
 ['(', '2009', ')', '.']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), ('.', '.')]

 (S (/( 2009/CD )/) ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('.', '.')]



============================ Sentence 56 =============================

The papers were chosen based on both novelty and discussion   of important topics related to big data and big data analytics in manners that serve the purpose of   the research. 


>> Tokens are: 
 ['The', 'papers', 'chosen', 'based', 'novelty', 'discussion', 'important', 'topics', 'related', 'big', 'data', 'big', 'data', 'analytics', 'manners', 'serve', 'purpose', 'research', '.']

>> Bigrams are: 
 [('The', 'papers'), ('papers', 'chosen'), ('chosen', 'based'), ('based', 'novelty'), ('novelty', 'discussion'), ('discussion', 'important'), ('important', 'topics'), ('topics', 'related'), ('related', 'big'), ('big', 'data'), ('data', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'manners'), ('manners', 'serve'), ('serve', 'purpose'), ('purpose', 'research'), ('research', '.')]

>> Trigrams are: 
 [('The', 'papers', 'chosen'), ('papers', 'chosen', 'based'), ('chosen', 'based', 'novelty'), ('based', 'novelty', 'discussion'), ('novelty', 'discussion', 'important'), ('discussion', 'important', 'topics'), ('important', 'topics', 'related'), ('topics', 'related', 'big'), ('related', 'big', 'data'), ('big', 'data', 'big'), ('data', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'manners'), ('analytics', 'manners', 'serve'), ('manners', 'serve', 'purpose'), ('serve', 'purpose', 'research'), ('purpose', 'research', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('papers', 'NNS'), ('chosen', 'VBP'), ('based', 'VBN'), ('novelty', 'NN'), ('discussion', 'NN'), ('important', 'JJ'), ('topics', 'NNS'), ('related', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('manners', 'NNS'), ('serve', 'VBP'), ('purpose', 'JJ'), ('research', 'NN'), ('.', '.')]

 (S
  (NP The/DT papers/NNS)
  chosen/VBP
  based/VBN
  (NP novelty/NN discussion/NN)
  (NP important/JJ topics/NNS)
  (NP related/JJ big/JJ data/NNS)
  (NP big/JJ data/NNS analytics/NNS manners/NNS)
  serve/VBP
  (NP purpose/JJ research/NN)
  ./.) 


>> Noun Phrases are: 
 ['The papers', 'novelty discussion', 'important topics', 'related big data', 'big data analytics manners', 'purpose research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('novelty', 'novelti'), ('discussion', 'discuss'), ('important', 'import'), ('topics', 'topic'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('manners', 'manner'), ('serve', 'serv'), ('purpose', 'purpos'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('novelty', 'novelti'), ('discussion', 'discuss'), ('important', 'import'), ('topics', 'topic'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('manners', 'manner'), ('serve', 'serv'), ('purpose', 'purpos'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'based'), ('novelty', 'novelty'), ('discussion', 'discussion'), ('important', 'important'), ('topics', 'topic'), ('related', 'related'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('manners', 'manner'), ('serve', 'serve'), ('purpose', 'purpose'), ('research', 'research'), ('.', '.')]



============================ Sentence 57 =============================

The selected publications thus focus on big data analytics during the period 2011 to   2019. 


>> Tokens are: 
 ['The', 'selected', 'publications', 'thus', 'focus', 'big', 'data', 'analytics', 'period', '2011', '2019', '.']

>> Bigrams are: 
 [('The', 'selected'), ('selected', 'publications'), ('publications', 'thus'), ('thus', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'period'), ('period', '2011'), ('2011', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('The', 'selected', 'publications'), ('selected', 'publications', 'thus'), ('publications', 'thus', 'focus'), ('thus', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'period'), ('analytics', 'period', '2011'), ('period', '2011', '2019'), ('2011', '2019', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('selected', 'VBN'), ('publications', 'NNS'), ('thus', 'RB'), ('focus', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('period', 'NN'), ('2011', 'CD'), ('2019', 'CD'), ('.', '.')]

 (S
  The/DT
  selected/VBN
  (NP publications/NNS)
  thus/RB
  focus/VBP
  (NP big/JJ data/NNS analytics/NNS period/NN)
  2011/CD
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['publications', 'big data analytics period']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('selected', 'select'), ('publications', 'public'), ('thus', 'thu'), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('selected', 'select'), ('publications', 'public'), ('thus', 'thus'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('selected', 'selected'), ('publications', 'publication'), ('thus', 'thus'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]



============================ Sentence 58 =============================

Most of the references were selected from prestigious journals or conferences, with a limited     Sarah Al-Shiakhli   2      number of white papers included; the search engines used included LTU library, Google Scholar,   IEEE Xplore, Springers, ACM DL, Websco, Emerald, and Elsevier. 


>> Tokens are: 
 ['Most', 'references', 'selected', 'prestigious', 'journals', 'conferences', ',', 'limited', 'Sarah', 'Al-Shiakhli', '2', 'number', 'white', 'papers', 'included', ';', 'search', 'engines', 'used', 'included', 'LTU', 'library', ',', 'Google', 'Scholar', ',', 'IEEE', 'Xplore', ',', 'Springers', ',', 'ACM', 'DL', ',', 'Websco', ',', 'Emerald', ',', 'Elsevier', '.']

>> Bigrams are: 
 [('Most', 'references'), ('references', 'selected'), ('selected', 'prestigious'), ('prestigious', 'journals'), ('journals', 'conferences'), ('conferences', ','), (',', 'limited'), ('limited', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '2'), ('2', 'number'), ('number', 'white'), ('white', 'papers'), ('papers', 'included'), ('included', ';'), (';', 'search'), ('search', 'engines'), ('engines', 'used'), ('used', 'included'), ('included', 'LTU'), ('LTU', 'library'), ('library', ','), (',', 'Google'), ('Google', 'Scholar'), ('Scholar', ','), (',', 'IEEE'), ('IEEE', 'Xplore'), ('Xplore', ','), (',', 'Springers'), ('Springers', ','), (',', 'ACM'), ('ACM', 'DL'), ('DL', ','), (',', 'Websco'), ('Websco', ','), (',', 'Emerald'), ('Emerald', ','), (',', 'Elsevier'), ('Elsevier', '.')]

>> Trigrams are: 
 [('Most', 'references', 'selected'), ('references', 'selected', 'prestigious'), ('selected', 'prestigious', 'journals'), ('prestigious', 'journals', 'conferences'), ('journals', 'conferences', ','), ('conferences', ',', 'limited'), (',', 'limited', 'Sarah'), ('limited', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '2'), ('Al-Shiakhli', '2', 'number'), ('2', 'number', 'white'), ('number', 'white', 'papers'), ('white', 'papers', 'included'), ('papers', 'included', ';'), ('included', ';', 'search'), (';', 'search', 'engines'), ('search', 'engines', 'used'), ('engines', 'used', 'included'), ('used', 'included', 'LTU'), ('included', 'LTU', 'library'), ('LTU', 'library', ','), ('library', ',', 'Google'), (',', 'Google', 'Scholar'), ('Google', 'Scholar', ','), ('Scholar', ',', 'IEEE'), (',', 'IEEE', 'Xplore'), ('IEEE', 'Xplore', ','), ('Xplore', ',', 'Springers'), (',', 'Springers', ','), ('Springers', ',', 'ACM'), (',', 'ACM', 'DL'), ('ACM', 'DL', ','), ('DL', ',', 'Websco'), (',', 'Websco', ','), ('Websco', ',', 'Emerald'), (',', 'Emerald', ','), ('Emerald', ',', 'Elsevier'), (',', 'Elsevier', '.')]

>> POS Tags are: 
 [('Most', 'JJS'), ('references', 'NNS'), ('selected', 'VBN'), ('prestigious', 'JJ'), ('journals', 'NNS'), ('conferences', 'NNS'), (',', ','), ('limited', 'JJ'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('2', 'CD'), ('number', 'NN'), ('white', 'JJ'), ('papers', 'NNS'), ('included', 'VBD'), (';', ':'), ('search', 'NN'), ('engines', 'NNS'), ('used', 'VBN'), ('included', 'VBD'), ('LTU', 'NNP'), ('library', 'NN'), (',', ','), ('Google', 'NNP'), ('Scholar', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Xplore', 'NNP'), (',', ','), ('Springers', 'NNP'), (',', ','), ('ACM', 'NNP'), ('DL', 'NNP'), (',', ','), ('Websco', 'NNP'), (',', ','), ('Emerald', 'NNP'), (',', ','), ('Elsevier', 'NNP'), ('.', '.')]

 (S
  Most/JJS
  (NP references/NNS)
  selected/VBN
  (NP prestigious/JJ journals/NNS conferences/NNS)
  ,/,
  (NP limited/JJ Sarah/NNP Al-Shiakhli/NNP)
  2/CD
  (NP number/NN)
  (NP white/JJ papers/NNS)
  included/VBD
  ;/:
  (NP search/NN engines/NNS)
  used/VBN
  included/VBD
  (NP LTU/NNP library/NN)
  ,/,
  (NP Google/NNP Scholar/NNP)
  ,/,
  (NP IEEE/NNP Xplore/NNP)
  ,/,
  (NP Springers/NNP)
  ,/,
  (NP ACM/NNP DL/NNP)
  ,/,
  (NP Websco/NNP)
  ,/,
  (NP Emerald/NNP)
  ,/,
  (NP Elsevier/NNP)
  ./.) 


>> Noun Phrases are: 
 ['references', 'prestigious journals conferences', 'limited Sarah Al-Shiakhli', 'number', 'white papers', 'search engines', 'LTU library', 'Google Scholar', 'IEEE Xplore', 'Springers', 'ACM DL', 'Websco', 'Emerald', 'Elsevier']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'LTU'), ('PERSON', 'Google Scholar'), ('ORGANIZATION', 'IEEE Xplore'), ('GPE', 'Springers'), ('ORGANIZATION', 'ACM'), ('GPE', 'Websco'), ('PERSON', 'Emerald'), ('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('Most', 'most'), ('references', 'refer'), ('selected', 'select'), ('prestigious', 'prestigi'), ('journals', 'journal'), ('conferences', 'confer'), (',', ','), ('limited', 'limit'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('2', '2'), ('number', 'number'), ('white', 'white'), ('papers', 'paper'), ('included', 'includ'), (';', ';'), ('search', 'search'), ('engines', 'engin'), ('used', 'use'), ('included', 'includ'), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ','), ('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Springers', 'springer'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('Websco', 'websco'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Most', 'most'), ('references', 'refer'), ('selected', 'select'), ('prestigious', 'prestigi'), ('journals', 'journal'), ('conferences', 'confer'), (',', ','), ('limited', 'limit'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('2', '2'), ('number', 'number'), ('white', 'white'), ('papers', 'paper'), ('included', 'includ'), (';', ';'), ('search', 'search'), ('engines', 'engin'), ('used', 'use'), ('included', 'includ'), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ','), ('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Springers', 'springer'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('Websco', 'websco'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Lemmatization: 
 [('Most', 'Most'), ('references', 'reference'), ('selected', 'selected'), ('prestigious', 'prestigious'), ('journals', 'journal'), ('conferences', 'conference'), (',', ','), ('limited', 'limited'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('2', '2'), ('number', 'number'), ('white', 'white'), ('papers', 'paper'), ('included', 'included'), (';', ';'), ('search', 'search'), ('engines', 'engine'), ('used', 'used'), ('included', 'included'), ('LTU', 'LTU'), ('library', 'library'), (',', ','), ('Google', 'Google'), ('Scholar', 'Scholar'), (',', ','), ('IEEE', 'IEEE'), ('Xplore', 'Xplore'), (',', ','), ('Springers', 'Springers'), (',', ','), ('ACM', 'ACM'), ('DL', 'DL'), (',', ','), ('Websco', 'Websco'), (',', ','), ('Emerald', 'Emerald'), (',', ','), ('Elsevier', 'Elsevier'), ('.', '.')]



============================ Sentence 59 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 60 =============================

Research Question   In order to develop a general overview of the topic, a literature study is an appropriate way to   identify the state-of-the-art in big data analytics. 


>> Tokens are: 
 ['Research', 'Question', 'In', 'order', 'develop', 'general', 'overview', 'topic', ',', 'literature', 'study', 'appropriate', 'way', 'identify', 'state-of-the-art', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Research', 'Question'), ('Question', 'In'), ('In', 'order'), ('order', 'develop'), ('develop', 'general'), ('general', 'overview'), ('overview', 'topic'), ('topic', ','), (',', 'literature'), ('literature', 'study'), ('study', 'appropriate'), ('appropriate', 'way'), ('way', 'identify'), ('identify', 'state-of-the-art'), ('state-of-the-art', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Research', 'Question', 'In'), ('Question', 'In', 'order'), ('In', 'order', 'develop'), ('order', 'develop', 'general'), ('develop', 'general', 'overview'), ('general', 'overview', 'topic'), ('overview', 'topic', ','), ('topic', ',', 'literature'), (',', 'literature', 'study'), ('literature', 'study', 'appropriate'), ('study', 'appropriate', 'way'), ('appropriate', 'way', 'identify'), ('way', 'identify', 'state-of-the-art'), ('identify', 'state-of-the-art', 'big'), ('state-of-the-art', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Question', 'NNP'), ('In', 'IN'), ('order', 'NN'), ('develop', 'VB'), ('general', 'JJ'), ('overview', 'NN'), ('topic', 'NN'), (',', ','), ('literature', 'NN'), ('study', 'NN'), ('appropriate', 'JJ'), ('way', 'NN'), ('identify', 'VB'), ('state-of-the-art', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Research/NNP Question/NNP)
  In/IN
  (NP order/NN)
  develop/VB
  (NP general/JJ overview/NN topic/NN)
  ,/,
  (NP literature/NN study/NN)
  (NP appropriate/JJ way/NN)
  identify/VB
  (NP state-of-the-art/JJ big/JJ data/NNS analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Research Question', 'order', 'general overview topic', 'literature study', 'appropriate way', 'state-of-the-art big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Question', 'question'), ('In', 'in'), ('order', 'order'), ('develop', 'develop'), ('general', 'gener'), ('overview', 'overview'), ('topic', 'topic'), (',', ','), ('literature', 'literatur'), ('study', 'studi'), ('appropriate', 'appropri'), ('way', 'way'), ('identify', 'identifi'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Question', 'question'), ('In', 'in'), ('order', 'order'), ('develop', 'develop'), ('general', 'general'), ('overview', 'overview'), ('topic', 'topic'), (',', ','), ('literature', 'literatur'), ('study', 'studi'), ('appropriate', 'appropri'), ('way', 'way'), ('identify', 'identifi'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Question', 'Question'), ('In', 'In'), ('order', 'order'), ('develop', 'develop'), ('general', 'general'), ('overview', 'overview'), ('topic', 'topic'), (',', ','), ('literature', 'literature'), ('study', 'study'), ('appropriate', 'appropriate'), ('way', 'way'), ('identify', 'identify'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 61 =============================

Big data is important because it is one of the main   technologies currently used to solve industrial issues and to provide roadmaps for research and   education. 


>> Tokens are: 
 ['Big', 'data', 'important', 'one', 'main', 'technologies', 'currently', 'used', 'solve', 'industrial', 'issues', 'provide', 'roadmaps', 'research', 'education', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'important'), ('important', 'one'), ('one', 'main'), ('main', 'technologies'), ('technologies', 'currently'), ('currently', 'used'), ('used', 'solve'), ('solve', 'industrial'), ('industrial', 'issues'), ('issues', 'provide'), ('provide', 'roadmaps'), ('roadmaps', 'research'), ('research', 'education'), ('education', '.')]

>> Trigrams are: 
 [('Big', 'data', 'important'), ('data', 'important', 'one'), ('important', 'one', 'main'), ('one', 'main', 'technologies'), ('main', 'technologies', 'currently'), ('technologies', 'currently', 'used'), ('currently', 'used', 'solve'), ('used', 'solve', 'industrial'), ('solve', 'industrial', 'issues'), ('industrial', 'issues', 'provide'), ('issues', 'provide', 'roadmaps'), ('provide', 'roadmaps', 'research'), ('roadmaps', 'research', 'education'), ('research', 'education', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('important', 'JJ'), ('one', 'CD'), ('main', 'JJ'), ('technologies', 'NNS'), ('currently', 'RB'), ('used', 'VBN'), ('solve', 'VB'), ('industrial', 'JJ'), ('issues', 'NNS'), ('provide', 'VBP'), ('roadmaps', 'NNS'), ('research', 'NN'), ('education', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  important/JJ
  one/CD
  (NP main/JJ technologies/NNS)
  currently/RB
  used/VBN
  solve/VB
  (NP industrial/JJ issues/NNS)
  provide/VBP
  (NP roadmaps/NNS research/NN education/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'main technologies', 'industrial issues', 'roadmaps research education']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('important', 'import'), ('one', 'one'), ('main', 'main'), ('technologies', 'technolog'), ('currently', 'current'), ('used', 'use'), ('solve', 'solv'), ('industrial', 'industri'), ('issues', 'issu'), ('provide', 'provid'), ('roadmaps', 'roadmap'), ('research', 'research'), ('education', 'educ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('important', 'import'), ('one', 'one'), ('main', 'main'), ('technologies', 'technolog'), ('currently', 'current'), ('used', 'use'), ('solve', 'solv'), ('industrial', 'industri'), ('issues', 'issu'), ('provide', 'provid'), ('roadmaps', 'roadmap'), ('research', 'research'), ('education', 'educ'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('important', 'important'), ('one', 'one'), ('main', 'main'), ('technologies', 'technology'), ('currently', 'currently'), ('used', 'used'), ('solve', 'solve'), ('industrial', 'industrial'), ('issues', 'issue'), ('provide', 'provide'), ('roadmaps', 'roadmaps'), ('research', 'research'), ('education', 'education'), ('.', '.')]



============================ Sentence 62 =============================

The question thus becomes What is the state of the art in big data analytics? 


>> Tokens are: 
 ['The', 'question', 'thus', 'becomes', 'What', 'state', 'art', 'big', 'data', 'analytics', '?']

>> Bigrams are: 
 [('The', 'question'), ('question', 'thus'), ('thus', 'becomes'), ('becomes', 'What'), ('What', 'state'), ('state', 'art'), ('art', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '?')]

>> Trigrams are: 
 [('The', 'question', 'thus'), ('question', 'thus', 'becomes'), ('thus', 'becomes', 'What'), ('becomes', 'What', 'state'), ('What', 'state', 'art'), ('state', 'art', 'big'), ('art', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '?')]

>> POS Tags are: 
 [('The', 'DT'), ('question', 'NN'), ('thus', 'RB'), ('becomes', 'VBZ'), ('What', 'WP'), ('state', 'NN'), ('art', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('?', '.')]

 (S
  (NP The/DT question/NN)
  thus/RB
  becomes/VBZ
  What/WP
  (NP state/NN art/NN)
  (NP big/JJ data/NN analytics/NNS)
  ?/.) 


>> Noun Phrases are: 
 ['The question', 'state art', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('question', 'question'), ('thus', 'thu'), ('becomes', 'becom'), ('What', 'what'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('question', 'question'), ('thus', 'thus'), ('becomes', 'becom'), ('What', 'what'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('?', '?')]

>> Lemmatization: 
 [('The', 'The'), ('question', 'question'), ('thus', 'thus'), ('becomes', 'becomes'), ('What', 'What'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('?', '?')]



============================ Sentence 63 =============================

This research question is important to academia due to a lack of similar studies addressing the state   of the art in big data analytics. 


>> Tokens are: 
 ['This', 'research', 'question', 'important', 'academia', 'due', 'lack', 'similar', 'studies', 'addressing', 'state', 'art', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('This', 'research'), ('research', 'question'), ('question', 'important'), ('important', 'academia'), ('academia', 'due'), ('due', 'lack'), ('lack', 'similar'), ('similar', 'studies'), ('studies', 'addressing'), ('addressing', 'state'), ('state', 'art'), ('art', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('This', 'research', 'question'), ('research', 'question', 'important'), ('question', 'important', 'academia'), ('important', 'academia', 'due'), ('academia', 'due', 'lack'), ('due', 'lack', 'similar'), ('lack', 'similar', 'studies'), ('similar', 'studies', 'addressing'), ('studies', 'addressing', 'state'), ('addressing', 'state', 'art'), ('state', 'art', 'big'), ('art', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('research', 'NN'), ('question', 'NN'), ('important', 'JJ'), ('academia', 'NN'), ('due', 'JJ'), ('lack', 'NN'), ('similar', 'JJ'), ('studies', 'NNS'), ('addressing', 'VBG'), ('state', 'NN'), ('art', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP This/DT research/NN question/NN)
  (NP important/JJ academia/NN)
  (NP due/JJ lack/NN)
  (NP similar/JJ studies/NNS)
  addressing/VBG
  (NP state/NN art/NN)
  (NP big/JJ data/NN analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This research question', 'important academia', 'due lack', 'similar studies', 'state art', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('research', 'research'), ('question', 'question'), ('important', 'import'), ('academia', 'academia'), ('due', 'due'), ('lack', 'lack'), ('similar', 'similar'), ('studies', 'studi'), ('addressing', 'address'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('research', 'research'), ('question', 'question'), ('important', 'import'), ('academia', 'academia'), ('due', 'due'), ('lack', 'lack'), ('similar', 'similar'), ('studies', 'studi'), ('addressing', 'address'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('research', 'research'), ('question', 'question'), ('important', 'important'), ('academia', 'academia'), ('due', 'due'), ('lack', 'lack'), ('similar', 'similar'), ('studies', 'study'), ('addressing', 'addressing'), ('state', 'state'), ('art', 'art'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 64 =============================

To the best of the researcher’s knowledge, no similar research has   been conducted in recent years, despite big data analytics providing a basis for advancements at   both technological and scientific levels (Nafus and Sherman, 2014; Elgendy and Elragal, 2014). 


>> Tokens are: 
 ['To', 'best', 'researcher', '’', 'knowledge', ',', 'similar', 'research', 'conducted', 'recent', 'years', ',', 'despite', 'big', 'data', 'analytics', 'providing', 'basis', 'advancements', 'technological', 'scientific', 'levels', '(', 'Nafus', 'Sherman', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('To', 'best'), ('best', 'researcher'), ('researcher', '’'), ('’', 'knowledge'), ('knowledge', ','), (',', 'similar'), ('similar', 'research'), ('research', 'conducted'), ('conducted', 'recent'), ('recent', 'years'), ('years', ','), (',', 'despite'), ('despite', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'providing'), ('providing', 'basis'), ('basis', 'advancements'), ('advancements', 'technological'), ('technological', 'scientific'), ('scientific', 'levels'), ('levels', '('), ('(', 'Nafus'), ('Nafus', 'Sherman'), ('Sherman', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('To', 'best', 'researcher'), ('best', 'researcher', '’'), ('researcher', '’', 'knowledge'), ('’', 'knowledge', ','), ('knowledge', ',', 'similar'), (',', 'similar', 'research'), ('similar', 'research', 'conducted'), ('research', 'conducted', 'recent'), ('conducted', 'recent', 'years'), ('recent', 'years', ','), ('years', ',', 'despite'), (',', 'despite', 'big'), ('despite', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'providing'), ('analytics', 'providing', 'basis'), ('providing', 'basis', 'advancements'), ('basis', 'advancements', 'technological'), ('advancements', 'technological', 'scientific'), ('technological', 'scientific', 'levels'), ('scientific', 'levels', '('), ('levels', '(', 'Nafus'), ('(', 'Nafus', 'Sherman'), ('Nafus', 'Sherman', ','), ('Sherman', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('best', 'VB'), ('researcher', 'NN'), ('’', 'NNP'), ('knowledge', 'NN'), (',', ','), ('similar', 'JJ'), ('research', 'NN'), ('conducted', 'VBN'), ('recent', 'JJ'), ('years', 'NNS'), (',', ','), ('despite', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('providing', 'VBG'), ('basis', 'NN'), ('advancements', 'NNS'), ('technological', 'JJ'), ('scientific', 'JJ'), ('levels', 'NNS'), ('(', '('), ('Nafus', 'NNP'), ('Sherman', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  To/TO
  best/VB
  (NP researcher/NN ’/NNP knowledge/NN)
  ,/,
  (NP similar/JJ research/NN)
  conducted/VBN
  (NP recent/JJ years/NNS)
  ,/,
  despite/IN
  (NP big/JJ data/NNS analytics/NNS)
  providing/VBG
  (NP basis/NN advancements/NNS)
  (NP technological/JJ scientific/JJ levels/NNS)
  (/(
  (NP Nafus/NNP Sherman/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['researcher ’ knowledge', 'similar research', 'recent years', 'big data analytics', 'basis advancements', 'technological scientific levels', 'Nafus Sherman', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Nafus Sherman'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('best', 'best'), ('researcher', 'research'), ('’', '’'), ('knowledge', 'knowledg'), (',', ','), ('similar', 'similar'), ('research', 'research'), ('conducted', 'conduct'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('despite', 'despit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('providing', 'provid'), ('basis', 'basi'), ('advancements', 'advanc'), ('technological', 'technolog'), ('scientific', 'scientif'), ('levels', 'level'), ('(', '('), ('Nafus', 'nafu'), ('Sherman', 'sherman'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('best', 'best'), ('researcher', 'research'), ('’', '’'), ('knowledge', 'knowledg'), (',', ','), ('similar', 'similar'), ('research', 'research'), ('conducted', 'conduct'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('despite', 'despit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('providing', 'provid'), ('basis', 'basi'), ('advancements', 'advanc'), ('technological', 'technolog'), ('scientific', 'scientif'), ('levels', 'level'), ('(', '('), ('Nafus', 'nafus'), ('Sherman', 'sherman'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('best', 'best'), ('researcher', 'researcher'), ('’', '’'), ('knowledge', 'knowledge'), (',', ','), ('similar', 'similar'), ('research', 'research'), ('conducted', 'conducted'), ('recent', 'recent'), ('years', 'year'), (',', ','), ('despite', 'despite'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('providing', 'providing'), ('basis', 'basis'), ('advancements', 'advancement'), ('technological', 'technological'), ('scientific', 'scientific'), ('levels', 'level'), ('(', '('), ('Nafus', 'Nafus'), ('Sherman', 'Sherman'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 65 =============================

• A literature review on big data analytics shows what is already known and what should be  known;   • It identifies research gaps in big data analytics by noting both “hot” topics that have already  been studied extensively and solved problems in big data analytics, and those problems   that are unsolved and research questions that remain unanswered and untouched;      • It opens the door for other researchers, better supporting the explosive increase in big data  analytics;      • This research also frames valid research methodologies, goals, and research questions for  such proposed study (Levy and Ellis, 2006; Cronin et al., 2008; Hart, 2018). 


>> Tokens are: 
 ['•', 'A', 'literature', 'review', 'big', 'data', 'analytics', 'shows', 'already', 'known', 'known', ';', '•', 'It', 'identifies', 'research', 'gaps', 'big', 'data', 'analytics', 'noting', '“', 'hot', '”', 'topics', 'already', 'studied', 'extensively', 'solved', 'problems', 'big', 'data', 'analytics', ',', 'problems', 'unsolved', 'research', 'questions', 'remain', 'unanswered', 'untouched', ';', '•', 'It', 'opens', 'door', 'researchers', ',', 'better', 'supporting', 'explosive', 'increase', 'big', 'data', 'analytics', ';', '•', 'This', 'research', 'also', 'frames', 'valid', 'research', 'methodologies', ',', 'goals', ',', 'research', 'questions', 'proposed', 'study', '(', 'Levy', 'Ellis', ',', '2006', ';', 'Cronin', 'et', 'al.', ',', '2008', ';', 'Hart', ',', '2018', ')', '.']

>> Bigrams are: 
 [('•', 'A'), ('A', 'literature'), ('literature', 'review'), ('review', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'shows'), ('shows', 'already'), ('already', 'known'), ('known', 'known'), ('known', ';'), (';', '•'), ('•', 'It'), ('It', 'identifies'), ('identifies', 'research'), ('research', 'gaps'), ('gaps', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'noting'), ('noting', '“'), ('“', 'hot'), ('hot', '”'), ('”', 'topics'), ('topics', 'already'), ('already', 'studied'), ('studied', 'extensively'), ('extensively', 'solved'), ('solved', 'problems'), ('problems', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'problems'), ('problems', 'unsolved'), ('unsolved', 'research'), ('research', 'questions'), ('questions', 'remain'), ('remain', 'unanswered'), ('unanswered', 'untouched'), ('untouched', ';'), (';', '•'), ('•', 'It'), ('It', 'opens'), ('opens', 'door'), ('door', 'researchers'), ('researchers', ','), (',', 'better'), ('better', 'supporting'), ('supporting', 'explosive'), ('explosive', 'increase'), ('increase', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ';'), (';', '•'), ('•', 'This'), ('This', 'research'), ('research', 'also'), ('also', 'frames'), ('frames', 'valid'), ('valid', 'research'), ('research', 'methodologies'), ('methodologies', ','), (',', 'goals'), ('goals', ','), (',', 'research'), ('research', 'questions'), ('questions', 'proposed'), ('proposed', 'study'), ('study', '('), ('(', 'Levy'), ('Levy', 'Ellis'), ('Ellis', ','), (',', '2006'), ('2006', ';'), (';', 'Cronin'), ('Cronin', 'et'), ('et', 'al.'), ('al.', ','), (',', '2008'), ('2008', ';'), (';', 'Hart'), ('Hart', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'A', 'literature'), ('A', 'literature', 'review'), ('literature', 'review', 'big'), ('review', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'shows'), ('analytics', 'shows', 'already'), ('shows', 'already', 'known'), ('already', 'known', 'known'), ('known', 'known', ';'), ('known', ';', '•'), (';', '•', 'It'), ('•', 'It', 'identifies'), ('It', 'identifies', 'research'), ('identifies', 'research', 'gaps'), ('research', 'gaps', 'big'), ('gaps', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'noting'), ('analytics', 'noting', '“'), ('noting', '“', 'hot'), ('“', 'hot', '”'), ('hot', '”', 'topics'), ('”', 'topics', 'already'), ('topics', 'already', 'studied'), ('already', 'studied', 'extensively'), ('studied', 'extensively', 'solved'), ('extensively', 'solved', 'problems'), ('solved', 'problems', 'big'), ('problems', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'problems'), (',', 'problems', 'unsolved'), ('problems', 'unsolved', 'research'), ('unsolved', 'research', 'questions'), ('research', 'questions', 'remain'), ('questions', 'remain', 'unanswered'), ('remain', 'unanswered', 'untouched'), ('unanswered', 'untouched', ';'), ('untouched', ';', '•'), (';', '•', 'It'), ('•', 'It', 'opens'), ('It', 'opens', 'door'), ('opens', 'door', 'researchers'), ('door', 'researchers', ','), ('researchers', ',', 'better'), (',', 'better', 'supporting'), ('better', 'supporting', 'explosive'), ('supporting', 'explosive', 'increase'), ('explosive', 'increase', 'big'), ('increase', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ';'), ('analytics', ';', '•'), (';', '•', 'This'), ('•', 'This', 'research'), ('This', 'research', 'also'), ('research', 'also', 'frames'), ('also', 'frames', 'valid'), ('frames', 'valid', 'research'), ('valid', 'research', 'methodologies'), ('research', 'methodologies', ','), ('methodologies', ',', 'goals'), (',', 'goals', ','), ('goals', ',', 'research'), (',', 'research', 'questions'), ('research', 'questions', 'proposed'), ('questions', 'proposed', 'study'), ('proposed', 'study', '('), ('study', '(', 'Levy'), ('(', 'Levy', 'Ellis'), ('Levy', 'Ellis', ','), ('Ellis', ',', '2006'), (',', '2006', ';'), ('2006', ';', 'Cronin'), (';', 'Cronin', 'et'), ('Cronin', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2008'), (',', '2008', ';'), ('2008', ';', 'Hart'), (';', 'Hart', ','), ('Hart', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('•', 'VB'), ('A', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('shows', 'VBZ'), ('already', 'RB'), ('known', 'VBN'), ('known', 'VBN'), (';', ':'), ('•', 'VB'), ('It', 'PRP'), ('identifies', 'VBZ'), ('research', 'NN'), ('gaps', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('noting', 'VBG'), ('“', 'JJ'), ('hot', 'JJ'), ('”', 'NN'), ('topics', 'NNS'), ('already', 'RB'), ('studied', 'VBN'), ('extensively', 'RB'), ('solved', 'VBN'), ('problems', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('problems', 'NNS'), ('unsolved', 'VBD'), ('research', 'NN'), ('questions', 'NNS'), ('remain', 'VBP'), ('unanswered', 'JJ'), ('untouched', 'JJ'), (';', ':'), ('•', 'VB'), ('It', 'PRP'), ('opens', 'VBZ'), ('door', 'NN'), ('researchers', 'NNS'), (',', ','), ('better', 'JJR'), ('supporting', 'VBG'), ('explosive', 'JJ'), ('increase', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (';', ':'), ('•', 'VB'), ('This', 'DT'), ('research', 'NN'), ('also', 'RB'), ('frames', 'VBZ'), ('valid', 'JJ'), ('research', 'NN'), ('methodologies', 'NNS'), (',', ','), ('goals', 'NNS'), (',', ','), ('research', 'NN'), ('questions', 'NNS'), ('proposed', 'VBN'), ('study', 'NN'), ('(', '('), ('Levy', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('2006', 'CD'), (';', ':'), ('Cronin', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2008', 'CD'), (';', ':'), ('Hart', 'NNP'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  •/VB
  (NP A/DT literature/NN review/NN)
  (NP big/JJ data/NN analytics/NNS)
  shows/VBZ
  already/RB
  known/VBN
  known/VBN
  ;/:
  •/VB
  It/PRP
  identifies/VBZ
  (NP research/NN gaps/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  noting/VBG
  (NP “/JJ hot/JJ ”/NN topics/NNS)
  already/RB
  studied/VBN
  extensively/RB
  solved/VBN
  (NP problems/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  ,/,
  (NP problems/NNS)
  unsolved/VBD
  (NP research/NN questions/NNS)
  remain/VBP
  unanswered/JJ
  untouched/JJ
  ;/:
  •/VB
  It/PRP
  opens/VBZ
  (NP door/NN researchers/NNS)
  ,/,
  better/JJR
  supporting/VBG
  (NP explosive/JJ increase/NN)
  (NP big/JJ data/NNS analytics/NNS)
  ;/:
  •/VB
  (NP This/DT research/NN)
  also/RB
  frames/VBZ
  (NP valid/JJ research/NN methodologies/NNS)
  ,/,
  (NP goals/NNS)
  ,/,
  (NP research/NN questions/NNS)
  proposed/VBN
  (NP study/NN)
  (/(
  (NP Levy/NNP Ellis/NNP)
  ,/,
  2006/CD
  ;/:
  (NP Cronin/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2008/CD
  ;/:
  (NP Hart/NNP)
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['A literature review', 'big data analytics', 'research gaps', 'big data analytics', '“ hot ” topics', 'problems', 'big data analytics', 'problems', 'research questions', 'door researchers', 'explosive increase', 'big data analytics', 'This research', 'valid research methodologies', 'goals', 'research questions', 'study', 'Levy Ellis', 'Cronin', 'al.', 'Hart']

>> Named Entities are: 
 [('ORGANIZATION', 'Levy Ellis'), ('GPE', 'Cronin'), ('PERSON', 'Hart')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shows', 'show'), ('already', 'alreadi'), ('known', 'known'), ('known', 'known'), (';', ';'), ('•', '•'), ('It', 'it'), ('identifies', 'identifi'), ('research', 'research'), ('gaps', 'gap'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('noting', 'note'), ('“', '“'), ('hot', 'hot'), ('”', '”'), ('topics', 'topic'), ('already', 'alreadi'), ('studied', 'studi'), ('extensively', 'extens'), ('solved', 'solv'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('problems', 'problem'), ('unsolved', 'unsolv'), ('research', 'research'), ('questions', 'question'), ('remain', 'remain'), ('unanswered', 'unansw'), ('untouched', 'untouch'), (';', ';'), ('•', '•'), ('It', 'it'), ('opens', 'open'), ('door', 'door'), ('researchers', 'research'), (',', ','), ('better', 'better'), ('supporting', 'support'), ('explosive', 'explos'), ('increase', 'increas'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (';', ';'), ('•', '•'), ('This', 'thi'), ('research', 'research'), ('also', 'also'), ('frames', 'frame'), ('valid', 'valid'), ('research', 'research'), ('methodologies', 'methodolog'), (',', ','), ('goals', 'goal'), (',', ','), ('research', 'research'), ('questions', 'question'), ('proposed', 'propos'), ('study', 'studi'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (';', ';'), ('Cronin', 'cronin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (';', ';'), ('Hart', 'hart'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shows', 'show'), ('already', 'alreadi'), ('known', 'known'), ('known', 'known'), (';', ';'), ('•', '•'), ('It', 'it'), ('identifies', 'identifi'), ('research', 'research'), ('gaps', 'gap'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('noting', 'note'), ('“', '“'), ('hot', 'hot'), ('”', '”'), ('topics', 'topic'), ('already', 'alreadi'), ('studied', 'studi'), ('extensively', 'extens'), ('solved', 'solv'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('problems', 'problem'), ('unsolved', 'unsolv'), ('research', 'research'), ('questions', 'question'), ('remain', 'remain'), ('unanswered', 'unansw'), ('untouched', 'untouch'), (';', ';'), ('•', '•'), ('It', 'it'), ('opens', 'open'), ('door', 'door'), ('researchers', 'research'), (',', ','), ('better', 'better'), ('supporting', 'support'), ('explosive', 'explos'), ('increase', 'increas'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (';', ';'), ('•', '•'), ('This', 'this'), ('research', 'research'), ('also', 'also'), ('frames', 'frame'), ('valid', 'valid'), ('research', 'research'), ('methodologies', 'methodolog'), (',', ','), ('goals', 'goal'), (',', ','), ('research', 'research'), ('questions', 'question'), ('proposed', 'propos'), ('study', 'studi'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (';', ';'), ('Cronin', 'cronin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (';', ';'), ('Hart', 'hart'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('A', 'A'), ('literature', 'literature'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('shows', 'show'), ('already', 'already'), ('known', 'known'), ('known', 'known'), (';', ';'), ('•', '•'), ('It', 'It'), ('identifies', 'identifies'), ('research', 'research'), ('gaps', 'gap'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('noting', 'noting'), ('“', '“'), ('hot', 'hot'), ('”', '”'), ('topics', 'topic'), ('already', 'already'), ('studied', 'studied'), ('extensively', 'extensively'), ('solved', 'solved'), ('problems', 'problem'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('problems', 'problem'), ('unsolved', 'unsolved'), ('research', 'research'), ('questions', 'question'), ('remain', 'remain'), ('unanswered', 'unanswered'), ('untouched', 'untouched'), (';', ';'), ('•', '•'), ('It', 'It'), ('opens', 'open'), ('door', 'door'), ('researchers', 'researcher'), (',', ','), ('better', 'better'), ('supporting', 'supporting'), ('explosive', 'explosive'), ('increase', 'increase'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (';', ';'), ('•', '•'), ('This', 'This'), ('research', 'research'), ('also', 'also'), ('frames', 'frame'), ('valid', 'valid'), ('research', 'research'), ('methodologies', 'methodology'), (',', ','), ('goals', 'goal'), (',', ','), ('research', 'research'), ('questions', 'question'), ('proposed', 'proposed'), ('study', 'study'), ('(', '('), ('Levy', 'Levy'), ('Ellis', 'Ellis'), (',', ','), ('2006', '2006'), (';', ';'), ('Cronin', 'Cronin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2008', '2008'), (';', ';'), ('Hart', 'Hart'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 66 =============================

For industry, a literature review helps with examining areas in big data analytics that are already   mature as well as identifying problems that have been solved and those that have not been solved   yet. 


>> Tokens are: 
 ['For', 'industry', ',', 'literature', 'review', 'helps', 'examining', 'areas', 'big', 'data', 'analytics', 'already', 'mature', 'well', 'identifying', 'problems', 'solved', 'solved', 'yet', '.']

>> Bigrams are: 
 [('For', 'industry'), ('industry', ','), (',', 'literature'), ('literature', 'review'), ('review', 'helps'), ('helps', 'examining'), ('examining', 'areas'), ('areas', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'already'), ('already', 'mature'), ('mature', 'well'), ('well', 'identifying'), ('identifying', 'problems'), ('problems', 'solved'), ('solved', 'solved'), ('solved', 'yet'), ('yet', '.')]

>> Trigrams are: 
 [('For', 'industry', ','), ('industry', ',', 'literature'), (',', 'literature', 'review'), ('literature', 'review', 'helps'), ('review', 'helps', 'examining'), ('helps', 'examining', 'areas'), ('examining', 'areas', 'big'), ('areas', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'already'), ('analytics', 'already', 'mature'), ('already', 'mature', 'well'), ('mature', 'well', 'identifying'), ('well', 'identifying', 'problems'), ('identifying', 'problems', 'solved'), ('problems', 'solved', 'solved'), ('solved', 'solved', 'yet'), ('solved', 'yet', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('industry', 'NN'), (',', ','), ('literature', 'NN'), ('review', 'NN'), ('helps', 'VBZ'), ('examining', 'VBG'), ('areas', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('already', 'RB'), ('mature', 'VBP'), ('well', 'RB'), ('identifying', 'VBG'), ('problems', 'NNS'), ('solved', 'VBD'), ('solved', 'VBN'), ('yet', 'RB'), ('.', '.')]

 (S
  For/IN
  (NP industry/NN)
  ,/,
  (NP literature/NN review/NN)
  helps/VBZ
  examining/VBG
  (NP areas/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  already/RB
  mature/VBP
  well/RB
  identifying/VBG
  (NP problems/NNS)
  solved/VBD
  solved/VBN
  yet/RB
  ./.) 


>> Noun Phrases are: 
 ['industry', 'literature review', 'areas', 'big data analytics', 'problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('industry', 'industri'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('helps', 'help'), ('examining', 'examin'), ('areas', 'area'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi'), ('mature', 'matur'), ('well', 'well'), ('identifying', 'identifi'), ('problems', 'problem'), ('solved', 'solv'), ('solved', 'solv'), ('yet', 'yet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('industry', 'industri'), (',', ','), ('literature', 'literatur'), ('review', 'review'), ('helps', 'help'), ('examining', 'examin'), ('areas', 'area'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('already', 'alreadi'), ('mature', 'matur'), ('well', 'well'), ('identifying', 'identifi'), ('problems', 'problem'), ('solved', 'solv'), ('solved', 'solv'), ('yet', 'yet'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('industry', 'industry'), (',', ','), ('literature', 'literature'), ('review', 'review'), ('helps', 'help'), ('examining', 'examining'), ('areas', 'area'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('already', 'already'), ('mature', 'mature'), ('well', 'well'), ('identifying', 'identifying'), ('problems', 'problem'), ('solved', 'solved'), ('solved', 'solved'), ('yet', 'yet'), ('.', '.')]



============================ Sentence 67 =============================

This clarity helps investors and businesses to think positively about big data (Lee et al., 2014;   Chen, M. et al., 2014). 


>> Tokens are: 
 ['This', 'clarity', 'helps', 'investors', 'businesses', 'think', 'positively', 'big', 'data', '(', 'Lee', 'et', 'al.', ',', '2014', ';', 'Chen', ',', 'M.', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('This', 'clarity'), ('clarity', 'helps'), ('helps', 'investors'), ('investors', 'businesses'), ('businesses', 'think'), ('think', 'positively'), ('positively', 'big'), ('big', 'data'), ('data', '('), ('(', 'Lee'), ('Lee', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'clarity', 'helps'), ('clarity', 'helps', 'investors'), ('helps', 'investors', 'businesses'), ('investors', 'businesses', 'think'), ('businesses', 'think', 'positively'), ('think', 'positively', 'big'), ('positively', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Lee'), ('(', 'Lee', 'et'), ('Lee', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Chen'), (';', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', 'et'), ('M.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('clarity', 'NN'), ('helps', 'VBZ'), ('investors', 'NNS'), ('businesses', 'NNS'), ('think', 'VBP'), ('positively', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Lee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (';', ':'), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT clarity/NN)
  helps/VBZ
  (NP investors/NNS businesses/NNS)
  think/VBP
  positively/RB
  (NP big/JJ data/NNS)
  (/(
  (NP Lee/NNP)
  et/RB
  al./RB
  ,/,
  2014/CD
  ;/:
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  et/FW
  (NP al./NN)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This clarity', 'investors businesses', 'big data', 'Lee', 'Chen', 'M.', 'al.']

>> Named Entities are: 
 [('PERSON', 'Lee'), ('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('clarity', 'clariti'), ('helps', 'help'), ('investors', 'investor'), ('businesses', 'busi'), ('think', 'think'), ('positively', 'posit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Lee', 'lee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('clarity', 'clariti'), ('helps', 'help'), ('investors', 'investor'), ('businesses', 'busi'), ('think', 'think'), ('positively', 'posit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Lee', 'lee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('clarity', 'clarity'), ('helps', 'help'), ('investors', 'investor'), ('businesses', 'business'), ('think', 'think'), ('positively', 'positively'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Lee', 'Lee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 68 =============================

With regard to society, big data analytics help to address economic problems such as allocating   funds, making strategic decisions, immigration problems, and healthcare problems such as cost   pressures on hospitals, adding an extra dimension to addressing such societal problems (Chen et   al., 2012). 


>> Tokens are: 
 ['With', 'regard', 'society', ',', 'big', 'data', 'analytics', 'help', 'address', 'economic', 'problems', 'allocating', 'funds', ',', 'making', 'strategic', 'decisions', ',', 'immigration', 'problems', ',', 'healthcare', 'problems', 'cost', 'pressures', 'hospitals', ',', 'adding', 'extra', 'dimension', 'addressing', 'societal', 'problems', '(', 'Chen', 'et', 'al.', ',', '2012', ')', '.']

>> Bigrams are: 
 [('With', 'regard'), ('regard', 'society'), ('society', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'help'), ('help', 'address'), ('address', 'economic'), ('economic', 'problems'), ('problems', 'allocating'), ('allocating', 'funds'), ('funds', ','), (',', 'making'), ('making', 'strategic'), ('strategic', 'decisions'), ('decisions', ','), (',', 'immigration'), ('immigration', 'problems'), ('problems', ','), (',', 'healthcare'), ('healthcare', 'problems'), ('problems', 'cost'), ('cost', 'pressures'), ('pressures', 'hospitals'), ('hospitals', ','), (',', 'adding'), ('adding', 'extra'), ('extra', 'dimension'), ('dimension', 'addressing'), ('addressing', 'societal'), ('societal', 'problems'), ('problems', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('With', 'regard', 'society'), ('regard', 'society', ','), ('society', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'help'), ('analytics', 'help', 'address'), ('help', 'address', 'economic'), ('address', 'economic', 'problems'), ('economic', 'problems', 'allocating'), ('problems', 'allocating', 'funds'), ('allocating', 'funds', ','), ('funds', ',', 'making'), (',', 'making', 'strategic'), ('making', 'strategic', 'decisions'), ('strategic', 'decisions', ','), ('decisions', ',', 'immigration'), (',', 'immigration', 'problems'), ('immigration', 'problems', ','), ('problems', ',', 'healthcare'), (',', 'healthcare', 'problems'), ('healthcare', 'problems', 'cost'), ('problems', 'cost', 'pressures'), ('cost', 'pressures', 'hospitals'), ('pressures', 'hospitals', ','), ('hospitals', ',', 'adding'), (',', 'adding', 'extra'), ('adding', 'extra', 'dimension'), ('extra', 'dimension', 'addressing'), ('dimension', 'addressing', 'societal'), ('addressing', 'societal', 'problems'), ('societal', 'problems', '('), ('problems', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('With', 'IN'), ('regard', 'JJ'), ('society', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('help', 'NN'), ('address', 'VB'), ('economic', 'JJ'), ('problems', 'NNS'), ('allocating', 'VBG'), ('funds', 'NNS'), (',', ','), ('making', 'VBG'), ('strategic', 'JJ'), ('decisions', 'NNS'), (',', ','), ('immigration', 'NN'), ('problems', 'NNS'), (',', ','), ('healthcare', 'VB'), ('problems', 'NNS'), ('cost', 'NN'), ('pressures', 'NNS'), ('hospitals', 'NNS'), (',', ','), ('adding', 'VBG'), ('extra', 'JJ'), ('dimension', 'NN'), ('addressing', 'VBG'), ('societal', 'JJ'), ('problems', 'NNS'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2012', 'CD'), (')', ')'), ('.', '.')]

 (S
  With/IN
  (NP regard/JJ society/NN)
  ,/,
  (NP big/JJ data/NN analytics/NNS help/NN)
  address/VB
  (NP economic/JJ problems/NNS)
  allocating/VBG
  (NP funds/NNS)
  ,/,
  making/VBG
  (NP strategic/JJ decisions/NNS)
  ,/,
  (NP immigration/NN problems/NNS)
  ,/,
  healthcare/VB
  (NP problems/NNS cost/NN pressures/NNS hospitals/NNS)
  ,/,
  adding/VBG
  (NP extra/JJ dimension/NN)
  addressing/VBG
  (NP societal/JJ problems/NNS)
  (/(
  (NP Chen/NNP)
  et/VBZ
  al./RB
  ,/,
  2012/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['regard society', 'big data analytics help', 'economic problems', 'funds', 'strategic decisions', 'immigration problems', 'problems cost pressures hospitals', 'extra dimension', 'societal problems', 'Chen']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('With', 'with'), ('regard', 'regard'), ('society', 'societi'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('address', 'address'), ('economic', 'econom'), ('problems', 'problem'), ('allocating', 'alloc'), ('funds', 'fund'), (',', ','), ('making', 'make'), ('strategic', 'strateg'), ('decisions', 'decis'), (',', ','), ('immigration', 'immigr'), ('problems', 'problem'), (',', ','), ('healthcare', 'healthcar'), ('problems', 'problem'), ('cost', 'cost'), ('pressures', 'pressur'), ('hospitals', 'hospit'), (',', ','), ('adding', 'ad'), ('extra', 'extra'), ('dimension', 'dimens'), ('addressing', 'address'), ('societal', 'societ'), ('problems', 'problem'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('With', 'with'), ('regard', 'regard'), ('society', 'societi'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('help', 'help'), ('address', 'address'), ('economic', 'econom'), ('problems', 'problem'), ('allocating', 'alloc'), ('funds', 'fund'), (',', ','), ('making', 'make'), ('strategic', 'strateg'), ('decisions', 'decis'), (',', ','), ('immigration', 'immigr'), ('problems', 'problem'), (',', ','), ('healthcare', 'healthcar'), ('problems', 'problem'), ('cost', 'cost'), ('pressures', 'pressur'), ('hospitals', 'hospit'), (',', ','), ('adding', 'ad'), ('extra', 'extra'), ('dimension', 'dimens'), ('addressing', 'address'), ('societal', 'societ'), ('problems', 'problem'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('With', 'With'), ('regard', 'regard'), ('society', 'society'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('help', 'help'), ('address', 'address'), ('economic', 'economic'), ('problems', 'problem'), ('allocating', 'allocating'), ('funds', 'fund'), (',', ','), ('making', 'making'), ('strategic', 'strategic'), ('decisions', 'decision'), (',', ','), ('immigration', 'immigration'), ('problems', 'problem'), (',', ','), ('healthcare', 'healthcare'), ('problems', 'problem'), ('cost', 'cost'), ('pressures', 'pressure'), ('hospitals', 'hospital'), (',', ','), ('adding', 'adding'), ('extra', 'extra'), ('dimension', 'dimension'), ('addressing', 'addressing'), ('societal', 'societal'), ('problems', 'problem'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]



============================ Sentence 69 =============================

Sarah Al-Shiakhli   3      3. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '3', '3', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '3'), ('3', '3'), ('3', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '3'), ('Al-Shiakhli', '3', '3'), ('3', '3', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('3', 'CD'), ('3', 'CD'), ('.', '.')]

 (S (NP Sarah/NNP Al-Shiakhli/NNP) 3/CD 3/CD ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('3', '3'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('3', '3'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('3', '3'), ('3', '3'), ('.', '.')]



============================ Sentence 70 =============================

Research Method    The research method for this work is a classic literature review, which is important because big   data analytics is a vital modern topic that requires a solid research base. 


>> Tokens are: 
 ['Research', 'Method', 'The', 'research', 'method', 'work', 'classic', 'literature', 'review', ',', 'important', 'big', 'data', 'analytics', 'vital', 'modern', 'topic', 'requires', 'solid', 'research', 'base', '.']

>> Bigrams are: 
 [('Research', 'Method'), ('Method', 'The'), ('The', 'research'), ('research', 'method'), ('method', 'work'), ('work', 'classic'), ('classic', 'literature'), ('literature', 'review'), ('review', ','), (',', 'important'), ('important', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'vital'), ('vital', 'modern'), ('modern', 'topic'), ('topic', 'requires'), ('requires', 'solid'), ('solid', 'research'), ('research', 'base'), ('base', '.')]

>> Trigrams are: 
 [('Research', 'Method', 'The'), ('Method', 'The', 'research'), ('The', 'research', 'method'), ('research', 'method', 'work'), ('method', 'work', 'classic'), ('work', 'classic', 'literature'), ('classic', 'literature', 'review'), ('literature', 'review', ','), ('review', ',', 'important'), (',', 'important', 'big'), ('important', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'vital'), ('analytics', 'vital', 'modern'), ('vital', 'modern', 'topic'), ('modern', 'topic', 'requires'), ('topic', 'requires', 'solid'), ('requires', 'solid', 'research'), ('solid', 'research', 'base'), ('research', 'base', '.')]

>> POS Tags are: 
 [('Research', 'NN'), ('Method', 'NNP'), ('The', 'DT'), ('research', 'NN'), ('method', 'NN'), ('work', 'NN'), ('classic', 'JJ'), ('literature', 'NN'), ('review', 'NN'), (',', ','), ('important', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('vital', 'JJ'), ('modern', 'JJ'), ('topic', 'NN'), ('requires', 'VBZ'), ('solid', 'JJ'), ('research', 'NN'), ('base', 'NN'), ('.', '.')]

 (S
  (NP Research/NN Method/NNP)
  (NP The/DT research/NN method/NN work/NN)
  (NP classic/JJ literature/NN review/NN)
  ,/,
  (NP important/JJ big/JJ data/NNS analytics/NNS)
  (NP vital/JJ modern/JJ topic/NN)
  requires/VBZ
  (NP solid/JJ research/NN base/NN)
  ./.) 


>> Noun Phrases are: 
 ['Research Method', 'The research method work', 'classic literature review', 'important big data analytics', 'vital modern topic', 'solid research base']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Method', 'method'), ('The', 'the'), ('research', 'research'), ('method', 'method'), ('work', 'work'), ('classic', 'classic'), ('literature', 'literatur'), ('review', 'review'), (',', ','), ('important', 'import'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('vital', 'vital'), ('modern', 'modern'), ('topic', 'topic'), ('requires', 'requir'), ('solid', 'solid'), ('research', 'research'), ('base', 'base'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Method', 'method'), ('The', 'the'), ('research', 'research'), ('method', 'method'), ('work', 'work'), ('classic', 'classic'), ('literature', 'literatur'), ('review', 'review'), (',', ','), ('important', 'import'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('vital', 'vital'), ('modern', 'modern'), ('topic', 'topic'), ('requires', 'requir'), ('solid', 'solid'), ('research', 'research'), ('base', 'base'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Method', 'Method'), ('The', 'The'), ('research', 'research'), ('method', 'method'), ('work', 'work'), ('classic', 'classic'), ('literature', 'literature'), ('review', 'review'), (',', ','), ('important', 'important'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('vital', 'vital'), ('modern', 'modern'), ('topic', 'topic'), ('requires', 'requires'), ('solid', 'solid'), ('research', 'research'), ('base', 'base'), ('.', '.')]



============================ Sentence 71 =============================

A literature review   reconstructs the knowledge available in a specific domain to support a subsequent literature   analysis. 


>> Tokens are: 
 ['A', 'literature', 'review', 'reconstructs', 'knowledge', 'available', 'specific', 'domain', 'support', 'subsequent', 'literature', 'analysis', '.']

>> Bigrams are: 
 [('A', 'literature'), ('literature', 'review'), ('review', 'reconstructs'), ('reconstructs', 'knowledge'), ('knowledge', 'available'), ('available', 'specific'), ('specific', 'domain'), ('domain', 'support'), ('support', 'subsequent'), ('subsequent', 'literature'), ('literature', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('A', 'literature', 'review'), ('literature', 'review', 'reconstructs'), ('review', 'reconstructs', 'knowledge'), ('reconstructs', 'knowledge', 'available'), ('knowledge', 'available', 'specific'), ('available', 'specific', 'domain'), ('specific', 'domain', 'support'), ('domain', 'support', 'subsequent'), ('support', 'subsequent', 'literature'), ('subsequent', 'literature', 'analysis'), ('literature', 'analysis', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('reconstructs', 'NNS'), ('knowledge', 'VBP'), ('available', 'JJ'), ('specific', 'JJ'), ('domain', 'NN'), ('support', 'NN'), ('subsequent', 'JJ'), ('literature', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP A/DT literature/NN review/NN reconstructs/NNS)
  knowledge/VBP
  (NP available/JJ specific/JJ domain/NN support/NN)
  (NP subsequent/JJ literature/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['A literature review reconstructs', 'available specific domain support', 'subsequent literature analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('reconstructs', 'reconstruct'), ('knowledge', 'knowledg'), ('available', 'avail'), ('specific', 'specif'), ('domain', 'domain'), ('support', 'support'), ('subsequent', 'subsequ'), ('literature', 'literatur'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('reconstructs', 'reconstruct'), ('knowledge', 'knowledg'), ('available', 'avail'), ('specific', 'specif'), ('domain', 'domain'), ('support', 'support'), ('subsequent', 'subsequ'), ('literature', 'literatur'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('literature', 'literature'), ('review', 'review'), ('reconstructs', 'reconstructs'), ('knowledge', 'knowledge'), ('available', 'available'), ('specific', 'specific'), ('domain', 'domain'), ('support', 'support'), ('subsequent', 'subsequent'), ('literature', 'literature'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 72 =============================

Many literature review processes are available, and three of the most common are shown   in Figure 1; one of these, most commonly used in the information systems field, is followed in this   work. 


>> Tokens are: 
 ['Many', 'literature', 'review', 'processes', 'available', ',', 'three', 'common', 'shown', 'Figure', '1', ';', 'one', ',', 'commonly', 'used', 'information', 'systems', 'field', ',', 'followed', 'work', '.']

>> Bigrams are: 
 [('Many', 'literature'), ('literature', 'review'), ('review', 'processes'), ('processes', 'available'), ('available', ','), (',', 'three'), ('three', 'common'), ('common', 'shown'), ('shown', 'Figure'), ('Figure', '1'), ('1', ';'), (';', 'one'), ('one', ','), (',', 'commonly'), ('commonly', 'used'), ('used', 'information'), ('information', 'systems'), ('systems', 'field'), ('field', ','), (',', 'followed'), ('followed', 'work'), ('work', '.')]

>> Trigrams are: 
 [('Many', 'literature', 'review'), ('literature', 'review', 'processes'), ('review', 'processes', 'available'), ('processes', 'available', ','), ('available', ',', 'three'), (',', 'three', 'common'), ('three', 'common', 'shown'), ('common', 'shown', 'Figure'), ('shown', 'Figure', '1'), ('Figure', '1', ';'), ('1', ';', 'one'), (';', 'one', ','), ('one', ',', 'commonly'), (',', 'commonly', 'used'), ('commonly', 'used', 'information'), ('used', 'information', 'systems'), ('information', 'systems', 'field'), ('systems', 'field', ','), ('field', ',', 'followed'), (',', 'followed', 'work'), ('followed', 'work', '.')]

>> POS Tags are: 
 [('Many', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('processes', 'VBZ'), ('available', 'JJ'), (',', ','), ('three', 'CD'), ('common', 'JJ'), ('shown', 'VBN'), ('Figure', 'NNP'), ('1', 'CD'), (';', ':'), ('one', 'CD'), (',', ','), ('commonly', 'RB'), ('used', 'VBN'), ('information', 'NN'), ('systems', 'NNS'), ('field', 'NN'), (',', ','), ('followed', 'VBD'), ('work', 'NN'), ('.', '.')]

 (S
  (NP Many/JJ literature/NN review/NN)
  processes/VBZ
  available/JJ
  ,/,
  three/CD
  common/JJ
  shown/VBN
  (NP Figure/NNP)
  1/CD
  ;/:
  one/CD
  ,/,
  commonly/RB
  used/VBN
  (NP information/NN systems/NNS field/NN)
  ,/,
  followed/VBD
  (NP work/NN)
  ./.) 


>> Noun Phrases are: 
 ['Many literature review', 'Figure', 'information systems field', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Many', 'mani'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('available', 'avail'), (',', ','), ('three', 'three'), ('common', 'common'), ('shown', 'shown'), ('Figure', 'figur'), ('1', '1'), (';', ';'), ('one', 'one'), (',', ','), ('commonly', 'commonli'), ('used', 'use'), ('information', 'inform'), ('systems', 'system'), ('field', 'field'), (',', ','), ('followed', 'follow'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Many', 'mani'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('available', 'avail'), (',', ','), ('three', 'three'), ('common', 'common'), ('shown', 'shown'), ('Figure', 'figur'), ('1', '1'), (';', ';'), ('one', 'one'), (',', ','), ('commonly', 'common'), ('used', 'use'), ('information', 'inform'), ('systems', 'system'), ('field', 'field'), (',', ','), ('followed', 'follow'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('Many', 'Many'), ('literature', 'literature'), ('review', 'review'), ('processes', 'process'), ('available', 'available'), (',', ','), ('three', 'three'), ('common', 'common'), ('shown', 'shown'), ('Figure', 'Figure'), ('1', '1'), (';', ';'), ('one', 'one'), (',', ','), ('commonly', 'commonly'), ('used', 'used'), ('information', 'information'), ('systems', 'system'), ('field', 'field'), (',', ','), ('followed', 'followed'), ('work', 'work'), ('.', '.')]



============================ Sentence 73 =============================

Figure 1: Approaches to writing an IS literature review. 


>> Tokens are: 
 ['Figure', '1', ':', 'Approaches', 'writing', 'IS', 'literature', 'review', '.']

>> Bigrams are: 
 [('Figure', '1'), ('1', ':'), (':', 'Approaches'), ('Approaches', 'writing'), ('writing', 'IS'), ('IS', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Figure', '1', ':'), ('1', ':', 'Approaches'), (':', 'Approaches', 'writing'), ('Approaches', 'writing', 'IS'), ('writing', 'IS', 'literature'), ('IS', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('1', 'CD'), (':', ':'), ('Approaches', 'NNS'), ('writing', 'VBG'), ('IS', 'NNP'), ('literature', 'JJ'), ('review', 'NN'), ('.', '.')]

 (S
  (NP Figure/NN)
  1/CD
  :/:
  (NP Approaches/NNS)
  writing/VBG
  (NP IS/NNP)
  (NP literature/JJ review/NN)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Approaches', 'IS', 'literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('1', '1'), (':', ':'), ('Approaches', 'approach'), ('writing', 'write'), ('IS', 'is'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('1', '1'), (':', ':'), ('Approaches', 'approach'), ('writing', 'write'), ('IS', 'is'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('1', '1'), (':', ':'), ('Approaches', 'Approaches'), ('writing', 'writing'), ('IS', 'IS'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]



============================ Sentence 74 =============================

Sarah Al-Shiakhli   4      A literature search according to Webster and Watson (2002), as shown in Figure 2, includes, the   querying of scholarly databases with keywords and backward or forward searches on the basis of   relevant articles discovered. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '4', 'A', 'literature', 'search', 'according', 'Webster', 'Watson', '(', '2002', ')', ',', 'shown', 'Figure', '2', ',', 'includes', ',', 'querying', 'scholarly', 'databases', 'keywords', 'backward', 'forward', 'searches', 'basis', 'relevant', 'articles', 'discovered', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '4'), ('4', 'A'), ('A', 'literature'), ('literature', 'search'), ('search', 'according'), ('according', 'Webster'), ('Webster', 'Watson'), ('Watson', '('), ('(', '2002'), ('2002', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '2'), ('2', ','), (',', 'includes'), ('includes', ','), (',', 'querying'), ('querying', 'scholarly'), ('scholarly', 'databases'), ('databases', 'keywords'), ('keywords', 'backward'), ('backward', 'forward'), ('forward', 'searches'), ('searches', 'basis'), ('basis', 'relevant'), ('relevant', 'articles'), ('articles', 'discovered'), ('discovered', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '4'), ('Al-Shiakhli', '4', 'A'), ('4', 'A', 'literature'), ('A', 'literature', 'search'), ('literature', 'search', 'according'), ('search', 'according', 'Webster'), ('according', 'Webster', 'Watson'), ('Webster', 'Watson', '('), ('Watson', '(', '2002'), ('(', '2002', ')'), ('2002', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '2'), ('Figure', '2', ','), ('2', ',', 'includes'), (',', 'includes', ','), ('includes', ',', 'querying'), (',', 'querying', 'scholarly'), ('querying', 'scholarly', 'databases'), ('scholarly', 'databases', 'keywords'), ('databases', 'keywords', 'backward'), ('keywords', 'backward', 'forward'), ('backward', 'forward', 'searches'), ('forward', 'searches', 'basis'), ('searches', 'basis', 'relevant'), ('basis', 'relevant', 'articles'), ('relevant', 'articles', 'discovered'), ('articles', 'discovered', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('4', 'CD'), ('A', 'NNP'), ('literature', 'NN'), ('search', 'NN'), ('according', 'VBG'), ('Webster', 'NNP'), ('Watson', 'NNP'), ('(', '('), ('2002', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NNP'), ('2', 'CD'), (',', ','), ('includes', 'VBZ'), (',', ','), ('querying', 'VBG'), ('scholarly', 'JJ'), ('databases', 'NNS'), ('keywords', 'NNS'), ('backward', 'RB'), ('forward', 'RB'), ('searches', 'VBZ'), ('basis', 'NN'), ('relevant', 'JJ'), ('articles', 'NNS'), ('discovered', 'VBN'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  4/CD
  (NP A/NNP literature/NN search/NN)
  according/VBG
  (NP Webster/NNP Watson/NNP)
  (/(
  2002/CD
  )/)
  ,/,
  shown/VBN
  (NP Figure/NNP)
  2/CD
  ,/,
  includes/VBZ
  ,/,
  querying/VBG
  (NP scholarly/JJ databases/NNS keywords/NNS)
  backward/RB
  forward/RB
  searches/VBZ
  (NP basis/NN)
  (NP relevant/JJ articles/NNS)
  discovered/VBN
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'A literature search', 'Webster Watson', 'Figure', 'scholarly databases keywords', 'basis', 'relevant articles']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Webster Watson')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('4', '4'), ('A', 'a'), ('literature', 'literatur'), ('search', 'search'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('2', '2'), (',', ','), ('includes', 'includ'), (',', ','), ('querying', 'queri'), ('scholarly', 'scholarli'), ('databases', 'databas'), ('keywords', 'keyword'), ('backward', 'backward'), ('forward', 'forward'), ('searches', 'search'), ('basis', 'basi'), ('relevant', 'relev'), ('articles', 'articl'), ('discovered', 'discov'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('4', '4'), ('A', 'a'), ('literature', 'literatur'), ('search', 'search'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('2', '2'), (',', ','), ('includes', 'includ'), (',', ','), ('querying', 'queri'), ('scholarly', 'scholar'), ('databases', 'databas'), ('keywords', 'keyword'), ('backward', 'backward'), ('forward', 'forward'), ('searches', 'search'), ('basis', 'basi'), ('relevant', 'relev'), ('articles', 'articl'), ('discovered', 'discov'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('4', '4'), ('A', 'A'), ('literature', 'literature'), ('search', 'search'), ('according', 'according'), ('Webster', 'Webster'), ('Watson', 'Watson'), ('(', '('), ('2002', '2002'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('2', '2'), (',', ','), ('includes', 'includes'), (',', ','), ('querying', 'querying'), ('scholarly', 'scholarly'), ('databases', 'database'), ('keywords', 'keywords'), ('backward', 'backward'), ('forward', 'forward'), ('searches', 'search'), ('basis', 'basis'), ('relevant', 'relevant'), ('articles', 'article'), ('discovered', 'discovered'), ('.', '.')]



============================ Sentence 75 =============================

This type of research is used for conducting many literature reviews   and can be used to support a researcher’s ideas at a given time. 


>> Tokens are: 
 ['This', 'type', 'research', 'used', 'conducting', 'many', 'literature', 'reviews', 'used', 'support', 'researcher', '’', 'ideas', 'given', 'time', '.']

>> Bigrams are: 
 [('This', 'type'), ('type', 'research'), ('research', 'used'), ('used', 'conducting'), ('conducting', 'many'), ('many', 'literature'), ('literature', 'reviews'), ('reviews', 'used'), ('used', 'support'), ('support', 'researcher'), ('researcher', '’'), ('’', 'ideas'), ('ideas', 'given'), ('given', 'time'), ('time', '.')]

>> Trigrams are: 
 [('This', 'type', 'research'), ('type', 'research', 'used'), ('research', 'used', 'conducting'), ('used', 'conducting', 'many'), ('conducting', 'many', 'literature'), ('many', 'literature', 'reviews'), ('literature', 'reviews', 'used'), ('reviews', 'used', 'support'), ('used', 'support', 'researcher'), ('support', 'researcher', '’'), ('researcher', '’', 'ideas'), ('’', 'ideas', 'given'), ('ideas', 'given', 'time'), ('given', 'time', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('type', 'NN'), ('research', 'NN'), ('used', 'VBD'), ('conducting', 'VBG'), ('many', 'JJ'), ('literature', 'NN'), ('reviews', 'NNS'), ('used', 'VBD'), ('support', 'NN'), ('researcher', 'NN'), ('’', 'NNP'), ('ideas', 'NNS'), ('given', 'VBN'), ('time', 'NN'), ('.', '.')]

 (S
  (NP This/DT type/NN research/NN)
  used/VBD
  conducting/VBG
  (NP many/JJ literature/NN reviews/NNS)
  used/VBD
  (NP support/NN researcher/NN ’/NNP ideas/NNS)
  given/VBN
  (NP time/NN)
  ./.) 


>> Noun Phrases are: 
 ['This type research', 'many literature reviews', 'support researcher ’ ideas', 'time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('type', 'type'), ('research', 'research'), ('used', 'use'), ('conducting', 'conduct'), ('many', 'mani'), ('literature', 'literatur'), ('reviews', 'review'), ('used', 'use'), ('support', 'support'), ('researcher', 'research'), ('’', '’'), ('ideas', 'idea'), ('given', 'given'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('type', 'type'), ('research', 'research'), ('used', 'use'), ('conducting', 'conduct'), ('many', 'mani'), ('literature', 'literatur'), ('reviews', 'review'), ('used', 'use'), ('support', 'support'), ('researcher', 'research'), ('’', '’'), ('ideas', 'idea'), ('given', 'given'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('type', 'type'), ('research', 'research'), ('used', 'used'), ('conducting', 'conducting'), ('many', 'many'), ('literature', 'literature'), ('reviews', 'review'), ('used', 'used'), ('support', 'support'), ('researcher', 'researcher'), ('’', '’'), ('ideas', 'idea'), ('given', 'given'), ('time', 'time'), ('.', '.')]



============================ Sentence 76 =============================

It includes citation searching, which   allows the use of applicable articles both backwards and forwards in time. 


>> Tokens are: 
 ['It', 'includes', 'citation', 'searching', ',', 'allows', 'use', 'applicable', 'articles', 'backwards', 'forwards', 'time', '.']

>> Bigrams are: 
 [('It', 'includes'), ('includes', 'citation'), ('citation', 'searching'), ('searching', ','), (',', 'allows'), ('allows', 'use'), ('use', 'applicable'), ('applicable', 'articles'), ('articles', 'backwards'), ('backwards', 'forwards'), ('forwards', 'time'), ('time', '.')]

>> Trigrams are: 
 [('It', 'includes', 'citation'), ('includes', 'citation', 'searching'), ('citation', 'searching', ','), ('searching', ',', 'allows'), (',', 'allows', 'use'), ('allows', 'use', 'applicable'), ('use', 'applicable', 'articles'), ('applicable', 'articles', 'backwards'), ('articles', 'backwards', 'forwards'), ('backwards', 'forwards', 'time'), ('forwards', 'time', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('includes', 'VBZ'), ('citation', 'NN'), ('searching', 'NN'), (',', ','), ('allows', 'VBZ'), ('use', 'VBP'), ('applicable', 'JJ'), ('articles', 'NNS'), ('backwards', 'NNS'), ('forwards', 'NNS'), ('time', 'NN'), ('.', '.')]

 (S
  It/PRP
  includes/VBZ
  (NP citation/NN searching/NN)
  ,/,
  allows/VBZ
  use/VBP
  (NP applicable/JJ articles/NNS backwards/NNS forwards/NNS time/NN)
  ./.) 


>> Noun Phrases are: 
 ['citation searching', 'applicable articles backwards forwards time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('includes', 'includ'), ('citation', 'citat'), ('searching', 'search'), (',', ','), ('allows', 'allow'), ('use', 'use'), ('applicable', 'applic'), ('articles', 'articl'), ('backwards', 'backward'), ('forwards', 'forward'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('includes', 'includ'), ('citation', 'citat'), ('searching', 'search'), (',', ','), ('allows', 'allow'), ('use', 'use'), ('applicable', 'applic'), ('articles', 'articl'), ('backwards', 'backward'), ('forwards', 'forward'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('includes', 'includes'), ('citation', 'citation'), ('searching', 'searching'), (',', ','), ('allows', 'allows'), ('use', 'use'), ('applicable', 'applicable'), ('articles', 'article'), ('backwards', 'backwards'), ('forwards', 'forward'), ('time', 'time'), ('.', '.')]



============================ Sentence 77 =============================

Reviewing such an   article’s references list to identify older articles that influenced or contributed to the author's work   is called a backward search, while finding more recent articles that cite the article is called a   forward search. 


>> Tokens are: 
 ['Reviewing', 'article', '’', 'references', 'list', 'identify', 'older', 'articles', 'influenced', 'contributed', 'author', "'s", 'work', 'called', 'backward', 'search', ',', 'finding', 'recent', 'articles', 'cite', 'article', 'called', 'forward', 'search', '.']

>> Bigrams are: 
 [('Reviewing', 'article'), ('article', '’'), ('’', 'references'), ('references', 'list'), ('list', 'identify'), ('identify', 'older'), ('older', 'articles'), ('articles', 'influenced'), ('influenced', 'contributed'), ('contributed', 'author'), ('author', "'s"), ("'s", 'work'), ('work', 'called'), ('called', 'backward'), ('backward', 'search'), ('search', ','), (',', 'finding'), ('finding', 'recent'), ('recent', 'articles'), ('articles', 'cite'), ('cite', 'article'), ('article', 'called'), ('called', 'forward'), ('forward', 'search'), ('search', '.')]

>> Trigrams are: 
 [('Reviewing', 'article', '’'), ('article', '’', 'references'), ('’', 'references', 'list'), ('references', 'list', 'identify'), ('list', 'identify', 'older'), ('identify', 'older', 'articles'), ('older', 'articles', 'influenced'), ('articles', 'influenced', 'contributed'), ('influenced', 'contributed', 'author'), ('contributed', 'author', "'s"), ('author', "'s", 'work'), ("'s", 'work', 'called'), ('work', 'called', 'backward'), ('called', 'backward', 'search'), ('backward', 'search', ','), ('search', ',', 'finding'), (',', 'finding', 'recent'), ('finding', 'recent', 'articles'), ('recent', 'articles', 'cite'), ('articles', 'cite', 'article'), ('cite', 'article', 'called'), ('article', 'called', 'forward'), ('called', 'forward', 'search'), ('forward', 'search', '.')]

>> POS Tags are: 
 [('Reviewing', 'VBG'), ('article', 'NN'), ('’', 'NNP'), ('references', 'NNS'), ('list', 'NN'), ('identify', 'NN'), ('older', 'JJR'), ('articles', 'NNS'), ('influenced', 'VBD'), ('contributed', 'VBD'), ('author', 'NN'), ("'s", 'POS'), ('work', 'NN'), ('called', 'VBN'), ('backward', 'RB'), ('search', 'NN'), (',', ','), ('finding', 'VBG'), ('recent', 'JJ'), ('articles', 'NNS'), ('cite', 'VBP'), ('article', 'NN'), ('called', 'VBN'), ('forward', 'RB'), ('search', 'NN'), ('.', '.')]

 (S
  Reviewing/VBG
  (NP article/NN ’/NNP references/NNS list/NN identify/NN)
  older/JJR
  (NP articles/NNS)
  influenced/VBD
  contributed/VBD
  (NP author/NN)
  's/POS
  (NP work/NN)
  called/VBN
  backward/RB
  (NP search/NN)
  ,/,
  finding/VBG
  (NP recent/JJ articles/NNS)
  cite/VBP
  (NP article/NN)
  called/VBN
  forward/RB
  (NP search/NN)
  ./.) 


>> Noun Phrases are: 
 ['article ’ references list identify', 'articles', 'author', 'work', 'search', 'recent articles', 'article', 'search']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reviewing', 'review'), ('article', 'articl'), ('’', '’'), ('references', 'refer'), ('list', 'list'), ('identify', 'identifi'), ('older', 'older'), ('articles', 'articl'), ('influenced', 'influenc'), ('contributed', 'contribut'), ('author', 'author'), ("'s", "'s"), ('work', 'work'), ('called', 'call'), ('backward', 'backward'), ('search', 'search'), (',', ','), ('finding', 'find'), ('recent', 'recent'), ('articles', 'articl'), ('cite', 'cite'), ('article', 'articl'), ('called', 'call'), ('forward', 'forward'), ('search', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reviewing', 'review'), ('article', 'articl'), ('’', '’'), ('references', 'refer'), ('list', 'list'), ('identify', 'identifi'), ('older', 'older'), ('articles', 'articl'), ('influenced', 'influenc'), ('contributed', 'contribut'), ('author', 'author'), ("'s", "'s"), ('work', 'work'), ('called', 'call'), ('backward', 'backward'), ('search', 'search'), (',', ','), ('finding', 'find'), ('recent', 'recent'), ('articles', 'articl'), ('cite', 'cite'), ('article', 'articl'), ('called', 'call'), ('forward', 'forward'), ('search', 'search'), ('.', '.')]

>> Lemmatization: 
 [('Reviewing', 'Reviewing'), ('article', 'article'), ('’', '’'), ('references', 'reference'), ('list', 'list'), ('identify', 'identify'), ('older', 'older'), ('articles', 'article'), ('influenced', 'influenced'), ('contributed', 'contributed'), ('author', 'author'), ("'s", "'s"), ('work', 'work'), ('called', 'called'), ('backward', 'backward'), ('search', 'search'), (',', ','), ('finding', 'finding'), ('recent', 'recent'), ('articles', 'article'), ('cite', 'cite'), ('article', 'article'), ('called', 'called'), ('forward', 'forward'), ('search', 'search'), ('.', '.')]



============================ Sentence 78 =============================

Figure 2: Research method according to Webster and Watson (2002). 


>> Tokens are: 
 ['Figure', '2', ':', 'Research', 'method', 'according', 'Webster', 'Watson', '(', '2002', ')', '.']

>> Bigrams are: 
 [('Figure', '2'), ('2', ':'), (':', 'Research'), ('Research', 'method'), ('method', 'according'), ('according', 'Webster'), ('Webster', 'Watson'), ('Watson', '('), ('(', '2002'), ('2002', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '2', ':'), ('2', ':', 'Research'), (':', 'Research', 'method'), ('Research', 'method', 'according'), ('method', 'according', 'Webster'), ('according', 'Webster', 'Watson'), ('Webster', 'Watson', '('), ('Watson', '(', '2002'), ('(', '2002', ')'), ('2002', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('2', 'CD'), (':', ':'), ('Research', 'NN'), ('method', 'NN'), ('according', 'VBG'), ('Webster', 'NNP'), ('Watson', 'NNP'), ('(', '('), ('2002', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  2/CD
  :/:
  (NP Research/NN method/NN)
  according/VBG
  (NP Webster/NNP Watson/NNP)
  (/(
  2002/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Research method', 'Webster Watson']

>> Named Entities are: 
 [('PERSON', 'Webster Watson')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('2', '2'), (':', ':'), ('Research', 'research'), ('method', 'method'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('2', '2'), (':', ':'), ('Research', 'research'), ('method', 'method'), ('according', 'accord'), ('Webster', 'webster'), ('Watson', 'watson'), ('(', '('), ('2002', '2002'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('2', '2'), (':', ':'), ('Research', 'Research'), ('method', 'method'), ('according', 'according'), ('Webster', 'Webster'), ('Watson', 'Watson'), ('(', '('), ('2002', '2002'), (')', ')'), ('.', '.')]



============================ Sentence 79 =============================

However, Levy and Ellis (2006) suggest a more systematic framework for a literature review. 


>> Tokens are: 
 ['However', ',', 'Levy', 'Ellis', '(', '2006', ')', 'suggest', 'systematic', 'framework', 'literature', 'review', '.']

>> Bigrams are: 
 [('However', ','), (',', 'Levy'), ('Levy', 'Ellis'), ('Ellis', '('), ('(', '2006'), ('2006', ')'), (')', 'suggest'), ('suggest', 'systematic'), ('systematic', 'framework'), ('framework', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('However', ',', 'Levy'), (',', 'Levy', 'Ellis'), ('Levy', 'Ellis', '('), ('Ellis', '(', '2006'), ('(', '2006', ')'), ('2006', ')', 'suggest'), (')', 'suggest', 'systematic'), ('suggest', 'systematic', 'framework'), ('systematic', 'framework', 'literature'), ('framework', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('Levy', 'NNP'), ('Ellis', 'NNP'), ('(', '('), ('2006', 'CD'), (')', ')'), ('suggest', 'VBP'), ('systematic', 'JJ'), ('framework', 'NN'), ('literature', 'NN'), ('review', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP Levy/NNP Ellis/NNP)
  (/(
  2006/CD
  )/)
  suggest/VBP
  (NP systematic/JJ framework/NN literature/NN review/NN)
  ./.) 


>> Noun Phrases are: 
 ['Levy Ellis', 'systematic framework literature review']

>> Named Entities are: 
 [('PERSON', 'Levy Ellis')] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('Levy', 'levi'), ('Ellis', 'elli'), ('(', '('), ('2006', '2006'), (')', ')'), ('suggest', 'suggest'), ('systematic', 'systemat'), ('framework', 'framework'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('Levy', 'levi'), ('Ellis', 'elli'), ('(', '('), ('2006', '2006'), (')', ')'), ('suggest', 'suggest'), ('systematic', 'systemat'), ('framework', 'framework'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('Levy', 'Levy'), ('Ellis', 'Ellis'), ('(', '('), ('2006', '2006'), (')', ')'), ('suggest', 'suggest'), ('systematic', 'systematic'), ('framework', 'framework'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]



============================ Sentence 80 =============================

A   three-stage approach as shown in Figure 3 is suggested by the proposed framework: 1. 


>> Tokens are: 
 ['A', 'three-stage', 'approach', 'shown', 'Figure', '3', 'suggested', 'proposed', 'framework', ':', '1', '.']

>> Bigrams are: 
 [('A', 'three-stage'), ('three-stage', 'approach'), ('approach', 'shown'), ('shown', 'Figure'), ('Figure', '3'), ('3', 'suggested'), ('suggested', 'proposed'), ('proposed', 'framework'), ('framework', ':'), (':', '1'), ('1', '.')]

>> Trigrams are: 
 [('A', 'three-stage', 'approach'), ('three-stage', 'approach', 'shown'), ('approach', 'shown', 'Figure'), ('shown', 'Figure', '3'), ('Figure', '3', 'suggested'), ('3', 'suggested', 'proposed'), ('suggested', 'proposed', 'framework'), ('proposed', 'framework', ':'), ('framework', ':', '1'), (':', '1', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('three-stage', 'JJ'), ('approach', 'NN'), ('shown', 'VBN'), ('Figure', 'NNP'), ('3', 'CD'), ('suggested', 'VBD'), ('proposed', 'VBN'), ('framework', 'NN'), (':', ':'), ('1', 'CD'), ('.', '.')]

 (S
  (NP A/DT three-stage/JJ approach/NN)
  shown/VBN
  (NP Figure/NNP)
  3/CD
  suggested/VBD
  proposed/VBN
  (NP framework/NN)
  :/:
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['A three-stage approach', 'Figure', 'framework']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('three-stage', 'three-stag'), ('approach', 'approach'), ('shown', 'shown'), ('Figure', 'figur'), ('3', '3'), ('suggested', 'suggest'), ('proposed', 'propos'), ('framework', 'framework'), (':', ':'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('three-stage', 'three-stag'), ('approach', 'approach'), ('shown', 'shown'), ('Figure', 'figur'), ('3', '3'), ('suggested', 'suggest'), ('proposed', 'propos'), ('framework', 'framework'), (':', ':'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('three-stage', 'three-stage'), ('approach', 'approach'), ('shown', 'shown'), ('Figure', 'Figure'), ('3', '3'), ('suggested', 'suggested'), ('proposed', 'proposed'), ('framework', 'framework'), (':', ':'), ('1', '1'), ('.', '.')]



============================ Sentence 81 =============================

Inputs, 2. 


>> Tokens are: 
 ['Inputs', ',', '2', '.']

>> Bigrams are: 
 [('Inputs', ','), (',', '2'), ('2', '.')]

>> Trigrams are: 
 [('Inputs', ',', '2'), (',', '2', '.')]

>> POS Tags are: 
 [('Inputs', 'NNP'), (',', ','), ('2', 'CD'), ('.', '.')]

 (S (NP Inputs/NNP) ,/, 2/CD ./.) 


>> Noun Phrases are: 
 ['Inputs']

>> Named Entities are: 
 [('GPE', 'Inputs')] 

>> Stemming using Porter Stemmer: 
 [('Inputs', 'input'), (',', ','), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inputs', 'input'), (',', ','), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Inputs', 'Inputs'), (',', ','), ('2', '2'), ('.', '.')]



============================ Sentence 82 =============================

Processing, 3. 


>> Tokens are: 
 ['Processing', ',', '3', '.']

>> Bigrams are: 
 [('Processing', ','), (',', '3'), ('3', '.')]

>> Trigrams are: 
 [('Processing', ',', '3'), (',', '3', '.')]

>> POS Tags are: 
 [('Processing', 'NN'), (',', ','), ('3', 'CD'), ('.', '.')]

 (S (NP Processing/NN) ,/, 3/CD ./.) 


>> Noun Phrases are: 
 ['Processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Processing', 'process'), (',', ','), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Processing', 'process'), (',', ','), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Processing', 'Processing'), (',', ','), ('3', '3'), ('.', '.')]



============================ Sentence 83 =============================

Outputs. 


>> Tokens are: 
 ['Outputs', '.']

>> Bigrams are: 
 [('Outputs', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Outputs', 'NNS'), ('.', '.')]

 (S (NP Outputs/NNS) ./.) 


>> Noun Phrases are: 
 ['Outputs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Outputs', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Outputs', 'output'), ('.', '.')]

>> Lemmatization: 
 [('Outputs', 'Outputs'), ('.', '.')]



============================ Sentence 84 =============================

The process should include “all sources that contain IS research   publications”, though this is challenging, as it is difficult and complicated to search and analyse   such a vast quantity of articles (Levy and Ellis, 2006). 


>> Tokens are: 
 ['The', 'process', 'include', '“', 'sources', 'contain', 'IS', 'research', 'publications', '”', ',', 'though', 'challenging', ',', 'difficult', 'complicated', 'search', 'analyse', 'vast', 'quantity', 'articles', '(', 'Levy', 'Ellis', ',', '2006', ')', '.']

>> Bigrams are: 
 [('The', 'process'), ('process', 'include'), ('include', '“'), ('“', 'sources'), ('sources', 'contain'), ('contain', 'IS'), ('IS', 'research'), ('research', 'publications'), ('publications', '”'), ('”', ','), (',', 'though'), ('though', 'challenging'), ('challenging', ','), (',', 'difficult'), ('difficult', 'complicated'), ('complicated', 'search'), ('search', 'analyse'), ('analyse', 'vast'), ('vast', 'quantity'), ('quantity', 'articles'), ('articles', '('), ('(', 'Levy'), ('Levy', 'Ellis'), ('Ellis', ','), (',', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'process', 'include'), ('process', 'include', '“'), ('include', '“', 'sources'), ('“', 'sources', 'contain'), ('sources', 'contain', 'IS'), ('contain', 'IS', 'research'), ('IS', 'research', 'publications'), ('research', 'publications', '”'), ('publications', '”', ','), ('”', ',', 'though'), (',', 'though', 'challenging'), ('though', 'challenging', ','), ('challenging', ',', 'difficult'), (',', 'difficult', 'complicated'), ('difficult', 'complicated', 'search'), ('complicated', 'search', 'analyse'), ('search', 'analyse', 'vast'), ('analyse', 'vast', 'quantity'), ('vast', 'quantity', 'articles'), ('quantity', 'articles', '('), ('articles', '(', 'Levy'), ('(', 'Levy', 'Ellis'), ('Levy', 'Ellis', ','), ('Ellis', ',', '2006'), (',', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('include', 'VBP'), ('“', 'JJ'), ('sources', 'NNS'), ('contain', 'VBP'), ('IS', 'NNP'), ('research', 'NN'), ('publications', 'NNS'), ('”', 'VBP'), (',', ','), ('though', 'IN'), ('challenging', 'JJ'), (',', ','), ('difficult', 'JJ'), ('complicated', 'VBN'), ('search', 'NN'), ('analyse', 'NN'), ('vast', 'JJ'), ('quantity', 'NN'), ('articles', 'NNS'), ('(', '('), ('Levy', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('2006', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT process/NN)
  include/VBP
  (NP “/JJ sources/NNS)
  contain/VBP
  (NP IS/NNP research/NN publications/NNS)
  ”/VBP
  ,/,
  though/IN
  challenging/JJ
  ,/,
  difficult/JJ
  complicated/VBN
  (NP search/NN analyse/NN)
  (NP vast/JJ quantity/NN articles/NNS)
  (/(
  (NP Levy/NNP Ellis/NNP)
  ,/,
  2006/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The process', '“ sources', 'IS research publications', 'search analyse', 'vast quantity articles', 'Levy Ellis']

>> Named Entities are: 
 [('ORGANIZATION', 'Levy Ellis')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('include', 'includ'), ('“', '“'), ('sources', 'sourc'), ('contain', 'contain'), ('IS', 'is'), ('research', 'research'), ('publications', 'public'), ('”', '”'), (',', ','), ('though', 'though'), ('challenging', 'challeng'), (',', ','), ('difficult', 'difficult'), ('complicated', 'complic'), ('search', 'search'), ('analyse', 'analys'), ('vast', 'vast'), ('quantity', 'quantiti'), ('articles', 'articl'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('include', 'includ'), ('“', '“'), ('sources', 'sourc'), ('contain', 'contain'), ('IS', 'is'), ('research', 'research'), ('publications', 'public'), ('”', '”'), (',', ','), ('though', 'though'), ('challenging', 'challeng'), (',', ','), ('difficult', 'difficult'), ('complicated', 'complic'), ('search', 'search'), ('analyse', 'analys'), ('vast', 'vast'), ('quantity', 'quantiti'), ('articles', 'articl'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('include', 'include'), ('“', '“'), ('sources', 'source'), ('contain', 'contain'), ('IS', 'IS'), ('research', 'research'), ('publications', 'publication'), ('”', '”'), (',', ','), ('though', 'though'), ('challenging', 'challenging'), (',', ','), ('difficult', 'difficult'), ('complicated', 'complicated'), ('search', 'search'), ('analyse', 'analyse'), ('vast', 'vast'), ('quantity', 'quantity'), ('articles', 'article'), ('(', '('), ('Levy', 'Levy'), ('Ellis', 'Ellis'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]



============================ Sentence 85 =============================

Figure 3: The three stages of the effective literature review process, adopted from (Levy and   Ellis, 2006). 


>> Tokens are: 
 ['Figure', '3', ':', 'The', 'three', 'stages', 'effective', 'literature', 'review', 'process', ',', 'adopted', '(', 'Levy', 'Ellis', ',', '2006', ')', '.']

>> Bigrams are: 
 [('Figure', '3'), ('3', ':'), (':', 'The'), ('The', 'three'), ('three', 'stages'), ('stages', 'effective'), ('effective', 'literature'), ('literature', 'review'), ('review', 'process'), ('process', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Levy'), ('Levy', 'Ellis'), ('Ellis', ','), (',', '2006'), ('2006', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '3', ':'), ('3', ':', 'The'), (':', 'The', 'three'), ('The', 'three', 'stages'), ('three', 'stages', 'effective'), ('stages', 'effective', 'literature'), ('effective', 'literature', 'review'), ('literature', 'review', 'process'), ('review', 'process', ','), ('process', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Levy'), ('(', 'Levy', 'Ellis'), ('Levy', 'Ellis', ','), ('Ellis', ',', '2006'), (',', '2006', ')'), ('2006', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('3', 'CD'), (':', ':'), ('The', 'DT'), ('three', 'CD'), ('stages', 'NNS'), ('effective', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('process', 'NN'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Levy', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('2006', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  3/CD
  :/:
  The/DT
  three/CD
  (NP stages/NNS)
  (NP effective/JJ literature/NN review/NN process/NN)
  ,/,
  adopted/VBN
  (/(
  (NP Levy/NNP Ellis/NNP)
  ,/,
  2006/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'stages', 'effective literature review process', 'Levy Ellis']

>> Named Entities are: 
 [('ORGANIZATION', 'Levy Ellis')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('3', '3'), (':', ':'), ('The', 'the'), ('three', 'three'), ('stages', 'stage'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('process', 'process'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('3', '3'), (':', ':'), ('The', 'the'), ('three', 'three'), ('stages', 'stage'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('process', 'process'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Levy', 'levi'), ('Ellis', 'elli'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('3', '3'), (':', ':'), ('The', 'The'), ('three', 'three'), ('stages', 'stage'), ('effective', 'effective'), ('literature', 'literature'), ('review', 'review'), ('process', 'process'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Levy', 'Levy'), ('Ellis', 'Ellis'), (',', ','), ('2006', '2006'), (')', ')'), ('.', '.')]



============================ Sentence 86 =============================

The third research method, described by Vom Brocke et al. 


>> Tokens are: 
 ['The', 'third', 'research', 'method', ',', 'described', 'Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'third'), ('third', 'research'), ('research', 'method'), ('method', ','), (',', 'described'), ('described', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'third', 'research'), ('third', 'research', 'method'), ('research', 'method', ','), ('method', ',', 'described'), (',', 'described', 'Vom'), ('described', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('research', 'NN'), ('method', 'NN'), (',', ','), ('described', 'VBN'), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  (NP The/DT third/JJ research/NN method/NN)
  ,/,
  described/VBN
  (NP Vom/NNP Brocke/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['The third research method', 'Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('research', 'research'), ('method', 'method'), (',', ','), ('described', 'describ'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('research', 'research'), ('method', 'method'), (',', ','), ('described', 'describ'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('research', 'research'), ('method', 'method'), (',', ','), ('described', 'described'), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 87 =============================

(2009) shows that only five research   papers are required for a review as long as they contain sufficient information and are chosen for   sensible reasons, and that this can be regarded as adding more value to both the authors and the     Sarah Al-Shiakhli   5      community than a review with a broad range of contribution analysis without sufficient   information about where, why, and what literature was obtained. 


>> Tokens are: 
 ['(', '2009', ')', 'shows', 'five', 'research', 'papers', 'required', 'review', 'long', 'contain', 'sufficient', 'information', 'chosen', 'sensible', 'reasons', ',', 'regarded', 'adding', 'value', 'authors', 'Sarah', 'Al-Shiakhli', '5', 'community', 'review', 'broad', 'range', 'contribution', 'analysis', 'without', 'sufficient', 'information', ',', ',', 'literature', 'obtained', '.']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', 'shows'), ('shows', 'five'), ('five', 'research'), ('research', 'papers'), ('papers', 'required'), ('required', 'review'), ('review', 'long'), ('long', 'contain'), ('contain', 'sufficient'), ('sufficient', 'information'), ('information', 'chosen'), ('chosen', 'sensible'), ('sensible', 'reasons'), ('reasons', ','), (',', 'regarded'), ('regarded', 'adding'), ('adding', 'value'), ('value', 'authors'), ('authors', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '5'), ('5', 'community'), ('community', 'review'), ('review', 'broad'), ('broad', 'range'), ('range', 'contribution'), ('contribution', 'analysis'), ('analysis', 'without'), ('without', 'sufficient'), ('sufficient', 'information'), ('information', ','), (',', ','), (',', 'literature'), ('literature', 'obtained'), ('obtained', '.')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', 'shows'), (')', 'shows', 'five'), ('shows', 'five', 'research'), ('five', 'research', 'papers'), ('research', 'papers', 'required'), ('papers', 'required', 'review'), ('required', 'review', 'long'), ('review', 'long', 'contain'), ('long', 'contain', 'sufficient'), ('contain', 'sufficient', 'information'), ('sufficient', 'information', 'chosen'), ('information', 'chosen', 'sensible'), ('chosen', 'sensible', 'reasons'), ('sensible', 'reasons', ','), ('reasons', ',', 'regarded'), (',', 'regarded', 'adding'), ('regarded', 'adding', 'value'), ('adding', 'value', 'authors'), ('value', 'authors', 'Sarah'), ('authors', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '5'), ('Al-Shiakhli', '5', 'community'), ('5', 'community', 'review'), ('community', 'review', 'broad'), ('review', 'broad', 'range'), ('broad', 'range', 'contribution'), ('range', 'contribution', 'analysis'), ('contribution', 'analysis', 'without'), ('analysis', 'without', 'sufficient'), ('without', 'sufficient', 'information'), ('sufficient', 'information', ','), ('information', ',', ','), (',', ',', 'literature'), (',', 'literature', 'obtained'), ('literature', 'obtained', '.')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), ('shows', 'VBZ'), ('five', 'CD'), ('research', 'NN'), ('papers', 'NNS'), ('required', 'VBD'), ('review', 'NN'), ('long', 'RB'), ('contain', 'JJ'), ('sufficient', 'JJ'), ('information', 'NN'), ('chosen', 'VBN'), ('sensible', 'JJ'), ('reasons', 'NNS'), (',', ','), ('regarded', 'VBD'), ('adding', 'VBG'), ('value', 'NN'), ('authors', 'NNS'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('5', 'CD'), ('community', 'NN'), ('review', 'NN'), ('broad', 'JJ'), ('range', 'NN'), ('contribution', 'NN'), ('analysis', 'NN'), ('without', 'IN'), ('sufficient', 'JJ'), ('information', 'NN'), (',', ','), (',', ','), ('literature', 'NN'), ('obtained', 'VBN'), ('.', '.')]

 (S
  (/(
  2009/CD
  )/)
  shows/VBZ
  five/CD
  (NP research/NN papers/NNS)
  required/VBD
  (NP review/NN)
  long/RB
  (NP contain/JJ sufficient/JJ information/NN)
  chosen/VBN
  (NP sensible/JJ reasons/NNS)
  ,/,
  regarded/VBD
  adding/VBG
  (NP value/NN authors/NNS Sarah/NNP Al-Shiakhli/NNP)
  5/CD
  (NP community/NN review/NN)
  (NP broad/JJ range/NN contribution/NN analysis/NN)
  without/IN
  (NP sufficient/JJ information/NN)
  ,/,
  ,/,
  (NP literature/NN)
  obtained/VBN
  ./.) 


>> Noun Phrases are: 
 ['research papers', 'review', 'contain sufficient information', 'sensible reasons', 'value authors Sarah Al-Shiakhli', 'community review', 'broad range contribution analysis', 'sufficient information', 'literature']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('shows', 'show'), ('five', 'five'), ('research', 'research'), ('papers', 'paper'), ('required', 'requir'), ('review', 'review'), ('long', 'long'), ('contain', 'contain'), ('sufficient', 'suffici'), ('information', 'inform'), ('chosen', 'chosen'), ('sensible', 'sensibl'), ('reasons', 'reason'), (',', ','), ('regarded', 'regard'), ('adding', 'ad'), ('value', 'valu'), ('authors', 'author'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('5', '5'), ('community', 'commun'), ('review', 'review'), ('broad', 'broad'), ('range', 'rang'), ('contribution', 'contribut'), ('analysis', 'analysi'), ('without', 'without'), ('sufficient', 'suffici'), ('information', 'inform'), (',', ','), (',', ','), ('literature', 'literatur'), ('obtained', 'obtain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('shows', 'show'), ('five', 'five'), ('research', 'research'), ('papers', 'paper'), ('required', 'requir'), ('review', 'review'), ('long', 'long'), ('contain', 'contain'), ('sufficient', 'suffici'), ('information', 'inform'), ('chosen', 'chosen'), ('sensible', 'sensibl'), ('reasons', 'reason'), (',', ','), ('regarded', 'regard'), ('adding', 'ad'), ('value', 'valu'), ('authors', 'author'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('5', '5'), ('community', 'communiti'), ('review', 'review'), ('broad', 'broad'), ('range', 'rang'), ('contribution', 'contribut'), ('analysis', 'analysi'), ('without', 'without'), ('sufficient', 'suffici'), ('information', 'inform'), (',', ','), (',', ','), ('literature', 'literatur'), ('obtained', 'obtain'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('shows', 'show'), ('five', 'five'), ('research', 'research'), ('papers', 'paper'), ('required', 'required'), ('review', 'review'), ('long', 'long'), ('contain', 'contain'), ('sufficient', 'sufficient'), ('information', 'information'), ('chosen', 'chosen'), ('sensible', 'sensible'), ('reasons', 'reason'), (',', ','), ('regarded', 'regarded'), ('adding', 'adding'), ('value', 'value'), ('authors', 'author'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('5', '5'), ('community', 'community'), ('review', 'review'), ('broad', 'broad'), ('range', 'range'), ('contribution', 'contribution'), ('analysis', 'analysis'), ('without', 'without'), ('sufficient', 'sufficient'), ('information', 'information'), (',', ','), (',', ','), ('literature', 'literature'), ('obtained', 'obtained'), ('.', '.')]



============================ Sentence 88 =============================

Such literature reviews are useful   as any review article must document the literature search process. 


>> Tokens are: 
 ['Such', 'literature', 'reviews', 'useful', 'review', 'article', 'must', 'document', 'literature', 'search', 'process', '.']

>> Bigrams are: 
 [('Such', 'literature'), ('literature', 'reviews'), ('reviews', 'useful'), ('useful', 'review'), ('review', 'article'), ('article', 'must'), ('must', 'document'), ('document', 'literature'), ('literature', 'search'), ('search', 'process'), ('process', '.')]

>> Trigrams are: 
 [('Such', 'literature', 'reviews'), ('literature', 'reviews', 'useful'), ('reviews', 'useful', 'review'), ('useful', 'review', 'article'), ('review', 'article', 'must'), ('article', 'must', 'document'), ('must', 'document', 'literature'), ('document', 'literature', 'search'), ('literature', 'search', 'process'), ('search', 'process', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('literature', 'NN'), ('reviews', 'NNS'), ('useful', 'JJ'), ('review', 'NN'), ('article', 'NN'), ('must', 'MD'), ('document', 'VB'), ('literature', 'NN'), ('search', 'NN'), ('process', 'NN'), ('.', '.')]

 (S
  (NP Such/JJ literature/NN reviews/NNS)
  (NP useful/JJ review/NN article/NN)
  must/MD
  document/VB
  (NP literature/NN search/NN process/NN)
  ./.) 


>> Noun Phrases are: 
 ['Such literature reviews', 'useful review article', 'literature search process']

>> Named Entities are: 
 [('GPE', 'Such')] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('literature', 'literatur'), ('reviews', 'review'), ('useful', 'use'), ('review', 'review'), ('article', 'articl'), ('must', 'must'), ('document', 'document'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('literature', 'literatur'), ('reviews', 'review'), ('useful', 'use'), ('review', 'review'), ('article', 'articl'), ('must', 'must'), ('document', 'document'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('literature', 'literature'), ('reviews', 'review'), ('useful', 'useful'), ('review', 'review'), ('article', 'article'), ('must', 'must'), ('document', 'document'), ('literature', 'literature'), ('search', 'search'), ('process', 'process'), ('.', '.')]



============================ Sentence 89 =============================

This method is based on the   literature review analysis of results gained from ten of the most important information systems   outlets based on a keyword search and a defined time period; it thus deliberately does not consider   taking all available IS research papers or sources and analysing them. 


>> Tokens are: 
 ['This', 'method', 'based', 'literature', 'review', 'analysis', 'results', 'gained', 'ten', 'important', 'information', 'systems', 'outlets', 'based', 'keyword', 'search', 'defined', 'time', 'period', ';', 'thus', 'deliberately', 'consider', 'taking', 'available', 'IS', 'research', 'papers', 'sources', 'analysing', '.']

>> Bigrams are: 
 [('This', 'method'), ('method', 'based'), ('based', 'literature'), ('literature', 'review'), ('review', 'analysis'), ('analysis', 'results'), ('results', 'gained'), ('gained', 'ten'), ('ten', 'important'), ('important', 'information'), ('information', 'systems'), ('systems', 'outlets'), ('outlets', 'based'), ('based', 'keyword'), ('keyword', 'search'), ('search', 'defined'), ('defined', 'time'), ('time', 'period'), ('period', ';'), (';', 'thus'), ('thus', 'deliberately'), ('deliberately', 'consider'), ('consider', 'taking'), ('taking', 'available'), ('available', 'IS'), ('IS', 'research'), ('research', 'papers'), ('papers', 'sources'), ('sources', 'analysing'), ('analysing', '.')]

>> Trigrams are: 
 [('This', 'method', 'based'), ('method', 'based', 'literature'), ('based', 'literature', 'review'), ('literature', 'review', 'analysis'), ('review', 'analysis', 'results'), ('analysis', 'results', 'gained'), ('results', 'gained', 'ten'), ('gained', 'ten', 'important'), ('ten', 'important', 'information'), ('important', 'information', 'systems'), ('information', 'systems', 'outlets'), ('systems', 'outlets', 'based'), ('outlets', 'based', 'keyword'), ('based', 'keyword', 'search'), ('keyword', 'search', 'defined'), ('search', 'defined', 'time'), ('defined', 'time', 'period'), ('time', 'period', ';'), ('period', ';', 'thus'), (';', 'thus', 'deliberately'), ('thus', 'deliberately', 'consider'), ('deliberately', 'consider', 'taking'), ('consider', 'taking', 'available'), ('taking', 'available', 'IS'), ('available', 'IS', 'research'), ('IS', 'research', 'papers'), ('research', 'papers', 'sources'), ('papers', 'sources', 'analysing'), ('sources', 'analysing', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('method', 'NN'), ('based', 'VBN'), ('literature', 'NN'), ('review', 'NN'), ('analysis', 'NN'), ('results', 'NNS'), ('gained', 'VBD'), ('ten', 'JJ'), ('important', 'JJ'), ('information', 'NN'), ('systems', 'NNS'), ('outlets', 'NNS'), ('based', 'VBN'), ('keyword', 'JJ'), ('search', 'NN'), ('defined', 'VBD'), ('time', 'NN'), ('period', 'NN'), (';', ':'), ('thus', 'RB'), ('deliberately', 'RB'), ('consider', 'VB'), ('taking', 'VBG'), ('available', 'JJ'), ('IS', 'NNP'), ('research', 'NN'), ('papers', 'NNS'), ('sources', 'NNS'), ('analysing', 'VBG'), ('.', '.')]

 (S
  (NP This/DT method/NN)
  based/VBN
  (NP literature/NN review/NN analysis/NN results/NNS)
  gained/VBD
  (NP ten/JJ important/JJ information/NN systems/NNS outlets/NNS)
  based/VBN
  (NP keyword/JJ search/NN)
  defined/VBD
  (NP time/NN period/NN)
  ;/:
  thus/RB
  deliberately/RB
  consider/VB
  taking/VBG
  (NP available/JJ IS/NNP research/NN papers/NNS sources/NNS)
  analysing/VBG
  ./.) 


>> Noun Phrases are: 
 ['This method', 'literature review analysis results', 'ten important information systems outlets', 'keyword search', 'time period', 'available IS research papers sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('method', 'method'), ('based', 'base'), ('literature', 'literatur'), ('review', 'review'), ('analysis', 'analysi'), ('results', 'result'), ('gained', 'gain'), ('ten', 'ten'), ('important', 'import'), ('information', 'inform'), ('systems', 'system'), ('outlets', 'outlet'), ('based', 'base'), ('keyword', 'keyword'), ('search', 'search'), ('defined', 'defin'), ('time', 'time'), ('period', 'period'), (';', ';'), ('thus', 'thu'), ('deliberately', 'deliber'), ('consider', 'consid'), ('taking', 'take'), ('available', 'avail'), ('IS', 'is'), ('research', 'research'), ('papers', 'paper'), ('sources', 'sourc'), ('analysing', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('method', 'method'), ('based', 'base'), ('literature', 'literatur'), ('review', 'review'), ('analysis', 'analysi'), ('results', 'result'), ('gained', 'gain'), ('ten', 'ten'), ('important', 'import'), ('information', 'inform'), ('systems', 'system'), ('outlets', 'outlet'), ('based', 'base'), ('keyword', 'keyword'), ('search', 'search'), ('defined', 'defin'), ('time', 'time'), ('period', 'period'), (';', ';'), ('thus', 'thus'), ('deliberately', 'deliber'), ('consider', 'consid'), ('taking', 'take'), ('available', 'avail'), ('IS', 'is'), ('research', 'research'), ('papers', 'paper'), ('sources', 'sourc'), ('analysing', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('method', 'method'), ('based', 'based'), ('literature', 'literature'), ('review', 'review'), ('analysis', 'analysis'), ('results', 'result'), ('gained', 'gained'), ('ten', 'ten'), ('important', 'important'), ('information', 'information'), ('systems', 'system'), ('outlets', 'outlet'), ('based', 'based'), ('keyword', 'keyword'), ('search', 'search'), ('defined', 'defined'), ('time', 'time'), ('period', 'period'), (';', ';'), ('thus', 'thus'), ('deliberately', 'deliberately'), ('consider', 'consider'), ('taking', 'taking'), ('available', 'available'), ('IS', 'IS'), ('research', 'research'), ('papers', 'paper'), ('sources', 'source'), ('analysing', 'analysing'), ('.', '.')]



============================ Sentence 90 =============================

The processes for this are   shown in  Figure 4. 


>> Tokens are: 
 ['The', 'processes', 'shown', 'Figure', '4', '.']

>> Bigrams are: 
 [('The', 'processes'), ('processes', 'shown'), ('shown', 'Figure'), ('Figure', '4'), ('4', '.')]

>> Trigrams are: 
 [('The', 'processes', 'shown'), ('processes', 'shown', 'Figure'), ('shown', 'Figure', '4'), ('Figure', '4', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('processes', 'NNS'), ('shown', 'VBN'), ('Figure', 'NNP'), ('4', 'CD'), ('.', '.')]

 (S (NP The/DT processes/NNS) shown/VBN (NP Figure/NNP) 4/CD ./.) 


>> Noun Phrases are: 
 ['The processes', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('processes', 'process'), ('shown', 'shown'), ('Figure', 'figur'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('processes', 'process'), ('shown', 'shown'), ('Figure', 'figur'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('processes', 'process'), ('shown', 'shown'), ('Figure', 'Figure'), ('4', '4'), ('.', '.')]



============================ Sentence 91 =============================

This research follows the procedure suggested by Vom Brocke et al. 


>> Tokens are: 
 ['This', 'research', 'follows', 'procedure', 'suggested', 'Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('This', 'research'), ('research', 'follows'), ('follows', 'procedure'), ('procedure', 'suggested'), ('suggested', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('This', 'research', 'follows'), ('research', 'follows', 'procedure'), ('follows', 'procedure', 'suggested'), ('procedure', 'suggested', 'Vom'), ('suggested', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('research', 'NN'), ('follows', 'VBZ'), ('procedure', 'NN'), ('suggested', 'VBD'), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  (NP This/DT research/NN)
  follows/VBZ
  (NP procedure/NN)
  suggested/VBD
  (NP Vom/NNP Brocke/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['This research', 'procedure', 'Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('research', 'research'), ('follows', 'follow'), ('procedure', 'procedur'), ('suggested', 'suggest'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('research', 'research'), ('follows', 'follow'), ('procedure', 'procedur'), ('suggested', 'suggest'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('research', 'research'), ('follows', 'follows'), ('procedure', 'procedure'), ('suggested', 'suggested'), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 92 =============================

(2009) for writing a literature   review as this method focuses on choosing papers for sensible reasons. 


>> Tokens are: 
 ['(', '2009', ')', 'writing', 'literature', 'review', 'method', 'focuses', 'choosing', 'papers', 'sensible', 'reasons', '.']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', 'writing'), ('writing', 'literature'), ('literature', 'review'), ('review', 'method'), ('method', 'focuses'), ('focuses', 'choosing'), ('choosing', 'papers'), ('papers', 'sensible'), ('sensible', 'reasons'), ('reasons', '.')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', 'writing'), (')', 'writing', 'literature'), ('writing', 'literature', 'review'), ('literature', 'review', 'method'), ('review', 'method', 'focuses'), ('method', 'focuses', 'choosing'), ('focuses', 'choosing', 'papers'), ('choosing', 'papers', 'sensible'), ('papers', 'sensible', 'reasons'), ('sensible', 'reasons', '.')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), ('writing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), ('method', 'NN'), ('focuses', 'VBZ'), ('choosing', 'VBG'), ('papers', 'NNS'), ('sensible', 'JJ'), ('reasons', 'NNS'), ('.', '.')]

 (S
  (/(
  2009/CD
  )/)
  writing/VBG
  (NP literature/NN review/NN method/NN)
  focuses/VBZ
  choosing/VBG
  (NP papers/NNS)
  (NP sensible/JJ reasons/NNS)
  ./.) 


>> Noun Phrases are: 
 ['literature review method', 'papers', 'sensible reasons']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('writing', 'write'), ('literature', 'literatur'), ('review', 'review'), ('method', 'method'), ('focuses', 'focus'), ('choosing', 'choos'), ('papers', 'paper'), ('sensible', 'sensibl'), ('reasons', 'reason'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('writing', 'write'), ('literature', 'literatur'), ('review', 'review'), ('method', 'method'), ('focuses', 'focus'), ('choosing', 'choos'), ('papers', 'paper'), ('sensible', 'sensibl'), ('reasons', 'reason'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), ('writing', 'writing'), ('literature', 'literature'), ('review', 'review'), ('method', 'method'), ('focuses', 'focus'), ('choosing', 'choosing'), ('papers', 'paper'), ('sensible', 'sensible'), ('reasons', 'reason'), ('.', '.')]



============================ Sentence 93 =============================

The criteria for choice are   dependent on the useful information that can be gained from such papers, the period of interest,   and the number of citations, as well as whether the paper is from a peer-reviewed journal,   conference, or other respectable source. 


>> Tokens are: 
 ['The', 'criteria', 'choice', 'dependent', 'useful', 'information', 'gained', 'papers', ',', 'period', 'interest', ',', 'number', 'citations', ',', 'well', 'whether', 'paper', 'peer-reviewed', 'journal', ',', 'conference', ',', 'respectable', 'source', '.']

>> Bigrams are: 
 [('The', 'criteria'), ('criteria', 'choice'), ('choice', 'dependent'), ('dependent', 'useful'), ('useful', 'information'), ('information', 'gained'), ('gained', 'papers'), ('papers', ','), (',', 'period'), ('period', 'interest'), ('interest', ','), (',', 'number'), ('number', 'citations'), ('citations', ','), (',', 'well'), ('well', 'whether'), ('whether', 'paper'), ('paper', 'peer-reviewed'), ('peer-reviewed', 'journal'), ('journal', ','), (',', 'conference'), ('conference', ','), (',', 'respectable'), ('respectable', 'source'), ('source', '.')]

>> Trigrams are: 
 [('The', 'criteria', 'choice'), ('criteria', 'choice', 'dependent'), ('choice', 'dependent', 'useful'), ('dependent', 'useful', 'information'), ('useful', 'information', 'gained'), ('information', 'gained', 'papers'), ('gained', 'papers', ','), ('papers', ',', 'period'), (',', 'period', 'interest'), ('period', 'interest', ','), ('interest', ',', 'number'), (',', 'number', 'citations'), ('number', 'citations', ','), ('citations', ',', 'well'), (',', 'well', 'whether'), ('well', 'whether', 'paper'), ('whether', 'paper', 'peer-reviewed'), ('paper', 'peer-reviewed', 'journal'), ('peer-reviewed', 'journal', ','), ('journal', ',', 'conference'), (',', 'conference', ','), ('conference', ',', 'respectable'), (',', 'respectable', 'source'), ('respectable', 'source', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('criteria', 'NN'), ('choice', 'NN'), ('dependent', 'JJ'), ('useful', 'JJ'), ('information', 'NN'), ('gained', 'VBD'), ('papers', 'NNS'), (',', ','), ('period', 'NN'), ('interest', 'NN'), (',', ','), ('number', 'NN'), ('citations', 'NNS'), (',', ','), ('well', 'RB'), ('whether', 'IN'), ('paper', 'NN'), ('peer-reviewed', 'JJ'), ('journal', 'NN'), (',', ','), ('conference', 'NN'), (',', ','), ('respectable', 'JJ'), ('source', 'NN'), ('.', '.')]

 (S
  (NP The/DT criteria/NN choice/NN)
  (NP dependent/JJ useful/JJ information/NN)
  gained/VBD
  (NP papers/NNS)
  ,/,
  (NP period/NN interest/NN)
  ,/,
  (NP number/NN citations/NNS)
  ,/,
  well/RB
  whether/IN
  (NP paper/NN)
  (NP peer-reviewed/JJ journal/NN)
  ,/,
  (NP conference/NN)
  ,/,
  (NP respectable/JJ source/NN)
  ./.) 


>> Noun Phrases are: 
 ['The criteria choice', 'dependent useful information', 'papers', 'period interest', 'number citations', 'paper', 'peer-reviewed journal', 'conference', 'respectable source']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('criteria', 'criteria'), ('choice', 'choic'), ('dependent', 'depend'), ('useful', 'use'), ('information', 'inform'), ('gained', 'gain'), ('papers', 'paper'), (',', ','), ('period', 'period'), ('interest', 'interest'), (',', ','), ('number', 'number'), ('citations', 'citat'), (',', ','), ('well', 'well'), ('whether', 'whether'), ('paper', 'paper'), ('peer-reviewed', 'peer-review'), ('journal', 'journal'), (',', ','), ('conference', 'confer'), (',', ','), ('respectable', 'respect'), ('source', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('criteria', 'criteria'), ('choice', 'choic'), ('dependent', 'depend'), ('useful', 'use'), ('information', 'inform'), ('gained', 'gain'), ('papers', 'paper'), (',', ','), ('period', 'period'), ('interest', 'interest'), (',', ','), ('number', 'number'), ('citations', 'citat'), (',', ','), ('well', 'well'), ('whether', 'whether'), ('paper', 'paper'), ('peer-reviewed', 'peer-review'), ('journal', 'journal'), (',', ','), ('conference', 'confer'), (',', ','), ('respectable', 'respect'), ('source', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('criteria', 'criterion'), ('choice', 'choice'), ('dependent', 'dependent'), ('useful', 'useful'), ('information', 'information'), ('gained', 'gained'), ('papers', 'paper'), (',', ','), ('period', 'period'), ('interest', 'interest'), (',', ','), ('number', 'number'), ('citations', 'citation'), (',', ','), ('well', 'well'), ('whether', 'whether'), ('paper', 'paper'), ('peer-reviewed', 'peer-reviewed'), ('journal', 'journal'), (',', ','), ('conference', 'conference'), (',', ','), ('respectable', 'respectable'), ('source', 'source'), ('.', '.')]



============================ Sentence 94 =============================

These criteria are thus not randomly dependent on time   periods or gathering all sources within all of the research field’s publications. 


>> Tokens are: 
 ['These', 'criteria', 'thus', 'randomly', 'dependent', 'time', 'periods', 'gathering', 'sources', 'within', 'research', 'field', '’', 'publications', '.']

>> Bigrams are: 
 [('These', 'criteria'), ('criteria', 'thus'), ('thus', 'randomly'), ('randomly', 'dependent'), ('dependent', 'time'), ('time', 'periods'), ('periods', 'gathering'), ('gathering', 'sources'), ('sources', 'within'), ('within', 'research'), ('research', 'field'), ('field', '’'), ('’', 'publications'), ('publications', '.')]

>> Trigrams are: 
 [('These', 'criteria', 'thus'), ('criteria', 'thus', 'randomly'), ('thus', 'randomly', 'dependent'), ('randomly', 'dependent', 'time'), ('dependent', 'time', 'periods'), ('time', 'periods', 'gathering'), ('periods', 'gathering', 'sources'), ('gathering', 'sources', 'within'), ('sources', 'within', 'research'), ('within', 'research', 'field'), ('research', 'field', '’'), ('field', '’', 'publications'), ('’', 'publications', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('criteria', 'NNS'), ('thus', 'RB'), ('randomly', 'RB'), ('dependent', 'JJ'), ('time', 'NN'), ('periods', 'NNS'), ('gathering', 'VBG'), ('sources', 'NNS'), ('within', 'IN'), ('research', 'NN'), ('field', 'NN'), ('’', 'NNP'), ('publications', 'NNS'), ('.', '.')]

 (S
  (NP These/DT criteria/NNS)
  thus/RB
  randomly/RB
  (NP dependent/JJ time/NN periods/NNS)
  gathering/VBG
  (NP sources/NNS)
  within/IN
  (NP research/NN field/NN ’/NNP publications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['These criteria', 'dependent time periods', 'sources', 'research field ’ publications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('criteria', 'criteria'), ('thus', 'thu'), ('randomly', 'randomli'), ('dependent', 'depend'), ('time', 'time'), ('periods', 'period'), ('gathering', 'gather'), ('sources', 'sourc'), ('within', 'within'), ('research', 'research'), ('field', 'field'), ('’', '’'), ('publications', 'public'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('criteria', 'criteria'), ('thus', 'thus'), ('randomly', 'random'), ('dependent', 'depend'), ('time', 'time'), ('periods', 'period'), ('gathering', 'gather'), ('sources', 'sourc'), ('within', 'within'), ('research', 'research'), ('field', 'field'), ('’', '’'), ('publications', 'public'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('criteria', 'criterion'), ('thus', 'thus'), ('randomly', 'randomly'), ('dependent', 'dependent'), ('time', 'time'), ('periods', 'period'), ('gathering', 'gathering'), ('sources', 'source'), ('within', 'within'), ('research', 'research'), ('field', 'field'), ('’', '’'), ('publications', 'publication'), ('.', '.')]



============================ Sentence 95 =============================

Figure 4: Stages of the effective search for the literature review process1                                                           1 Based on (Vom Brocke et al., 2009)    Select a reference  Sources: Top-ten-ranked peer-reviewed IS  Journals, conferences, or books   Consider Keyword search  Consider Period covered  Consider Number of citations  Consider Literature search    Sarah Al-Shiakhli   6      The literature review processes followed in this thesis are shown in Figure 5. 


>> Tokens are: 
 ['Figure', '4', ':', 'Stages', 'effective', 'search', 'literature', 'review', 'process1', '1', 'Based', '(', 'Vom', 'Brocke', 'et', 'al.', ',', '2009', ')', 'Select', 'reference', 'Sources', ':', 'Top-ten-ranked', 'peer-reviewed', 'IS', 'Journals', ',', 'conferences', ',', 'books', 'Consider', 'Keyword', 'search', 'Consider', 'Period', 'covered', 'Consider', 'Number', 'citations', 'Consider', 'Literature', 'search', 'Sarah', 'Al-Shiakhli', '6', 'The', 'literature', 'review', 'processes', 'followed', 'thesis', 'shown', 'Figure', '5', '.']

>> Bigrams are: 
 [('Figure', '4'), ('4', ':'), (':', 'Stages'), ('Stages', 'effective'), ('effective', 'search'), ('search', 'literature'), ('literature', 'review'), ('review', 'process1'), ('process1', '1'), ('1', 'Based'), ('Based', '('), ('(', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al.'), ('al.', ','), (',', '2009'), ('2009', ')'), (')', 'Select'), ('Select', 'reference'), ('reference', 'Sources'), ('Sources', ':'), (':', 'Top-ten-ranked'), ('Top-ten-ranked', 'peer-reviewed'), ('peer-reviewed', 'IS'), ('IS', 'Journals'), ('Journals', ','), (',', 'conferences'), ('conferences', ','), (',', 'books'), ('books', 'Consider'), ('Consider', 'Keyword'), ('Keyword', 'search'), ('search', 'Consider'), ('Consider', 'Period'), ('Period', 'covered'), ('covered', 'Consider'), ('Consider', 'Number'), ('Number', 'citations'), ('citations', 'Consider'), ('Consider', 'Literature'), ('Literature', 'search'), ('search', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '6'), ('6', 'The'), ('The', 'literature'), ('literature', 'review'), ('review', 'processes'), ('processes', 'followed'), ('followed', 'thesis'), ('thesis', 'shown'), ('shown', 'Figure'), ('Figure', '5'), ('5', '.')]

>> Trigrams are: 
 [('Figure', '4', ':'), ('4', ':', 'Stages'), (':', 'Stages', 'effective'), ('Stages', 'effective', 'search'), ('effective', 'search', 'literature'), ('search', 'literature', 'review'), ('literature', 'review', 'process1'), ('review', 'process1', '1'), ('process1', '1', 'Based'), ('1', 'Based', '('), ('Based', '(', 'Vom'), ('(', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2009'), (',', '2009', ')'), ('2009', ')', 'Select'), (')', 'Select', 'reference'), ('Select', 'reference', 'Sources'), ('reference', 'Sources', ':'), ('Sources', ':', 'Top-ten-ranked'), (':', 'Top-ten-ranked', 'peer-reviewed'), ('Top-ten-ranked', 'peer-reviewed', 'IS'), ('peer-reviewed', 'IS', 'Journals'), ('IS', 'Journals', ','), ('Journals', ',', 'conferences'), (',', 'conferences', ','), ('conferences', ',', 'books'), (',', 'books', 'Consider'), ('books', 'Consider', 'Keyword'), ('Consider', 'Keyword', 'search'), ('Keyword', 'search', 'Consider'), ('search', 'Consider', 'Period'), ('Consider', 'Period', 'covered'), ('Period', 'covered', 'Consider'), ('covered', 'Consider', 'Number'), ('Consider', 'Number', 'citations'), ('Number', 'citations', 'Consider'), ('citations', 'Consider', 'Literature'), ('Consider', 'Literature', 'search'), ('Literature', 'search', 'Sarah'), ('search', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '6'), ('Al-Shiakhli', '6', 'The'), ('6', 'The', 'literature'), ('The', 'literature', 'review'), ('literature', 'review', 'processes'), ('review', 'processes', 'followed'), ('processes', 'followed', 'thesis'), ('followed', 'thesis', 'shown'), ('thesis', 'shown', 'Figure'), ('shown', 'Figure', '5'), ('Figure', '5', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('4', 'CD'), (':', ':'), ('Stages', 'NNS'), ('effective', 'JJ'), ('search', 'NN'), ('literature', 'NN'), ('review', 'NN'), ('process1', 'VBP'), ('1', 'CD'), ('Based', 'VBN'), ('(', '('), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2009', 'CD'), (')', ')'), ('Select', 'NNP'), ('reference', 'NN'), ('Sources', 'NNS'), (':', ':'), ('Top-ten-ranked', 'JJ'), ('peer-reviewed', 'NN'), ('IS', 'NNP'), ('Journals', 'NNP'), (',', ','), ('conferences', 'NNS'), (',', ','), ('books', 'NNS'), ('Consider', 'VBP'), ('Keyword', 'NNP'), ('search', 'NN'), ('Consider', 'NNP'), ('Period', 'NNP'), ('covered', 'VBD'), ('Consider', 'NNP'), ('Number', 'NNP'), ('citations', 'NNS'), ('Consider', 'NNP'), ('Literature', 'NNP'), ('search', 'NN'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('6', 'CD'), ('The', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('processes', 'VBZ'), ('followed', 'JJ'), ('thesis', 'NN'), ('shown', 'VBN'), ('Figure', 'NNP'), ('5', 'CD'), ('.', '.')]

 (S
  (NP Figure/NN)
  4/CD
  :/:
  (NP Stages/NNS)
  (NP effective/JJ search/NN literature/NN review/NN)
  process1/VBP
  1/CD
  Based/VBN
  (/(
  (NP Vom/NNP Brocke/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2009/CD
  )/)
  (NP Select/NNP reference/NN Sources/NNS)
  :/:
  (NP Top-ten-ranked/JJ peer-reviewed/NN IS/NNP Journals/NNP)
  ,/,
  (NP conferences/NNS)
  ,/,
  (NP books/NNS)
  Consider/VBP
  (NP Keyword/NNP search/NN Consider/NNP Period/NNP)
  covered/VBD
  (NP
    Consider/NNP
    Number/NNP
    citations/NNS
    Consider/NNP
    Literature/NNP
    search/NN
    Sarah/NNP
    Al-Shiakhli/NNP)
  6/CD
  (NP The/DT literature/NN review/NN)
  processes/VBZ
  (NP followed/JJ thesis/NN)
  shown/VBN
  (NP Figure/NNP)
  5/CD
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Stages', 'effective search literature review', 'Vom Brocke', 'al.', 'Select reference Sources', 'Top-ten-ranked peer-reviewed IS Journals', 'conferences', 'books', 'Keyword search Consider Period', 'Consider Number citations Consider Literature search Sarah Al-Shiakhli', 'The literature review', 'followed thesis', 'Figure']

>> Named Entities are: 
 [('ORGANIZATION', 'Vom Brocke'), ('PERSON', 'Keyword'), ('ORGANIZATION', 'Consider Period'), ('ORGANIZATION', 'Consider'), ('ORGANIZATION', 'Consider Literature'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('4', '4'), (':', ':'), ('Stages', 'stage'), ('effective', 'effect'), ('search', 'search'), ('literature', 'literatur'), ('review', 'review'), ('process1', 'process1'), ('1', '1'), ('Based', 'base'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('Select', 'select'), ('reference', 'refer'), ('Sources', 'sourc'), (':', ':'), ('Top-ten-ranked', 'top-ten-rank'), ('peer-reviewed', 'peer-review'), ('IS', 'is'), ('Journals', 'journal'), (',', ','), ('conferences', 'confer'), (',', ','), ('books', 'book'), ('Consider', 'consid'), ('Keyword', 'keyword'), ('search', 'search'), ('Consider', 'consid'), ('Period', 'period'), ('covered', 'cover'), ('Consider', 'consid'), ('Number', 'number'), ('citations', 'citat'), ('Consider', 'consid'), ('Literature', 'literatur'), ('search', 'search'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('6', '6'), ('The', 'the'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('followed', 'follow'), ('thesis', 'thesi'), ('shown', 'shown'), ('Figure', 'figur'), ('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('4', '4'), (':', ':'), ('Stages', 'stage'), ('effective', 'effect'), ('search', 'search'), ('literature', 'literatur'), ('review', 'review'), ('process1', 'process1'), ('1', '1'), ('Based', 'base'), ('(', '('), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('Select', 'select'), ('reference', 'refer'), ('Sources', 'sourc'), (':', ':'), ('Top-ten-ranked', 'top-ten-rank'), ('peer-reviewed', 'peer-review'), ('IS', 'is'), ('Journals', 'journal'), (',', ','), ('conferences', 'confer'), (',', ','), ('books', 'book'), ('Consider', 'consid'), ('Keyword', 'keyword'), ('search', 'search'), ('Consider', 'consid'), ('Period', 'period'), ('covered', 'cover'), ('Consider', 'consid'), ('Number', 'number'), ('citations', 'citat'), ('Consider', 'consid'), ('Literature', 'literatur'), ('search', 'search'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('6', '6'), ('The', 'the'), ('literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('followed', 'follow'), ('thesis', 'thesi'), ('shown', 'shown'), ('Figure', 'figur'), ('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('4', '4'), (':', ':'), ('Stages', 'Stages'), ('effective', 'effective'), ('search', 'search'), ('literature', 'literature'), ('review', 'review'), ('process1', 'process1'), ('1', '1'), ('Based', 'Based'), ('(', '('), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2009', '2009'), (')', ')'), ('Select', 'Select'), ('reference', 'reference'), ('Sources', 'Sources'), (':', ':'), ('Top-ten-ranked', 'Top-ten-ranked'), ('peer-reviewed', 'peer-reviewed'), ('IS', 'IS'), ('Journals', 'Journals'), (',', ','), ('conferences', 'conference'), (',', ','), ('books', 'book'), ('Consider', 'Consider'), ('Keyword', 'Keyword'), ('search', 'search'), ('Consider', 'Consider'), ('Period', 'Period'), ('covered', 'covered'), ('Consider', 'Consider'), ('Number', 'Number'), ('citations', 'citation'), ('Consider', 'Consider'), ('Literature', 'Literature'), ('search', 'search'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('6', '6'), ('The', 'The'), ('literature', 'literature'), ('review', 'review'), ('processes', 'process'), ('followed', 'followed'), ('thesis', 'thesis'), ('shown', 'shown'), ('Figure', 'Figure'), ('5', '5'), ('.', '.')]



============================ Sentence 96 =============================

They include   Identifying the concept and review scope    Identifying the concept means determining what is needed to achieve the goal, and what  work should be done to deliver the project. 


>> Tokens are: 
 ['They', 'include', 'Identifying', 'concept', 'review', 'scope', '\uf075', 'Identifying', 'concept', 'means', 'determining', 'needed', 'achieve', 'goal', ',', 'work', 'done', 'deliver', 'project', '.']

>> Bigrams are: 
 [('They', 'include'), ('include', 'Identifying'), ('Identifying', 'concept'), ('concept', 'review'), ('review', 'scope'), ('scope', '\uf075'), ('\uf075', 'Identifying'), ('Identifying', 'concept'), ('concept', 'means'), ('means', 'determining'), ('determining', 'needed'), ('needed', 'achieve'), ('achieve', 'goal'), ('goal', ','), (',', 'work'), ('work', 'done'), ('done', 'deliver'), ('deliver', 'project'), ('project', '.')]

>> Trigrams are: 
 [('They', 'include', 'Identifying'), ('include', 'Identifying', 'concept'), ('Identifying', 'concept', 'review'), ('concept', 'review', 'scope'), ('review', 'scope', '\uf075'), ('scope', '\uf075', 'Identifying'), ('\uf075', 'Identifying', 'concept'), ('Identifying', 'concept', 'means'), ('concept', 'means', 'determining'), ('means', 'determining', 'needed'), ('determining', 'needed', 'achieve'), ('needed', 'achieve', 'goal'), ('achieve', 'goal', ','), ('goal', ',', 'work'), (',', 'work', 'done'), ('work', 'done', 'deliver'), ('done', 'deliver', 'project'), ('deliver', 'project', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('include', 'VBP'), ('Identifying', 'VBG'), ('concept', 'NN'), ('review', 'NN'), ('scope', 'NN'), ('\uf075', 'IN'), ('Identifying', 'NNP'), ('concept', 'NN'), ('means', 'VBZ'), ('determining', 'VBG'), ('needed', 'VBN'), ('achieve', 'JJ'), ('goal', 'NN'), (',', ','), ('work', 'NN'), ('done', 'VBN'), ('deliver', 'NN'), ('project', 'NN'), ('.', '.')]

 (S
  They/PRP
  include/VBP
  Identifying/VBG
  (NP concept/NN review/NN scope/NN)
  /IN
  (NP Identifying/NNP concept/NN)
  means/VBZ
  determining/VBG
  needed/VBN
  (NP achieve/JJ goal/NN)
  ,/,
  (NP work/NN)
  done/VBN
  (NP deliver/NN project/NN)
  ./.) 


>> Noun Phrases are: 
 ['concept review scope', 'Identifying concept', 'achieve goal', 'work', 'deliver project']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('include', 'includ'), ('Identifying', 'identifi'), ('concept', 'concept'), ('review', 'review'), ('scope', 'scope'), ('\uf075', '\uf075'), ('Identifying', 'identifi'), ('concept', 'concept'), ('means', 'mean'), ('determining', 'determin'), ('needed', 'need'), ('achieve', 'achiev'), ('goal', 'goal'), (',', ','), ('work', 'work'), ('done', 'done'), ('deliver', 'deliv'), ('project', 'project'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('include', 'includ'), ('Identifying', 'identifi'), ('concept', 'concept'), ('review', 'review'), ('scope', 'scope'), ('\uf075', '\uf075'), ('Identifying', 'identifi'), ('concept', 'concept'), ('means', 'mean'), ('determining', 'determin'), ('needed', 'need'), ('achieve', 'achiev'), ('goal', 'goal'), (',', ','), ('work', 'work'), ('done', 'done'), ('deliver', 'deliv'), ('project', 'project'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('include', 'include'), ('Identifying', 'Identifying'), ('concept', 'concept'), ('review', 'review'), ('scope', 'scope'), ('\uf075', '\uf075'), ('Identifying', 'Identifying'), ('concept', 'concept'), ('means', 'mean'), ('determining', 'determining'), ('needed', 'needed'), ('achieve', 'achieve'), ('goal', 'goal'), (',', ','), ('work', 'work'), ('done', 'done'), ('deliver', 'deliver'), ('project', 'project'), ('.', '.')]



============================ Sentence 97 =============================

Such planning consists of documenting the   project goals, features, tasks, and deadlines. 


>> Tokens are: 
 ['Such', 'planning', 'consists', 'documenting', 'project', 'goals', ',', 'features', ',', 'tasks', ',', 'deadlines', '.']

>> Bigrams are: 
 [('Such', 'planning'), ('planning', 'consists'), ('consists', 'documenting'), ('documenting', 'project'), ('project', 'goals'), ('goals', ','), (',', 'features'), ('features', ','), (',', 'tasks'), ('tasks', ','), (',', 'deadlines'), ('deadlines', '.')]

>> Trigrams are: 
 [('Such', 'planning', 'consists'), ('planning', 'consists', 'documenting'), ('consists', 'documenting', 'project'), ('documenting', 'project', 'goals'), ('project', 'goals', ','), ('goals', ',', 'features'), (',', 'features', ','), ('features', ',', 'tasks'), (',', 'tasks', ','), ('tasks', ',', 'deadlines'), (',', 'deadlines', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('planning', 'NN'), ('consists', 'VBZ'), ('documenting', 'VBG'), ('project', 'NN'), ('goals', 'NNS'), (',', ','), ('features', 'NNS'), (',', ','), ('tasks', 'NNS'), (',', ','), ('deadlines', 'NNS'), ('.', '.')]

 (S
  (NP Such/JJ planning/NN)
  consists/VBZ
  documenting/VBG
  (NP project/NN goals/NNS)
  ,/,
  (NP features/NNS)
  ,/,
  (NP tasks/NNS)
  ,/,
  (NP deadlines/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Such planning', 'project goals', 'features', 'tasks', 'deadlines']

>> Named Entities are: 
 [('GPE', 'Such')] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('planning', 'plan'), ('consists', 'consist'), ('documenting', 'document'), ('project', 'project'), ('goals', 'goal'), (',', ','), ('features', 'featur'), (',', ','), ('tasks', 'task'), (',', ','), ('deadlines', 'deadlin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('planning', 'plan'), ('consists', 'consist'), ('documenting', 'document'), ('project', 'project'), ('goals', 'goal'), (',', ','), ('features', 'featur'), (',', ','), ('tasks', 'task'), (',', ','), ('deadlines', 'deadlin'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('planning', 'planning'), ('consists', 'consists'), ('documenting', 'documenting'), ('project', 'project'), ('goals', 'goal'), (',', ','), ('features', 'feature'), (',', ','), ('tasks', 'task'), (',', ','), ('deadlines', 'deadline'), ('.', '.')]



============================ Sentence 98 =============================

In this research, this referred to the process of   developing a literature review perspective on big data analytics. 


>> Tokens are: 
 ['In', 'research', ',', 'referred', 'process', 'developing', 'literature', 'review', 'perspective', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('In', 'research'), ('research', ','), (',', 'referred'), ('referred', 'process'), ('process', 'developing'), ('developing', 'literature'), ('literature', 'review'), ('review', 'perspective'), ('perspective', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('In', 'research', ','), ('research', ',', 'referred'), (',', 'referred', 'process'), ('referred', 'process', 'developing'), ('process', 'developing', 'literature'), ('developing', 'literature', 'review'), ('literature', 'review', 'perspective'), ('review', 'perspective', 'big'), ('perspective', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('research', 'NN'), (',', ','), ('referred', 'VBD'), ('process', 'NN'), ('developing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), ('perspective', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP research/NN)
  ,/,
  referred/VBD
  (NP process/NN)
  developing/VBG
  (NP literature/NN review/NN)
  perspective/VBP
  (NP big/JJ data/NNS analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['research', 'process', 'literature review', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('research', 'research'), (',', ','), ('referred', 'refer'), ('process', 'process'), ('developing', 'develop'), ('literature', 'literatur'), ('review', 'review'), ('perspective', 'perspect'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('research', 'research'), (',', ','), ('referred', 'refer'), ('process', 'process'), ('developing', 'develop'), ('literature', 'literatur'), ('review', 'review'), ('perspective', 'perspect'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('research', 'research'), (',', ','), ('referred', 'referred'), ('process', 'process'), ('developing', 'developing'), ('literature', 'literature'), ('review', 'review'), ('perspective', 'perspective'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 99 =============================

Finding related databases and sources    The search procedure for this thesis included the use of a range of relevant sources, such  as ACM DL, IEEE Xplore, Emerald, EBSCO, WoS, LTU library, Google Scholar,   Springers, and Elsevier. 


>> Tokens are: 
 ['Finding', 'related', 'databases', 'sources', '\uf075', 'The', 'search', 'procedure', 'thesis', 'included', 'use', 'range', 'relevant', 'sources', ',', 'ACM', 'DL', ',', 'IEEE', 'Xplore', ',', 'Emerald', ',', 'EBSCO', ',', 'WoS', ',', 'LTU', 'library', ',', 'Google', 'Scholar', ',', 'Springers', ',', 'Elsevier', '.']

>> Bigrams are: 
 [('Finding', 'related'), ('related', 'databases'), ('databases', 'sources'), ('sources', '\uf075'), ('\uf075', 'The'), ('The', 'search'), ('search', 'procedure'), ('procedure', 'thesis'), ('thesis', 'included'), ('included', 'use'), ('use', 'range'), ('range', 'relevant'), ('relevant', 'sources'), ('sources', ','), (',', 'ACM'), ('ACM', 'DL'), ('DL', ','), (',', 'IEEE'), ('IEEE', 'Xplore'), ('Xplore', ','), (',', 'Emerald'), ('Emerald', ','), (',', 'EBSCO'), ('EBSCO', ','), (',', 'WoS'), ('WoS', ','), (',', 'LTU'), ('LTU', 'library'), ('library', ','), (',', 'Google'), ('Google', 'Scholar'), ('Scholar', ','), (',', 'Springers'), ('Springers', ','), (',', 'Elsevier'), ('Elsevier', '.')]

>> Trigrams are: 
 [('Finding', 'related', 'databases'), ('related', 'databases', 'sources'), ('databases', 'sources', '\uf075'), ('sources', '\uf075', 'The'), ('\uf075', 'The', 'search'), ('The', 'search', 'procedure'), ('search', 'procedure', 'thesis'), ('procedure', 'thesis', 'included'), ('thesis', 'included', 'use'), ('included', 'use', 'range'), ('use', 'range', 'relevant'), ('range', 'relevant', 'sources'), ('relevant', 'sources', ','), ('sources', ',', 'ACM'), (',', 'ACM', 'DL'), ('ACM', 'DL', ','), ('DL', ',', 'IEEE'), (',', 'IEEE', 'Xplore'), ('IEEE', 'Xplore', ','), ('Xplore', ',', 'Emerald'), (',', 'Emerald', ','), ('Emerald', ',', 'EBSCO'), (',', 'EBSCO', ','), ('EBSCO', ',', 'WoS'), (',', 'WoS', ','), ('WoS', ',', 'LTU'), (',', 'LTU', 'library'), ('LTU', 'library', ','), ('library', ',', 'Google'), (',', 'Google', 'Scholar'), ('Google', 'Scholar', ','), ('Scholar', ',', 'Springers'), (',', 'Springers', ','), ('Springers', ',', 'Elsevier'), (',', 'Elsevier', '.')]

>> POS Tags are: 
 [('Finding', 'VBG'), ('related', 'JJ'), ('databases', 'NNS'), ('sources', 'NNS'), ('\uf075', 'VBP'), ('The', 'DT'), ('search', 'NN'), ('procedure', 'NN'), ('thesis', 'NN'), ('included', 'VBD'), ('use', 'NN'), ('range', 'NN'), ('relevant', 'JJ'), ('sources', 'NNS'), (',', ','), ('ACM', 'NNP'), ('DL', 'NNP'), (',', ','), ('IEEE', 'NNP'), ('Xplore', 'NNP'), (',', ','), ('Emerald', 'NNP'), (',', ','), ('EBSCO', 'NNP'), (',', ','), ('WoS', 'NNP'), (',', ','), ('LTU', 'NNP'), ('library', 'NN'), (',', ','), ('Google', 'NNP'), ('Scholar', 'NNP'), (',', ','), ('Springers', 'NNP'), (',', ','), ('Elsevier', 'NNP'), ('.', '.')]

 (S
  Finding/VBG
  (NP related/JJ databases/NNS sources/NNS)
  /VBP
  (NP The/DT search/NN procedure/NN thesis/NN)
  included/VBD
  (NP use/NN range/NN)
  (NP relevant/JJ sources/NNS)
  ,/,
  (NP ACM/NNP DL/NNP)
  ,/,
  (NP IEEE/NNP Xplore/NNP)
  ,/,
  (NP Emerald/NNP)
  ,/,
  (NP EBSCO/NNP)
  ,/,
  (NP WoS/NNP)
  ,/,
  (NP LTU/NNP library/NN)
  ,/,
  (NP Google/NNP Scholar/NNP)
  ,/,
  (NP Springers/NNP)
  ,/,
  (NP Elsevier/NNP)
  ./.) 


>> Noun Phrases are: 
 ['related databases sources', 'The search procedure thesis', 'use range', 'relevant sources', 'ACM DL', 'IEEE Xplore', 'Emerald', 'EBSCO', 'WoS', 'LTU library', 'Google Scholar', 'Springers', 'Elsevier']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'IEEE Xplore'), ('PERSON', 'Emerald'), ('ORGANIZATION', 'EBSCO'), ('ORGANIZATION', 'WoS'), ('ORGANIZATION', 'LTU'), ('PERSON', 'Google Scholar'), ('GPE', 'Springers'), ('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('Finding', 'find'), ('related', 'relat'), ('databases', 'databas'), ('sources', 'sourc'), ('\uf075', '\uf075'), ('The', 'the'), ('search', 'search'), ('procedure', 'procedur'), ('thesis', 'thesi'), ('included', 'includ'), ('use', 'use'), ('range', 'rang'), ('relevant', 'relev'), ('sources', 'sourc'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('EBSCO', 'ebsco'), (',', ','), ('WoS', 'wo'), (',', ','), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ','), ('Springers', 'springer'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finding', 'find'), ('related', 'relat'), ('databases', 'databas'), ('sources', 'sourc'), ('\uf075', '\uf075'), ('The', 'the'), ('search', 'search'), ('procedure', 'procedur'), ('thesis', 'thesi'), ('included', 'includ'), ('use', 'use'), ('range', 'rang'), ('relevant', 'relev'), ('sources', 'sourc'), (',', ','), ('ACM', 'acm'), ('DL', 'dl'), (',', ','), ('IEEE', 'ieee'), ('Xplore', 'xplore'), (',', ','), ('Emerald', 'emerald'), (',', ','), ('EBSCO', 'ebsco'), (',', ','), ('WoS', 'wos'), (',', ','), ('LTU', 'ltu'), ('library', 'librari'), (',', ','), ('Google', 'googl'), ('Scholar', 'scholar'), (',', ','), ('Springers', 'springer'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Lemmatization: 
 [('Finding', 'Finding'), ('related', 'related'), ('databases', 'database'), ('sources', 'source'), ('\uf075', '\uf075'), ('The', 'The'), ('search', 'search'), ('procedure', 'procedure'), ('thesis', 'thesis'), ('included', 'included'), ('use', 'use'), ('range', 'range'), ('relevant', 'relevant'), ('sources', 'source'), (',', ','), ('ACM', 'ACM'), ('DL', 'DL'), (',', ','), ('IEEE', 'IEEE'), ('Xplore', 'Xplore'), (',', ','), ('Emerald', 'Emerald'), (',', ','), ('EBSCO', 'EBSCO'), (',', ','), ('WoS', 'WoS'), (',', ','), ('LTU', 'LTU'), ('library', 'library'), (',', ','), ('Google', 'Google'), ('Scholar', 'Scholar'), (',', ','), ('Springers', 'Springers'), (',', ','), ('Elsevier', 'Elsevier'), ('.', '.')]



============================ Sentence 100 =============================

 The resulting papers were then filtered based on year, abstract, content, citations, etc. 


>> Tokens are: 
 ['\uf075', 'The', 'resulting', 'papers', 'filtered', 'based', 'year', ',', 'abstract', ',', 'content', ',', 'citations', ',', 'etc', '.']

>> Bigrams are: 
 [('\uf075', 'The'), ('The', 'resulting'), ('resulting', 'papers'), ('papers', 'filtered'), ('filtered', 'based'), ('based', 'year'), ('year', ','), (',', 'abstract'), ('abstract', ','), (',', 'content'), ('content', ','), (',', 'citations'), ('citations', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('\uf075', 'The', 'resulting'), ('The', 'resulting', 'papers'), ('resulting', 'papers', 'filtered'), ('papers', 'filtered', 'based'), ('filtered', 'based', 'year'), ('based', 'year', ','), ('year', ',', 'abstract'), (',', 'abstract', ','), ('abstract', ',', 'content'), (',', 'content', ','), ('content', ',', 'citations'), (',', 'citations', ','), ('citations', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('\uf075', 'IN'), ('The', 'DT'), ('resulting', 'VBG'), ('papers', 'NNS'), ('filtered', 'VBD'), ('based', 'VBN'), ('year', 'NN'), (',', ','), ('abstract', 'NN'), (',', ','), ('content', 'NN'), (',', ','), ('citations', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  /IN
  The/DT
  resulting/VBG
  (NP papers/NNS)
  filtered/VBD
  based/VBN
  (NP year/NN)
  ,/,
  (NP abstract/NN)
  ,/,
  (NP content/NN)
  ,/,
  (NP citations/NNS)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['papers', 'year', 'abstract', 'content', 'citations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('resulting', 'result'), ('papers', 'paper'), ('filtered', 'filter'), ('based', 'base'), ('year', 'year'), (',', ','), ('abstract', 'abstract'), (',', ','), ('content', 'content'), (',', ','), ('citations', 'citat'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('The', 'the'), ('resulting', 'result'), ('papers', 'paper'), ('filtered', 'filter'), ('based', 'base'), ('year', 'year'), (',', ','), ('abstract', 'abstract'), (',', ','), ('content', 'content'), (',', ','), ('citations', 'citat'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('The', 'The'), ('resulting', 'resulting'), ('papers', 'paper'), ('filtered', 'filtered'), ('based', 'based'), ('year', 'year'), (',', ','), ('abstract', 'abstract'), (',', ','), ('content', 'content'), (',', ','), ('citations', 'citation'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 101 =============================

The  searches on big data analytics were filtered based on the top ten ranked peer-reviewed   papers such as MIS Quarterly: Management Information Systems and Information Systems   Research, with keyword searches including terms such as “Big data” and “big data   analytics” for the period 2011 to 2019. 


>> Tokens are: 
 ['The', 'searches', 'big', 'data', 'analytics', 'filtered', 'based', 'top', 'ten', 'ranked', 'peer-reviewed', 'papers', 'MIS', 'Quarterly', ':', 'Management', 'Information', 'Systems', 'Information', 'Systems', 'Research', ',', 'keyword', 'searches', 'including', 'terms', '“', 'Big', 'data', '”', '“', 'big', 'data', 'analytics', '”', 'period', '2011', '2019', '.']

>> Bigrams are: 
 [('The', 'searches'), ('searches', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'filtered'), ('filtered', 'based'), ('based', 'top'), ('top', 'ten'), ('ten', 'ranked'), ('ranked', 'peer-reviewed'), ('peer-reviewed', 'papers'), ('papers', 'MIS'), ('MIS', 'Quarterly'), ('Quarterly', ':'), (':', 'Management'), ('Management', 'Information'), ('Information', 'Systems'), ('Systems', 'Information'), ('Information', 'Systems'), ('Systems', 'Research'), ('Research', ','), (',', 'keyword'), ('keyword', 'searches'), ('searches', 'including'), ('including', 'terms'), ('terms', '“'), ('“', 'Big'), ('Big', 'data'), ('data', '”'), ('”', '“'), ('“', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '”'), ('”', 'period'), ('period', '2011'), ('2011', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('The', 'searches', 'big'), ('searches', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'filtered'), ('analytics', 'filtered', 'based'), ('filtered', 'based', 'top'), ('based', 'top', 'ten'), ('top', 'ten', 'ranked'), ('ten', 'ranked', 'peer-reviewed'), ('ranked', 'peer-reviewed', 'papers'), ('peer-reviewed', 'papers', 'MIS'), ('papers', 'MIS', 'Quarterly'), ('MIS', 'Quarterly', ':'), ('Quarterly', ':', 'Management'), (':', 'Management', 'Information'), ('Management', 'Information', 'Systems'), ('Information', 'Systems', 'Information'), ('Systems', 'Information', 'Systems'), ('Information', 'Systems', 'Research'), ('Systems', 'Research', ','), ('Research', ',', 'keyword'), (',', 'keyword', 'searches'), ('keyword', 'searches', 'including'), ('searches', 'including', 'terms'), ('including', 'terms', '“'), ('terms', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', '”'), ('data', '”', '“'), ('”', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '”'), ('analytics', '”', 'period'), ('”', 'period', '2011'), ('period', '2011', '2019'), ('2011', '2019', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('searches', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('filtered', 'VBD'), ('based', 'VBN'), ('top', 'JJ'), ('ten', 'NN'), ('ranked', 'VBD'), ('peer-reviewed', 'JJ'), ('papers', 'NNS'), ('MIS', 'NNP'), ('Quarterly', 'NNP'), (':', ':'), ('Management', 'JJ'), ('Information', 'NNP'), ('Systems', 'NNPS'), ('Information', 'NNP'), ('Systems', 'NNP'), ('Research', 'NNP'), (',', ','), ('keyword', 'NN'), ('searches', 'NNS'), ('including', 'VBG'), ('terms', 'NNS'), ('“', 'VBP'), ('Big', 'NNP'), ('data', 'NNS'), ('”', 'NNP'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('”', 'JJ'), ('period', 'NN'), ('2011', 'CD'), ('2019', 'CD'), ('.', '.')]

 (S
  (NP The/DT searches/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  filtered/VBD
  based/VBN
  (NP top/JJ ten/NN)
  ranked/VBD
  (NP peer-reviewed/JJ papers/NNS MIS/NNP Quarterly/NNP)
  :/:
  (NP Management/JJ Information/NNP)
  Systems/NNPS
  (NP Information/NNP Systems/NNP Research/NNP)
  ,/,
  (NP keyword/NN searches/NNS)
  including/VBG
  (NP terms/NNS)
  “/VBP
  (NP Big/NNP data/NNS ”/NNP “/NNP)
  (NP big/JJ data/NNS analytics/NNS)
  (NP ”/JJ period/NN)
  2011/CD
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['The searches', 'big data analytics', 'top ten', 'peer-reviewed papers MIS Quarterly', 'Management Information', 'Information Systems Research', 'keyword searches', 'terms', 'Big data ” “', 'big data analytics', '” period']

>> Named Entities are: 
 [('ORGANIZATION', 'MIS'), ('ORGANIZATION', 'Information Systems Information Systems Research')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('searches', 'search'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('filtered', 'filter'), ('based', 'base'), ('top', 'top'), ('ten', 'ten'), ('ranked', 'rank'), ('peer-reviewed', 'peer-review'), ('papers', 'paper'), ('MIS', 'mi'), ('Quarterly', 'quarterli'), (':', ':'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), ('Information', 'inform'), ('Systems', 'system'), ('Research', 'research'), (',', ','), ('keyword', 'keyword'), ('searches', 'search'), ('including', 'includ'), ('terms', 'term'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('”', '”'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('searches', 'search'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('filtered', 'filter'), ('based', 'base'), ('top', 'top'), ('ten', 'ten'), ('ranked', 'rank'), ('peer-reviewed', 'peer-review'), ('papers', 'paper'), ('MIS', 'mis'), ('Quarterly', 'quarter'), (':', ':'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), ('Information', 'inform'), ('Systems', 'system'), ('Research', 'research'), (',', ','), ('keyword', 'keyword'), ('searches', 'search'), ('including', 'includ'), ('terms', 'term'), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('”', '”'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('searches', 'search'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('filtered', 'filtered'), ('based', 'based'), ('top', 'top'), ('ten', 'ten'), ('ranked', 'ranked'), ('peer-reviewed', 'peer-reviewed'), ('papers', 'paper'), ('MIS', 'MIS'), ('Quarterly', 'Quarterly'), (':', ':'), ('Management', 'Management'), ('Information', 'Information'), ('Systems', 'Systems'), ('Information', 'Information'), ('Systems', 'Systems'), ('Research', 'Research'), (',', ','), ('keyword', 'keyword'), ('searches', 'search'), ('including', 'including'), ('terms', 'term'), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('”', '”'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('”', '”'), ('period', 'period'), ('2011', '2011'), ('2019', '2019'), ('.', '.')]



============================ Sentence 102 =============================

Literature search    Analytical reading of papers refers to reading the papers chosen based on the  aforementioned criteria deeply in order to understand the goals and the messages of those   papers. 


>> Tokens are: 
 ['Literature', 'search', '\uf075', 'Analytical', 'reading', 'papers', 'refers', 'reading', 'papers', 'chosen', 'based', 'aforementioned', 'criteria', 'deeply', 'order', 'understand', 'goals', 'messages', 'papers', '.']

>> Bigrams are: 
 [('Literature', 'search'), ('search', '\uf075'), ('\uf075', 'Analytical'), ('Analytical', 'reading'), ('reading', 'papers'), ('papers', 'refers'), ('refers', 'reading'), ('reading', 'papers'), ('papers', 'chosen'), ('chosen', 'based'), ('based', 'aforementioned'), ('aforementioned', 'criteria'), ('criteria', 'deeply'), ('deeply', 'order'), ('order', 'understand'), ('understand', 'goals'), ('goals', 'messages'), ('messages', 'papers'), ('papers', '.')]

>> Trigrams are: 
 [('Literature', 'search', '\uf075'), ('search', '\uf075', 'Analytical'), ('\uf075', 'Analytical', 'reading'), ('Analytical', 'reading', 'papers'), ('reading', 'papers', 'refers'), ('papers', 'refers', 'reading'), ('refers', 'reading', 'papers'), ('reading', 'papers', 'chosen'), ('papers', 'chosen', 'based'), ('chosen', 'based', 'aforementioned'), ('based', 'aforementioned', 'criteria'), ('aforementioned', 'criteria', 'deeply'), ('criteria', 'deeply', 'order'), ('deeply', 'order', 'understand'), ('order', 'understand', 'goals'), ('understand', 'goals', 'messages'), ('goals', 'messages', 'papers'), ('messages', 'papers', '.')]

>> POS Tags are: 
 [('Literature', 'NNP'), ('search', 'NN'), ('\uf075', 'NNP'), ('Analytical', 'NNP'), ('reading', 'NN'), ('papers', 'NNS'), ('refers', 'NNS'), ('reading', 'VBG'), ('papers', 'NNS'), ('chosen', 'VBP'), ('based', 'VBN'), ('aforementioned', 'JJ'), ('criteria', 'NNS'), ('deeply', 'RB'), ('order', 'NN'), ('understand', 'JJ'), ('goals', 'NNS'), ('messages', 'VBZ'), ('papers', 'NNS'), ('.', '.')]

 (S
  (NP
    Literature/NNP
    search/NN
    /NNP
    Analytical/NNP
    reading/NN
    papers/NNS
    refers/NNS)
  reading/VBG
  (NP papers/NNS)
  chosen/VBP
  based/VBN
  (NP aforementioned/JJ criteria/NNS)
  deeply/RB
  (NP order/NN)
  (NP understand/JJ goals/NNS)
  messages/VBZ
  (NP papers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Literature search \uf075 Analytical reading papers refers', 'papers', 'aforementioned criteria', 'order', 'understand goals', 'papers']

>> Named Entities are: 
 [('GPE', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Literature', 'literatur'), ('search', 'search'), ('\uf075', '\uf075'), ('Analytical', 'analyt'), ('reading', 'read'), ('papers', 'paper'), ('refers', 'refer'), ('reading', 'read'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('aforementioned', 'aforement'), ('criteria', 'criteria'), ('deeply', 'deepli'), ('order', 'order'), ('understand', 'understand'), ('goals', 'goal'), ('messages', 'messag'), ('papers', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Literature', 'literatur'), ('search', 'search'), ('\uf075', '\uf075'), ('Analytical', 'analyt'), ('reading', 'read'), ('papers', 'paper'), ('refers', 'refer'), ('reading', 'read'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'base'), ('aforementioned', 'aforement'), ('criteria', 'criteria'), ('deeply', 'deepli'), ('order', 'order'), ('understand', 'understand'), ('goals', 'goal'), ('messages', 'messag'), ('papers', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('Literature', 'Literature'), ('search', 'search'), ('\uf075', '\uf075'), ('Analytical', 'Analytical'), ('reading', 'reading'), ('papers', 'paper'), ('refers', 'refers'), ('reading', 'reading'), ('papers', 'paper'), ('chosen', 'chosen'), ('based', 'based'), ('aforementioned', 'aforementioned'), ('criteria', 'criterion'), ('deeply', 'deeply'), ('order', 'order'), ('understand', 'understand'), ('goals', 'goal'), ('messages', 'message'), ('papers', 'paper'), ('.', '.')]



============================ Sentence 103 =============================

Accordingly, the first step is to prepare the reading, reading the paper more than   once and writing notes. 


>> Tokens are: 
 ['Accordingly', ',', 'first', 'step', 'prepare', 'reading', ',', 'reading', 'paper', 'writing', 'notes', '.']

>> Bigrams are: 
 [('Accordingly', ','), (',', 'first'), ('first', 'step'), ('step', 'prepare'), ('prepare', 'reading'), ('reading', ','), (',', 'reading'), ('reading', 'paper'), ('paper', 'writing'), ('writing', 'notes'), ('notes', '.')]

>> Trigrams are: 
 [('Accordingly', ',', 'first'), (',', 'first', 'step'), ('first', 'step', 'prepare'), ('step', 'prepare', 'reading'), ('prepare', 'reading', ','), ('reading', ',', 'reading'), (',', 'reading', 'paper'), ('reading', 'paper', 'writing'), ('paper', 'writing', 'notes'), ('writing', 'notes', '.')]

>> POS Tags are: 
 [('Accordingly', 'RB'), (',', ','), ('first', 'JJ'), ('step', 'NN'), ('prepare', 'NN'), ('reading', 'NN'), (',', ','), ('reading', 'VBG'), ('paper', 'NN'), ('writing', 'VBG'), ('notes', 'NNS'), ('.', '.')]

 (S
  Accordingly/RB
  ,/,
  (NP first/JJ step/NN prepare/NN reading/NN)
  ,/,
  reading/VBG
  (NP paper/NN)
  writing/VBG
  (NP notes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['first step prepare reading', 'paper', 'notes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Accordingly', 'accordingli'), (',', ','), ('first', 'first'), ('step', 'step'), ('prepare', 'prepar'), ('reading', 'read'), (',', ','), ('reading', 'read'), ('paper', 'paper'), ('writing', 'write'), ('notes', 'note'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Accordingly', 'accord'), (',', ','), ('first', 'first'), ('step', 'step'), ('prepare', 'prepar'), ('reading', 'read'), (',', ','), ('reading', 'read'), ('paper', 'paper'), ('writing', 'write'), ('notes', 'note'), ('.', '.')]

>> Lemmatization: 
 [('Accordingly', 'Accordingly'), (',', ','), ('first', 'first'), ('step', 'step'), ('prepare', 'prepare'), ('reading', 'reading'), (',', ','), ('reading', 'reading'), ('paper', 'paper'), ('writing', 'writing'), ('notes', 'note'), ('.', '.')]



============================ Sentence 104 =============================

The second is to use advanced reading techniques to re-read the   paper to gain a better picture of and more insight into the paper’s work as well as   developing a better understanding. 


>> Tokens are: 
 ['The', 'second', 'use', 'advanced', 'reading', 'techniques', 're-read', 'paper', 'gain', 'better', 'picture', 'insight', 'paper', '’', 'work', 'well', 'developing', 'better', 'understanding', '.']

>> Bigrams are: 
 [('The', 'second'), ('second', 'use'), ('use', 'advanced'), ('advanced', 'reading'), ('reading', 'techniques'), ('techniques', 're-read'), ('re-read', 'paper'), ('paper', 'gain'), ('gain', 'better'), ('better', 'picture'), ('picture', 'insight'), ('insight', 'paper'), ('paper', '’'), ('’', 'work'), ('work', 'well'), ('well', 'developing'), ('developing', 'better'), ('better', 'understanding'), ('understanding', '.')]

>> Trigrams are: 
 [('The', 'second', 'use'), ('second', 'use', 'advanced'), ('use', 'advanced', 'reading'), ('advanced', 'reading', 'techniques'), ('reading', 'techniques', 're-read'), ('techniques', 're-read', 'paper'), ('re-read', 'paper', 'gain'), ('paper', 'gain', 'better'), ('gain', 'better', 'picture'), ('better', 'picture', 'insight'), ('picture', 'insight', 'paper'), ('insight', 'paper', '’'), ('paper', '’', 'work'), ('’', 'work', 'well'), ('work', 'well', 'developing'), ('well', 'developing', 'better'), ('developing', 'better', 'understanding'), ('better', 'understanding', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('use', 'NN'), ('advanced', 'VBD'), ('reading', 'VBG'), ('techniques', 'NNS'), ('re-read', 'JJ'), ('paper', 'NN'), ('gain', 'NN'), ('better', 'RBR'), ('picture', 'NN'), ('insight', 'JJ'), ('paper', 'NN'), ('’', 'NN'), ('work', 'NN'), ('well', 'RB'), ('developing', 'VBG'), ('better', 'RBR'), ('understanding', 'NN'), ('.', '.')]

 (S
  (NP The/DT second/JJ use/NN)
  advanced/VBD
  reading/VBG
  (NP techniques/NNS)
  (NP re-read/JJ paper/NN gain/NN)
  better/RBR
  (NP picture/NN)
  (NP insight/JJ paper/NN ’/NN work/NN)
  well/RB
  developing/VBG
  better/RBR
  (NP understanding/NN)
  ./.) 


>> Noun Phrases are: 
 ['The second use', 'techniques', 're-read paper gain', 'picture', 'insight paper ’ work', 'understanding']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('use', 'use'), ('advanced', 'advanc'), ('reading', 'read'), ('techniques', 'techniqu'), ('re-read', 're-read'), ('paper', 'paper'), ('gain', 'gain'), ('better', 'better'), ('picture', 'pictur'), ('insight', 'insight'), ('paper', 'paper'), ('’', '’'), ('work', 'work'), ('well', 'well'), ('developing', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('use', 'use'), ('advanced', 'advanc'), ('reading', 'read'), ('techniques', 'techniqu'), ('re-read', 're-read'), ('paper', 'paper'), ('gain', 'gain'), ('better', 'better'), ('picture', 'pictur'), ('insight', 'insight'), ('paper', 'paper'), ('’', '’'), ('work', 'work'), ('well', 'well'), ('developing', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('use', 'use'), ('advanced', 'advanced'), ('reading', 'reading'), ('techniques', 'technique'), ('re-read', 're-read'), ('paper', 'paper'), ('gain', 'gain'), ('better', 'better'), ('picture', 'picture'), ('insight', 'insight'), ('paper', 'paper'), ('’', '’'), ('work', 'work'), ('well', 'well'), ('developing', 'developing'), ('better', 'better'), ('understanding', 'understanding'), ('.', '.')]



============================ Sentence 105 =============================

A final evaluative reading of the paper is then required. 


>> Tokens are: 
 ['A', 'final', 'evaluative', 'reading', 'paper', 'required', '.']

>> Bigrams are: 
 [('A', 'final'), ('final', 'evaluative'), ('evaluative', 'reading'), ('reading', 'paper'), ('paper', 'required'), ('required', '.')]

>> Trigrams are: 
 [('A', 'final', 'evaluative'), ('final', 'evaluative', 'reading'), ('evaluative', 'reading', 'paper'), ('reading', 'paper', 'required'), ('paper', 'required', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('final', 'JJ'), ('evaluative', 'NN'), ('reading', 'VBG'), ('paper', 'NN'), ('required', 'VBN'), ('.', '.')]

 (S
  (NP A/DT final/JJ evaluative/NN)
  reading/VBG
  (NP paper/NN)
  required/VBN
  ./.) 


>> Noun Phrases are: 
 ['A final evaluative', 'paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('final', 'final'), ('evaluative', 'evalu'), ('reading', 'read'), ('paper', 'paper'), ('required', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('final', 'final'), ('evaluative', 'evalu'), ('reading', 'read'), ('paper', 'paper'), ('required', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('final', 'final'), ('evaluative', 'evaluative'), ('reading', 'reading'), ('paper', 'paper'), ('required', 'required'), ('.', '.')]



============================ Sentence 106 =============================

Literature analysis and synthesis     This literature review seeks to provide a description and evaluation of the current state of  big data analytics. 


>> Tokens are: 
 ['Literature', 'analysis', 'synthesis', '\uf075', 'This', 'literature', 'review', 'seeks', 'provide', 'description', 'evaluation', 'current', 'state', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Literature', 'analysis'), ('analysis', 'synthesis'), ('synthesis', '\uf075'), ('\uf075', 'This'), ('This', 'literature'), ('literature', 'review'), ('review', 'seeks'), ('seeks', 'provide'), ('provide', 'description'), ('description', 'evaluation'), ('evaluation', 'current'), ('current', 'state'), ('state', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Literature', 'analysis', 'synthesis'), ('analysis', 'synthesis', '\uf075'), ('synthesis', '\uf075', 'This'), ('\uf075', 'This', 'literature'), ('This', 'literature', 'review'), ('literature', 'review', 'seeks'), ('review', 'seeks', 'provide'), ('seeks', 'provide', 'description'), ('provide', 'description', 'evaluation'), ('description', 'evaluation', 'current'), ('evaluation', 'current', 'state'), ('current', 'state', 'big'), ('state', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Literature', 'NN'), ('analysis', 'NN'), ('synthesis', 'NN'), ('\uf075', 'NN'), ('This', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('seeks', 'VBZ'), ('provide', 'JJ'), ('description', 'NN'), ('evaluation', 'NN'), ('current', 'JJ'), ('state', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Literature/NN analysis/NN synthesis/NN /NN)
  (NP This/DT literature/NN review/NN)
  seeks/VBZ
  (NP provide/JJ description/NN evaluation/NN)
  (NP current/JJ state/NN)
  (NP big/JJ data/NN analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Literature analysis synthesis \uf075', 'This literature review', 'provide description evaluation', 'current state', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Literature')] 

>> Stemming using Porter Stemmer: 
 [('Literature', 'literatur'), ('analysis', 'analysi'), ('synthesis', 'synthesi'), ('\uf075', '\uf075'), ('This', 'thi'), ('literature', 'literatur'), ('review', 'review'), ('seeks', 'seek'), ('provide', 'provid'), ('description', 'descript'), ('evaluation', 'evalu'), ('current', 'current'), ('state', 'state'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Literature', 'literatur'), ('analysis', 'analysi'), ('synthesis', 'synthesi'), ('\uf075', '\uf075'), ('This', 'this'), ('literature', 'literatur'), ('review', 'review'), ('seeks', 'seek'), ('provide', 'provid'), ('description', 'descript'), ('evaluation', 'evalu'), ('current', 'current'), ('state', 'state'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Literature', 'Literature'), ('analysis', 'analysis'), ('synthesis', 'synthesis'), ('\uf075', '\uf075'), ('This', 'This'), ('literature', 'literature'), ('review', 'review'), ('seeks', 'seek'), ('provide', 'provide'), ('description', 'description'), ('evaluation', 'evaluation'), ('current', 'current'), ('state', 'state'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 107 =============================

It designed to give an overview of the explored sources based on   extensive searches around this topic, showing how the research covers a large study field   in both academia and industry. 


>> Tokens are: 
 ['It', 'designed', 'give', 'overview', 'explored', 'sources', 'based', 'extensive', 'searches', 'around', 'topic', ',', 'showing', 'research', 'covers', 'large', 'study', 'field', 'academia', 'industry', '.']

>> Bigrams are: 
 [('It', 'designed'), ('designed', 'give'), ('give', 'overview'), ('overview', 'explored'), ('explored', 'sources'), ('sources', 'based'), ('based', 'extensive'), ('extensive', 'searches'), ('searches', 'around'), ('around', 'topic'), ('topic', ','), (',', 'showing'), ('showing', 'research'), ('research', 'covers'), ('covers', 'large'), ('large', 'study'), ('study', 'field'), ('field', 'academia'), ('academia', 'industry'), ('industry', '.')]

>> Trigrams are: 
 [('It', 'designed', 'give'), ('designed', 'give', 'overview'), ('give', 'overview', 'explored'), ('overview', 'explored', 'sources'), ('explored', 'sources', 'based'), ('sources', 'based', 'extensive'), ('based', 'extensive', 'searches'), ('extensive', 'searches', 'around'), ('searches', 'around', 'topic'), ('around', 'topic', ','), ('topic', ',', 'showing'), (',', 'showing', 'research'), ('showing', 'research', 'covers'), ('research', 'covers', 'large'), ('covers', 'large', 'study'), ('large', 'study', 'field'), ('study', 'field', 'academia'), ('field', 'academia', 'industry'), ('academia', 'industry', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('designed', 'VBD'), ('give', 'JJ'), ('overview', 'NN'), ('explored', 'VBD'), ('sources', 'NNS'), ('based', 'VBN'), ('extensive', 'JJ'), ('searches', 'NNS'), ('around', 'IN'), ('topic', 'NN'), (',', ','), ('showing', 'VBG'), ('research', 'NN'), ('covers', 'VBZ'), ('large', 'JJ'), ('study', 'NN'), ('field', 'NN'), ('academia', 'NN'), ('industry', 'NN'), ('.', '.')]

 (S
  It/PRP
  designed/VBD
  (NP give/JJ overview/NN)
  explored/VBD
  (NP sources/NNS)
  based/VBN
  (NP extensive/JJ searches/NNS)
  around/IN
  (NP topic/NN)
  ,/,
  showing/VBG
  (NP research/NN)
  covers/VBZ
  (NP large/JJ study/NN field/NN academia/NN industry/NN)
  ./.) 


>> Noun Phrases are: 
 ['give overview', 'sources', 'extensive searches', 'topic', 'research', 'large study field academia industry']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('designed', 'design'), ('give', 'give'), ('overview', 'overview'), ('explored', 'explor'), ('sources', 'sourc'), ('based', 'base'), ('extensive', 'extens'), ('searches', 'search'), ('around', 'around'), ('topic', 'topic'), (',', ','), ('showing', 'show'), ('research', 'research'), ('covers', 'cover'), ('large', 'larg'), ('study', 'studi'), ('field', 'field'), ('academia', 'academia'), ('industry', 'industri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('designed', 'design'), ('give', 'give'), ('overview', 'overview'), ('explored', 'explor'), ('sources', 'sourc'), ('based', 'base'), ('extensive', 'extens'), ('searches', 'search'), ('around', 'around'), ('topic', 'topic'), (',', ','), ('showing', 'show'), ('research', 'research'), ('covers', 'cover'), ('large', 'larg'), ('study', 'studi'), ('field', 'field'), ('academia', 'academia'), ('industry', 'industri'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('designed', 'designed'), ('give', 'give'), ('overview', 'overview'), ('explored', 'explored'), ('sources', 'source'), ('based', 'based'), ('extensive', 'extensive'), ('searches', 'search'), ('around', 'around'), ('topic', 'topic'), (',', ','), ('showing', 'showing'), ('research', 'research'), ('covers', 'cover'), ('large', 'large'), ('study', 'study'), ('field', 'field'), ('academia', 'academia'), ('industry', 'industry'), ('.', '.')]



============================ Sentence 108 =============================

 Writing a literary analysis and synthesis for this topic thus involved generating a discussion  based on several sources and showing the relationships between the sources, particularly   when different ideas or focuses emerged in the research that required explanation or   demonstrated new ideas or theories. 


>> Tokens are: 
 ['\uf075', 'Writing', 'literary', 'analysis', 'synthesis', 'topic', 'thus', 'involved', 'generating', 'discussion', 'based', 'several', 'sources', 'showing', 'relationships', 'sources', ',', 'particularly', 'different', 'ideas', 'focuses', 'emerged', 'research', 'required', 'explanation', 'demonstrated', 'new', 'ideas', 'theories', '.']

>> Bigrams are: 
 [('\uf075', 'Writing'), ('Writing', 'literary'), ('literary', 'analysis'), ('analysis', 'synthesis'), ('synthesis', 'topic'), ('topic', 'thus'), ('thus', 'involved'), ('involved', 'generating'), ('generating', 'discussion'), ('discussion', 'based'), ('based', 'several'), ('several', 'sources'), ('sources', 'showing'), ('showing', 'relationships'), ('relationships', 'sources'), ('sources', ','), (',', 'particularly'), ('particularly', 'different'), ('different', 'ideas'), ('ideas', 'focuses'), ('focuses', 'emerged'), ('emerged', 'research'), ('research', 'required'), ('required', 'explanation'), ('explanation', 'demonstrated'), ('demonstrated', 'new'), ('new', 'ideas'), ('ideas', 'theories'), ('theories', '.')]

>> Trigrams are: 
 [('\uf075', 'Writing', 'literary'), ('Writing', 'literary', 'analysis'), ('literary', 'analysis', 'synthesis'), ('analysis', 'synthesis', 'topic'), ('synthesis', 'topic', 'thus'), ('topic', 'thus', 'involved'), ('thus', 'involved', 'generating'), ('involved', 'generating', 'discussion'), ('generating', 'discussion', 'based'), ('discussion', 'based', 'several'), ('based', 'several', 'sources'), ('several', 'sources', 'showing'), ('sources', 'showing', 'relationships'), ('showing', 'relationships', 'sources'), ('relationships', 'sources', ','), ('sources', ',', 'particularly'), (',', 'particularly', 'different'), ('particularly', 'different', 'ideas'), ('different', 'ideas', 'focuses'), ('ideas', 'focuses', 'emerged'), ('focuses', 'emerged', 'research'), ('emerged', 'research', 'required'), ('research', 'required', 'explanation'), ('required', 'explanation', 'demonstrated'), ('explanation', 'demonstrated', 'new'), ('demonstrated', 'new', 'ideas'), ('new', 'ideas', 'theories'), ('ideas', 'theories', '.')]

>> POS Tags are: 
 [('\uf075', 'NN'), ('Writing', 'NNP'), ('literary', 'JJ'), ('analysis', 'NN'), ('synthesis', 'NN'), ('topic', 'NN'), ('thus', 'RB'), ('involved', 'JJ'), ('generating', 'VBG'), ('discussion', 'NN'), ('based', 'VBN'), ('several', 'JJ'), ('sources', 'NNS'), ('showing', 'VBG'), ('relationships', 'NNS'), ('sources', 'NNS'), (',', ','), ('particularly', 'RB'), ('different', 'JJ'), ('ideas', 'NNS'), ('focuses', 'VBZ'), ('emerged', 'VBD'), ('research', 'NN'), ('required', 'VBN'), ('explanation', 'NN'), ('demonstrated', 'VBD'), ('new', 'JJ'), ('ideas', 'NNS'), ('theories', 'NNS'), ('.', '.')]

 (S
  (NP /NN Writing/NNP)
  (NP literary/JJ analysis/NN synthesis/NN topic/NN)
  thus/RB
  involved/JJ
  generating/VBG
  (NP discussion/NN)
  based/VBN
  (NP several/JJ sources/NNS)
  showing/VBG
  (NP relationships/NNS sources/NNS)
  ,/,
  particularly/RB
  (NP different/JJ ideas/NNS)
  focuses/VBZ
  emerged/VBD
  (NP research/NN)
  required/VBN
  (NP explanation/NN)
  demonstrated/VBD
  (NP new/JJ ideas/NNS theories/NNS)
  ./.) 


>> Noun Phrases are: 
 ['\uf075 Writing', 'literary analysis synthesis topic', 'discussion', 'several sources', 'relationships sources', 'different ideas', 'research', 'explanation', 'new ideas theories']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('\uf075', '\uf075'), ('Writing', 'write'), ('literary', 'literari'), ('analysis', 'analysi'), ('synthesis', 'synthesi'), ('topic', 'topic'), ('thus', 'thu'), ('involved', 'involv'), ('generating', 'gener'), ('discussion', 'discuss'), ('based', 'base'), ('several', 'sever'), ('sources', 'sourc'), ('showing', 'show'), ('relationships', 'relationship'), ('sources', 'sourc'), (',', ','), ('particularly', 'particularli'), ('different', 'differ'), ('ideas', 'idea'), ('focuses', 'focus'), ('emerged', 'emerg'), ('research', 'research'), ('required', 'requir'), ('explanation', 'explan'), ('demonstrated', 'demonstr'), ('new', 'new'), ('ideas', 'idea'), ('theories', 'theori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('\uf075', '\uf075'), ('Writing', 'write'), ('literary', 'literari'), ('analysis', 'analysi'), ('synthesis', 'synthesi'), ('topic', 'topic'), ('thus', 'thus'), ('involved', 'involv'), ('generating', 'generat'), ('discussion', 'discuss'), ('based', 'base'), ('several', 'sever'), ('sources', 'sourc'), ('showing', 'show'), ('relationships', 'relationship'), ('sources', 'sourc'), (',', ','), ('particularly', 'particular'), ('different', 'differ'), ('ideas', 'idea'), ('focuses', 'focus'), ('emerged', 'emerg'), ('research', 'research'), ('required', 'requir'), ('explanation', 'explan'), ('demonstrated', 'demonstr'), ('new', 'new'), ('ideas', 'idea'), ('theories', 'theori'), ('.', '.')]

>> Lemmatization: 
 [('\uf075', '\uf075'), ('Writing', 'Writing'), ('literary', 'literary'), ('analysis', 'analysis'), ('synthesis', 'synthesis'), ('topic', 'topic'), ('thus', 'thus'), ('involved', 'involved'), ('generating', 'generating'), ('discussion', 'discussion'), ('based', 'based'), ('several', 'several'), ('sources', 'source'), ('showing', 'showing'), ('relationships', 'relationship'), ('sources', 'source'), (',', ','), ('particularly', 'particularly'), ('different', 'different'), ('ideas', 'idea'), ('focuses', 'focus'), ('emerged', 'emerged'), ('research', 'research'), ('required', 'required'), ('explanation', 'explanation'), ('demonstrated', 'demonstrated'), ('new', 'new'), ('ideas', 'idea'), ('theories', 'theory'), ('.', '.')]



============================ Sentence 109 =============================

Reviewing and combining the result    The research results from the big data analytics literature review are combined, then the  work is reviewed, alongside an explanation of the methodology used and the debates   arising. 


>> Tokens are: 
 ['Reviewing', 'combining', 'result', '\uf075', 'The', 'research', 'results', 'big', 'data', 'analytics', 'literature', 'review', 'combined', ',', 'work', 'reviewed', ',', 'alongside', 'explanation', 'methodology', 'used', 'debates', 'arising', '.']

>> Bigrams are: 
 [('Reviewing', 'combining'), ('combining', 'result'), ('result', '\uf075'), ('\uf075', 'The'), ('The', 'research'), ('research', 'results'), ('results', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'literature'), ('literature', 'review'), ('review', 'combined'), ('combined', ','), (',', 'work'), ('work', 'reviewed'), ('reviewed', ','), (',', 'alongside'), ('alongside', 'explanation'), ('explanation', 'methodology'), ('methodology', 'used'), ('used', 'debates'), ('debates', 'arising'), ('arising', '.')]

>> Trigrams are: 
 [('Reviewing', 'combining', 'result'), ('combining', 'result', '\uf075'), ('result', '\uf075', 'The'), ('\uf075', 'The', 'research'), ('The', 'research', 'results'), ('research', 'results', 'big'), ('results', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'literature'), ('analytics', 'literature', 'review'), ('literature', 'review', 'combined'), ('review', 'combined', ','), ('combined', ',', 'work'), (',', 'work', 'reviewed'), ('work', 'reviewed', ','), ('reviewed', ',', 'alongside'), (',', 'alongside', 'explanation'), ('alongside', 'explanation', 'methodology'), ('explanation', 'methodology', 'used'), ('methodology', 'used', 'debates'), ('used', 'debates', 'arising'), ('debates', 'arising', '.')]

>> POS Tags are: 
 [('Reviewing', 'VBG'), ('combining', 'VBG'), ('result', 'NN'), ('\uf075', 'VBD'), ('The', 'DT'), ('research', 'NN'), ('results', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('literature', 'VBP'), ('review', 'NN'), ('combined', 'VBN'), (',', ','), ('work', 'NN'), ('reviewed', 'VBD'), (',', ','), ('alongside', 'JJ'), ('explanation', 'NN'), ('methodology', 'NN'), ('used', 'VBN'), ('debates', 'NNS'), ('arising', 'VBG'), ('.', '.')]

 (S
  Reviewing/VBG
  combining/VBG
  (NP result/NN)
  /VBD
  (NP The/DT research/NN results/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  literature/VBP
  (NP review/NN)
  combined/VBN
  ,/,
  (NP work/NN)
  reviewed/VBD
  ,/,
  (NP alongside/JJ explanation/NN methodology/NN)
  used/VBN
  (NP debates/NNS)
  arising/VBG
  ./.) 


>> Noun Phrases are: 
 ['result', 'The research results', 'big data analytics', 'review', 'work', 'alongside explanation methodology', 'debates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reviewing', 'review'), ('combining', 'combin'), ('result', 'result'), ('\uf075', '\uf075'), ('The', 'the'), ('research', 'research'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('literature', 'literatur'), ('review', 'review'), ('combined', 'combin'), (',', ','), ('work', 'work'), ('reviewed', 'review'), (',', ','), ('alongside', 'alongsid'), ('explanation', 'explan'), ('methodology', 'methodolog'), ('used', 'use'), ('debates', 'debat'), ('arising', 'aris'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reviewing', 'review'), ('combining', 'combin'), ('result', 'result'), ('\uf075', '\uf075'), ('The', 'the'), ('research', 'research'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('literature', 'literatur'), ('review', 'review'), ('combined', 'combin'), (',', ','), ('work', 'work'), ('reviewed', 'review'), (',', ','), ('alongside', 'alongsid'), ('explanation', 'explan'), ('methodology', 'methodolog'), ('used', 'use'), ('debates', 'debat'), ('arising', 'aris'), ('.', '.')]

>> Lemmatization: 
 [('Reviewing', 'Reviewing'), ('combining', 'combining'), ('result', 'result'), ('\uf075', '\uf075'), ('The', 'The'), ('research', 'research'), ('results', 'result'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('literature', 'literature'), ('review', 'review'), ('combined', 'combined'), (',', ','), ('work', 'work'), ('reviewed', 'reviewed'), (',', ','), ('alongside', 'alongside'), ('explanation', 'explanation'), ('methodology', 'methodology'), ('used', 'used'), ('debates', 'debate'), ('arising', 'arising'), ('.', '.')]



============================ Sentence 110 =============================

https://www.scimagojr.com/journalsearch.php?q=12402&tip=sid&clean=0 https://www.scimagojr.com/journalsearch.php?q=15574&tip=sid&clean=0 https://www.scimagojr.com/journalsearch.php?q=15574&tip=sid&clean=0   Sarah Al-Shiakhli   7         Figure 5: Literature review processes. 


>> Tokens are: 
 ['https', ':', '//www.scimagojr.com/journalsearch.php', '?', 'q=12402', '&', 'tip=sid', '&', 'clean=0', 'https', ':', '//www.scimagojr.com/journalsearch.php', '?', 'q=15574', '&', 'tip=sid', '&', 'clean=0', 'https', ':', '//www.scimagojr.com/journalsearch.php', '?', 'q=15574', '&', 'tip=sid', '&', 'clean=0', 'Sarah', 'Al-Shiakhli', '7', 'Figure', '5', ':', 'Literature', 'review', 'processes', '.']

>> Bigrams are: 
 [('https', ':'), (':', '//www.scimagojr.com/journalsearch.php'), ('//www.scimagojr.com/journalsearch.php', '?'), ('?', 'q=12402'), ('q=12402', '&'), ('&', 'tip=sid'), ('tip=sid', '&'), ('&', 'clean=0'), ('clean=0', 'https'), ('https', ':'), (':', '//www.scimagojr.com/journalsearch.php'), ('//www.scimagojr.com/journalsearch.php', '?'), ('?', 'q=15574'), ('q=15574', '&'), ('&', 'tip=sid'), ('tip=sid', '&'), ('&', 'clean=0'), ('clean=0', 'https'), ('https', ':'), (':', '//www.scimagojr.com/journalsearch.php'), ('//www.scimagojr.com/journalsearch.php', '?'), ('?', 'q=15574'), ('q=15574', '&'), ('&', 'tip=sid'), ('tip=sid', '&'), ('&', 'clean=0'), ('clean=0', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '7'), ('7', 'Figure'), ('Figure', '5'), ('5', ':'), (':', 'Literature'), ('Literature', 'review'), ('review', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('https', ':', '//www.scimagojr.com/journalsearch.php'), (':', '//www.scimagojr.com/journalsearch.php', '?'), ('//www.scimagojr.com/journalsearch.php', '?', 'q=12402'), ('?', 'q=12402', '&'), ('q=12402', '&', 'tip=sid'), ('&', 'tip=sid', '&'), ('tip=sid', '&', 'clean=0'), ('&', 'clean=0', 'https'), ('clean=0', 'https', ':'), ('https', ':', '//www.scimagojr.com/journalsearch.php'), (':', '//www.scimagojr.com/journalsearch.php', '?'), ('//www.scimagojr.com/journalsearch.php', '?', 'q=15574'), ('?', 'q=15574', '&'), ('q=15574', '&', 'tip=sid'), ('&', 'tip=sid', '&'), ('tip=sid', '&', 'clean=0'), ('&', 'clean=0', 'https'), ('clean=0', 'https', ':'), ('https', ':', '//www.scimagojr.com/journalsearch.php'), (':', '//www.scimagojr.com/journalsearch.php', '?'), ('//www.scimagojr.com/journalsearch.php', '?', 'q=15574'), ('?', 'q=15574', '&'), ('q=15574', '&', 'tip=sid'), ('&', 'tip=sid', '&'), ('tip=sid', '&', 'clean=0'), ('&', 'clean=0', 'Sarah'), ('clean=0', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '7'), ('Al-Shiakhli', '7', 'Figure'), ('7', 'Figure', '5'), ('Figure', '5', ':'), ('5', ':', 'Literature'), (':', 'Literature', 'review'), ('Literature', 'review', 'processes'), ('review', 'processes', '.')]

>> POS Tags are: 
 [('https', 'NN'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', 'NN'), ('?', '.'), ('q=12402', 'NN'), ('&', 'CC'), ('tip=sid', 'NN'), ('&', 'CC'), ('clean=0', 'NN'), ('https', 'NN'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', 'NN'), ('?', '.'), ('q=15574', 'NN'), ('&', 'CC'), ('tip=sid', 'NN'), ('&', 'CC'), ('clean=0', 'NN'), ('https', 'NN'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', 'NN'), ('?', '.'), ('q=15574', 'NN'), ('&', 'CC'), ('tip=sid', 'NN'), ('&', 'CC'), ('clean=0', 'NN'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('7', 'CD'), ('Figure', 'NNP'), ('5', 'CD'), (':', ':'), ('Literature', 'NN'), ('review', 'NN'), ('processes', 'VBZ'), ('.', '.')]

 (S
  (NP https/NN)
  :/:
  (NP //www.scimagojr.com/journalsearch.php/NN)
  ?/.
  (NP q=12402/NN)
  &/CC
  (NP tip=sid/NN)
  &/CC
  (NP clean=0/NN https/NN)
  :/:
  (NP //www.scimagojr.com/journalsearch.php/NN)
  ?/.
  (NP q=15574/NN)
  &/CC
  (NP tip=sid/NN)
  &/CC
  (NP clean=0/NN https/NN)
  :/:
  (NP //www.scimagojr.com/journalsearch.php/NN)
  ?/.
  (NP q=15574/NN)
  &/CC
  (NP tip=sid/NN)
  &/CC
  (NP clean=0/NN Sarah/NNP Al-Shiakhli/NNP)
  7/CD
  (NP Figure/NNP)
  5/CD
  :/:
  (NP Literature/NN review/NN)
  processes/VBZ
  ./.) 


>> Noun Phrases are: 
 ['https', '//www.scimagojr.com/journalsearch.php', 'q=12402', 'tip=sid', 'clean=0 https', '//www.scimagojr.com/journalsearch.php', 'q=15574', 'tip=sid', 'clean=0 https', '//www.scimagojr.com/journalsearch.php', 'q=15574', 'tip=sid', 'clean=0 Sarah Al-Shiakhli', 'Figure', 'Literature review']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('https', 'http'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=12402', 'q=12402'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('https', 'http'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=15574', 'q=15574'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('https', 'http'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=15574', 'q=15574'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('7', '7'), ('Figure', 'figur'), ('5', '5'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('https', 'https'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=12402', 'q=12402'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('https', 'https'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=15574', 'q=15574'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('https', 'https'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=15574', 'q=15574'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('7', '7'), ('Figure', 'figur'), ('5', '5'), (':', ':'), ('Literature', 'literatur'), ('review', 'review'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('https', 'http'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=12402', 'q=12402'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('https', 'http'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=15574', 'q=15574'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('https', 'http'), (':', ':'), ('//www.scimagojr.com/journalsearch.php', '//www.scimagojr.com/journalsearch.php'), ('?', '?'), ('q=15574', 'q=15574'), ('&', '&'), ('tip=sid', 'tip=sid'), ('&', '&'), ('clean=0', 'clean=0'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('7', '7'), ('Figure', 'Figure'), ('5', '5'), (':', ':'), ('Literature', 'Literature'), ('review', 'review'), ('processes', 'process'), ('.', '.')]



============================ Sentence 111 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 112 =============================

Scope delimitation and risks    The scope of this research will be determining the shortcomings in reviewing big data analytics,   one can determine what has been defined and what is the criteria for selecting the analytics and   tools for big data. 


>> Tokens are: 
 ['Scope', 'delimitation', 'risks', 'The', 'scope', 'research', 'determining', 'shortcomings', 'reviewing', 'big', 'data', 'analytics', ',', 'one', 'determine', 'defined', 'criteria', 'selecting', 'analytics', 'tools', 'big', 'data', '.']

>> Bigrams are: 
 [('Scope', 'delimitation'), ('delimitation', 'risks'), ('risks', 'The'), ('The', 'scope'), ('scope', 'research'), ('research', 'determining'), ('determining', 'shortcomings'), ('shortcomings', 'reviewing'), ('reviewing', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'one'), ('one', 'determine'), ('determine', 'defined'), ('defined', 'criteria'), ('criteria', 'selecting'), ('selecting', 'analytics'), ('analytics', 'tools'), ('tools', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Scope', 'delimitation', 'risks'), ('delimitation', 'risks', 'The'), ('risks', 'The', 'scope'), ('The', 'scope', 'research'), ('scope', 'research', 'determining'), ('research', 'determining', 'shortcomings'), ('determining', 'shortcomings', 'reviewing'), ('shortcomings', 'reviewing', 'big'), ('reviewing', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'one'), (',', 'one', 'determine'), ('one', 'determine', 'defined'), ('determine', 'defined', 'criteria'), ('defined', 'criteria', 'selecting'), ('criteria', 'selecting', 'analytics'), ('selecting', 'analytics', 'tools'), ('analytics', 'tools', 'big'), ('tools', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Scope', 'NNP'), ('delimitation', 'NN'), ('risks', 'VBZ'), ('The', 'DT'), ('scope', 'NN'), ('research', 'NN'), ('determining', 'VBG'), ('shortcomings', 'NNS'), ('reviewing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('one', 'CD'), ('determine', 'NN'), ('defined', 'VBN'), ('criteria', 'NNS'), ('selecting', 'VBG'), ('analytics', 'NNS'), ('tools', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Scope/NNP delimitation/NN)
  risks/VBZ
  (NP The/DT scope/NN research/NN)
  determining/VBG
  (NP shortcomings/NNS)
  reviewing/VBG
  (NP big/JJ data/NNS analytics/NNS)
  ,/,
  one/CD
  (NP determine/NN)
  defined/VBN
  (NP criteria/NNS)
  selecting/VBG
  (NP analytics/NNS tools/NNS)
  (NP big/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Scope delimitation', 'The scope research', 'shortcomings', 'big data analytics', 'determine', 'criteria', 'analytics tools', 'big data']

>> Named Entities are: 
 [('GPE', 'Scope')] 

>> Stemming using Porter Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk'), ('The', 'the'), ('scope', 'scope'), ('research', 'research'), ('determining', 'determin'), ('shortcomings', 'shortcom'), ('reviewing', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('one', 'one'), ('determine', 'determin'), ('defined', 'defin'), ('criteria', 'criteria'), ('selecting', 'select'), ('analytics', 'analyt'), ('tools', 'tool'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Scope', 'scope'), ('delimitation', 'delimit'), ('risks', 'risk'), ('The', 'the'), ('scope', 'scope'), ('research', 'research'), ('determining', 'determin'), ('shortcomings', 'shortcom'), ('reviewing', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('one', 'one'), ('determine', 'determin'), ('defined', 'defin'), ('criteria', 'criteria'), ('selecting', 'select'), ('analytics', 'analyt'), ('tools', 'tool'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Scope', 'Scope'), ('delimitation', 'delimitation'), ('risks', 'risk'), ('The', 'The'), ('scope', 'scope'), ('research', 'research'), ('determining', 'determining'), ('shortcomings', 'shortcoming'), ('reviewing', 'reviewing'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('one', 'one'), ('determine', 'determine'), ('defined', 'defined'), ('criteria', 'criterion'), ('selecting', 'selecting'), ('analytics', 'analytics'), ('tools', 'tool'), ('big', 'big'), ('data', 'data'), ('.', '.')]



============================ Sentence 113 =============================

The review can reveal which problems have been solved, and what else should   be known. 


>> Tokens are: 
 ['The', 'review', 'reveal', 'problems', 'solved', ',', 'else', 'known', '.']

>> Bigrams are: 
 [('The', 'review'), ('review', 'reveal'), ('reveal', 'problems'), ('problems', 'solved'), ('solved', ','), (',', 'else'), ('else', 'known'), ('known', '.')]

>> Trigrams are: 
 [('The', 'review', 'reveal'), ('review', 'reveal', 'problems'), ('reveal', 'problems', 'solved'), ('problems', 'solved', ','), ('solved', ',', 'else'), (',', 'else', 'known'), ('else', 'known', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('review', 'NN'), ('reveal', 'NN'), ('problems', 'NNS'), ('solved', 'VBD'), (',', ','), ('else', 'RB'), ('known', 'VBN'), ('.', '.')]

 (S
  (NP The/DT review/NN reveal/NN problems/NNS)
  solved/VBD
  ,/,
  else/RB
  known/VBN
  ./.) 


>> Noun Phrases are: 
 ['The review reveal problems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('review', 'review'), ('reveal', 'reveal'), ('problems', 'problem'), ('solved', 'solv'), (',', ','), ('else', 'els'), ('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('review', 'review'), ('reveal', 'reveal'), ('problems', 'problem'), ('solved', 'solv'), (',', ','), ('else', 'els'), ('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('review', 'review'), ('reveal', 'reveal'), ('problems', 'problem'), ('solved', 'solved'), (',', ','), ('else', 'else'), ('known', 'known'), ('.', '.')]



============================ Sentence 114 =============================

Moreover, it helps notifying the researchers about what have been presented which   might open the doors for them to conduct more analytics for big data being an important topic   nowadays and people directing toward this concept. 


>> Tokens are: 
 ['Moreover', ',', 'helps', 'notifying', 'researchers', 'presented', 'might', 'open', 'doors', 'conduct', 'analytics', 'big', 'data', 'important', 'topic', 'nowadays', 'people', 'directing', 'toward', 'concept', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'helps'), ('helps', 'notifying'), ('notifying', 'researchers'), ('researchers', 'presented'), ('presented', 'might'), ('might', 'open'), ('open', 'doors'), ('doors', 'conduct'), ('conduct', 'analytics'), ('analytics', 'big'), ('big', 'data'), ('data', 'important'), ('important', 'topic'), ('topic', 'nowadays'), ('nowadays', 'people'), ('people', 'directing'), ('directing', 'toward'), ('toward', 'concept'), ('concept', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'helps'), (',', 'helps', 'notifying'), ('helps', 'notifying', 'researchers'), ('notifying', 'researchers', 'presented'), ('researchers', 'presented', 'might'), ('presented', 'might', 'open'), ('might', 'open', 'doors'), ('open', 'doors', 'conduct'), ('doors', 'conduct', 'analytics'), ('conduct', 'analytics', 'big'), ('analytics', 'big', 'data'), ('big', 'data', 'important'), ('data', 'important', 'topic'), ('important', 'topic', 'nowadays'), ('topic', 'nowadays', 'people'), ('nowadays', 'people', 'directing'), ('people', 'directing', 'toward'), ('directing', 'toward', 'concept'), ('toward', 'concept', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('helps', 'VBZ'), ('notifying', 'VBG'), ('researchers', 'NNS'), ('presented', 'VBD'), ('might', 'MD'), ('open', 'VB'), ('doors', 'NNS'), ('conduct', 'VBP'), ('analytics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('important', 'JJ'), ('topic', 'NN'), ('nowadays', 'JJ'), ('people', 'NNS'), ('directing', 'VBG'), ('toward', 'IN'), ('concept', 'NN'), ('.', '.')]

 (S
  Moreover/RB
  ,/,
  helps/VBZ
  notifying/VBG
  (NP researchers/NNS)
  presented/VBD
  might/MD
  open/VB
  (NP doors/NNS)
  conduct/VBP
  (NP analytics/NNS)
  (NP big/JJ data/NNS)
  (NP important/JJ topic/NN)
  (NP nowadays/JJ people/NNS)
  directing/VBG
  toward/IN
  (NP concept/NN)
  ./.) 


>> Noun Phrases are: 
 ['researchers', 'doors', 'analytics', 'big data', 'important topic', 'nowadays people', 'concept']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('helps', 'help'), ('notifying', 'notifi'), ('researchers', 'research'), ('presented', 'present'), ('might', 'might'), ('open', 'open'), ('doors', 'door'), ('conduct', 'conduct'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('important', 'import'), ('topic', 'topic'), ('nowadays', 'nowaday'), ('people', 'peopl'), ('directing', 'direct'), ('toward', 'toward'), ('concept', 'concept'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('helps', 'help'), ('notifying', 'notifi'), ('researchers', 'research'), ('presented', 'present'), ('might', 'might'), ('open', 'open'), ('doors', 'door'), ('conduct', 'conduct'), ('analytics', 'analyt'), ('big', 'big'), ('data', 'data'), ('important', 'import'), ('topic', 'topic'), ('nowadays', 'nowaday'), ('people', 'peopl'), ('directing', 'direct'), ('toward', 'toward'), ('concept', 'concept'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('helps', 'help'), ('notifying', 'notifying'), ('researchers', 'researcher'), ('presented', 'presented'), ('might', 'might'), ('open', 'open'), ('doors', 'door'), ('conduct', 'conduct'), ('analytics', 'analytics'), ('big', 'big'), ('data', 'data'), ('important', 'important'), ('topic', 'topic'), ('nowadays', 'nowadays'), ('people', 'people'), ('directing', 'directing'), ('toward', 'toward'), ('concept', 'concept'), ('.', '.')]



============================ Sentence 115 =============================

The main challenges of using big data, which need to be resolved before it can be used effectively,   include security and privacy issues, data capturing issues, and challenges in data analysis and   visualization to raise the positive role of big data analytics to many sectors. 


>> Tokens are: 
 ['The', 'main', 'challenges', 'using', 'big', 'data', ',', 'need', 'resolved', 'used', 'effectively', ',', 'include', 'security', 'privacy', 'issues', ',', 'data', 'capturing', 'issues', ',', 'challenges', 'data', 'analysis', 'visualization', 'raise', 'positive', 'role', 'big', 'data', 'analytics', 'many', 'sectors', '.']

>> Bigrams are: 
 [('The', 'main'), ('main', 'challenges'), ('challenges', 'using'), ('using', 'big'), ('big', 'data'), ('data', ','), (',', 'need'), ('need', 'resolved'), ('resolved', 'used'), ('used', 'effectively'), ('effectively', ','), (',', 'include'), ('include', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', ','), (',', 'data'), ('data', 'capturing'), ('capturing', 'issues'), ('issues', ','), (',', 'challenges'), ('challenges', 'data'), ('data', 'analysis'), ('analysis', 'visualization'), ('visualization', 'raise'), ('raise', 'positive'), ('positive', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'many'), ('many', 'sectors'), ('sectors', '.')]

>> Trigrams are: 
 [('The', 'main', 'challenges'), ('main', 'challenges', 'using'), ('challenges', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'need'), (',', 'need', 'resolved'), ('need', 'resolved', 'used'), ('resolved', 'used', 'effectively'), ('used', 'effectively', ','), ('effectively', ',', 'include'), (',', 'include', 'security'), ('include', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', ','), ('issues', ',', 'data'), (',', 'data', 'capturing'), ('data', 'capturing', 'issues'), ('capturing', 'issues', ','), ('issues', ',', 'challenges'), (',', 'challenges', 'data'), ('challenges', 'data', 'analysis'), ('data', 'analysis', 'visualization'), ('analysis', 'visualization', 'raise'), ('visualization', 'raise', 'positive'), ('raise', 'positive', 'role'), ('positive', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'many'), ('analytics', 'many', 'sectors'), ('many', 'sectors', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('challenges', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('need', 'VBP'), ('resolved', 'VBN'), ('used', 'JJ'), ('effectively', 'RB'), (',', ','), ('include', 'VBP'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), (',', ','), ('data', 'NNS'), ('capturing', 'VBG'), ('issues', 'NNS'), (',', ','), ('challenges', 'NNS'), ('data', 'VBP'), ('analysis', 'NN'), ('visualization', 'NN'), ('raise', 'VB'), ('positive', 'JJ'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('many', 'JJ'), ('sectors', 'NNS'), ('.', '.')]

 (S
  (NP The/DT main/JJ challenges/NNS)
  using/VBG
  (NP big/JJ data/NNS)
  ,/,
  need/VBP
  resolved/VBN
  used/JJ
  effectively/RB
  ,/,
  include/VBP
  (NP security/NN privacy/NN issues/NNS)
  ,/,
  (NP data/NNS)
  capturing/VBG
  (NP issues/NNS)
  ,/,
  (NP challenges/NNS)
  data/VBP
  (NP analysis/NN visualization/NN)
  raise/VB
  (NP positive/JJ role/NN)
  (NP big/JJ data/NNS analytics/NNS)
  (NP many/JJ sectors/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The main challenges', 'big data', 'security privacy issues', 'data', 'issues', 'challenges', 'analysis visualization', 'positive role', 'big data analytics', 'many sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use'), ('effectively', 'effect'), (',', ','), ('include', 'includ'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('data', 'data'), ('capturing', 'captur'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualization', 'visual'), ('raise', 'rais'), ('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use'), ('effectively', 'effect'), (',', ','), ('include', 'includ'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('data', 'data'), ('capturing', 'captur'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualization', 'visual'), ('raise', 'rais'), ('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('challenges', 'challenge'), ('using', 'using'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolved'), ('used', 'used'), ('effectively', 'effectively'), (',', ','), ('include', 'include'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), (',', ','), ('data', 'data'), ('capturing', 'capturing'), ('issues', 'issue'), (',', ','), ('challenges', 'challenge'), ('data', 'data'), ('analysis', 'analysis'), ('visualization', 'visualization'), ('raise', 'raise'), ('positive', 'positive'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('many', 'many'), ('sectors', 'sector'), ('.', '.')]



============================ Sentence 116 =============================

Storing the massive   volume of data coming from different sources is another key point that needs to be addressed yet   not currently resolved with the available tools. 


>> Tokens are: 
 ['Storing', 'massive', 'volume', 'data', 'coming', 'different', 'sources', 'another', 'key', 'point', 'needs', 'addressed', 'yet', 'currently', 'resolved', 'available', 'tools', '.']

>> Bigrams are: 
 [('Storing', 'massive'), ('massive', 'volume'), ('volume', 'data'), ('data', 'coming'), ('coming', 'different'), ('different', 'sources'), ('sources', 'another'), ('another', 'key'), ('key', 'point'), ('point', 'needs'), ('needs', 'addressed'), ('addressed', 'yet'), ('yet', 'currently'), ('currently', 'resolved'), ('resolved', 'available'), ('available', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('Storing', 'massive', 'volume'), ('massive', 'volume', 'data'), ('volume', 'data', 'coming'), ('data', 'coming', 'different'), ('coming', 'different', 'sources'), ('different', 'sources', 'another'), ('sources', 'another', 'key'), ('another', 'key', 'point'), ('key', 'point', 'needs'), ('point', 'needs', 'addressed'), ('needs', 'addressed', 'yet'), ('addressed', 'yet', 'currently'), ('yet', 'currently', 'resolved'), ('currently', 'resolved', 'available'), ('resolved', 'available', 'tools'), ('available', 'tools', '.')]

>> POS Tags are: 
 [('Storing', 'VBG'), ('massive', 'JJ'), ('volume', 'NN'), ('data', 'NNS'), ('coming', 'VBG'), ('different', 'JJ'), ('sources', 'NNS'), ('another', 'DT'), ('key', 'JJ'), ('point', 'NN'), ('needs', 'NNS'), ('addressed', 'VBN'), ('yet', 'RB'), ('currently', 'RB'), ('resolved', 'VBN'), ('available', 'JJ'), ('tools', 'NNS'), ('.', '.')]

 (S
  Storing/VBG
  (NP massive/JJ volume/NN data/NNS)
  coming/VBG
  (NP different/JJ sources/NNS)
  (NP another/DT key/JJ point/NN needs/NNS)
  addressed/VBN
  yet/RB
  currently/RB
  resolved/VBN
  (NP available/JJ tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['massive volume data', 'different sources', 'another key point needs', 'available tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Storing', 'store'), ('massive', 'massiv'), ('volume', 'volum'), ('data', 'data'), ('coming', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('another', 'anoth'), ('key', 'key'), ('point', 'point'), ('needs', 'need'), ('addressed', 'address'), ('yet', 'yet'), ('currently', 'current'), ('resolved', 'resolv'), ('available', 'avail'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Storing', 'store'), ('massive', 'massiv'), ('volume', 'volum'), ('data', 'data'), ('coming', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('another', 'anoth'), ('key', 'key'), ('point', 'point'), ('needs', 'need'), ('addressed', 'address'), ('yet', 'yet'), ('currently', 'current'), ('resolved', 'resolv'), ('available', 'avail'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('Storing', 'Storing'), ('massive', 'massive'), ('volume', 'volume'), ('data', 'data'), ('coming', 'coming'), ('different', 'different'), ('sources', 'source'), ('another', 'another'), ('key', 'key'), ('point', 'point'), ('needs', 'need'), ('addressed', 'addressed'), ('yet', 'yet'), ('currently', 'currently'), ('resolved', 'resolved'), ('available', 'available'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 117 =============================

That created a need for studying and exploring new   analytics method which might help in addressing some difficulties in some sectors such as in retail,   banking, healthcare, etc. 


>> Tokens are: 
 ['That', 'created', 'need', 'studying', 'exploring', 'new', 'analytics', 'method', 'might', 'help', 'addressing', 'difficulties', 'sectors', 'retail', ',', 'banking', ',', 'healthcare', ',', 'etc', '.']

>> Bigrams are: 
 [('That', 'created'), ('created', 'need'), ('need', 'studying'), ('studying', 'exploring'), ('exploring', 'new'), ('new', 'analytics'), ('analytics', 'method'), ('method', 'might'), ('might', 'help'), ('help', 'addressing'), ('addressing', 'difficulties'), ('difficulties', 'sectors'), ('sectors', 'retail'), ('retail', ','), (',', 'banking'), ('banking', ','), (',', 'healthcare'), ('healthcare', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('That', 'created', 'need'), ('created', 'need', 'studying'), ('need', 'studying', 'exploring'), ('studying', 'exploring', 'new'), ('exploring', 'new', 'analytics'), ('new', 'analytics', 'method'), ('analytics', 'method', 'might'), ('method', 'might', 'help'), ('might', 'help', 'addressing'), ('help', 'addressing', 'difficulties'), ('addressing', 'difficulties', 'sectors'), ('difficulties', 'sectors', 'retail'), ('sectors', 'retail', ','), ('retail', ',', 'banking'), (',', 'banking', ','), ('banking', ',', 'healthcare'), (',', 'healthcare', ','), ('healthcare', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('created', 'VBD'), ('need', 'MD'), ('studying', 'VBG'), ('exploring', 'VBG'), ('new', 'JJ'), ('analytics', 'NNS'), ('method', 'NN'), ('might', 'MD'), ('help', 'VB'), ('addressing', 'VBG'), ('difficulties', 'NNS'), ('sectors', 'NNS'), ('retail', 'JJ'), (',', ','), ('banking', 'NN'), (',', ','), ('healthcare', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  That/DT
  created/VBD
  need/MD
  studying/VBG
  exploring/VBG
  (NP new/JJ analytics/NNS method/NN)
  might/MD
  help/VB
  addressing/VBG
  (NP difficulties/NNS sectors/NNS)
  retail/JJ
  ,/,
  (NP banking/NN)
  ,/,
  (NP healthcare/NN)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['new analytics method', 'difficulties sectors', 'banking', 'healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('created', 'creat'), ('need', 'need'), ('studying', 'studi'), ('exploring', 'explor'), ('new', 'new'), ('analytics', 'analyt'), ('method', 'method'), ('might', 'might'), ('help', 'help'), ('addressing', 'address'), ('difficulties', 'difficulti'), ('sectors', 'sector'), ('retail', 'retail'), (',', ','), ('banking', 'bank'), (',', ','), ('healthcare', 'healthcar'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('created', 'creat'), ('need', 'need'), ('studying', 'studi'), ('exploring', 'explor'), ('new', 'new'), ('analytics', 'analyt'), ('method', 'method'), ('might', 'might'), ('help', 'help'), ('addressing', 'address'), ('difficulties', 'difficulti'), ('sectors', 'sector'), ('retail', 'retail'), (',', ','), ('banking', 'bank'), (',', ','), ('healthcare', 'healthcar'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('created', 'created'), ('need', 'need'), ('studying', 'studying'), ('exploring', 'exploring'), ('new', 'new'), ('analytics', 'analytics'), ('method', 'method'), ('might', 'might'), ('help', 'help'), ('addressing', 'addressing'), ('difficulties', 'difficulty'), ('sectors', 'sector'), ('retail', 'retail'), (',', ','), ('banking', 'banking'), (',', ','), ('healthcare', 'healthcare'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 118 =============================

Determining the possible solutions to the shortcomings with, data visualization, predictive   analytics, descriptive analytics, and diagnostic analytics which are solutions to big data challenges   in capturing and analysing the data. 


>> Tokens are: 
 ['Determining', 'possible', 'solutions', 'shortcomings', ',', 'data', 'visualization', ',', 'predictive', 'analytics', ',', 'descriptive', 'analytics', ',', 'diagnostic', 'analytics', 'solutions', 'big', 'data', 'challenges', 'capturing', 'analysing', 'data', '.']

>> Bigrams are: 
 [('Determining', 'possible'), ('possible', 'solutions'), ('solutions', 'shortcomings'), ('shortcomings', ','), (',', 'data'), ('data', 'visualization'), ('visualization', ','), (',', 'predictive'), ('predictive', 'analytics'), ('analytics', ','), (',', 'descriptive'), ('descriptive', 'analytics'), ('analytics', ','), (',', 'diagnostic'), ('diagnostic', 'analytics'), ('analytics', 'solutions'), ('solutions', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'capturing'), ('capturing', 'analysing'), ('analysing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Determining', 'possible', 'solutions'), ('possible', 'solutions', 'shortcomings'), ('solutions', 'shortcomings', ','), ('shortcomings', ',', 'data'), (',', 'data', 'visualization'), ('data', 'visualization', ','), ('visualization', ',', 'predictive'), (',', 'predictive', 'analytics'), ('predictive', 'analytics', ','), ('analytics', ',', 'descriptive'), (',', 'descriptive', 'analytics'), ('descriptive', 'analytics', ','), ('analytics', ',', 'diagnostic'), (',', 'diagnostic', 'analytics'), ('diagnostic', 'analytics', 'solutions'), ('analytics', 'solutions', 'big'), ('solutions', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'capturing'), ('challenges', 'capturing', 'analysing'), ('capturing', 'analysing', 'data'), ('analysing', 'data', '.')]

>> POS Tags are: 
 [('Determining', 'VBG'), ('possible', 'JJ'), ('solutions', 'NNS'), ('shortcomings', 'NNS'), (',', ','), ('data', 'NNS'), ('visualization', 'NN'), (',', ','), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('descriptive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('diagnostic', 'JJ'), ('analytics', 'NNS'), ('solutions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('capturing', 'VBG'), ('analysing', 'VBG'), ('data', 'NNS'), ('.', '.')]

 (S
  Determining/VBG
  (NP possible/JJ solutions/NNS shortcomings/NNS)
  ,/,
  (NP data/NNS visualization/NN)
  ,/,
  (NP predictive/JJ analytics/NNS)
  ,/,
  (NP descriptive/JJ analytics/NNS)
  ,/,
  (NP diagnostic/JJ analytics/NNS solutions/NNS)
  (NP big/JJ data/NNS challenges/NNS)
  capturing/VBG
  analysing/VBG
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['possible solutions shortcomings', 'data visualization', 'predictive analytics', 'descriptive analytics', 'diagnostic analytics solutions', 'big data challenges', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Determining', 'determin'), ('possible', 'possibl'), ('solutions', 'solut'), ('shortcomings', 'shortcom'), (',', ','), ('data', 'data'), ('visualization', 'visual'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('capturing', 'captur'), ('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Determining', 'determin'), ('possible', 'possibl'), ('solutions', 'solut'), ('shortcomings', 'shortcom'), (',', ','), ('data', 'data'), ('visualization', 'visual'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('solutions', 'solut'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('capturing', 'captur'), ('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Determining', 'Determining'), ('possible', 'possible'), ('solutions', 'solution'), ('shortcomings', 'shortcoming'), (',', ','), ('data', 'data'), ('visualization', 'visualization'), (',', ','), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ','), ('descriptive', 'descriptive'), ('analytics', 'analytics'), (',', ','), ('diagnostic', 'diagnostic'), ('analytics', 'analytics'), ('solutions', 'solution'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('capturing', 'capturing'), ('analysing', 'analysing'), ('data', 'data'), ('.', '.')]



============================ Sentence 119 =============================

Organisations and individual use statistical models and     Sarah Al-Shiakhli   8      artificial intelligence modelling. 


>> Tokens are: 
 ['Organisations', 'individual', 'use', 'statistical', 'models', 'Sarah', 'Al-Shiakhli', '8', 'artificial', 'intelligence', 'modelling', '.']

>> Bigrams are: 
 [('Organisations', 'individual'), ('individual', 'use'), ('use', 'statistical'), ('statistical', 'models'), ('models', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '8'), ('8', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'modelling'), ('modelling', '.')]

>> Trigrams are: 
 [('Organisations', 'individual', 'use'), ('individual', 'use', 'statistical'), ('use', 'statistical', 'models'), ('statistical', 'models', 'Sarah'), ('models', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '8'), ('Al-Shiakhli', '8', 'artificial'), ('8', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'modelling'), ('intelligence', 'modelling', '.')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('individual', 'JJ'), ('use', 'RB'), ('statistical', 'JJ'), ('models', 'NNS'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('8', 'CD'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('modelling', 'NN'), ('.', '.')]

 (S
  (NP Organisations/NNS)
  individual/JJ
  use/RB
  (NP statistical/JJ models/NNS Sarah/NNP Al-Shiakhli/NNP)
  8/CD
  (NP artificial/JJ intelligence/NN modelling/NN)
  ./.) 


>> Noun Phrases are: 
 ['Organisations', 'statistical models Sarah Al-Shiakhli', 'artificial intelligence modelling']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('8', '8'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('8', '8'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('.', '.')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('individual', 'individual'), ('use', 'use'), ('statistical', 'statistical'), ('models', 'model'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('8', '8'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('modelling', 'modelling'), ('.', '.')]



============================ Sentence 120 =============================

Also, machine learning algorithms can integrate statistical and   artificial intelligence methods to analyse massive amounts of data with high-performance. 


>> Tokens are: 
 ['Also', ',', 'machine', 'learning', 'algorithms', 'integrate', 'statistical', 'artificial', 'intelligence', 'methods', 'analyse', 'massive', 'amounts', 'data', 'high-performance', '.']

>> Bigrams are: 
 [('Also', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'integrate'), ('integrate', 'statistical'), ('statistical', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'methods'), ('methods', 'analyse'), ('analyse', 'massive'), ('massive', 'amounts'), ('amounts', 'data'), ('data', 'high-performance'), ('high-performance', '.')]

>> Trigrams are: 
 [('Also', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'integrate'), ('algorithms', 'integrate', 'statistical'), ('integrate', 'statistical', 'artificial'), ('statistical', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'methods'), ('intelligence', 'methods', 'analyse'), ('methods', 'analyse', 'massive'), ('analyse', 'massive', 'amounts'), ('massive', 'amounts', 'data'), ('amounts', 'data', 'high-performance'), ('data', 'high-performance', '.')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('integrate', 'JJ'), ('statistical', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('methods', 'NNS'), ('analyse', 'VBP'), ('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('high-performance', 'NN'), ('.', '.')]

 (S
  Also/RB
  ,/,
  (NP machine/NN)
  learning/VBG
  (NP
    algorithms/JJ
    integrate/JJ
    statistical/JJ
    artificial/JJ
    intelligence/NN
    methods/NNS)
  analyse/VBP
  (NP massive/JJ amounts/NNS data/NNS high-performance/NN)
  ./.) 


>> Noun Phrases are: 
 ['machine', 'algorithms integrate statistical artificial intelligence methods', 'massive amounts data high-performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('integrate', 'integr'), ('statistical', 'statist'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('methods', 'method'), ('analyse', 'analys'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('integrate', 'integr'), ('statistical', 'statist'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('methods', 'method'), ('analyse', 'analys'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('.', '.')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('integrate', 'integrate'), ('statistical', 'statistical'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('methods', 'method'), ('analyse', 'analyse'), ('massive', 'massive'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-performance'), ('.', '.')]



============================ Sentence 121 =============================

One   solution for the storage challenge is utilizing Hadoop (Apache platform) that has the power to   process highly large amounts of data. 


>> Tokens are: 
 ['One', 'solution', 'storage', 'challenge', 'utilizing', 'Hadoop', '(', 'Apache', 'platform', ')', 'power', 'process', 'highly', 'large', 'amounts', 'data', '.']

>> Bigrams are: 
 [('One', 'solution'), ('solution', 'storage'), ('storage', 'challenge'), ('challenge', 'utilizing'), ('utilizing', 'Hadoop'), ('Hadoop', '('), ('(', 'Apache'), ('Apache', 'platform'), ('platform', ')'), (')', 'power'), ('power', 'process'), ('process', 'highly'), ('highly', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', '.')]

>> Trigrams are: 
 [('One', 'solution', 'storage'), ('solution', 'storage', 'challenge'), ('storage', 'challenge', 'utilizing'), ('challenge', 'utilizing', 'Hadoop'), ('utilizing', 'Hadoop', '('), ('Hadoop', '(', 'Apache'), ('(', 'Apache', 'platform'), ('Apache', 'platform', ')'), ('platform', ')', 'power'), (')', 'power', 'process'), ('power', 'process', 'highly'), ('process', 'highly', 'large'), ('highly', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('solution', 'NN'), ('storage', 'NN'), ('challenge', 'NN'), ('utilizing', 'VBG'), ('Hadoop', 'NNP'), ('(', '('), ('Apache', 'NNP'), ('platform', 'NN'), (')', ')'), ('power', 'NN'), ('process', 'NN'), ('highly', 'RB'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('.', '.')]

 (S
  One/CD
  (NP solution/NN storage/NN challenge/NN)
  utilizing/VBG
  (NP Hadoop/NNP)
  (/(
  (NP Apache/NNP platform/NN)
  )/)
  (NP power/NN process/NN)
  highly/RB
  (NP large/JJ amounts/NNS data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['solution storage challenge', 'Hadoop', 'Apache platform', 'power process', 'large amounts data']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('ORGANIZATION', 'Apache')] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('utilizing', 'util'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), ('power', 'power'), ('process', 'process'), ('highly', 'highli'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('utilizing', 'util'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), ('power', 'power'), ('process', 'process'), ('highly', 'high'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('solution', 'solution'), ('storage', 'storage'), ('challenge', 'challenge'), ('utilizing', 'utilizing'), ('Hadoop', 'Hadoop'), ('(', '('), ('Apache', 'Apache'), ('platform', 'platform'), (')', ')'), ('power', 'power'), ('process', 'process'), ('highly', 'highly'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]



============================ Sentence 122 =============================

By separating the data into smaller parts then assigning some   parts of the datasets to separate servers (nodes). 


>> Tokens are: 
 ['By', 'separating', 'data', 'smaller', 'parts', 'assigning', 'parts', 'datasets', 'separate', 'servers', '(', 'nodes', ')', '.']

>> Bigrams are: 
 [('By', 'separating'), ('separating', 'data'), ('data', 'smaller'), ('smaller', 'parts'), ('parts', 'assigning'), ('assigning', 'parts'), ('parts', 'datasets'), ('datasets', 'separate'), ('separate', 'servers'), ('servers', '('), ('(', 'nodes'), ('nodes', ')'), (')', '.')]

>> Trigrams are: 
 [('By', 'separating', 'data'), ('separating', 'data', 'smaller'), ('data', 'smaller', 'parts'), ('smaller', 'parts', 'assigning'), ('parts', 'assigning', 'parts'), ('assigning', 'parts', 'datasets'), ('parts', 'datasets', 'separate'), ('datasets', 'separate', 'servers'), ('separate', 'servers', '('), ('servers', '(', 'nodes'), ('(', 'nodes', ')'), ('nodes', ')', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('separating', 'VBG'), ('data', 'NNS'), ('smaller', 'JJR'), ('parts', 'NNS'), ('assigning', 'VBG'), ('parts', 'NNS'), ('datasets', 'NNS'), ('separate', 'JJ'), ('servers', 'NNS'), ('(', '('), ('nodes', 'NNS'), (')', ')'), ('.', '.')]

 (S
  By/IN
  separating/VBG
  (NP data/NNS)
  smaller/JJR
  (NP parts/NNS)
  assigning/VBG
  (NP parts/NNS datasets/NNS)
  (NP separate/JJ servers/NNS)
  (/(
  (NP nodes/NNS)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['data', 'parts', 'parts datasets', 'separate servers', 'nodes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('separating', 'separ'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('assigning', 'assign'), ('parts', 'part'), ('datasets', 'dataset'), ('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('separating', 'separ'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('assigning', 'assign'), ('parts', 'part'), ('datasets', 'dataset'), ('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('separating', 'separating'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('assigning', 'assigning'), ('parts', 'part'), ('datasets', 'datasets'), ('separate', 'separate'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('.', '.')]



============================ Sentence 123 =============================

Organizations should observe data sources, with   end-to-end encryption used to prevent gaining access to the data in transit. 


>> Tokens are: 
 ['Organizations', 'observe', 'data', 'sources', ',', 'end-to-end', 'encryption', 'used', 'prevent', 'gaining', 'access', 'data', 'transit', '.']

>> Bigrams are: 
 [('Organizations', 'observe'), ('observe', 'data'), ('data', 'sources'), ('sources', ','), (',', 'end-to-end'), ('end-to-end', 'encryption'), ('encryption', 'used'), ('used', 'prevent'), ('prevent', 'gaining'), ('gaining', 'access'), ('access', 'data'), ('data', 'transit'), ('transit', '.')]

>> Trigrams are: 
 [('Organizations', 'observe', 'data'), ('observe', 'data', 'sources'), ('data', 'sources', ','), ('sources', ',', 'end-to-end'), (',', 'end-to-end', 'encryption'), ('end-to-end', 'encryption', 'used'), ('encryption', 'used', 'prevent'), ('used', 'prevent', 'gaining'), ('prevent', 'gaining', 'access'), ('gaining', 'access', 'data'), ('access', 'data', 'transit'), ('data', 'transit', '.')]

>> POS Tags are: 
 [('Organizations', 'NNS'), ('observe', 'VBP'), ('data', 'NNS'), ('sources', 'NNS'), (',', ','), ('end-to-end', 'JJ'), ('encryption', 'NN'), ('used', 'VBN'), ('prevent', 'NN'), ('gaining', 'VBG'), ('access', 'NN'), ('data', 'NNS'), ('transit', 'NN'), ('.', '.')]

 (S
  (NP Organizations/NNS)
  observe/VBP
  (NP data/NNS sources/NNS)
  ,/,
  (NP end-to-end/JJ encryption/NN)
  used/VBN
  (NP prevent/NN)
  gaining/VBG
  (NP access/NN data/NNS transit/NN)
  ./.) 


>> Noun Phrases are: 
 ['Organizations', 'data sources', 'end-to-end encryption', 'prevent', 'access data transit']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organizations', 'organ'), ('observe', 'observ'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent'), ('gaining', 'gain'), ('access', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organizations', 'organ'), ('observe', 'observ'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent'), ('gaining', 'gain'), ('access', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Lemmatization: 
 [('Organizations', 'Organizations'), ('observe', 'observe'), ('data', 'data'), ('sources', 'source'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encryption'), ('used', 'used'), ('prevent', 'prevent'), ('gaining', 'gaining'), ('access', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]



============================ Sentence 124 =============================

Companies must examine their cloud providers, as many cloud providers do not encrypt the data   because of the massive amount of data convey at any given time, while encryption/decryption   slows down the stream of data. 


>> Tokens are: 
 ['Companies', 'must', 'examine', 'cloud', 'providers', ',', 'many', 'cloud', 'providers', 'encrypt', 'data', 'massive', 'amount', 'data', 'convey', 'given', 'time', ',', 'encryption/decryption', 'slows', 'stream', 'data', '.']

>> Bigrams are: 
 [('Companies', 'must'), ('must', 'examine'), ('examine', 'cloud'), ('cloud', 'providers'), ('providers', ','), (',', 'many'), ('many', 'cloud'), ('cloud', 'providers'), ('providers', 'encrypt'), ('encrypt', 'data'), ('data', 'massive'), ('massive', 'amount'), ('amount', 'data'), ('data', 'convey'), ('convey', 'given'), ('given', 'time'), ('time', ','), (',', 'encryption/decryption'), ('encryption/decryption', 'slows'), ('slows', 'stream'), ('stream', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Companies', 'must', 'examine'), ('must', 'examine', 'cloud'), ('examine', 'cloud', 'providers'), ('cloud', 'providers', ','), ('providers', ',', 'many'), (',', 'many', 'cloud'), ('many', 'cloud', 'providers'), ('cloud', 'providers', 'encrypt'), ('providers', 'encrypt', 'data'), ('encrypt', 'data', 'massive'), ('data', 'massive', 'amount'), ('massive', 'amount', 'data'), ('amount', 'data', 'convey'), ('data', 'convey', 'given'), ('convey', 'given', 'time'), ('given', 'time', ','), ('time', ',', 'encryption/decryption'), (',', 'encryption/decryption', 'slows'), ('encryption/decryption', 'slows', 'stream'), ('slows', 'stream', 'data'), ('stream', 'data', '.')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('must', 'MD'), ('examine', 'VB'), ('cloud', 'NN'), ('providers', 'NNS'), (',', ','), ('many', 'JJ'), ('cloud', 'VBP'), ('providers', 'NNS'), ('encrypt', 'VBP'), ('data', 'NNS'), ('massive', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('convey', 'VB'), ('given', 'VBN'), ('time', 'NN'), (',', ','), ('encryption/decryption', 'NN'), ('slows', 'VBZ'), ('stream', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Companies/NNS)
  must/MD
  examine/VB
  (NP cloud/NN providers/NNS)
  ,/,
  many/JJ
  cloud/VBP
  (NP providers/NNS)
  encrypt/VBP
  (NP data/NNS)
  (NP massive/JJ amount/NN data/NNS)
  convey/VB
  given/VBN
  (NP time/NN)
  ,/,
  (NP encryption/decryption/NN)
  slows/VBZ
  (NP stream/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Companies', 'cloud providers', 'providers', 'data', 'massive amount data', 'time', 'encryption/decryption', 'stream data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('must', 'must'), ('examine', 'examin'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ','), ('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data'), ('massive', 'massiv'), ('amount', 'amount'), ('data', 'data'), ('convey', 'convey'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt'), ('slows', 'slow'), ('stream', 'stream'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('must', 'must'), ('examine', 'examin'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ','), ('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data'), ('massive', 'massiv'), ('amount', 'amount'), ('data', 'data'), ('convey', 'convey'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt'), ('slows', 'slow'), ('stream', 'stream'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('must', 'must'), ('examine', 'examine'), ('cloud', 'cloud'), ('providers', 'provider'), (',', ','), ('many', 'many'), ('cloud', 'cloud'), ('providers', 'provider'), ('encrypt', 'encrypt'), ('data', 'data'), ('massive', 'massive'), ('amount', 'amount'), ('data', 'data'), ('convey', 'convey'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decryption'), ('slows', 'slows'), ('stream', 'stream'), ('data', 'data'), ('.', '.')]



============================ Sentence 125 =============================

Big data privacy solutions include protecting personal data privacy   during gathering data such as personal interests, habits, and body properties, etc. 


>> Tokens are: 
 ['Big', 'data', 'privacy', 'solutions', 'include', 'protecting', 'personal', 'data', 'privacy', 'gathering', 'data', 'personal', 'interests', ',', 'habits', ',', 'body', 'properties', ',', 'etc', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'privacy'), ('privacy', 'solutions'), ('solutions', 'include'), ('include', 'protecting'), ('protecting', 'personal'), ('personal', 'data'), ('data', 'privacy'), ('privacy', 'gathering'), ('gathering', 'data'), ('data', 'personal'), ('personal', 'interests'), ('interests', ','), (',', 'habits'), ('habits', ','), (',', 'body'), ('body', 'properties'), ('properties', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Big', 'data', 'privacy'), ('data', 'privacy', 'solutions'), ('privacy', 'solutions', 'include'), ('solutions', 'include', 'protecting'), ('include', 'protecting', 'personal'), ('protecting', 'personal', 'data'), ('personal', 'data', 'privacy'), ('data', 'privacy', 'gathering'), ('privacy', 'gathering', 'data'), ('gathering', 'data', 'personal'), ('data', 'personal', 'interests'), ('personal', 'interests', ','), ('interests', ',', 'habits'), (',', 'habits', ','), ('habits', ',', 'body'), (',', 'body', 'properties'), ('body', 'properties', ','), ('properties', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('privacy', 'NN'), ('solutions', 'NNS'), ('include', 'VBP'), ('protecting', 'VBG'), ('personal', 'JJ'), ('data', 'NNS'), ('privacy', 'NN'), ('gathering', 'NN'), ('data', 'NNS'), ('personal', 'JJ'), ('interests', 'NNS'), (',', ','), ('habits', 'NNS'), (',', ','), ('body', 'NN'), ('properties', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS privacy/NN solutions/NNS)
  include/VBP
  protecting/VBG
  (NP personal/JJ data/NNS privacy/NN gathering/NN data/NNS)
  (NP personal/JJ interests/NNS)
  ,/,
  (NP habits/NNS)
  ,/,
  (NP body/NN properties/NNS)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['Big data privacy solutions', 'personal data privacy gathering data', 'personal interests', 'habits', 'body properties']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('solutions', 'solut'), ('include', 'includ'), ('protecting', 'protect'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci'), ('gathering', 'gather'), ('data', 'data'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('solutions', 'solut'), ('include', 'includ'), ('protecting', 'protect'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci'), ('gathering', 'gather'), ('data', 'data'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('privacy', 'privacy'), ('solutions', 'solution'), ('include', 'include'), ('protecting', 'protecting'), ('personal', 'personal'), ('data', 'data'), ('privacy', 'privacy'), ('gathering', 'gathering'), ('data', 'data'), ('personal', 'personal'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'body'), ('properties', 'property'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 126 =============================

of users who do   not aware or easy to gain information from them. 


>> Tokens are: 
 ['users', 'aware', 'easy', 'gain', 'information', '.']

>> Bigrams are: 
 [('users', 'aware'), ('aware', 'easy'), ('easy', 'gain'), ('gain', 'information'), ('information', '.')]

>> Trigrams are: 
 [('users', 'aware', 'easy'), ('aware', 'easy', 'gain'), ('easy', 'gain', 'information'), ('gain', 'information', '.')]

>> POS Tags are: 
 [('users', 'NNS'), ('aware', 'JJ'), ('easy', 'JJ'), ('gain', 'NN'), ('information', 'NN'), ('.', '.')]

 (S (NP users/NNS) (NP aware/JJ easy/JJ gain/NN information/NN) ./.) 


>> Noun Phrases are: 
 ['users', 'aware easy gain information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('users', 'user'), ('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('users', 'user'), ('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('users', 'user'), ('aware', 'aware'), ('easy', 'easy'), ('gain', 'gain'), ('information', 'information'), ('.', '.')]



============================ Sentence 127 =============================

Also, protecting personal privacy data which   might discharge during storage, transmission, and usage, even if it gained with the user permission. 


>> Tokens are: 
 ['Also', ',', 'protecting', 'personal', 'privacy', 'data', 'might', 'discharge', 'storage', ',', 'transmission', ',', 'usage', ',', 'even', 'gained', 'user', 'permission', '.']

>> Bigrams are: 
 [('Also', ','), (',', 'protecting'), ('protecting', 'personal'), ('personal', 'privacy'), ('privacy', 'data'), ('data', 'might'), ('might', 'discharge'), ('discharge', 'storage'), ('storage', ','), (',', 'transmission'), ('transmission', ','), (',', 'usage'), ('usage', ','), (',', 'even'), ('even', 'gained'), ('gained', 'user'), ('user', 'permission'), ('permission', '.')]

>> Trigrams are: 
 [('Also', ',', 'protecting'), (',', 'protecting', 'personal'), ('protecting', 'personal', 'privacy'), ('personal', 'privacy', 'data'), ('privacy', 'data', 'might'), ('data', 'might', 'discharge'), ('might', 'discharge', 'storage'), ('discharge', 'storage', ','), ('storage', ',', 'transmission'), (',', 'transmission', ','), ('transmission', ',', 'usage'), (',', 'usage', ','), ('usage', ',', 'even'), (',', 'even', 'gained'), ('even', 'gained', 'user'), ('gained', 'user', 'permission'), ('user', 'permission', '.')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('protecting', 'VBG'), ('personal', 'JJ'), ('privacy', 'NN'), ('data', 'NNS'), ('might', 'MD'), ('discharge', 'VB'), ('storage', 'NN'), (',', ','), ('transmission', 'NN'), (',', ','), ('usage', 'NN'), (',', ','), ('even', 'RB'), ('gained', 'VBD'), ('user', 'JJ'), ('permission', 'NN'), ('.', '.')]

 (S
  Also/RB
  ,/,
  protecting/VBG
  (NP personal/JJ privacy/NN data/NNS)
  might/MD
  discharge/VB
  (NP storage/NN)
  ,/,
  (NP transmission/NN)
  ,/,
  (NP usage/NN)
  ,/,
  even/RB
  gained/VBD
  (NP user/JJ permission/NN)
  ./.) 


>> Noun Phrases are: 
 ['personal privacy data', 'storage', 'transmission', 'usage', 'user permission']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('protecting', 'protect'), ('personal', 'person'), ('privacy', 'privaci'), ('data', 'data'), ('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user'), ('permission', 'permiss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('protecting', 'protect'), ('personal', 'person'), ('privacy', 'privaci'), ('data', 'data'), ('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user'), ('permission', 'permiss'), ('.', '.')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('protecting', 'protecting'), ('personal', 'personal'), ('privacy', 'privacy'), ('data', 'data'), ('might', 'might'), ('discharge', 'discharge'), ('storage', 'storage'), (',', ','), ('transmission', 'transmission'), (',', ','), ('usage', 'usage'), (',', ','), ('even', 'even'), ('gained', 'gained'), ('user', 'user'), ('permission', 'permission'), ('.', '.')]



============================ Sentence 128 =============================

Possible risks for this thesis could be in conducting the research which is how to identify a suitable   subject based on the important point of finding a personal practical or professional need or a   personal urge to face the research question. 


>> Tokens are: 
 ['Possible', 'risks', 'thesis', 'could', 'conducting', 'research', 'identify', 'suitable', 'subject', 'based', 'important', 'point', 'finding', 'personal', 'practical', 'professional', 'need', 'personal', 'urge', 'face', 'research', 'question', '.']

>> Bigrams are: 
 [('Possible', 'risks'), ('risks', 'thesis'), ('thesis', 'could'), ('could', 'conducting'), ('conducting', 'research'), ('research', 'identify'), ('identify', 'suitable'), ('suitable', 'subject'), ('subject', 'based'), ('based', 'important'), ('important', 'point'), ('point', 'finding'), ('finding', 'personal'), ('personal', 'practical'), ('practical', 'professional'), ('professional', 'need'), ('need', 'personal'), ('personal', 'urge'), ('urge', 'face'), ('face', 'research'), ('research', 'question'), ('question', '.')]

>> Trigrams are: 
 [('Possible', 'risks', 'thesis'), ('risks', 'thesis', 'could'), ('thesis', 'could', 'conducting'), ('could', 'conducting', 'research'), ('conducting', 'research', 'identify'), ('research', 'identify', 'suitable'), ('identify', 'suitable', 'subject'), ('suitable', 'subject', 'based'), ('subject', 'based', 'important'), ('based', 'important', 'point'), ('important', 'point', 'finding'), ('point', 'finding', 'personal'), ('finding', 'personal', 'practical'), ('personal', 'practical', 'professional'), ('practical', 'professional', 'need'), ('professional', 'need', 'personal'), ('need', 'personal', 'urge'), ('personal', 'urge', 'face'), ('urge', 'face', 'research'), ('face', 'research', 'question'), ('research', 'question', '.')]

>> POS Tags are: 
 [('Possible', 'JJ'), ('risks', 'NNS'), ('thesis', 'NN'), ('could', 'MD'), ('conducting', 'VB'), ('research', 'NN'), ('identify', 'NN'), ('suitable', 'JJ'), ('subject', 'NN'), ('based', 'VBN'), ('important', 'JJ'), ('point', 'NN'), ('finding', 'VBG'), ('personal', 'JJ'), ('practical', 'JJ'), ('professional', 'NN'), ('need', 'MD'), ('personal', 'JJ'), ('urge', 'VB'), ('face', 'NN'), ('research', 'NN'), ('question', 'NN'), ('.', '.')]

 (S
  (NP Possible/JJ risks/NNS thesis/NN)
  could/MD
  conducting/VB
  (NP research/NN identify/NN)
  (NP suitable/JJ subject/NN)
  based/VBN
  (NP important/JJ point/NN)
  finding/VBG
  (NP personal/JJ practical/JJ professional/NN)
  need/MD
  personal/JJ
  urge/VB
  (NP face/NN research/NN question/NN)
  ./.) 


>> Noun Phrases are: 
 ['Possible risks thesis', 'research identify', 'suitable subject', 'important point', 'personal practical professional', 'face research question']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Possible', 'possibl'), ('risks', 'risk'), ('thesis', 'thesi'), ('could', 'could'), ('conducting', 'conduct'), ('research', 'research'), ('identify', 'identifi'), ('suitable', 'suitabl'), ('subject', 'subject'), ('based', 'base'), ('important', 'import'), ('point', 'point'), ('finding', 'find'), ('personal', 'person'), ('practical', 'practic'), ('professional', 'profession'), ('need', 'need'), ('personal', 'person'), ('urge', 'urg'), ('face', 'face'), ('research', 'research'), ('question', 'question'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Possible', 'possibl'), ('risks', 'risk'), ('thesis', 'thesi'), ('could', 'could'), ('conducting', 'conduct'), ('research', 'research'), ('identify', 'identifi'), ('suitable', 'suitabl'), ('subject', 'subject'), ('based', 'base'), ('important', 'import'), ('point', 'point'), ('finding', 'find'), ('personal', 'person'), ('practical', 'practic'), ('professional', 'profession'), ('need', 'need'), ('personal', 'person'), ('urge', 'urg'), ('face', 'face'), ('research', 'research'), ('question', 'question'), ('.', '.')]

>> Lemmatization: 
 [('Possible', 'Possible'), ('risks', 'risk'), ('thesis', 'thesis'), ('could', 'could'), ('conducting', 'conducting'), ('research', 'research'), ('identify', 'identify'), ('suitable', 'suitable'), ('subject', 'subject'), ('based', 'based'), ('important', 'important'), ('point', 'point'), ('finding', 'finding'), ('personal', 'personal'), ('practical', 'practical'), ('professional', 'professional'), ('need', 'need'), ('personal', 'personal'), ('urge', 'urge'), ('face', 'face'), ('research', 'research'), ('question', 'question'), ('.', '.')]



============================ Sentence 129 =============================

The risk was to confront two essential sources of   confusion concerning the final success means in thesis writing. 


>> Tokens are: 
 ['The', 'risk', 'confront', 'two', 'essential', 'sources', 'confusion', 'concerning', 'final', 'success', 'means', 'thesis', 'writing', '.']

>> Bigrams are: 
 [('The', 'risk'), ('risk', 'confront'), ('confront', 'two'), ('two', 'essential'), ('essential', 'sources'), ('sources', 'confusion'), ('confusion', 'concerning'), ('concerning', 'final'), ('final', 'success'), ('success', 'means'), ('means', 'thesis'), ('thesis', 'writing'), ('writing', '.')]

>> Trigrams are: 
 [('The', 'risk', 'confront'), ('risk', 'confront', 'two'), ('confront', 'two', 'essential'), ('two', 'essential', 'sources'), ('essential', 'sources', 'confusion'), ('sources', 'confusion', 'concerning'), ('confusion', 'concerning', 'final'), ('concerning', 'final', 'success'), ('final', 'success', 'means'), ('success', 'means', 'thesis'), ('means', 'thesis', 'writing'), ('thesis', 'writing', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('risk', 'NN'), ('confront', 'NN'), ('two', 'CD'), ('essential', 'JJ'), ('sources', 'NNS'), ('confusion', 'NN'), ('concerning', 'VBG'), ('final', 'JJ'), ('success', 'NN'), ('means', 'VBZ'), ('thesis', 'NN'), ('writing', 'NN'), ('.', '.')]

 (S
  (NP The/DT risk/NN confront/NN)
  two/CD
  (NP essential/JJ sources/NNS confusion/NN)
  concerning/VBG
  (NP final/JJ success/NN)
  means/VBZ
  (NP thesis/NN writing/NN)
  ./.) 


>> Noun Phrases are: 
 ['The risk confront', 'essential sources confusion', 'final success', 'thesis writing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('risk', 'risk'), ('confront', 'confront'), ('two', 'two'), ('essential', 'essenti'), ('sources', 'sourc'), ('confusion', 'confus'), ('concerning', 'concern'), ('final', 'final'), ('success', 'success'), ('means', 'mean'), ('thesis', 'thesi'), ('writing', 'write'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('risk', 'risk'), ('confront', 'confront'), ('two', 'two'), ('essential', 'essenti'), ('sources', 'sourc'), ('confusion', 'confus'), ('concerning', 'concern'), ('final', 'final'), ('success', 'success'), ('means', 'mean'), ('thesis', 'thesi'), ('writing', 'write'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('risk', 'risk'), ('confront', 'confront'), ('two', 'two'), ('essential', 'essential'), ('sources', 'source'), ('confusion', 'confusion'), ('concerning', 'concerning'), ('final', 'final'), ('success', 'success'), ('means', 'mean'), ('thesis', 'thesis'), ('writing', 'writing'), ('.', '.')]



============================ Sentence 130 =============================

The first was the uncertainty about   the understanding of the assessment criteria that will be applied to the work. 


>> Tokens are: 
 ['The', 'first', 'uncertainty', 'understanding', 'assessment', 'criteria', 'applied', 'work', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'uncertainty'), ('uncertainty', 'understanding'), ('understanding', 'assessment'), ('assessment', 'criteria'), ('criteria', 'applied'), ('applied', 'work'), ('work', '.')]

>> Trigrams are: 
 [('The', 'first', 'uncertainty'), ('first', 'uncertainty', 'understanding'), ('uncertainty', 'understanding', 'assessment'), ('understanding', 'assessment', 'criteria'), ('assessment', 'criteria', 'applied'), ('criteria', 'applied', 'work'), ('applied', 'work', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('uncertainty', 'NN'), ('understanding', 'VBG'), ('assessment', 'JJ'), ('criteria', 'NNS'), ('applied', 'VBN'), ('work', 'NN'), ('.', '.')]

 (S
  (NP The/DT first/JJ uncertainty/NN)
  understanding/VBG
  (NP assessment/JJ criteria/NNS)
  applied/VBN
  (NP work/NN)
  ./.) 


>> Noun Phrases are: 
 ['The first uncertainty', 'assessment criteria', 'work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('uncertainty', 'uncertainti'), ('understanding', 'understand'), ('assessment', 'assess'), ('criteria', 'criteria'), ('applied', 'appli'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('uncertainty', 'uncertainti'), ('understanding', 'understand'), ('assessment', 'assess'), ('criteria', 'criteria'), ('applied', 'appli'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('uncertainty', 'uncertainty'), ('understanding', 'understanding'), ('assessment', 'assessment'), ('criteria', 'criterion'), ('applied', 'applied'), ('work', 'work'), ('.', '.')]



============================ Sentence 131 =============================

The second relates to   the insecurity concerning the risks that will be faced along the journey. 


>> Tokens are: 
 ['The', 'second', 'relates', 'insecurity', 'concerning', 'risks', 'faced', 'along', 'journey', '.']

>> Bigrams are: 
 [('The', 'second'), ('second', 'relates'), ('relates', 'insecurity'), ('insecurity', 'concerning'), ('concerning', 'risks'), ('risks', 'faced'), ('faced', 'along'), ('along', 'journey'), ('journey', '.')]

>> Trigrams are: 
 [('The', 'second', 'relates'), ('second', 'relates', 'insecurity'), ('relates', 'insecurity', 'concerning'), ('insecurity', 'concerning', 'risks'), ('concerning', 'risks', 'faced'), ('risks', 'faced', 'along'), ('faced', 'along', 'journey'), ('along', 'journey', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('relates', 'VBZ'), ('insecurity', 'NN'), ('concerning', 'VBG'), ('risks', 'NNS'), ('faced', 'VBN'), ('along', 'IN'), ('journey', 'NN'), ('.', '.')]

 (S
  The/DT
  second/JJ
  relates/VBZ
  (NP insecurity/NN)
  concerning/VBG
  (NP risks/NNS)
  faced/VBN
  along/IN
  (NP journey/NN)
  ./.) 


>> Noun Phrases are: 
 ['insecurity', 'risks', 'journey']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('relates', 'relat'), ('insecurity', 'insecur'), ('concerning', 'concern'), ('risks', 'risk'), ('faced', 'face'), ('along', 'along'), ('journey', 'journey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('relates', 'relat'), ('insecurity', 'insecur'), ('concerning', 'concern'), ('risks', 'risk'), ('faced', 'face'), ('along', 'along'), ('journey', 'journey'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('relates', 'relates'), ('insecurity', 'insecurity'), ('concerning', 'concerning'), ('risks', 'risk'), ('faced', 'faced'), ('along', 'along'), ('journey', 'journey'), ('.', '.')]



============================ Sentence 132 =============================

The limitations of the study   were those characteristics of design and the methodology that have been chosen which impacted   the application results of the study. 


>> Tokens are: 
 ['The', 'limitations', 'study', 'characteristics', 'design', 'methodology', 'chosen', 'impacted', 'application', 'results', 'study', '.']

>> Bigrams are: 
 [('The', 'limitations'), ('limitations', 'study'), ('study', 'characteristics'), ('characteristics', 'design'), ('design', 'methodology'), ('methodology', 'chosen'), ('chosen', 'impacted'), ('impacted', 'application'), ('application', 'results'), ('results', 'study'), ('study', '.')]

>> Trigrams are: 
 [('The', 'limitations', 'study'), ('limitations', 'study', 'characteristics'), ('study', 'characteristics', 'design'), ('characteristics', 'design', 'methodology'), ('design', 'methodology', 'chosen'), ('methodology', 'chosen', 'impacted'), ('chosen', 'impacted', 'application'), ('impacted', 'application', 'results'), ('application', 'results', 'study'), ('results', 'study', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('limitations', 'NNS'), ('study', 'VBP'), ('characteristics', 'NNS'), ('design', 'JJ'), ('methodology', 'NN'), ('chosen', 'VBN'), ('impacted', 'JJ'), ('application', 'NN'), ('results', 'NNS'), ('study', 'NN'), ('.', '.')]

 (S
  (NP The/DT limitations/NNS)
  study/VBP
  (NP characteristics/NNS)
  (NP design/JJ methodology/NN)
  chosen/VBN
  (NP impacted/JJ application/NN results/NNS study/NN)
  ./.) 


>> Noun Phrases are: 
 ['The limitations', 'characteristics', 'design methodology', 'impacted application results study']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('limitations', 'limit'), ('study', 'studi'), ('characteristics', 'characterist'), ('design', 'design'), ('methodology', 'methodolog'), ('chosen', 'chosen'), ('impacted', 'impact'), ('application', 'applic'), ('results', 'result'), ('study', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('limitations', 'limit'), ('study', 'studi'), ('characteristics', 'characterist'), ('design', 'design'), ('methodology', 'methodolog'), ('chosen', 'chosen'), ('impacted', 'impact'), ('application', 'applic'), ('results', 'result'), ('study', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('limitations', 'limitation'), ('study', 'study'), ('characteristics', 'characteristic'), ('design', 'design'), ('methodology', 'methodology'), ('chosen', 'chosen'), ('impacted', 'impacted'), ('application', 'application'), ('results', 'result'), ('study', 'study'), ('.', '.')]



============================ Sentence 133 =============================

As the chosen method was a literature review according to   Vom Brocke et al. 


>> Tokens are: 
 ['As', 'chosen', 'method', 'literature', 'review', 'according', 'Vom', 'Brocke', 'et', 'al', '.']

>> Bigrams are: 
 [('As', 'chosen'), ('chosen', 'method'), ('method', 'literature'), ('literature', 'review'), ('review', 'according'), ('according', 'Vom'), ('Vom', 'Brocke'), ('Brocke', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('As', 'chosen', 'method'), ('chosen', 'method', 'literature'), ('method', 'literature', 'review'), ('literature', 'review', 'according'), ('review', 'according', 'Vom'), ('according', 'Vom', 'Brocke'), ('Vom', 'Brocke', 'et'), ('Brocke', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('chosen', 'VBN'), ('method', 'NN'), ('literature', 'NN'), ('review', 'NN'), ('according', 'VBG'), ('Vom', 'NNP'), ('Brocke', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  As/IN
  chosen/VBN
  (NP method/NN literature/NN review/NN)
  according/VBG
  (NP Vom/NNP Brocke/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['method literature review', 'Vom Brocke', 'al']

>> Named Entities are: 
 [('PERSON', 'Vom Brocke')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('chosen', 'chosen'), ('method', 'method'), ('literature', 'literatur'), ('review', 'review'), ('according', 'accord'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('chosen', 'chosen'), ('method', 'method'), ('literature', 'literatur'), ('review', 'review'), ('according', 'accord'), ('Vom', 'vom'), ('Brocke', 'brock'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('chosen', 'chosen'), ('method', 'method'), ('literature', 'literature'), ('review', 'review'), ('according', 'according'), ('Vom', 'Vom'), ('Brocke', 'Brocke'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 134 =============================

(2009), the criteria for selecting references was not easy and a lot of references   comply to the criteria of multi-dimension as aforementioned in the research method section. 


>> Tokens are: 
 ['(', '2009', ')', ',', 'criteria', 'selecting', 'references', 'easy', 'lot', 'references', 'comply', 'criteria', 'multi-dimension', 'aforementioned', 'research', 'method', 'section', '.']

>> Bigrams are: 
 [('(', '2009'), ('2009', ')'), (')', ','), (',', 'criteria'), ('criteria', 'selecting'), ('selecting', 'references'), ('references', 'easy'), ('easy', 'lot'), ('lot', 'references'), ('references', 'comply'), ('comply', 'criteria'), ('criteria', 'multi-dimension'), ('multi-dimension', 'aforementioned'), ('aforementioned', 'research'), ('research', 'method'), ('method', 'section'), ('section', '.')]

>> Trigrams are: 
 [('(', '2009', ')'), ('2009', ')', ','), (')', ',', 'criteria'), (',', 'criteria', 'selecting'), ('criteria', 'selecting', 'references'), ('selecting', 'references', 'easy'), ('references', 'easy', 'lot'), ('easy', 'lot', 'references'), ('lot', 'references', 'comply'), ('references', 'comply', 'criteria'), ('comply', 'criteria', 'multi-dimension'), ('criteria', 'multi-dimension', 'aforementioned'), ('multi-dimension', 'aforementioned', 'research'), ('aforementioned', 'research', 'method'), ('research', 'method', 'section'), ('method', 'section', '.')]

>> POS Tags are: 
 [('(', '('), ('2009', 'CD'), (')', ')'), (',', ','), ('criteria', 'NNS'), ('selecting', 'VBG'), ('references', 'NNS'), ('easy', 'JJ'), ('lot', 'NN'), ('references', 'NNS'), ('comply', 'VBP'), ('criteria', 'JJ'), ('multi-dimension', 'NN'), ('aforementioned', 'VBD'), ('research', 'NN'), ('method', 'NN'), ('section', 'NN'), ('.', '.')]

 (S
  (/(
  2009/CD
  )/)
  ,/,
  (NP criteria/NNS)
  selecting/VBG
  (NP references/NNS)
  (NP easy/JJ lot/NN references/NNS)
  comply/VBP
  (NP criteria/JJ multi-dimension/NN)
  aforementioned/VBD
  (NP research/NN method/NN section/NN)
  ./.) 


>> Noun Phrases are: 
 ['criteria', 'references', 'easy lot references', 'criteria multi-dimension', 'research method section']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), (',', ','), ('criteria', 'criteria'), ('selecting', 'select'), ('references', 'refer'), ('easy', 'easi'), ('lot', 'lot'), ('references', 'refer'), ('comply', 'compli'), ('criteria', 'criteria'), ('multi-dimension', 'multi-dimens'), ('aforementioned', 'aforement'), ('research', 'research'), ('method', 'method'), ('section', 'section'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2009', '2009'), (')', ')'), (',', ','), ('criteria', 'criteria'), ('selecting', 'select'), ('references', 'refer'), ('easy', 'easi'), ('lot', 'lot'), ('references', 'refer'), ('comply', 'compli'), ('criteria', 'criteria'), ('multi-dimension', 'multi-dimens'), ('aforementioned', 'aforement'), ('research', 'research'), ('method', 'method'), ('section', 'section'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2009', '2009'), (')', ')'), (',', ','), ('criteria', 'criterion'), ('selecting', 'selecting'), ('references', 'reference'), ('easy', 'easy'), ('lot', 'lot'), ('references', 'reference'), ('comply', 'comply'), ('criteria', 'criterion'), ('multi-dimension', 'multi-dimension'), ('aforementioned', 'aforementioned'), ('research', 'research'), ('method', 'method'), ('section', 'section'), ('.', '.')]



============================ Sentence 135 =============================

5. 


>> Tokens are: 
 ['5', '.']

>> Bigrams are: 
 [('5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5', 'CD'), ('.', '.')]

 (S 5/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5', '5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5', '5'), ('.', '.')]

>> Lemmatization: 
 [('5', '5'), ('.', '.')]



============================ Sentence 136 =============================

What is “big data”? 


>> Tokens are: 
 ['What', '“', 'big', 'data', '”', '?']

>> Bigrams are: 
 [('What', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', '?')]

>> Trigrams are: 
 [('What', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', '?')]

>> POS Tags are: 
 [('What', 'WP'), ('“', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('?', '.')]

 (S What/WP “/VBZ (NP big/JJ data/NNS ”/NN) ?/.) 


>> Noun Phrases are: 
 ['big data ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('What', 'what'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]

>> Lemmatization: 
 [('What', 'What'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('?', '?')]



============================ Sentence 137 =============================

Big data generally refers datasets that have grown too large for and become too difficult to work   with by means of traditional tools and database management systems. 


>> Tokens are: 
 ['Big', 'data', 'generally', 'refers', 'datasets', 'grown', 'large', 'become', 'difficult', 'work', 'means', 'traditional', 'tools', 'database', 'management', 'systems', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'generally'), ('generally', 'refers'), ('refers', 'datasets'), ('datasets', 'grown'), ('grown', 'large'), ('large', 'become'), ('become', 'difficult'), ('difficult', 'work'), ('work', 'means'), ('means', 'traditional'), ('traditional', 'tools'), ('tools', 'database'), ('database', 'management'), ('management', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Big', 'data', 'generally'), ('data', 'generally', 'refers'), ('generally', 'refers', 'datasets'), ('refers', 'datasets', 'grown'), ('datasets', 'grown', 'large'), ('grown', 'large', 'become'), ('large', 'become', 'difficult'), ('become', 'difficult', 'work'), ('difficult', 'work', 'means'), ('work', 'means', 'traditional'), ('means', 'traditional', 'tools'), ('traditional', 'tools', 'database'), ('tools', 'database', 'management'), ('database', 'management', 'systems'), ('management', 'systems', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('generally', 'RB'), ('refers', 'NNS'), ('datasets', 'NNS'), ('grown', 'VBP'), ('large', 'JJ'), ('become', 'NN'), ('difficult', 'JJ'), ('work', 'NN'), ('means', 'VBZ'), ('traditional', 'JJ'), ('tools', 'NNS'), ('database', 'JJ'), ('management', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  generally/RB
  (NP refers/NNS datasets/NNS)
  grown/VBP
  (NP large/JJ become/NN)
  (NP difficult/JJ work/NN)
  means/VBZ
  (NP traditional/JJ tools/NNS)
  (NP database/JJ management/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'refers datasets', 'large become', 'difficult work', 'traditional tools', 'database management systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('generally', 'gener'), ('refers', 'refer'), ('datasets', 'dataset'), ('grown', 'grown'), ('large', 'larg'), ('become', 'becom'), ('difficult', 'difficult'), ('work', 'work'), ('means', 'mean'), ('traditional', 'tradit'), ('tools', 'tool'), ('database', 'databas'), ('management', 'manag'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('generally', 'general'), ('refers', 'refer'), ('datasets', 'dataset'), ('grown', 'grown'), ('large', 'larg'), ('become', 'becom'), ('difficult', 'difficult'), ('work', 'work'), ('means', 'mean'), ('traditional', 'tradit'), ('tools', 'tool'), ('database', 'databas'), ('management', 'manag'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('generally', 'generally'), ('refers', 'refers'), ('datasets', 'datasets'), ('grown', 'grown'), ('large', 'large'), ('become', 'become'), ('difficult', 'difficult'), ('work', 'work'), ('means', 'mean'), ('traditional', 'traditional'), ('tools', 'tool'), ('database', 'database'), ('management', 'management'), ('systems', 'system'), ('.', '.')]



============================ Sentence 138 =============================

It also implies datasets that   have a great deal of variety and velocity, generating a need to develop possible solutions to extract   value and knowledge from wide-ranging, fast-moving datasets (Elgendy, N. and Elragal, A.,   2014). 


>> Tokens are: 
 ['It', 'also', 'implies', 'datasets', 'great', 'deal', 'variety', 'velocity', ',', 'generating', 'need', 'develop', 'possible', 'solutions', 'extract', 'value', 'knowledge', 'wide-ranging', ',', 'fast-moving', 'datasets', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'implies'), ('implies', 'datasets'), ('datasets', 'great'), ('great', 'deal'), ('deal', 'variety'), ('variety', 'velocity'), ('velocity', ','), (',', 'generating'), ('generating', 'need'), ('need', 'develop'), ('develop', 'possible'), ('possible', 'solutions'), ('solutions', 'extract'), ('extract', 'value'), ('value', 'knowledge'), ('knowledge', 'wide-ranging'), ('wide-ranging', ','), (',', 'fast-moving'), ('fast-moving', 'datasets'), ('datasets', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'also', 'implies'), ('also', 'implies', 'datasets'), ('implies', 'datasets', 'great'), ('datasets', 'great', 'deal'), ('great', 'deal', 'variety'), ('deal', 'variety', 'velocity'), ('variety', 'velocity', ','), ('velocity', ',', 'generating'), (',', 'generating', 'need'), ('generating', 'need', 'develop'), ('need', 'develop', 'possible'), ('develop', 'possible', 'solutions'), ('possible', 'solutions', 'extract'), ('solutions', 'extract', 'value'), ('extract', 'value', 'knowledge'), ('value', 'knowledge', 'wide-ranging'), ('knowledge', 'wide-ranging', ','), ('wide-ranging', ',', 'fast-moving'), (',', 'fast-moving', 'datasets'), ('fast-moving', 'datasets', '('), ('datasets', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('implies', 'VBZ'), ('datasets', 'NNS'), ('great', 'JJ'), ('deal', 'NN'), ('variety', 'NN'), ('velocity', 'NN'), (',', ','), ('generating', 'VBG'), ('need', 'NN'), ('develop', 'VB'), ('possible', 'JJ'), ('solutions', 'NNS'), ('extract', 'VBP'), ('value', 'NN'), ('knowledge', 'NN'), ('wide-ranging', 'JJ'), (',', ','), ('fast-moving', 'JJ'), ('datasets', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  also/RB
  implies/VBZ
  (NP datasets/NNS)
  (NP great/JJ deal/NN variety/NN velocity/NN)
  ,/,
  generating/VBG
  (NP need/NN)
  develop/VB
  (NP possible/JJ solutions/NNS)
  extract/VBP
  (NP value/NN knowledge/NN)
  wide-ranging/JJ
  ,/,
  (NP fast-moving/JJ datasets/NNS)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['datasets', 'great deal variety velocity', 'need', 'possible solutions', 'value knowledge', 'fast-moving datasets', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('implies', 'impli'), ('datasets', 'dataset'), ('great', 'great'), ('deal', 'deal'), ('variety', 'varieti'), ('velocity', 'veloc'), (',', ','), ('generating', 'gener'), ('need', 'need'), ('develop', 'develop'), ('possible', 'possibl'), ('solutions', 'solut'), ('extract', 'extract'), ('value', 'valu'), ('knowledge', 'knowledg'), ('wide-ranging', 'wide-rang'), (',', ','), ('fast-moving', 'fast-mov'), ('datasets', 'dataset'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('implies', 'impli'), ('datasets', 'dataset'), ('great', 'great'), ('deal', 'deal'), ('variety', 'varieti'), ('velocity', 'veloc'), (',', ','), ('generating', 'generat'), ('need', 'need'), ('develop', 'develop'), ('possible', 'possibl'), ('solutions', 'solut'), ('extract', 'extract'), ('value', 'valu'), ('knowledge', 'knowledg'), ('wide-ranging', 'wide-rang'), (',', ','), ('fast-moving', 'fast-mov'), ('datasets', 'dataset'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('implies', 'implies'), ('datasets', 'datasets'), ('great', 'great'), ('deal', 'deal'), ('variety', 'variety'), ('velocity', 'velocity'), (',', ','), ('generating', 'generating'), ('need', 'need'), ('develop', 'develop'), ('possible', 'possible'), ('solutions', 'solution'), ('extract', 'extract'), ('value', 'value'), ('knowledge', 'knowledge'), ('wide-ranging', 'wide-ranging'), (',', ','), ('fast-moving', 'fast-moving'), ('datasets', 'datasets'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 139 =============================

According to the Oxford English Dictionary, “Big data” as a term is defined as “extremely large   data sets that may be analysed computationally to reveal patterns, trends, and associations,   especially relating to human behaviour and interactions”. 


>> Tokens are: 
 ['According', 'Oxford', 'English', 'Dictionary', ',', '“', 'Big', 'data', '”', 'term', 'defined', '“', 'extremely', 'large', 'data', 'sets', 'may', 'analysed', 'computationally', 'reveal', 'patterns', ',', 'trends', ',', 'associations', ',', 'especially', 'relating', 'human', 'behaviour', 'interactions', '”', '.']

>> Bigrams are: 
 [('According', 'Oxford'), ('Oxford', 'English'), ('English', 'Dictionary'), ('Dictionary', ','), (',', '“'), ('“', 'Big'), ('Big', 'data'), ('data', '”'), ('”', 'term'), ('term', 'defined'), ('defined', '“'), ('“', 'extremely'), ('extremely', 'large'), ('large', 'data'), ('data', 'sets'), ('sets', 'may'), ('may', 'analysed'), ('analysed', 'computationally'), ('computationally', 'reveal'), ('reveal', 'patterns'), ('patterns', ','), (',', 'trends'), ('trends', ','), (',', 'associations'), ('associations', ','), (',', 'especially'), ('especially', 'relating'), ('relating', 'human'), ('human', 'behaviour'), ('behaviour', 'interactions'), ('interactions', '”'), ('”', '.')]

>> Trigrams are: 
 [('According', 'Oxford', 'English'), ('Oxford', 'English', 'Dictionary'), ('English', 'Dictionary', ','), ('Dictionary', ',', '“'), (',', '“', 'Big'), ('“', 'Big', 'data'), ('Big', 'data', '”'), ('data', '”', 'term'), ('”', 'term', 'defined'), ('term', 'defined', '“'), ('defined', '“', 'extremely'), ('“', 'extremely', 'large'), ('extremely', 'large', 'data'), ('large', 'data', 'sets'), ('data', 'sets', 'may'), ('sets', 'may', 'analysed'), ('may', 'analysed', 'computationally'), ('analysed', 'computationally', 'reveal'), ('computationally', 'reveal', 'patterns'), ('reveal', 'patterns', ','), ('patterns', ',', 'trends'), (',', 'trends', ','), ('trends', ',', 'associations'), (',', 'associations', ','), ('associations', ',', 'especially'), (',', 'especially', 'relating'), ('especially', 'relating', 'human'), ('relating', 'human', 'behaviour'), ('human', 'behaviour', 'interactions'), ('behaviour', 'interactions', '”'), ('interactions', '”', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Oxford', 'NNP'), ('English', 'NNP'), ('Dictionary', 'NNP'), (',', ','), ('“', 'NNP'), ('Big', 'NNP'), ('data', 'NNS'), ('”', 'NNP'), ('term', 'NN'), ('defined', 'VBD'), ('“', 'NNP'), ('extremely', 'RB'), ('large', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('may', 'MD'), ('analysed', 'VBN'), ('computationally', 'RB'), ('reveal', 'JJ'), ('patterns', 'NNS'), (',', ','), ('trends', 'NNS'), (',', ','), ('associations', 'NNS'), (',', ','), ('especially', 'RB'), ('relating', 'VBG'), ('human', 'JJ'), ('behaviour', 'NN'), ('interactions', 'NNS'), ('”', 'VBP'), ('.', '.')]

 (S
  According/VBG
  (NP Oxford/NNP English/NNP Dictionary/NNP)
  ,/,
  (NP “/NNP Big/NNP data/NNS ”/NNP term/NN)
  defined/VBD
  (NP “/NNP)
  extremely/RB
  (NP large/JJ data/NNS sets/NNS)
  may/MD
  analysed/VBN
  computationally/RB
  (NP reveal/JJ patterns/NNS)
  ,/,
  (NP trends/NNS)
  ,/,
  (NP associations/NNS)
  ,/,
  especially/RB
  relating/VBG
  (NP human/JJ behaviour/NN interactions/NNS)
  ”/VBP
  ./.) 


>> Noun Phrases are: 
 ['Oxford English Dictionary', '“ Big data ” term', '“', 'large data sets', 'reveal patterns', 'trends', 'associations', 'human behaviour interactions']

>> Named Entities are: 
 [('PERSON', 'Oxford English Dictionary')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Oxford', 'oxford'), ('English', 'english'), ('Dictionary', 'dictionari'), (',', ','), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('term', 'term'), ('defined', 'defin'), ('“', '“'), ('extremely', 'extrem'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('may', 'may'), ('analysed', 'analys'), ('computationally', 'comput'), ('reveal', 'reveal'), ('patterns', 'pattern'), (',', ','), ('trends', 'trend'), (',', ','), ('associations', 'associ'), (',', ','), ('especially', 'especi'), ('relating', 'relat'), ('human', 'human'), ('behaviour', 'behaviour'), ('interactions', 'interact'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Oxford', 'oxford'), ('English', 'english'), ('Dictionary', 'dictionari'), (',', ','), ('“', '“'), ('Big', 'big'), ('data', 'data'), ('”', '”'), ('term', 'term'), ('defined', 'defin'), ('“', '“'), ('extremely', 'extrem'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('may', 'may'), ('analysed', 'analys'), ('computationally', 'comput'), ('reveal', 'reveal'), ('patterns', 'pattern'), (',', ','), ('trends', 'trend'), (',', ','), ('associations', 'associ'), (',', ','), ('especially', 'especi'), ('relating', 'relat'), ('human', 'human'), ('behaviour', 'behaviour'), ('interactions', 'interact'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Oxford', 'Oxford'), ('English', 'English'), ('Dictionary', 'Dictionary'), (',', ','), ('“', '“'), ('Big', 'Big'), ('data', 'data'), ('”', '”'), ('term', 'term'), ('defined', 'defined'), ('“', '“'), ('extremely', 'extremely'), ('large', 'large'), ('data', 'data'), ('sets', 'set'), ('may', 'may'), ('analysed', 'analysed'), ('computationally', 'computationally'), ('reveal', 'reveal'), ('patterns', 'pattern'), (',', ','), ('trends', 'trend'), (',', ','), ('associations', 'association'), (',', ','), ('especially', 'especially'), ('relating', 'relating'), ('human', 'human'), ('behaviour', 'behaviour'), ('interactions', 'interaction'), ('”', '”'), ('.', '.')]



============================ Sentence 140 =============================

Arunachalam et al. 


>> Tokens are: 
 ['Arunachalam', 'et', 'al', '.']

>> Bigrams are: 
 [('Arunachalam', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Arunachalam', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Arunachalam', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Arunachalam/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Arunachalam', 'al']

>> Named Entities are: 
 [('GPE', 'Arunachalam')] 

>> Stemming using Porter Stemmer: 
 [('Arunachalam', 'arunachalam'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Arunachalam', 'arunachalam'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Arunachalam', 'Arunachalam'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 141 =============================

(2018) argued that   this definition does not give the whole picture of big data, however, as big data must be   differentiated from data as being difficult to handle using traditional data analyses. 


>> Tokens are: 
 ['(', '2018', ')', 'argued', 'definition', 'give', 'whole', 'picture', 'big', 'data', ',', 'however', ',', 'big', 'data', 'must', 'differentiated', 'data', 'difficult', 'handle', 'using', 'traditional', 'data', 'analyses', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'argued'), ('argued', 'definition'), ('definition', 'give'), ('give', 'whole'), ('whole', 'picture'), ('picture', 'big'), ('big', 'data'), ('data', ','), (',', 'however'), ('however', ','), (',', 'big'), ('big', 'data'), ('data', 'must'), ('must', 'differentiated'), ('differentiated', 'data'), ('data', 'difficult'), ('difficult', 'handle'), ('handle', 'using'), ('using', 'traditional'), ('traditional', 'data'), ('data', 'analyses'), ('analyses', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'argued'), (')', 'argued', 'definition'), ('argued', 'definition', 'give'), ('definition', 'give', 'whole'), ('give', 'whole', 'picture'), ('whole', 'picture', 'big'), ('picture', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'however'), (',', 'however', ','), ('however', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'must'), ('data', 'must', 'differentiated'), ('must', 'differentiated', 'data'), ('differentiated', 'data', 'difficult'), ('data', 'difficult', 'handle'), ('difficult', 'handle', 'using'), ('handle', 'using', 'traditional'), ('using', 'traditional', 'data'), ('traditional', 'data', 'analyses'), ('data', 'analyses', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('argued', 'VBD'), ('definition', 'NN'), ('give', 'JJ'), ('whole', 'JJ'), ('picture', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('must', 'MD'), ('differentiated', 'VBN'), ('data', 'NNS'), ('difficult', 'JJ'), ('handle', 'JJ'), ('using', 'VBG'), ('traditional', 'JJ'), ('data', 'NN'), ('analyses', 'NNS'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  argued/VBD
  (NP definition/NN)
  (NP give/JJ whole/JJ picture/NN)
  (NP big/JJ data/NNS)
  ,/,
  however/RB
  ,/,
  (NP big/JJ data/NNS)
  must/MD
  differentiated/VBN
  (NP data/NNS)
  difficult/JJ
  handle/JJ
  using/VBG
  (NP traditional/JJ data/NN analyses/NNS)
  ./.) 


>> Noun Phrases are: 
 ['definition', 'give whole picture', 'big data', 'big data', 'data', 'traditional data analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu'), ('definition', 'definit'), ('give', 'give'), ('whole', 'whole'), ('picture', 'pictur'), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('big', 'big'), ('data', 'data'), ('must', 'must'), ('differentiated', 'differenti'), ('data', 'data'), ('difficult', 'difficult'), ('handle', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('data', 'data'), ('analyses', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu'), ('definition', 'definit'), ('give', 'give'), ('whole', 'whole'), ('picture', 'pictur'), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('big', 'big'), ('data', 'data'), ('must', 'must'), ('differentiated', 'differenti'), ('data', 'data'), ('difficult', 'difficult'), ('handle', 'handl'), ('using', 'use'), ('traditional', 'tradit'), ('data', 'data'), ('analyses', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argued'), ('definition', 'definition'), ('give', 'give'), ('whole', 'whole'), ('picture', 'picture'), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'however'), (',', ','), ('big', 'big'), ('data', 'data'), ('must', 'must'), ('differentiated', 'differentiated'), ('data', 'data'), ('difficult', 'difficult'), ('handle', 'handle'), ('using', 'using'), ('traditional', 'traditional'), ('data', 'data'), ('analyses', 'analysis'), ('.', '.')]



============================ Sentence 142 =============================

Big data thus   inherently requires more sophisticated techniques for handling complexity, as this is exponentially   increased. 


>> Tokens are: 
 ['Big', 'data', 'thus', 'inherently', 'requires', 'sophisticated', 'techniques', 'handling', 'complexity', ',', 'exponentially', 'increased', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'thus'), ('thus', 'inherently'), ('inherently', 'requires'), ('requires', 'sophisticated'), ('sophisticated', 'techniques'), ('techniques', 'handling'), ('handling', 'complexity'), ('complexity', ','), (',', 'exponentially'), ('exponentially', 'increased'), ('increased', '.')]

>> Trigrams are: 
 [('Big', 'data', 'thus'), ('data', 'thus', 'inherently'), ('thus', 'inherently', 'requires'), ('inherently', 'requires', 'sophisticated'), ('requires', 'sophisticated', 'techniques'), ('sophisticated', 'techniques', 'handling'), ('techniques', 'handling', 'complexity'), ('handling', 'complexity', ','), ('complexity', ',', 'exponentially'), (',', 'exponentially', 'increased'), ('exponentially', 'increased', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('thus', 'RB'), ('inherently', 'RB'), ('requires', 'VBZ'), ('sophisticated', 'JJ'), ('techniques', 'NNS'), ('handling', 'VBG'), ('complexity', 'NN'), (',', ','), ('exponentially', 'RB'), ('increased', 'VBN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  thus/RB
  inherently/RB
  requires/VBZ
  (NP sophisticated/JJ techniques/NNS)
  handling/VBG
  (NP complexity/NN)
  ,/,
  exponentially/RB
  increased/VBN
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'sophisticated techniques', 'complexity']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('thus', 'thu'), ('inherently', 'inher'), ('requires', 'requir'), ('sophisticated', 'sophist'), ('techniques', 'techniqu'), ('handling', 'handl'), ('complexity', 'complex'), (',', ','), ('exponentially', 'exponenti'), ('increased', 'increas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('thus', 'thus'), ('inherently', 'inher'), ('requires', 'requir'), ('sophisticated', 'sophist'), ('techniques', 'techniqu'), ('handling', 'handl'), ('complexity', 'complex'), (',', ','), ('exponentially', 'exponenti'), ('increased', 'increas'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('thus', 'thus'), ('inherently', 'inherently'), ('requires', 'requires'), ('sophisticated', 'sophisticated'), ('techniques', 'technique'), ('handling', 'handling'), ('complexity', 'complexity'), (',', ','), ('exponentially', 'exponentially'), ('increased', 'increased'), ('.', '.')]



============================ Sentence 143 =============================

By 2011, the term big data had become quite widespread, but shows the frequency distribution of   the “big data” in the ProQuest Research Library more clearly (Gandomi and Haider, 2015). 


>> Tokens are: 
 ['By', '2011', ',', 'term', 'big', 'data', 'become', 'quite', 'widespread', ',', 'shows', 'frequency', 'distribution', '“', 'big', 'data', '”', 'ProQuest', 'Research', 'Library', 'clearly', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('By', '2011'), ('2011', ','), (',', 'term'), ('term', 'big'), ('big', 'data'), ('data', 'become'), ('become', 'quite'), ('quite', 'widespread'), ('widespread', ','), (',', 'shows'), ('shows', 'frequency'), ('frequency', 'distribution'), ('distribution', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', 'ProQuest'), ('ProQuest', 'Research'), ('Research', 'Library'), ('Library', 'clearly'), ('clearly', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('By', '2011', ','), ('2011', ',', 'term'), (',', 'term', 'big'), ('term', 'big', 'data'), ('big', 'data', 'become'), ('data', 'become', 'quite'), ('become', 'quite', 'widespread'), ('quite', 'widespread', ','), ('widespread', ',', 'shows'), (',', 'shows', 'frequency'), ('shows', 'frequency', 'distribution'), ('frequency', 'distribution', '“'), ('distribution', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', 'ProQuest'), ('”', 'ProQuest', 'Research'), ('ProQuest', 'Research', 'Library'), ('Research', 'Library', 'clearly'), ('Library', 'clearly', '('), ('clearly', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('2011', 'CD'), (',', ','), ('term', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('become', 'VBP'), ('quite', 'RB'), ('widespread', 'JJ'), (',', ','), ('shows', 'VBZ'), ('frequency', 'NN'), ('distribution', 'NN'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('ProQuest', 'NNP'), ('Research', 'NNP'), ('Library', 'NNP'), ('clearly', 'RB'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  By/IN
  2011/CD
  ,/,
  (NP term/NN)
  (NP big/JJ data/NNS)
  become/VBP
  quite/RB
  widespread/JJ
  ,/,
  shows/VBZ
  (NP frequency/NN distribution/NN “/NNP)
  (NP big/JJ data/NNS ”/NN ProQuest/NNP Research/NNP Library/NNP)
  clearly/RB
  (/(
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['term', 'big data', 'frequency distribution “', 'big data ” ProQuest Research Library', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'ProQuest Research'), ('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('2011', '2011'), (',', ','), ('term', 'term'), ('big', 'big'), ('data', 'data'), ('become', 'becom'), ('quite', 'quit'), ('widespread', 'widespread'), (',', ','), ('shows', 'show'), ('frequency', 'frequenc'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('clearly', 'clearli'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('2011', '2011'), (',', ','), ('term', 'term'), ('big', 'big'), ('data', 'data'), ('become', 'becom'), ('quite', 'quit'), ('widespread', 'widespread'), (',', ','), ('shows', 'show'), ('frequency', 'frequenc'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('clearly', 'clear'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('2011', '2011'), (',', ','), ('term', 'term'), ('big', 'big'), ('data', 'data'), ('become', 'become'), ('quite', 'quite'), ('widespread', 'widespread'), (',', ','), ('shows', 'show'), ('frequency', 'frequency'), ('distribution', 'distribution'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'ProQuest'), ('Research', 'Research'), ('Library', 'Library'), ('clearly', 'clearly'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 144 =============================

Sarah Al-Shiakhli   9         Figure 6: Frequency distribution of “big data” in the ProQuest Research Library (Gandomi and   Haider, 2015). 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '9', 'Figure', '6', ':', 'Frequency', 'distribution', '“', 'big', 'data', '”', 'ProQuest', 'Research', 'Library', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '9'), ('9', 'Figure'), ('Figure', '6'), ('6', ':'), (':', 'Frequency'), ('Frequency', 'distribution'), ('distribution', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', 'ProQuest'), ('ProQuest', 'Research'), ('Research', 'Library'), ('Library', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '9'), ('Al-Shiakhli', '9', 'Figure'), ('9', 'Figure', '6'), ('Figure', '6', ':'), ('6', ':', 'Frequency'), (':', 'Frequency', 'distribution'), ('Frequency', 'distribution', '“'), ('distribution', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', 'ProQuest'), ('”', 'ProQuest', 'Research'), ('ProQuest', 'Research', 'Library'), ('Research', 'Library', '('), ('Library', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('9', 'CD'), ('Figure', 'NNP'), ('6', 'CD'), (':', ':'), ('Frequency', 'NN'), ('distribution', 'NN'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'NN'), ('ProQuest', 'NNP'), ('Research', 'NNP'), ('Library', 'NNP'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  9/CD
  (NP Figure/NNP)
  6/CD
  :/:
  (NP Frequency/NN distribution/NN “/NNP)
  (NP big/JJ data/NNS ”/NN ProQuest/NNP Research/NNP Library/NNP)
  (/(
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Figure', 'Frequency distribution “', 'big data ” ProQuest Research Library', 'Gandomi Haider']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'ProQuest Research'), ('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('9', '9'), ('Figure', 'figur'), ('6', '6'), (':', ':'), ('Frequency', 'frequenc'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('9', '9'), ('Figure', 'figur'), ('6', '6'), (':', ':'), ('Frequency', 'frequenc'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'proquest'), ('Research', 'research'), ('Library', 'librari'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('9', '9'), ('Figure', 'Figure'), ('6', '6'), (':', ':'), ('Frequency', 'Frequency'), ('distribution', 'distribution'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('ProQuest', 'ProQuest'), ('Research', 'Research'), ('Library', 'Library'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 145 =============================

Research by Gandomi and Haider (2015) shows that different definitions of big data are used in   research and business. 


>> Tokens are: 
 ['Research', 'Gandomi', 'Haider', '(', '2015', ')', 'shows', 'different', 'definitions', 'big', 'data', 'used', 'research', 'business', '.']

>> Bigrams are: 
 [('Research', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', '('), ('(', '2015'), ('2015', ')'), (')', 'shows'), ('shows', 'different'), ('different', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'used'), ('used', 'research'), ('research', 'business'), ('business', '.')]

>> Trigrams are: 
 [('Research', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', '('), ('Haider', '(', '2015'), ('(', '2015', ')'), ('2015', ')', 'shows'), (')', 'shows', 'different'), ('shows', 'different', 'definitions'), ('different', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'used'), ('data', 'used', 'research'), ('used', 'research', 'business'), ('research', 'business', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Gandomi', 'NNP'), ('Haider', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('shows', 'VBZ'), ('different', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('used', 'VBN'), ('research', 'NN'), ('business', 'NN'), ('.', '.')]

 (S
  (NP Research/NNP Gandomi/NNP Haider/NNP)
  (/(
  2015/CD
  )/)
  shows/VBZ
  (NP different/JJ definitions/NNS)
  (NP big/JJ data/NNS)
  used/VBN
  (NP research/NN business/NN)
  ./.) 


>> Noun Phrases are: 
 ['Research Gandomi Haider', 'different definitions', 'big data', 'research business']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('used', 'use'), ('research', 'research'), ('business', 'busi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('used', 'use'), ('research', 'research'), ('business', 'busi'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('shows', 'show'), ('different', 'different'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('used', 'used'), ('research', 'research'), ('business', 'business'), ('.', '.')]



============================ Sentence 146 =============================

These big data definitions are vary depending on the understanding of the   user, with some focused on the characteristics of big data in terms of volume, variety, and velocity,   some focused on what it does, and others defining it dependent on their business’s requirements. 


>> Tokens are: 
 ['These', 'big', 'data', 'definitions', 'vary', 'depending', 'understanding', 'user', ',', 'focused', 'characteristics', 'big', 'data', 'terms', 'volume', ',', 'variety', ',', 'velocity', ',', 'focused', ',', 'others', 'defining', 'dependent', 'business', '’', 'requirements', '.']

>> Bigrams are: 
 [('These', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'vary'), ('vary', 'depending'), ('depending', 'understanding'), ('understanding', 'user'), ('user', ','), (',', 'focused'), ('focused', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', 'terms'), ('terms', 'volume'), ('volume', ','), (',', 'variety'), ('variety', ','), (',', 'velocity'), ('velocity', ','), (',', 'focused'), ('focused', ','), (',', 'others'), ('others', 'defining'), ('defining', 'dependent'), ('dependent', 'business'), ('business', '’'), ('’', 'requirements'), ('requirements', '.')]

>> Trigrams are: 
 [('These', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'vary'), ('definitions', 'vary', 'depending'), ('vary', 'depending', 'understanding'), ('depending', 'understanding', 'user'), ('understanding', 'user', ','), ('user', ',', 'focused'), (',', 'focused', 'characteristics'), ('focused', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', 'terms'), ('data', 'terms', 'volume'), ('terms', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'focused'), (',', 'focused', ','), ('focused', ',', 'others'), (',', 'others', 'defining'), ('others', 'defining', 'dependent'), ('defining', 'dependent', 'business'), ('dependent', 'business', '’'), ('business', '’', 'requirements'), ('’', 'requirements', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('vary', 'VBP'), ('depending', 'VBG'), ('understanding', 'VBG'), ('user', 'NN'), (',', ','), ('focused', 'VBD'), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('terms', 'NNS'), ('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('focused', 'VBD'), (',', ','), ('others', 'NNS'), ('defining', 'VBG'), ('dependent', 'NN'), ('business', 'NN'), ('’', 'NN'), ('requirements', 'NNS'), ('.', '.')]

 (S
  (NP These/DT big/JJ data/NNS definitions/NNS)
  vary/VBP
  depending/VBG
  understanding/VBG
  (NP user/NN)
  ,/,
  focused/VBD
  (NP characteristics/NNS)
  (NP big/JJ data/NNS terms/NNS volume/NN)
  ,/,
  (NP variety/NN)
  ,/,
  (NP velocity/NN)
  ,/,
  focused/VBD
  ,/,
  (NP others/NNS)
  defining/VBG
  (NP dependent/NN business/NN ’/NN requirements/NNS)
  ./.) 


>> Noun Phrases are: 
 ['These big data definitions', 'user', 'characteristics', 'big data terms volume', 'variety', 'velocity', 'others', 'dependent business ’ requirements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('vary', 'vari'), ('depending', 'depend'), ('understanding', 'understand'), ('user', 'user'), (',', ','), ('focused', 'focus'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('terms', 'term'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ','), ('focused', 'focus'), (',', ','), ('others', 'other'), ('defining', 'defin'), ('dependent', 'depend'), ('business', 'busi'), ('’', '’'), ('requirements', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('vary', 'vari'), ('depending', 'depend'), ('understanding', 'understand'), ('user', 'user'), (',', ','), ('focused', 'focus'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), ('terms', 'term'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ','), ('focused', 'focus'), (',', ','), ('others', 'other'), ('defining', 'defin'), ('dependent', 'depend'), ('business', 'busi'), ('’', '’'), ('requirements', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('vary', 'vary'), ('depending', 'depending'), ('understanding', 'understanding'), ('user', 'user'), (',', ','), ('focused', 'focused'), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), ('terms', 'term'), ('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('velocity', 'velocity'), (',', ','), ('focused', 'focused'), (',', ','), ('others', 'others'), ('defining', 'defining'), ('dependent', 'dependent'), ('business', 'business'), ('’', '’'), ('requirements', 'requirement'), ('.', '.')]



============================ Sentence 147 =============================

Figure 7 shows the different definitions of big found in an online survey of 154 C-suite global   executives conducted by Harris Interactive on behalf of SAP in April 2012. 


>> Tokens are: 
 ['Figure', '7', 'shows', 'different', 'definitions', 'big', 'found', 'online', 'survey', '154', 'C-suite', 'global', 'executives', 'conducted', 'Harris', 'Interactive', 'behalf', 'SAP', 'April', '2012', '.']

>> Bigrams are: 
 [('Figure', '7'), ('7', 'shows'), ('shows', 'different'), ('different', 'definitions'), ('definitions', 'big'), ('big', 'found'), ('found', 'online'), ('online', 'survey'), ('survey', '154'), ('154', 'C-suite'), ('C-suite', 'global'), ('global', 'executives'), ('executives', 'conducted'), ('conducted', 'Harris'), ('Harris', 'Interactive'), ('Interactive', 'behalf'), ('behalf', 'SAP'), ('SAP', 'April'), ('April', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Figure', '7', 'shows'), ('7', 'shows', 'different'), ('shows', 'different', 'definitions'), ('different', 'definitions', 'big'), ('definitions', 'big', 'found'), ('big', 'found', 'online'), ('found', 'online', 'survey'), ('online', 'survey', '154'), ('survey', '154', 'C-suite'), ('154', 'C-suite', 'global'), ('C-suite', 'global', 'executives'), ('global', 'executives', 'conducted'), ('executives', 'conducted', 'Harris'), ('conducted', 'Harris', 'Interactive'), ('Harris', 'Interactive', 'behalf'), ('Interactive', 'behalf', 'SAP'), ('behalf', 'SAP', 'April'), ('SAP', 'April', '2012'), ('April', '2012', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('7', 'CD'), ('shows', 'NNS'), ('different', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('found', 'VBD'), ('online', 'JJ'), ('survey', 'NN'), ('154', 'CD'), ('C-suite', 'JJ'), ('global', 'JJ'), ('executives', 'NNS'), ('conducted', 'VBN'), ('Harris', 'NNP'), ('Interactive', 'NNP'), ('behalf', 'NN'), ('SAP', 'NNP'), ('April', 'NNP'), ('2012', 'CD'), ('.', '.')]

 (S
  (NP Figure/NN)
  7/CD
  (NP shows/NNS)
  (NP different/JJ definitions/NNS)
  big/JJ
  found/VBD
  (NP online/JJ survey/NN)
  154/CD
  (NP C-suite/JJ global/JJ executives/NNS)
  conducted/VBN
  (NP Harris/NNP Interactive/NNP behalf/NN SAP/NNP April/NNP)
  2012/CD
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'shows', 'different definitions', 'online survey', 'C-suite global executives', 'Harris Interactive behalf SAP April']

>> Named Entities are: 
 [('PERSON', 'Harris Interactive'), ('ORGANIZATION', 'SAP')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('7', '7'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('found', 'found'), ('online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('C-suite', 'c-suit'), ('global', 'global'), ('executives', 'execut'), ('conducted', 'conduct'), ('Harris', 'harri'), ('Interactive', 'interact'), ('behalf', 'behalf'), ('SAP', 'sap'), ('April', 'april'), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('7', '7'), ('shows', 'show'), ('different', 'differ'), ('definitions', 'definit'), ('big', 'big'), ('found', 'found'), ('online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('C-suite', 'c-suit'), ('global', 'global'), ('executives', 'execut'), ('conducted', 'conduct'), ('Harris', 'harri'), ('Interactive', 'interact'), ('behalf', 'behalf'), ('SAP', 'sap'), ('April', 'april'), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('7', '7'), ('shows', 'show'), ('different', 'different'), ('definitions', 'definition'), ('big', 'big'), ('found', 'found'), ('online', 'online'), ('survey', 'survey'), ('154', '154'), ('C-suite', 'C-suite'), ('global', 'global'), ('executives', 'executive'), ('conducted', 'conducted'), ('Harris', 'Harris'), ('Interactive', 'Interactive'), ('behalf', 'behalf'), ('SAP', 'SAP'), ('April', 'April'), ('2012', '2012'), ('.', '.')]



============================ Sentence 148 =============================

Early research work (Laney, 2001) focused on big data definition based on the 3Vs (volume,   velocity, and variety). 


>> Tokens are: 
 ['Early', 'research', 'work', '(', 'Laney', ',', '2001', ')', 'focused', 'big', 'data', 'definition', 'based', '3Vs', '(', 'volume', ',', 'velocity', ',', 'variety', ')', '.']

>> Bigrams are: 
 [('Early', 'research'), ('research', 'work'), ('work', '('), ('(', 'Laney'), ('Laney', ','), (',', '2001'), ('2001', ')'), (')', 'focused'), ('focused', 'big'), ('big', 'data'), ('data', 'definition'), ('definition', 'based'), ('based', '3Vs'), ('3Vs', '('), ('(', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', ')'), (')', '.')]

>> Trigrams are: 
 [('Early', 'research', 'work'), ('research', 'work', '('), ('work', '(', 'Laney'), ('(', 'Laney', ','), ('Laney', ',', '2001'), (',', '2001', ')'), ('2001', ')', 'focused'), (')', 'focused', 'big'), ('focused', 'big', 'data'), ('big', 'data', 'definition'), ('data', 'definition', 'based'), ('definition', 'based', '3Vs'), ('based', '3Vs', '('), ('3Vs', '(', 'volume'), ('(', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', ')'), ('variety', ')', '.')]

>> POS Tags are: 
 [('Early', 'JJ'), ('research', 'NN'), ('work', 'NN'), ('(', '('), ('Laney', 'NNP'), (',', ','), ('2001', 'CD'), (')', ')'), ('focused', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('definition', 'NN'), ('based', 'VBN'), ('3Vs', 'CD'), ('(', '('), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Early/JJ research/NN work/NN)
  (/(
  (NP Laney/NNP)
  ,/,
  2001/CD
  )/)
  focused/VBD
  (NP big/JJ data/NNS definition/NN)
  based/VBN
  3Vs/CD
  (/(
  (NP volume/NN)
  ,/,
  (NP velocity/NN)
  ,/,
  (NP variety/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Early research work', 'Laney', 'big data definition', 'volume', 'velocity', 'variety']

>> Named Entities are: 
 [('GPE', 'Early'), ('PERSON', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('Early', 'earli'), ('research', 'research'), ('work', 'work'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (')', ')'), ('focused', 'focus'), ('big', 'big'), ('data', 'data'), ('definition', 'definit'), ('based', 'base'), ('3Vs', '3v'), ('(', '('), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Early', 'earli'), ('research', 'research'), ('work', 'work'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (')', ')'), ('focused', 'focus'), ('big', 'big'), ('data', 'data'), ('definition', 'definit'), ('based', 'base'), ('3Vs', '3vs'), ('(', '('), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Early', 'Early'), ('research', 'research'), ('work', 'work'), ('(', '('), ('Laney', 'Laney'), (',', ','), ('2001', '2001'), (')', ')'), ('focused', 'focused'), ('big', 'big'), ('data', 'data'), ('definition', 'definition'), ('based', 'based'), ('3Vs', '3Vs'), ('(', '('), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), (')', ')'), ('.', '.')]



============================ Sentence 149 =============================

Sagiroglu and Sinanc (2013) later presented a big data research review and   examined its security issues, while Lomotey et al. 


>> Tokens are: 
 ['Sagiroglu', 'Sinanc', '(', '2013', ')', 'later', 'presented', 'big', 'data', 'research', 'review', 'examined', 'security', 'issues', ',', 'Lomotey', 'et', 'al', '.']

>> Bigrams are: 
 [('Sagiroglu', 'Sinanc'), ('Sinanc', '('), ('(', '2013'), ('2013', ')'), (')', 'later'), ('later', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'research'), ('research', 'review'), ('review', 'examined'), ('examined', 'security'), ('security', 'issues'), ('issues', ','), (',', 'Lomotey'), ('Lomotey', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Sagiroglu', 'Sinanc', '('), ('Sinanc', '(', '2013'), ('(', '2013', ')'), ('2013', ')', 'later'), (')', 'later', 'presented'), ('later', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'research'), ('data', 'research', 'review'), ('research', 'review', 'examined'), ('review', 'examined', 'security'), ('examined', 'security', 'issues'), ('security', 'issues', ','), ('issues', ',', 'Lomotey'), (',', 'Lomotey', 'et'), ('Lomotey', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Sagiroglu', 'NNP'), ('Sinanc', 'NNP'), ('(', '('), ('2013', 'CD'), (')', ')'), ('later', 'RB'), ('presented', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('research', 'NN'), ('review', 'NN'), ('examined', 'VBD'), ('security', 'NN'), ('issues', 'NNS'), (',', ','), ('Lomotey', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S
  (NP Sagiroglu/NNP Sinanc/NNP)
  (/(
  2013/CD
  )/)
  later/RB
  presented/VBN
  (NP big/JJ data/NNS research/NN review/NN)
  examined/VBD
  (NP security/NN issues/NNS)
  ,/,
  (NP Lomotey/NNP)
  et/CC
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sagiroglu Sinanc', 'big data research review', 'security issues', 'Lomotey', 'al']

>> Named Entities are: 
 [('PERSON', 'Sagiroglu'), ('ORGANIZATION', 'Sinanc'), ('PERSON', 'Lomotey')] 

>> Stemming using Porter Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('Sinanc', 'sinanc'), ('(', '('), ('2013', '2013'), (')', ')'), ('later', 'later'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('review', 'review'), ('examined', 'examin'), ('security', 'secur'), ('issues', 'issu'), (',', ','), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sagiroglu', 'sagiroglu'), ('Sinanc', 'sinanc'), ('(', '('), ('2013', '2013'), (')', ')'), ('later', 'later'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('review', 'review'), ('examined', 'examin'), ('security', 'secur'), ('issues', 'issu'), (',', ','), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Sagiroglu', 'Sagiroglu'), ('Sinanc', 'Sinanc'), ('(', '('), ('2013', '2013'), (')', ')'), ('later', 'later'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('research', 'research'), ('review', 'review'), ('examined', 'examined'), ('security', 'security'), ('issues', 'issue'), (',', ','), ('Lomotey', 'Lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 150 =============================

(2014) defined big data by 5Vs, extending the   work done by Laney (2001) from 3Vs to include value, and veracity (Al-Barashdi and Al-Karousi,   2019 ). 


>> Tokens are: 
 ['(', '2014', ')', 'defined', 'big', 'data', '5Vs', ',', 'extending', 'work', 'done', 'Laney', '(', '2001', ')', '3Vs', 'include', 'value', ',', 'veracity', '(', 'Al-Barashdi', 'Al-Karousi', ',', '2019', ')', '.']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'defined'), ('defined', 'big'), ('big', 'data'), ('data', '5Vs'), ('5Vs', ','), (',', 'extending'), ('extending', 'work'), ('work', 'done'), ('done', 'Laney'), ('Laney', '('), ('(', '2001'), ('2001', ')'), (')', '3Vs'), ('3Vs', 'include'), ('include', 'value'), ('value', ','), (',', 'veracity'), ('veracity', '('), ('(', 'Al-Barashdi'), ('Al-Barashdi', 'Al-Karousi'), ('Al-Karousi', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'defined'), (')', 'defined', 'big'), ('defined', 'big', 'data'), ('big', 'data', '5Vs'), ('data', '5Vs', ','), ('5Vs', ',', 'extending'), (',', 'extending', 'work'), ('extending', 'work', 'done'), ('work', 'done', 'Laney'), ('done', 'Laney', '('), ('Laney', '(', '2001'), ('(', '2001', ')'), ('2001', ')', '3Vs'), (')', '3Vs', 'include'), ('3Vs', 'include', 'value'), ('include', 'value', ','), ('value', ',', 'veracity'), (',', 'veracity', '('), ('veracity', '(', 'Al-Barashdi'), ('(', 'Al-Barashdi', 'Al-Karousi'), ('Al-Barashdi', 'Al-Karousi', ','), ('Al-Karousi', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('defined', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('5Vs', 'CD'), (',', ','), ('extending', 'VBG'), ('work', 'NN'), ('done', 'VBN'), ('Laney', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('3Vs', 'CD'), ('include', 'VBP'), ('value', 'NN'), (',', ','), ('veracity', 'NN'), ('(', '('), ('Al-Barashdi', 'JJ'), ('Al-Karousi', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (/(
  2014/CD
  )/)
  defined/VBD
  (NP big/JJ data/NNS)
  5Vs/CD
  ,/,
  extending/VBG
  (NP work/NN)
  done/VBN
  (NP Laney/NNP)
  (/(
  2001/CD
  )/)
  3Vs/CD
  include/VBP
  (NP value/NN)
  ,/,
  (NP veracity/NN)
  (/(
  (NP Al-Barashdi/JJ Al-Karousi/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'work', 'Laney', 'value', 'veracity', 'Al-Barashdi Al-Karousi']

>> Named Entities are: 
 [('GPE', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('5Vs', '5v'), (',', ','), ('extending', 'extend'), ('work', 'work'), ('done', 'done'), ('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('3Vs', '3v'), ('include', 'includ'), ('value', 'valu'), (',', ','), ('veracity', 'verac'), ('(', '('), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('5Vs', '5vs'), (',', ','), ('extending', 'extend'), ('work', 'work'), ('done', 'done'), ('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('3Vs', '3vs'), ('include', 'includ'), ('value', 'valu'), (',', ','), ('veracity', 'verac'), ('(', '('), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('defined', 'defined'), ('big', 'big'), ('data', 'data'), ('5Vs', '5Vs'), (',', ','), ('extending', 'extending'), ('work', 'work'), ('done', 'done'), ('Laney', 'Laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('3Vs', '3Vs'), ('include', 'include'), ('value', 'value'), (',', ','), ('veracity', 'veracity'), ('(', '('), ('Al-Barashdi', 'Al-Barashdi'), ('Al-Karousi', 'Al-Karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 151 =============================

Ren et al. 


>> Tokens are: 
 ['Ren', 'et', 'al', '.']

>> Bigrams are: 
 [('Ren', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Ren', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Ren', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Ren/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Ren', 'al']

>> Named Entities are: 
 [('PERSON', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('Ren', 'ren'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ren', 'ren'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Ren', 'Ren'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 152 =============================

(2019) thus recently developed a set of up-to-date big data definitions, as shown in Table   1. 


>> Tokens are: 
 ['(', '2019', ')', 'thus', 'recently', 'developed', 'set', 'up-to-date', 'big', 'data', 'definitions', ',', 'shown', 'Table', '1', '.']

>> Bigrams are: 
 [('(', '2019'), ('2019', ')'), (')', 'thus'), ('thus', 'recently'), ('recently', 'developed'), ('developed', 'set'), ('set', 'up-to-date'), ('up-to-date', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', ','), (',', 'shown'), ('shown', 'Table'), ('Table', '1'), ('1', '.')]

>> Trigrams are: 
 [('(', '2019', ')'), ('2019', ')', 'thus'), (')', 'thus', 'recently'), ('thus', 'recently', 'developed'), ('recently', 'developed', 'set'), ('developed', 'set', 'up-to-date'), ('set', 'up-to-date', 'big'), ('up-to-date', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', ','), ('definitions', ',', 'shown'), (',', 'shown', 'Table'), ('shown', 'Table', '1'), ('Table', '1', '.')]

>> POS Tags are: 
 [('(', '('), ('2019', 'CD'), (')', ')'), ('thus', 'RB'), ('recently', 'RB'), ('developed', 'VBN'), ('set', 'VBN'), ('up-to-date', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), (',', ','), ('shown', 'VBN'), ('Table', 'JJ'), ('1', 'CD'), ('.', '.')]

 (S
  (/(
  2019/CD
  )/)
  thus/RB
  recently/RB
  developed/VBN
  set/VBN
  (NP up-to-date/JJ big/JJ data/NNS definitions/NNS)
  ,/,
  shown/VBN
  Table/JJ
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['up-to-date big data definitions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2019', '2019'), (')', ')'), ('thus', 'thu'), ('recently', 'recent'), ('developed', 'develop'), ('set', 'set'), ('up-to-date', 'up-to-d'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2019', '2019'), (')', ')'), ('thus', 'thus'), ('recently', 'recent'), ('developed', 'develop'), ('set', 'set'), ('up-to-date', 'up-to-d'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2019', '2019'), (')', ')'), ('thus', 'thus'), ('recently', 'recently'), ('developed', 'developed'), ('set', 'set'), ('up-to-date', 'up-to-date'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), (',', ','), ('shown', 'shown'), ('Table', 'Table'), ('1', '1'), ('.', '.')]



============================ Sentence 153 =============================

Figure 8 shows predictions of global data volume provided by International Data Corporation   (IDC) (Tien, J.M., 2013). 


>> Tokens are: 
 ['Figure', '8', 'shows', 'predictions', 'global', 'data', 'volume', 'provided', 'International', 'Data', 'Corporation', '(', 'IDC', ')', '(', 'Tien', ',', 'J.M.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('Figure', '8'), ('8', 'shows'), ('shows', 'predictions'), ('predictions', 'global'), ('global', 'data'), ('data', 'volume'), ('volume', 'provided'), ('provided', 'International'), ('International', 'Data'), ('Data', 'Corporation'), ('Corporation', '('), ('(', 'IDC'), ('IDC', ')'), (')', '('), ('(', 'Tien'), ('Tien', ','), (',', 'J.M.'), ('J.M.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '8', 'shows'), ('8', 'shows', 'predictions'), ('shows', 'predictions', 'global'), ('predictions', 'global', 'data'), ('global', 'data', 'volume'), ('data', 'volume', 'provided'), ('volume', 'provided', 'International'), ('provided', 'International', 'Data'), ('International', 'Data', 'Corporation'), ('Data', 'Corporation', '('), ('Corporation', '(', 'IDC'), ('(', 'IDC', ')'), ('IDC', ')', '('), (')', '(', 'Tien'), ('(', 'Tien', ','), ('Tien', ',', 'J.M.'), (',', 'J.M.', ','), ('J.M.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('8', 'CD'), ('shows', 'NNS'), ('predictions', 'NNS'), ('global', 'JJ'), ('data', 'NN'), ('volume', 'NN'), ('provided', 'VBD'), ('International', 'NNP'), ('Data', 'NNP'), ('Corporation', 'NNP'), ('(', '('), ('IDC', 'NNP'), (')', ')'), ('(', '('), ('Tien', 'NNP'), (',', ','), ('J.M.', 'NNP'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  8/CD
  (NP shows/NNS predictions/NNS)
  (NP global/JJ data/NN volume/NN)
  provided/VBD
  (NP International/NNP Data/NNP Corporation/NNP)
  (/(
  (NP IDC/NNP)
  )/)
  (/(
  (NP Tien/NNP)
  ,/,
  (NP J.M./NNP)
  ,/,
  2013/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'shows predictions', 'global data volume', 'International Data Corporation', 'IDC', 'Tien', 'J.M.']

>> Named Entities are: 
 [('ORGANIZATION', 'International Data Corporation'), ('ORGANIZATION', 'IDC'), ('ORGANIZATION', 'Tien')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('8', '8'), ('shows', 'show'), ('predictions', 'predict'), ('global', 'global'), ('data', 'data'), ('volume', 'volum'), ('provided', 'provid'), ('International', 'intern'), ('Data', 'data'), ('Corporation', 'corpor'), ('(', '('), ('IDC', 'idc'), (')', ')'), ('(', '('), ('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('8', '8'), ('shows', 'show'), ('predictions', 'predict'), ('global', 'global'), ('data', 'data'), ('volume', 'volum'), ('provided', 'provid'), ('International', 'intern'), ('Data', 'data'), ('Corporation', 'corpor'), ('(', '('), ('IDC', 'idc'), (')', ')'), ('(', '('), ('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('8', '8'), ('shows', 'show'), ('predictions', 'prediction'), ('global', 'global'), ('data', 'data'), ('volume', 'volume'), ('provided', 'provided'), ('International', 'International'), ('Data', 'Data'), ('Corporation', 'Corporation'), ('(', '('), ('IDC', 'IDC'), (')', ')'), ('(', '('), ('Tien', 'Tien'), (',', ','), ('J.M.', 'J.M.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



============================ Sentence 154 =============================

Besides the massive volume of big data, the complex structure of this   new data and the difficulty in managing and protecting such data have added further issues. 


>> Tokens are: 
 ['Besides', 'massive', 'volume', 'big', 'data', ',', 'complex', 'structure', 'new', 'data', 'difficulty', 'managing', 'protecting', 'data', 'added', 'issues', '.']

>> Bigrams are: 
 [('Besides', 'massive'), ('massive', 'volume'), ('volume', 'big'), ('big', 'data'), ('data', ','), (',', 'complex'), ('complex', 'structure'), ('structure', 'new'), ('new', 'data'), ('data', 'difficulty'), ('difficulty', 'managing'), ('managing', 'protecting'), ('protecting', 'data'), ('data', 'added'), ('added', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('Besides', 'massive', 'volume'), ('massive', 'volume', 'big'), ('volume', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'complex'), (',', 'complex', 'structure'), ('complex', 'structure', 'new'), ('structure', 'new', 'data'), ('new', 'data', 'difficulty'), ('data', 'difficulty', 'managing'), ('difficulty', 'managing', 'protecting'), ('managing', 'protecting', 'data'), ('protecting', 'data', 'added'), ('data', 'added', 'issues'), ('added', 'issues', '.')]

>> POS Tags are: 
 [('Besides', 'IN'), ('massive', 'JJ'), ('volume', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('complex', 'JJ'), ('structure', 'NN'), ('new', 'JJ'), ('data', 'NNS'), ('difficulty', 'NN'), ('managing', 'VBG'), ('protecting', 'VBG'), ('data', 'NNS'), ('added', 'VBD'), ('issues', 'NNS'), ('.', '.')]

 (S
  Besides/IN
  (NP massive/JJ volume/NN)
  (NP big/JJ data/NNS)
  ,/,
  (NP complex/JJ structure/NN)
  (NP new/JJ data/NNS difficulty/NN)
  managing/VBG
  protecting/VBG
  (NP data/NNS)
  added/VBD
  (NP issues/NNS)
  ./.) 


>> Noun Phrases are: 
 ['massive volume', 'big data', 'complex structure', 'new data difficulty', 'data', 'issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Besides', 'besid'), ('massive', 'massiv'), ('volume', 'volum'), ('big', 'big'), ('data', 'data'), (',', ','), ('complex', 'complex'), ('structure', 'structur'), ('new', 'new'), ('data', 'data'), ('difficulty', 'difficulti'), ('managing', 'manag'), ('protecting', 'protect'), ('data', 'data'), ('added', 'ad'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Besides', 'besid'), ('massive', 'massiv'), ('volume', 'volum'), ('big', 'big'), ('data', 'data'), (',', ','), ('complex', 'complex'), ('structure', 'structur'), ('new', 'new'), ('data', 'data'), ('difficulty', 'difficulti'), ('managing', 'manag'), ('protecting', 'protect'), ('data', 'data'), ('added', 'ad'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('Besides', 'Besides'), ('massive', 'massive'), ('volume', 'volume'), ('big', 'big'), ('data', 'data'), (',', ','), ('complex', 'complex'), ('structure', 'structure'), ('new', 'new'), ('data', 'data'), ('difficulty', 'difficulty'), ('managing', 'managing'), ('protecting', 'protecting'), ('data', 'data'), ('added', 'added'), ('issues', 'issue'), ('.', '.')]



============================ Sentence 155 =============================

Since   the idea of big data was raised, it has thus become one of the most popular focuses in both technical   and engineering areas (Wang et al., 2016). 


>> Tokens are: 
 ['Since', 'idea', 'big', 'data', 'raised', ',', 'thus', 'become', 'one', 'popular', 'focuses', 'technical', 'engineering', 'areas', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Since', 'idea'), ('idea', 'big'), ('big', 'data'), ('data', 'raised'), ('raised', ','), (',', 'thus'), ('thus', 'become'), ('become', 'one'), ('one', 'popular'), ('popular', 'focuses'), ('focuses', 'technical'), ('technical', 'engineering'), ('engineering', 'areas'), ('areas', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Since', 'idea', 'big'), ('idea', 'big', 'data'), ('big', 'data', 'raised'), ('data', 'raised', ','), ('raised', ',', 'thus'), (',', 'thus', 'become'), ('thus', 'become', 'one'), ('become', 'one', 'popular'), ('one', 'popular', 'focuses'), ('popular', 'focuses', 'technical'), ('focuses', 'technical', 'engineering'), ('technical', 'engineering', 'areas'), ('engineering', 'areas', '('), ('areas', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Since', 'IN'), ('idea', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('raised', 'VBD'), (',', ','), ('thus', 'RB'), ('become', 'VB'), ('one', 'CD'), ('popular', 'JJ'), ('focuses', 'VBZ'), ('technical', 'JJ'), ('engineering', 'NN'), ('areas', 'NNS'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  Since/IN
  (NP idea/NN)
  (NP big/JJ data/NNS)
  raised/VBD
  ,/,
  thus/RB
  become/VB
  one/CD
  popular/JJ
  focuses/VBZ
  (NP technical/JJ engineering/NN areas/NNS)
  (/(
  (NP Wang/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['idea', 'big data', 'technical engineering areas', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Since', 'sinc'), ('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('raised', 'rais'), (',', ','), ('thus', 'thu'), ('become', 'becom'), ('one', 'one'), ('popular', 'popular'), ('focuses', 'focus'), ('technical', 'technic'), ('engineering', 'engin'), ('areas', 'area'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Since', 'sinc'), ('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('raised', 'rais'), (',', ','), ('thus', 'thus'), ('become', 'becom'), ('one', 'one'), ('popular', 'popular'), ('focuses', 'focus'), ('technical', 'technic'), ('engineering', 'engin'), ('areas', 'area'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Since', 'Since'), ('idea', 'idea'), ('big', 'big'), ('data', 'data'), ('raised', 'raised'), (',', ','), ('thus', 'thus'), ('become', 'become'), ('one', 'one'), ('popular', 'popular'), ('focuses', 'focus'), ('technical', 'technical'), ('engineering', 'engineering'), ('areas', 'area'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 156 =============================

Sarah Al-Shiakhli   10         Figure 7: Definitions of big data (Online survey of 154 global executives in April 2012,   Gandomi and Haider, 2015). 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '10', 'Figure', '7', ':', 'Definitions', 'big', 'data', '(', 'Online', 'survey', '154', 'global', 'executives', 'April', '2012', ',', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '10'), ('10', 'Figure'), ('Figure', '7'), ('7', ':'), (':', 'Definitions'), ('Definitions', 'big'), ('big', 'data'), ('data', '('), ('(', 'Online'), ('Online', 'survey'), ('survey', '154'), ('154', 'global'), ('global', 'executives'), ('executives', 'April'), ('April', '2012'), ('2012', ','), (',', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '10'), ('Al-Shiakhli', '10', 'Figure'), ('10', 'Figure', '7'), ('Figure', '7', ':'), ('7', ':', 'Definitions'), (':', 'Definitions', 'big'), ('Definitions', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Online'), ('(', 'Online', 'survey'), ('Online', 'survey', '154'), ('survey', '154', 'global'), ('154', 'global', 'executives'), ('global', 'executives', 'April'), ('executives', 'April', '2012'), ('April', '2012', ','), ('2012', ',', 'Gandomi'), (',', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('10', 'CD'), ('Figure', 'NNP'), ('7', 'CD'), (':', ':'), ('Definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Online', 'NNP'), ('survey', 'NN'), ('154', 'CD'), ('global', 'JJ'), ('executives', 'NNS'), ('April', 'NNP'), ('2012', 'CD'), (',', ','), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  10/CD
  (NP Figure/NNP)
  7/CD
  :/:
  (NP Definitions/NNS)
  (NP big/JJ data/NNS)
  (/(
  (NP Online/NNP survey/NN)
  154/CD
  (NP global/JJ executives/NNS April/NNP)
  2012/CD
  ,/,
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Figure', 'Definitions', 'big data', 'Online survey', 'global executives April', 'Gandomi Haider']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Online'), ('PERSON', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('10', '10'), ('Figure', 'figur'), ('7', '7'), (':', ':'), ('Definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('global', 'global'), ('executives', 'execut'), ('April', 'april'), ('2012', '2012'), (',', ','), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('10', '10'), ('Figure', 'figur'), ('7', '7'), (':', ':'), ('Definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Online', 'onlin'), ('survey', 'survey'), ('154', '154'), ('global', 'global'), ('executives', 'execut'), ('April', 'april'), ('2012', '2012'), (',', ','), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('10', '10'), ('Figure', 'Figure'), ('7', '7'), (':', ':'), ('Definitions', 'Definitions'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Online', 'Online'), ('survey', 'survey'), ('154', '154'), ('global', 'global'), ('executives', 'executive'), ('April', 'April'), ('2012', '2012'), (',', ','), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 157 =============================

To realise big data’s potential, the data should be gathered in a new way which enables it to be   utilised for different purposes many times without recollection; this can be seen today in the many   devices connected to the internet and the huge amount of data accesses even by individuals. 


>> Tokens are: 
 ['To', 'realise', 'big', 'data', '’', 'potential', ',', 'data', 'gathered', 'new', 'way', 'enables', 'utilised', 'different', 'purposes', 'many', 'times', 'without', 'recollection', ';', 'seen', 'today', 'many', 'devices', 'connected', 'internet', 'huge', 'amount', 'data', 'accesses', 'even', 'individuals', '.']

>> Bigrams are: 
 [('To', 'realise'), ('realise', 'big'), ('big', 'data'), ('data', '’'), ('’', 'potential'), ('potential', ','), (',', 'data'), ('data', 'gathered'), ('gathered', 'new'), ('new', 'way'), ('way', 'enables'), ('enables', 'utilised'), ('utilised', 'different'), ('different', 'purposes'), ('purposes', 'many'), ('many', 'times'), ('times', 'without'), ('without', 'recollection'), ('recollection', ';'), (';', 'seen'), ('seen', 'today'), ('today', 'many'), ('many', 'devices'), ('devices', 'connected'), ('connected', 'internet'), ('internet', 'huge'), ('huge', 'amount'), ('amount', 'data'), ('data', 'accesses'), ('accesses', 'even'), ('even', 'individuals'), ('individuals', '.')]

>> Trigrams are: 
 [('To', 'realise', 'big'), ('realise', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'potential'), ('’', 'potential', ','), ('potential', ',', 'data'), (',', 'data', 'gathered'), ('data', 'gathered', 'new'), ('gathered', 'new', 'way'), ('new', 'way', 'enables'), ('way', 'enables', 'utilised'), ('enables', 'utilised', 'different'), ('utilised', 'different', 'purposes'), ('different', 'purposes', 'many'), ('purposes', 'many', 'times'), ('many', 'times', 'without'), ('times', 'without', 'recollection'), ('without', 'recollection', ';'), ('recollection', ';', 'seen'), (';', 'seen', 'today'), ('seen', 'today', 'many'), ('today', 'many', 'devices'), ('many', 'devices', 'connected'), ('devices', 'connected', 'internet'), ('connected', 'internet', 'huge'), ('internet', 'huge', 'amount'), ('huge', 'amount', 'data'), ('amount', 'data', 'accesses'), ('data', 'accesses', 'even'), ('accesses', 'even', 'individuals'), ('even', 'individuals', '.')]

>> POS Tags are: 
 [('To', 'TO'), ('realise', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'MD'), ('potential', 'JJ'), (',', ','), ('data', 'NNS'), ('gathered', 'VBD'), ('new', 'JJ'), ('way', 'NN'), ('enables', 'NNS'), ('utilised', 'JJ'), ('different', 'JJ'), ('purposes', 'NNS'), ('many', 'JJ'), ('times', 'NNS'), ('without', 'IN'), ('recollection', 'NN'), (';', ':'), ('seen', 'VBN'), ('today', 'NN'), ('many', 'JJ'), ('devices', 'NNS'), ('connected', 'VBN'), ('internet', 'RB'), ('huge', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('accesses', 'NNS'), ('even', 'RB'), ('individuals', 'NNS'), ('.', '.')]

 (S
  To/TO
  realise/VB
  (NP big/JJ data/NNS)
  ’/MD
  potential/JJ
  ,/,
  (NP data/NNS)
  gathered/VBD
  (NP new/JJ way/NN enables/NNS)
  (NP utilised/JJ different/JJ purposes/NNS)
  (NP many/JJ times/NNS)
  without/IN
  (NP recollection/NN)
  ;/:
  seen/VBN
  (NP today/NN)
  (NP many/JJ devices/NNS)
  connected/VBN
  internet/RB
  (NP huge/JJ amount/NN data/NNS accesses/NNS)
  even/RB
  (NP individuals/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'data', 'new way enables', 'utilised different purposes', 'many times', 'recollection', 'today', 'many devices', 'huge amount data accesses', 'individuals']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('To', 'to'), ('realise', 'realis'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), (',', ','), ('data', 'data'), ('gathered', 'gather'), ('new', 'new'), ('way', 'way'), ('enables', 'enabl'), ('utilised', 'utilis'), ('different', 'differ'), ('purposes', 'purpos'), ('many', 'mani'), ('times', 'time'), ('without', 'without'), ('recollection', 'recollect'), (';', ';'), ('seen', 'seen'), ('today', 'today'), ('many', 'mani'), ('devices', 'devic'), ('connected', 'connect'), ('internet', 'internet'), ('huge', 'huge'), ('amount', 'amount'), ('data', 'data'), ('accesses', 'access'), ('even', 'even'), ('individuals', 'individu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('To', 'to'), ('realise', 'realis'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), (',', ','), ('data', 'data'), ('gathered', 'gather'), ('new', 'new'), ('way', 'way'), ('enables', 'enabl'), ('utilised', 'utilis'), ('different', 'differ'), ('purposes', 'purpos'), ('many', 'mani'), ('times', 'time'), ('without', 'without'), ('recollection', 'recollect'), (';', ';'), ('seen', 'seen'), ('today', 'today'), ('many', 'mani'), ('devices', 'devic'), ('connected', 'connect'), ('internet', 'internet'), ('huge', 'huge'), ('amount', 'amount'), ('data', 'data'), ('accesses', 'access'), ('even', 'even'), ('individuals', 'individu'), ('.', '.')]

>> Lemmatization: 
 [('To', 'To'), ('realise', 'realise'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potential'), (',', ','), ('data', 'data'), ('gathered', 'gathered'), ('new', 'new'), ('way', 'way'), ('enables', 'enables'), ('utilised', 'utilised'), ('different', 'different'), ('purposes', 'purpose'), ('many', 'many'), ('times', 'time'), ('without', 'without'), ('recollection', 'recollection'), (';', ';'), ('seen', 'seen'), ('today', 'today'), ('many', 'many'), ('devices', 'device'), ('connected', 'connected'), ('internet', 'internet'), ('huge', 'huge'), ('amount', 'amount'), ('data', 'data'), ('accesses', 'access'), ('even', 'even'), ('individuals', 'individual'), ('.', '.')]



============================ Sentence 158 =============================

By   2020, the predicted value of data is posited to double every 24 months (Mayer-Schonberger and   Padova, 2015). 


>> Tokens are: 
 ['By', '2020', ',', 'predicted', 'value', 'data', 'posited', 'double', 'every', '24', 'months', '(', 'Mayer-Schonberger', 'Padova', ',', '2015', ')', '.']

>> Bigrams are: 
 [('By', '2020'), ('2020', ','), (',', 'predicted'), ('predicted', 'value'), ('value', 'data'), ('data', 'posited'), ('posited', 'double'), ('double', 'every'), ('every', '24'), ('24', 'months'), ('months', '('), ('(', 'Mayer-Schonberger'), ('Mayer-Schonberger', 'Padova'), ('Padova', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('By', '2020', ','), ('2020', ',', 'predicted'), (',', 'predicted', 'value'), ('predicted', 'value', 'data'), ('value', 'data', 'posited'), ('data', 'posited', 'double'), ('posited', 'double', 'every'), ('double', 'every', '24'), ('every', '24', 'months'), ('24', 'months', '('), ('months', '(', 'Mayer-Schonberger'), ('(', 'Mayer-Schonberger', 'Padova'), ('Mayer-Schonberger', 'Padova', ','), ('Padova', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('By', 'IN'), ('2020', 'CD'), (',', ','), ('predicted', 'VBD'), ('value', 'NN'), ('data', 'NNS'), ('posited', 'VBD'), ('double', 'JJ'), ('every', 'DT'), ('24', 'CD'), ('months', 'NNS'), ('(', '('), ('Mayer-Schonberger', 'NNP'), ('Padova', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  By/IN
  2020/CD
  ,/,
  predicted/VBD
  (NP value/NN data/NNS)
  posited/VBD
  double/JJ
  every/DT
  24/CD
  (NP months/NNS)
  (/(
  (NP Mayer-Schonberger/NNP Padova/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['value data', 'months', 'Mayer-Schonberger Padova']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('By', 'by'), ('2020', '2020'), (',', ','), ('predicted', 'predict'), ('value', 'valu'), ('data', 'data'), ('posited', 'posit'), ('double', 'doubl'), ('every', 'everi'), ('24', '24'), ('months', 'month'), ('(', '('), ('Mayer-Schonberger', 'mayer-schonberg'), ('Padova', 'padova'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('By', 'by'), ('2020', '2020'), (',', ','), ('predicted', 'predict'), ('value', 'valu'), ('data', 'data'), ('posited', 'posit'), ('double', 'doubl'), ('every', 'everi'), ('24', '24'), ('months', 'month'), ('(', '('), ('Mayer-Schonberger', 'mayer-schonberg'), ('Padova', 'padova'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('By', 'By'), ('2020', '2020'), (',', ','), ('predicted', 'predicted'), ('value', 'value'), ('data', 'data'), ('posited', 'posited'), ('double', 'double'), ('every', 'every'), ('24', '24'), ('months', 'month'), ('(', '('), ('Mayer-Schonberger', 'Mayer-Schonberger'), ('Padova', 'Padova'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 159 =============================

Figure 8: Global data volume predicted by IDC (Wang et al., 2016)        Sarah Al-Shiakhli   11         Table 1 shows various big data definitions or characteristics from the period 2001 to 2017. 


>> Tokens are: 
 ['Figure', '8', ':', 'Global', 'data', 'volume', 'predicted', 'IDC', '(', 'Wang', 'et', 'al.', ',', '2016', ')', 'Sarah', 'Al-Shiakhli', '11', 'Table', '1', 'shows', 'various', 'big', 'data', 'definitions', 'characteristics', 'period', '2001', '2017', '.']

>> Bigrams are: 
 [('Figure', '8'), ('8', ':'), (':', 'Global'), ('Global', 'data'), ('data', 'volume'), ('volume', 'predicted'), ('predicted', 'IDC'), ('IDC', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '11'), ('11', 'Table'), ('Table', '1'), ('1', 'shows'), ('shows', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'characteristics'), ('characteristics', 'period'), ('period', '2001'), ('2001', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Figure', '8', ':'), ('8', ':', 'Global'), (':', 'Global', 'data'), ('Global', 'data', 'volume'), ('data', 'volume', 'predicted'), ('volume', 'predicted', 'IDC'), ('predicted', 'IDC', '('), ('IDC', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', 'Sarah'), (')', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '11'), ('Al-Shiakhli', '11', 'Table'), ('11', 'Table', '1'), ('Table', '1', 'shows'), ('1', 'shows', 'various'), ('shows', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'characteristics'), ('definitions', 'characteristics', 'period'), ('characteristics', 'period', '2001'), ('period', '2001', '2017'), ('2001', '2017', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('8', 'CD'), (':', ':'), ('Global', 'JJ'), ('data', 'NN'), ('volume', 'NN'), ('predicted', 'VBD'), ('IDC', 'NNP'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('11', 'CD'), ('Table', 'NNP'), ('1', 'CD'), ('shows', 'VBZ'), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('characteristics', 'NNS'), ('period', 'NN'), ('2001', 'CD'), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Figure/NN)
  8/CD
  :/:
  (NP Global/JJ data/NN volume/NN)
  predicted/VBD
  (NP IDC/NNP)
  (/(
  (NP Wang/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  (NP Sarah/NNP Al-Shiakhli/NNP)
  11/CD
  (NP Table/NNP)
  1/CD
  shows/VBZ
  (NP
    various/JJ
    big/JJ
    data/NNS
    definitions/NNS
    characteristics/NNS
    period/NN)
  2001/CD
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Global data volume', 'IDC', 'Wang', 'Sarah Al-Shiakhli', 'Table', 'various big data definitions characteristics period']

>> Named Entities are: 
 [('ORGANIZATION', 'IDC'), ('PERSON', 'Wang'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('8', '8'), (':', ':'), ('Global', 'global'), ('data', 'data'), ('volume', 'volum'), ('predicted', 'predict'), ('IDC', 'idc'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('11', '11'), ('Table', 'tabl'), ('1', '1'), ('shows', 'show'), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('characteristics', 'characterist'), ('period', 'period'), ('2001', '2001'), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('8', '8'), (':', ':'), ('Global', 'global'), ('data', 'data'), ('volume', 'volum'), ('predicted', 'predict'), ('IDC', 'idc'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('11', '11'), ('Table', 'tabl'), ('1', '1'), ('shows', 'show'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('characteristics', 'characterist'), ('period', 'period'), ('2001', '2001'), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('8', '8'), (':', ':'), ('Global', 'Global'), ('data', 'data'), ('volume', 'volume'), ('predicted', 'predicted'), ('IDC', 'IDC'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('11', '11'), ('Table', 'Table'), ('1', '1'), ('shows', 'show'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('characteristics', 'characteristic'), ('period', 'period'), ('2001', '2001'), ('2017', '2017'), ('.', '.')]



============================ Sentence 160 =============================

Table 1: Six representative definitions of big data adopted from (Ren et al., 2019). 


>> Tokens are: 
 ['Table', '1', ':', 'Six', 'representative', 'definitions', 'big', 'data', 'adopted', '(', 'Ren', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Table', '1'), ('1', ':'), (':', 'Six'), ('Six', 'representative'), ('representative', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'adopted'), ('adopted', '('), ('(', 'Ren'), ('Ren', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Table', '1', ':'), ('1', ':', 'Six'), (':', 'Six', 'representative'), ('Six', 'representative', 'definitions'), ('representative', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'adopted'), ('data', 'adopted', '('), ('adopted', '(', 'Ren'), ('(', 'Ren', 'et'), ('Ren', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Table', 'JJ'), ('1', 'CD'), (':', ':'), ('Six', 'CD'), ('representative', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('adopted', 'VBD'), ('(', '('), ('Ren', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  Table/JJ
  1/CD
  :/:
  Six/CD
  (NP representative/JJ definitions/NNS)
  (NP big/JJ data/NNS)
  adopted/VBD
  (/(
  (NP Ren/NNP)
  et/VBZ
  al./RB
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['representative definitions', 'big data', 'Ren']

>> Named Entities are: 
 [('ORGANIZATION', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('1', '1'), (':', ':'), ('Six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('1', '1'), (':', ':'), ('Six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Table', 'Table'), ('1', '1'), (':', ':'), ('Six', 'Six'), ('representative', 'representative'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopted'), ('(', '('), ('Ren', 'Ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 161 =============================

Sarah Al-Shiakhli   12      Grover and Kar (2017) highlight that the number of big data articles published in reputable journals   is increasing, as shown in Figure 9. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '12', 'Grover', 'Kar', '(', '2017', ')', 'highlight', 'number', 'big', 'data', 'articles', 'published', 'reputable', 'journals', 'increasing', ',', 'shown', 'Figure', '9', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '12'), ('12', 'Grover'), ('Grover', 'Kar'), ('Kar', '('), ('(', '2017'), ('2017', ')'), (')', 'highlight'), ('highlight', 'number'), ('number', 'big'), ('big', 'data'), ('data', 'articles'), ('articles', 'published'), ('published', 'reputable'), ('reputable', 'journals'), ('journals', 'increasing'), ('increasing', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '9'), ('9', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '12'), ('Al-Shiakhli', '12', 'Grover'), ('12', 'Grover', 'Kar'), ('Grover', 'Kar', '('), ('Kar', '(', '2017'), ('(', '2017', ')'), ('2017', ')', 'highlight'), (')', 'highlight', 'number'), ('highlight', 'number', 'big'), ('number', 'big', 'data'), ('big', 'data', 'articles'), ('data', 'articles', 'published'), ('articles', 'published', 'reputable'), ('published', 'reputable', 'journals'), ('reputable', 'journals', 'increasing'), ('journals', 'increasing', ','), ('increasing', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '9'), ('Figure', '9', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('12', 'CD'), ('Grover', 'NNP'), ('Kar', 'NNP'), ('(', '('), ('2017', 'CD'), (')', ')'), ('highlight', 'VBD'), ('number', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('articles', 'NNS'), ('published', 'VBN'), ('reputable', 'JJ'), ('journals', 'NNS'), ('increasing', 'VBG'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('9', 'CD'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  12/CD
  (NP Grover/NNP Kar/NNP)
  (/(
  2017/CD
  )/)
  highlight/VBD
  (NP number/NN)
  (NP big/JJ data/NNS articles/NNS)
  published/VBN
  (NP reputable/JJ journals/NNS)
  increasing/VBG
  ,/,
  shown/VBN
  (NP Figure/NN)
  9/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Grover Kar', 'number', 'big data articles', 'reputable journals', 'Figure']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('12', '12'), ('Grover', 'grover'), ('Kar', 'kar'), ('(', '('), ('2017', '2017'), (')', ')'), ('highlight', 'highlight'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('articles', 'articl'), ('published', 'publish'), ('reputable', 'reput'), ('journals', 'journal'), ('increasing', 'increas'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('12', '12'), ('Grover', 'grover'), ('Kar', 'kar'), ('(', '('), ('2017', '2017'), (')', ')'), ('highlight', 'highlight'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('articles', 'articl'), ('published', 'publish'), ('reputable', 'reput'), ('journals', 'journal'), ('increasing', 'increas'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('12', '12'), ('Grover', 'Grover'), ('Kar', 'Kar'), ('(', '('), ('2017', '2017'), (')', ')'), ('highlight', 'highlight'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('articles', 'article'), ('published', 'published'), ('reputable', 'reputable'), ('journals', 'journal'), ('increasing', 'increasing'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('9', '9'), ('.', '.')]



============================ Sentence 162 =============================

Figure 9: Yearly distribution of “big data” research studies (Grover and Kar, 2017). 


>> Tokens are: 
 ['Figure', '9', ':', 'Yearly', 'distribution', '“', 'big', 'data', '”', 'research', 'studies', '(', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Figure', '9'), ('9', ':'), (':', 'Yearly'), ('Yearly', 'distribution'), ('distribution', '“'), ('“', 'big'), ('big', 'data'), ('data', '”'), ('”', 'research'), ('research', 'studies'), ('studies', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '9', ':'), ('9', ':', 'Yearly'), (':', 'Yearly', 'distribution'), ('Yearly', 'distribution', '“'), ('distribution', '“', 'big'), ('“', 'big', 'data'), ('big', 'data', '”'), ('data', '”', 'research'), ('”', 'research', 'studies'), ('research', 'studies', '('), ('studies', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('9', 'CD'), (':', ':'), ('Yearly', 'JJ'), ('distribution', 'NN'), ('“', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('”', 'VBP'), ('research', 'NN'), ('studies', 'NNS'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  9/CD
  :/:
  (NP Yearly/JJ distribution/NN “/NNP)
  (NP big/JJ data/NNS)
  ”/VBP
  (NP research/NN studies/NNS)
  (/(
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Yearly distribution “', 'big data', 'research studies', 'Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('9', '9'), (':', ':'), ('Yearly', 'yearli'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('research', 'research'), ('studies', 'studi'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('9', '9'), (':', ':'), ('Yearly', 'year'), ('distribution', 'distribut'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('research', 'research'), ('studies', 'studi'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('9', '9'), (':', ':'), ('Yearly', 'Yearly'), ('distribution', 'distribution'), ('“', '“'), ('big', 'big'), ('data', 'data'), ('”', '”'), ('research', 'research'), ('studies', 'study'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 163 =============================

Mikalef et al. 


>> Tokens are: 
 ['Mikalef', 'et', 'al', '.']

>> Bigrams are: 
 [('Mikalef', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Mikalef', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Mikalef', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Mikalef/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Mikalef', 'al']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Mikalef', 'Mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 164 =============================

(2018) also provided an overview of big data definitions in past studies, as shown   in Table 2. 


>> Tokens are: 
 ['(', '2018', ')', 'also', 'provided', 'overview', 'big', 'data', 'definitions', 'past', 'studies', ',', 'shown', 'Table', '2', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'also'), ('also', 'provided'), ('provided', 'overview'), ('overview', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'past'), ('past', 'studies'), ('studies', ','), (',', 'shown'), ('shown', 'Table'), ('Table', '2'), ('2', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'also'), (')', 'also', 'provided'), ('also', 'provided', 'overview'), ('provided', 'overview', 'big'), ('overview', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'past'), ('definitions', 'past', 'studies'), ('past', 'studies', ','), ('studies', ',', 'shown'), (',', 'shown', 'Table'), ('shown', 'Table', '2'), ('Table', '2', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('also', 'RB'), ('provided', 'VBN'), ('overview', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('past', 'IN'), ('studies', 'NNS'), (',', ','), ('shown', 'VBN'), ('Table', 'JJ'), ('2', 'CD'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  also/RB
  provided/VBN
  (NP overview/NN)
  (NP big/JJ data/NNS definitions/NNS)
  past/IN
  (NP studies/NNS)
  ,/,
  shown/VBN
  Table/JJ
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['overview', 'big data definitions', 'studies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('also', 'also'), ('provided', 'provid'), ('overview', 'overview'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('past', 'past'), ('studies', 'studi'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('also', 'also'), ('provided', 'provid'), ('overview', 'overview'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('past', 'past'), ('studies', 'studi'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('also', 'also'), ('provided', 'provided'), ('overview', 'overview'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('past', 'past'), ('studies', 'study'), (',', ','), ('shown', 'shown'), ('Table', 'Table'), ('2', '2'), ('.', '.')]



============================ Sentence 165 =============================

Sarah Al-Shiakhli   13      Table 2: Sample definitions of big data adopted from (Mikalef et al., 2018). 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '13', 'Table', '2', ':', 'Sample', 'definitions', 'big', 'data', 'adopted', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '13'), ('13', 'Table'), ('Table', '2'), ('2', ':'), (':', 'Sample'), ('Sample', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'adopted'), ('adopted', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '13'), ('Al-Shiakhli', '13', 'Table'), ('13', 'Table', '2'), ('Table', '2', ':'), ('2', ':', 'Sample'), (':', 'Sample', 'definitions'), ('Sample', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'adopted'), ('data', 'adopted', '('), ('adopted', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('13', 'CD'), ('Table', 'JJ'), ('2', 'CD'), (':', ':'), ('Sample', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('adopted', 'VBD'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  13/CD
  Table/JJ
  2/CD
  :/:
  (NP Sample/JJ definitions/NNS)
  (NP big/JJ data/NNS)
  adopted/VBD
  (/(
  (NP Mikalef/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Sample definitions', 'big data', 'Mikalef']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('13', '13'), ('Table', 'tabl'), ('2', '2'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('13', '13'), ('Table', 'tabl'), ('2', '2'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('13', '13'), ('Table', 'Table'), ('2', '2'), (':', ':'), ('Sample', 'Sample'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('adopted', 'adopted'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 166 =============================

Sarah Al-Shiakhli   14            The abovementioned definitions are complimentary to each other at some points such as defining   the big data by 5Vs in Lomotey et al. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '14', 'The', 'abovementioned', 'definitions', 'complimentary', 'points', 'defining', 'big', 'data', '5Vs', 'Lomotey', 'et', 'al', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '14'), ('14', 'The'), ('The', 'abovementioned'), ('abovementioned', 'definitions'), ('definitions', 'complimentary'), ('complimentary', 'points'), ('points', 'defining'), ('defining', 'big'), ('big', 'data'), ('data', '5Vs'), ('5Vs', 'Lomotey'), ('Lomotey', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '14'), ('Al-Shiakhli', '14', 'The'), ('14', 'The', 'abovementioned'), ('The', 'abovementioned', 'definitions'), ('abovementioned', 'definitions', 'complimentary'), ('definitions', 'complimentary', 'points'), ('complimentary', 'points', 'defining'), ('points', 'defining', 'big'), ('defining', 'big', 'data'), ('big', 'data', '5Vs'), ('data', '5Vs', 'Lomotey'), ('5Vs', 'Lomotey', 'et'), ('Lomotey', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('14', 'CD'), ('The', 'DT'), ('abovementioned', 'JJ'), ('definitions', 'NNS'), ('complimentary', 'JJ'), ('points', 'NNS'), ('defining', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('5Vs', 'CD'), ('Lomotey', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  14/CD
  (NP The/DT abovementioned/JJ definitions/NNS)
  (NP complimentary/JJ points/NNS)
  defining/VBG
  (NP big/JJ data/NNS)
  5Vs/CD
  (NP Lomotey/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'The abovementioned definitions', 'complimentary points', 'big data', 'Lomotey', 'al']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('14', '14'), ('The', 'the'), ('abovementioned', 'abovement'), ('definitions', 'definit'), ('complimentary', 'complimentari'), ('points', 'point'), ('defining', 'defin'), ('big', 'big'), ('data', 'data'), ('5Vs', '5v'), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('14', '14'), ('The', 'the'), ('abovementioned', 'abovement'), ('definitions', 'definit'), ('complimentary', 'complimentari'), ('points', 'point'), ('defining', 'defin'), ('big', 'big'), ('data', 'data'), ('5Vs', '5vs'), ('Lomotey', 'lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('14', '14'), ('The', 'The'), ('abovementioned', 'abovementioned'), ('definitions', 'definition'), ('complimentary', 'complimentary'), ('points', 'point'), ('defining', 'defining'), ('big', 'big'), ('data', 'data'), ('5Vs', '5Vs'), ('Lomotey', 'Lomotey'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 167 =============================

(2014). 


>> Tokens are: 
 ['(', '2014', ')', '.']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S (/( 2014/CD )/) ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 168 =============================

At other points, some of them are contradicting with   the six representative definitions adopted from (Ren et al., 2019) that are shown in Table 1. 


>> Tokens are: 
 ['At', 'points', ',', 'contradicting', 'six', 'representative', 'definitions', 'adopted', '(', 'Ren', 'et', 'al.', ',', '2019', ')', 'shown', 'Table', '1', '.']

>> Bigrams are: 
 [('At', 'points'), ('points', ','), (',', 'contradicting'), ('contradicting', 'six'), ('six', 'representative'), ('representative', 'definitions'), ('definitions', 'adopted'), ('adopted', '('), ('(', 'Ren'), ('Ren', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', 'shown'), ('shown', 'Table'), ('Table', '1'), ('1', '.')]

>> Trigrams are: 
 [('At', 'points', ','), ('points', ',', 'contradicting'), (',', 'contradicting', 'six'), ('contradicting', 'six', 'representative'), ('six', 'representative', 'definitions'), ('representative', 'definitions', 'adopted'), ('definitions', 'adopted', '('), ('adopted', '(', 'Ren'), ('(', 'Ren', 'et'), ('Ren', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', 'shown'), (')', 'shown', 'Table'), ('shown', 'Table', '1'), ('Table', '1', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('points', 'NNS'), (',', ','), ('contradicting', 'VBG'), ('six', 'CD'), ('representative', 'JJ'), ('definitions', 'NNS'), ('adopted', 'VBN'), ('(', '('), ('Ren', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('shown', 'VBN'), ('Table', 'JJ'), ('1', 'CD'), ('.', '.')]

 (S
  At/IN
  (NP points/NNS)
  ,/,
  contradicting/VBG
  six/CD
  (NP representative/JJ definitions/NNS)
  adopted/VBN
  (/(
  (NP Ren/NNP)
  et/VBZ
  al./RB
  ,/,
  2019/CD
  )/)
  shown/VBN
  Table/JJ
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['points', 'representative definitions', 'Ren']

>> Named Entities are: 
 [('ORGANIZATION', 'Ren')] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('points', 'point'), (',', ','), ('contradicting', 'contradict'), ('six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('shown', 'shown'), ('Table', 'tabl'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('points', 'point'), (',', ','), ('contradicting', 'contradict'), ('six', 'six'), ('representative', 'repres'), ('definitions', 'definit'), ('adopted', 'adopt'), ('(', '('), ('Ren', 'ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('shown', 'shown'), ('Table', 'tabl'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('points', 'point'), (',', ','), ('contradicting', 'contradicting'), ('six', 'six'), ('representative', 'representative'), ('definitions', 'definition'), ('adopted', 'adopted'), ('(', '('), ('Ren', 'Ren'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('shown', 'shown'), ('Table', 'Table'), ('1', '1'), ('.', '.')]



============================ Sentence 169 =============================

They   defined big data in term of three ‘Vs’ and they focused on the size of data ignoring the other   dimensions. 


>> Tokens are: 
 ['They', 'defined', 'big', 'data', 'term', 'three', '‘', 'Vs', '’', 'focused', 'size', 'data', 'ignoring', 'dimensions', '.']

>> Bigrams are: 
 [('They', 'defined'), ('defined', 'big'), ('big', 'data'), ('data', 'term'), ('term', 'three'), ('three', '‘'), ('‘', 'Vs'), ('Vs', '’'), ('’', 'focused'), ('focused', 'size'), ('size', 'data'), ('data', 'ignoring'), ('ignoring', 'dimensions'), ('dimensions', '.')]

>> Trigrams are: 
 [('They', 'defined', 'big'), ('defined', 'big', 'data'), ('big', 'data', 'term'), ('data', 'term', 'three'), ('term', 'three', '‘'), ('three', '‘', 'Vs'), ('‘', 'Vs', '’'), ('Vs', '’', 'focused'), ('’', 'focused', 'size'), ('focused', 'size', 'data'), ('size', 'data', 'ignoring'), ('data', 'ignoring', 'dimensions'), ('ignoring', 'dimensions', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('defined', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('term', 'NN'), ('three', 'CD'), ('‘', 'NNP'), ('Vs', 'NNP'), ('’', 'NNP'), ('focused', 'VBD'), ('size', 'NN'), ('data', 'NNS'), ('ignoring', 'VBG'), ('dimensions', 'NNS'), ('.', '.')]

 (S
  They/PRP
  defined/VBD
  (NP big/JJ data/NNS term/NN)
  three/CD
  (NP ‘/NNP Vs/NNP ’/NNP)
  focused/VBD
  (NP size/NN data/NNS)
  ignoring/VBG
  (NP dimensions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data term', '‘ Vs ’', 'size data', 'dimensions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('term', 'term'), ('three', 'three'), ('‘', '‘'), ('Vs', 'vs'), ('’', '’'), ('focused', 'focus'), ('size', 'size'), ('data', 'data'), ('ignoring', 'ignor'), ('dimensions', 'dimens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('defined', 'defin'), ('big', 'big'), ('data', 'data'), ('term', 'term'), ('three', 'three'), ('‘', '‘'), ('Vs', 'vs'), ('’', '’'), ('focused', 'focus'), ('size', 'size'), ('data', 'data'), ('ignoring', 'ignor'), ('dimensions', 'dimens'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('defined', 'defined'), ('big', 'big'), ('data', 'data'), ('term', 'term'), ('three', 'three'), ('‘', '‘'), ('Vs', 'Vs'), ('’', '’'), ('focused', 'focused'), ('size', 'size'), ('data', 'data'), ('ignoring', 'ignoring'), ('dimensions', 'dimension'), ('.', '.')]



============================ Sentence 170 =============================

When taken from the user understanding viewpoints, these definitions show different angles of big   data used in research and business as in Gandomi and Haider (2015). 


>> Tokens are: 
 ['When', 'taken', 'user', 'understanding', 'viewpoints', ',', 'definitions', 'show', 'different', 'angles', 'big', 'data', 'used', 'research', 'business', 'Gandomi', 'Haider', '(', '2015', ')', '.']

>> Bigrams are: 
 [('When', 'taken'), ('taken', 'user'), ('user', 'understanding'), ('understanding', 'viewpoints'), ('viewpoints', ','), (',', 'definitions'), ('definitions', 'show'), ('show', 'different'), ('different', 'angles'), ('angles', 'big'), ('big', 'data'), ('data', 'used'), ('used', 'research'), ('research', 'business'), ('business', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', '('), ('(', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('When', 'taken', 'user'), ('taken', 'user', 'understanding'), ('user', 'understanding', 'viewpoints'), ('understanding', 'viewpoints', ','), ('viewpoints', ',', 'definitions'), (',', 'definitions', 'show'), ('definitions', 'show', 'different'), ('show', 'different', 'angles'), ('different', 'angles', 'big'), ('angles', 'big', 'data'), ('big', 'data', 'used'), ('data', 'used', 'research'), ('used', 'research', 'business'), ('research', 'business', 'Gandomi'), ('business', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', '('), ('Haider', '(', '2015'), ('(', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('taken', 'VBN'), ('user', 'RB'), ('understanding', 'JJ'), ('viewpoints', 'NNS'), (',', ','), ('definitions', 'NNS'), ('show', 'VBP'), ('different', 'JJ'), ('angles', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('used', 'VBN'), ('research', 'NN'), ('business', 'NN'), ('Gandomi', 'NNP'), ('Haider', 'NNP'), ('(', '('), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  When/WRB
  taken/VBN
  user/RB
  (NP understanding/JJ viewpoints/NNS)
  ,/,
  (NP definitions/NNS)
  show/VBP
  (NP different/JJ angles/NNS)
  (NP big/JJ data/NNS)
  used/VBN
  (NP research/NN business/NN Gandomi/NNP Haider/NNP)
  (/(
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['understanding viewpoints', 'definitions', 'different angles', 'big data', 'research business Gandomi Haider']

>> Named Entities are: 
 [('PERSON', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('taken', 'taken'), ('user', 'user'), ('understanding', 'understand'), ('viewpoints', 'viewpoint'), (',', ','), ('definitions', 'definit'), ('show', 'show'), ('different', 'differ'), ('angles', 'angl'), ('big', 'big'), ('data', 'data'), ('used', 'use'), ('research', 'research'), ('business', 'busi'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('taken', 'taken'), ('user', 'user'), ('understanding', 'understand'), ('viewpoints', 'viewpoint'), (',', ','), ('definitions', 'definit'), ('show', 'show'), ('different', 'differ'), ('angles', 'angl'), ('big', 'big'), ('data', 'data'), ('used', 'use'), ('research', 'research'), ('business', 'busi'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('taken', 'taken'), ('user', 'user'), ('understanding', 'understanding'), ('viewpoints', 'viewpoint'), (',', ','), ('definitions', 'definition'), ('show', 'show'), ('different', 'different'), ('angles', 'angle'), ('big', 'big'), ('data', 'data'), ('used', 'used'), ('research', 'research'), ('business', 'business'), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), ('(', '('), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 171 =============================

The characteristics in terms   of volume, variety, and velocity are the focus in some of them, whilst the function and   requirements are the focus points in others such as the business requirements and how the data is   stored. 


>> Tokens are: 
 ['The', 'characteristics', 'terms', 'volume', ',', 'variety', ',', 'velocity', 'focus', ',', 'whilst', 'function', 'requirements', 'focus', 'points', 'others', 'business', 'requirements', 'data', 'stored', '.']

>> Bigrams are: 
 [('The', 'characteristics'), ('characteristics', 'terms'), ('terms', 'volume'), ('volume', ','), (',', 'variety'), ('variety', ','), (',', 'velocity'), ('velocity', 'focus'), ('focus', ','), (',', 'whilst'), ('whilst', 'function'), ('function', 'requirements'), ('requirements', 'focus'), ('focus', 'points'), ('points', 'others'), ('others', 'business'), ('business', 'requirements'), ('requirements', 'data'), ('data', 'stored'), ('stored', '.')]

>> Trigrams are: 
 [('The', 'characteristics', 'terms'), ('characteristics', 'terms', 'volume'), ('terms', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'velocity'), (',', 'velocity', 'focus'), ('velocity', 'focus', ','), ('focus', ',', 'whilst'), (',', 'whilst', 'function'), ('whilst', 'function', 'requirements'), ('function', 'requirements', 'focus'), ('requirements', 'focus', 'points'), ('focus', 'points', 'others'), ('points', 'others', 'business'), ('others', 'business', 'requirements'), ('business', 'requirements', 'data'), ('requirements', 'data', 'stored'), ('data', 'stored', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('characteristics', 'NNS'), ('terms', 'NNS'), ('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('velocity', 'NN'), ('focus', 'NN'), (',', ','), ('whilst', 'NN'), ('function', 'NN'), ('requirements', 'NNS'), ('focus', 'VBP'), ('points', 'NNS'), ('others', 'NNS'), ('business', 'NN'), ('requirements', 'NNS'), ('data', 'NNS'), ('stored', 'VBD'), ('.', '.')]

 (S
  (NP The/DT characteristics/NNS terms/NNS volume/NN)
  ,/,
  (NP variety/NN)
  ,/,
  (NP velocity/NN focus/NN)
  ,/,
  (NP whilst/NN function/NN requirements/NNS)
  focus/VBP
  (NP points/NNS others/NNS business/NN requirements/NNS data/NNS)
  stored/VBD
  ./.) 


>> Noun Phrases are: 
 ['The characteristics terms volume', 'variety', 'velocity focus', 'whilst function requirements', 'points others business requirements data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('characteristics', 'characterist'), ('terms', 'term'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), ('focus', 'focu'), (',', ','), ('whilst', 'whilst'), ('function', 'function'), ('requirements', 'requir'), ('focus', 'focu'), ('points', 'point'), ('others', 'other'), ('business', 'busi'), ('requirements', 'requir'), ('data', 'data'), ('stored', 'store'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('characteristics', 'characterist'), ('terms', 'term'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), ('focus', 'focus'), (',', ','), ('whilst', 'whilst'), ('function', 'function'), ('requirements', 'requir'), ('focus', 'focus'), ('points', 'point'), ('others', 'other'), ('business', 'busi'), ('requirements', 'requir'), ('data', 'data'), ('stored', 'store'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('characteristics', 'characteristic'), ('terms', 'term'), ('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('velocity', 'velocity'), ('focus', 'focus'), (',', ','), ('whilst', 'whilst'), ('function', 'function'), ('requirements', 'requirement'), ('focus', 'focus'), ('points', 'point'), ('others', 'others'), ('business', 'business'), ('requirements', 'requirement'), ('data', 'data'), ('stored', 'stored'), ('.', '.')]



============================ Sentence 172 =============================

However, the definition adopted in this work is the one that contains all the dimensions (i.e.- the   5Vs). 


>> Tokens are: 
 ['However', ',', 'definition', 'adopted', 'work', 'one', 'contains', 'dimensions', '(', 'i.e.-', '5Vs', ')', '.']

>> Bigrams are: 
 [('However', ','), (',', 'definition'), ('definition', 'adopted'), ('adopted', 'work'), ('work', 'one'), ('one', 'contains'), ('contains', 'dimensions'), ('dimensions', '('), ('(', 'i.e.-'), ('i.e.-', '5Vs'), ('5Vs', ')'), (')', '.')]

>> Trigrams are: 
 [('However', ',', 'definition'), (',', 'definition', 'adopted'), ('definition', 'adopted', 'work'), ('adopted', 'work', 'one'), ('work', 'one', 'contains'), ('one', 'contains', 'dimensions'), ('contains', 'dimensions', '('), ('dimensions', '(', 'i.e.-'), ('(', 'i.e.-', '5Vs'), ('i.e.-', '5Vs', ')'), ('5Vs', ')', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('definition', 'NN'), ('adopted', 'VBD'), ('work', 'NN'), ('one', 'CD'), ('contains', 'VBZ'), ('dimensions', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), ('5Vs', 'CD'), (')', ')'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP definition/NN)
  adopted/VBD
  (NP work/NN)
  one/CD
  contains/VBZ
  (NP dimensions/NNS)
  (/(
  i.e.-/JJ
  5Vs/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['definition', 'work', 'dimensions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('definition', 'definit'), ('adopted', 'adopt'), ('work', 'work'), ('one', 'one'), ('contains', 'contain'), ('dimensions', 'dimens'), ('(', '('), ('i.e.-', 'i.e.-'), ('5Vs', '5v'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('definition', 'definit'), ('adopted', 'adopt'), ('work', 'work'), ('one', 'one'), ('contains', 'contain'), ('dimensions', 'dimens'), ('(', '('), ('i.e.-', 'i.e.-'), ('5Vs', '5vs'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('definition', 'definition'), ('adopted', 'adopted'), ('work', 'work'), ('one', 'one'), ('contains', 'contains'), ('dimensions', 'dimension'), ('(', '('), ('i.e.-', 'i.e.-'), ('5Vs', '5Vs'), (')', ')'), ('.', '.')]



============================ Sentence 173 =============================

This is because it is regarded as being of very high density, timeliness, and different   structure, format, and sources, which requires high performing processing. 


>> Tokens are: 
 ['This', 'regarded', 'high', 'density', ',', 'timeliness', ',', 'different', 'structure', ',', 'format', ',', 'sources', ',', 'requires', 'high', 'performing', 'processing', '.']

>> Bigrams are: 
 [('This', 'regarded'), ('regarded', 'high'), ('high', 'density'), ('density', ','), (',', 'timeliness'), ('timeliness', ','), (',', 'different'), ('different', 'structure'), ('structure', ','), (',', 'format'), ('format', ','), (',', 'sources'), ('sources', ','), (',', 'requires'), ('requires', 'high'), ('high', 'performing'), ('performing', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('This', 'regarded', 'high'), ('regarded', 'high', 'density'), ('high', 'density', ','), ('density', ',', 'timeliness'), (',', 'timeliness', ','), ('timeliness', ',', 'different'), (',', 'different', 'structure'), ('different', 'structure', ','), ('structure', ',', 'format'), (',', 'format', ','), ('format', ',', 'sources'), (',', 'sources', ','), ('sources', ',', 'requires'), (',', 'requires', 'high'), ('requires', 'high', 'performing'), ('high', 'performing', 'processing'), ('performing', 'processing', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('regarded', 'VBD'), ('high', 'JJ'), ('density', 'NN'), (',', ','), ('timeliness', 'NN'), (',', ','), ('different', 'JJ'), ('structure', 'NN'), (',', ','), ('format', 'NN'), (',', ','), ('sources', 'NNS'), (',', ','), ('requires', 'VBZ'), ('high', 'JJ'), ('performing', 'VBG'), ('processing', 'NN'), ('.', '.')]

 (S
  This/DT
  regarded/VBD
  (NP high/JJ density/NN)
  ,/,
  (NP timeliness/NN)
  ,/,
  (NP different/JJ structure/NN)
  ,/,
  (NP format/NN)
  ,/,
  (NP sources/NNS)
  ,/,
  requires/VBZ
  high/JJ
  performing/VBG
  (NP processing/NN)
  ./.) 


>> Noun Phrases are: 
 ['high density', 'timeliness', 'different structure', 'format', 'sources', 'processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('regarded', 'regard'), ('high', 'high'), ('density', 'densiti'), (',', ','), ('timeliness', 'timeli'), (',', ','), ('different', 'differ'), ('structure', 'structur'), (',', ','), ('format', 'format'), (',', ','), ('sources', 'sourc'), (',', ','), ('requires', 'requir'), ('high', 'high'), ('performing', 'perform'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('regarded', 'regard'), ('high', 'high'), ('density', 'densiti'), (',', ','), ('timeliness', 'timeli'), (',', ','), ('different', 'differ'), ('structure', 'structur'), (',', ','), ('format', 'format'), (',', ','), ('sources', 'sourc'), (',', ','), ('requires', 'requir'), ('high', 'high'), ('performing', 'perform'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('regarded', 'regarded'), ('high', 'high'), ('density', 'density'), (',', ','), ('timeliness', 'timeliness'), (',', ','), ('different', 'different'), ('structure', 'structure'), (',', ','), ('format', 'format'), (',', ','), ('sources', 'source'), (',', ','), ('requires', 'requires'), ('high', 'high'), ('performing', 'performing'), ('processing', 'processing'), ('.', '.')]



============================ Sentence 174 =============================

Sarah Al-Shiakhli   15      6. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '15', '6', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '15'), ('15', '6'), ('6', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '15'), ('Al-Shiakhli', '15', '6'), ('15', '6', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('15', 'CD'), ('6', 'CD'), ('.', '.')]

 (S (NP Sarah/NNP Al-Shiakhli/NNP) 15/CD 6/CD ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('15', '15'), ('6', '6'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('15', '15'), ('6', '6'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('15', '15'), ('6', '6'), ('.', '.')]



============================ Sentence 175 =============================

Big data characteristics    Based on the various big data definitions, it is obvious that the size is the dominating characteristic   despite other characteristics’ importance. 


>> Tokens are: 
 ['Big', 'data', 'characteristics', 'Based', 'various', 'big', 'data', 'definitions', ',', 'obvious', 'size', 'dominating', 'characteristic', 'despite', 'characteristics', '’', 'importance', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'characteristics'), ('characteristics', 'Based'), ('Based', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', ','), (',', 'obvious'), ('obvious', 'size'), ('size', 'dominating'), ('dominating', 'characteristic'), ('characteristic', 'despite'), ('despite', 'characteristics'), ('characteristics', '’'), ('’', 'importance'), ('importance', '.')]

>> Trigrams are: 
 [('Big', 'data', 'characteristics'), ('data', 'characteristics', 'Based'), ('characteristics', 'Based', 'various'), ('Based', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', ','), ('definitions', ',', 'obvious'), (',', 'obvious', 'size'), ('obvious', 'size', 'dominating'), ('size', 'dominating', 'characteristic'), ('dominating', 'characteristic', 'despite'), ('characteristic', 'despite', 'characteristics'), ('despite', 'characteristics', '’'), ('characteristics', '’', 'importance'), ('’', 'importance', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('characteristics', 'NNS'), ('Based', 'VBD'), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), (',', ','), ('obvious', 'JJ'), ('size', 'NN'), ('dominating', 'VBG'), ('characteristic', 'JJ'), ('despite', 'IN'), ('characteristics', 'NNS'), ('’', 'JJ'), ('importance', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS characteristics/NNS)
  Based/VBD
  (NP various/JJ big/JJ data/NNS definitions/NNS)
  ,/,
  (NP obvious/JJ size/NN)
  dominating/VBG
  characteristic/JJ
  despite/IN
  (NP characteristics/NNS)
  (NP ’/JJ importance/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data characteristics', 'various big data definitions', 'obvious size', 'characteristics', '’ importance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('Based', 'base'), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('obvious', 'obviou'), ('size', 'size'), ('dominating', 'domin'), ('characteristic', 'characterist'), ('despite', 'despit'), ('characteristics', 'characterist'), ('’', '’'), ('importance', 'import'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('Based', 'base'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), (',', ','), ('obvious', 'obvious'), ('size', 'size'), ('dominating', 'domin'), ('characteristic', 'characterist'), ('despite', 'despit'), ('characteristics', 'characterist'), ('’', '’'), ('importance', 'import'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('characteristics', 'characteristic'), ('Based', 'Based'), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), (',', ','), ('obvious', 'obvious'), ('size', 'size'), ('dominating', 'dominating'), ('characteristic', 'characteristic'), ('despite', 'despite'), ('characteristics', 'characteristic'), ('’', '’'), ('importance', 'importance'), ('.', '.')]



============================ Sentence 176 =============================

Laney (2001) proposed the three V’s as the dimensions   of challenge to data management, and the three V's constitute a common framework (Laney, 2001;   Chen et al., 2012). 


>> Tokens are: 
 ['Laney', '(', '2001', ')', 'proposed', 'three', 'V', '’', 'dimensions', 'challenge', 'data', 'management', ',', 'three', 'V', "'s", 'constitute', 'common', 'framework', '(', 'Laney', ',', '2001', ';', 'Chen', 'et', 'al.', ',', '2012', ')', '.']

>> Bigrams are: 
 [('Laney', '('), ('(', '2001'), ('2001', ')'), (')', 'proposed'), ('proposed', 'three'), ('three', 'V'), ('V', '’'), ('’', 'dimensions'), ('dimensions', 'challenge'), ('challenge', 'data'), ('data', 'management'), ('management', ','), (',', 'three'), ('three', 'V'), ('V', "'s"), ("'s", 'constitute'), ('constitute', 'common'), ('common', 'framework'), ('framework', '('), ('(', 'Laney'), ('Laney', ','), (',', '2001'), ('2001', ';'), (';', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Laney', '(', '2001'), ('(', '2001', ')'), ('2001', ')', 'proposed'), (')', 'proposed', 'three'), ('proposed', 'three', 'V'), ('three', 'V', '’'), ('V', '’', 'dimensions'), ('’', 'dimensions', 'challenge'), ('dimensions', 'challenge', 'data'), ('challenge', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'three'), (',', 'three', 'V'), ('three', 'V', "'s"), ('V', "'s", 'constitute'), ("'s", 'constitute', 'common'), ('constitute', 'common', 'framework'), ('common', 'framework', '('), ('framework', '(', 'Laney'), ('(', 'Laney', ','), ('Laney', ',', '2001'), (',', '2001', ';'), ('2001', ';', 'Chen'), (';', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Laney', 'NNP'), ('(', '('), ('2001', 'CD'), (')', ')'), ('proposed', 'VBD'), ('three', 'CD'), ('V', 'NNP'), ('’', 'NNP'), ('dimensions', 'NNS'), ('challenge', 'VBP'), ('data', 'NNS'), ('management', 'NN'), (',', ','), ('three', 'CD'), ('V', 'NNP'), ("'s", 'POS'), ('constitute', 'NN'), ('common', 'JJ'), ('framework', 'NN'), ('(', '('), ('Laney', 'NNP'), (',', ','), ('2001', 'CD'), (';', ':'), ('Chen', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2012', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Laney/NNP)
  (/(
  2001/CD
  )/)
  proposed/VBD
  three/CD
  (NP V/NNP ’/NNP dimensions/NNS)
  challenge/VBP
  (NP data/NNS management/NN)
  ,/,
  three/CD
  (NP V/NNP)
  's/POS
  (NP constitute/NN)
  (NP common/JJ framework/NN)
  (/(
  (NP Laney/NNP)
  ,/,
  2001/CD
  ;/:
  (NP Chen/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2012/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Laney', 'V ’ dimensions', 'data management', 'V', 'constitute', 'common framework', 'Laney', 'Chen', 'al.']

>> Named Entities are: 
 [('GPE', 'Laney'), ('PERSON', 'Laney'), ('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('proposed', 'propos'), ('three', 'three'), ('V', 'v'), ('’', '’'), ('dimensions', 'dimens'), ('challenge', 'challeng'), ('data', 'data'), ('management', 'manag'), (',', ','), ('three', 'three'), ('V', 'v'), ("'s", "'s"), ('constitute', 'constitut'), ('common', 'common'), ('framework', 'framework'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (';', ';'), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Laney', 'laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('proposed', 'propos'), ('three', 'three'), ('V', 'v'), ('’', '’'), ('dimensions', 'dimens'), ('challenge', 'challeng'), ('data', 'data'), ('management', 'manag'), (',', ','), ('three', 'three'), ('V', 'v'), ("'s", "'s"), ('constitute', 'constitut'), ('common', 'common'), ('framework', 'framework'), ('(', '('), ('Laney', 'laney'), (',', ','), ('2001', '2001'), (';', ';'), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Laney', 'Laney'), ('(', '('), ('2001', '2001'), (')', ')'), ('proposed', 'proposed'), ('three', 'three'), ('V', 'V'), ('’', '’'), ('dimensions', 'dimension'), ('challenge', 'challenge'), ('data', 'data'), ('management', 'management'), (',', ','), ('three', 'three'), ('V', 'V'), ("'s", "'s"), ('constitute', 'constitute'), ('common', 'common'), ('framework', 'framework'), ('(', '('), ('Laney', 'Laney'), (',', ','), ('2001', '2001'), (';', ';'), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]



============================ Sentence 177 =============================

These three dimensions are not independent of each other; if one-dimension   changes, the probability of changing another dimension also increases (Gandomi and Haider,   2015). 


>> Tokens are: 
 ['These', 'three', 'dimensions', 'independent', ';', 'one-dimension', 'changes', ',', 'probability', 'changing', 'another', 'dimension', 'also', 'increases', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('These', 'three'), ('three', 'dimensions'), ('dimensions', 'independent'), ('independent', ';'), (';', 'one-dimension'), ('one-dimension', 'changes'), ('changes', ','), (',', 'probability'), ('probability', 'changing'), ('changing', 'another'), ('another', 'dimension'), ('dimension', 'also'), ('also', 'increases'), ('increases', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('These', 'three', 'dimensions'), ('three', 'dimensions', 'independent'), ('dimensions', 'independent', ';'), ('independent', ';', 'one-dimension'), (';', 'one-dimension', 'changes'), ('one-dimension', 'changes', ','), ('changes', ',', 'probability'), (',', 'probability', 'changing'), ('probability', 'changing', 'another'), ('changing', 'another', 'dimension'), ('another', 'dimension', 'also'), ('dimension', 'also', 'increases'), ('also', 'increases', '('), ('increases', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('three', 'CD'), ('dimensions', 'NNS'), ('independent', 'JJ'), (';', ':'), ('one-dimension', 'JJ'), ('changes', 'NNS'), (',', ','), ('probability', 'NN'), ('changing', 'VBG'), ('another', 'DT'), ('dimension', 'NN'), ('also', 'RB'), ('increases', 'VBZ'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  These/DT
  three/CD
  (NP dimensions/NNS)
  independent/JJ
  ;/:
  (NP one-dimension/JJ changes/NNS)
  ,/,
  (NP probability/NN)
  changing/VBG
  (NP another/DT dimension/NN)
  also/RB
  increases/VBZ
  (/(
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['dimensions', 'one-dimension changes', 'probability', 'another dimension', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('three', 'three'), ('dimensions', 'dimens'), ('independent', 'independ'), (';', ';'), ('one-dimension', 'one-dimens'), ('changes', 'chang'), (',', ','), ('probability', 'probabl'), ('changing', 'chang'), ('another', 'anoth'), ('dimension', 'dimens'), ('also', 'also'), ('increases', 'increas'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('three', 'three'), ('dimensions', 'dimens'), ('independent', 'independ'), (';', ';'), ('one-dimension', 'one-dimens'), ('changes', 'chang'), (',', ','), ('probability', 'probabl'), ('changing', 'chang'), ('another', 'anoth'), ('dimension', 'dimens'), ('also', 'also'), ('increases', 'increas'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('three', 'three'), ('dimensions', 'dimension'), ('independent', 'independent'), (';', ';'), ('one-dimension', 'one-dimension'), ('changes', 'change'), (',', ','), ('probability', 'probability'), ('changing', 'changing'), ('another', 'another'), ('dimension', 'dimension'), ('also', 'also'), ('increases', 'increase'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 178 =============================

A further two dimensions are often added to the big data characteristics, veracity and variability   (Gandomi, A. and Haider, M., 2015) as shown in Figure 10. 


>> Tokens are: 
 ['A', 'two', 'dimensions', 'often', 'added', 'big', 'data', 'characteristics', ',', 'veracity', 'variability', '(', 'Gandomi', ',', 'A.', 'Haider', ',', 'M.', ',', '2015', ')', 'shown', 'Figure', '10', '.']

>> Bigrams are: 
 [('A', 'two'), ('two', 'dimensions'), ('dimensions', 'often'), ('often', 'added'), ('added', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', ','), (',', 'veracity'), ('veracity', 'variability'), ('variability', '('), ('(', 'Gandomi'), ('Gandomi', ','), (',', 'A.'), ('A.', 'Haider'), ('Haider', ','), (',', 'M.'), ('M.', ','), (',', '2015'), ('2015', ')'), (')', 'shown'), ('shown', 'Figure'), ('Figure', '10'), ('10', '.')]

>> Trigrams are: 
 [('A', 'two', 'dimensions'), ('two', 'dimensions', 'often'), ('dimensions', 'often', 'added'), ('often', 'added', 'big'), ('added', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', ','), ('characteristics', ',', 'veracity'), (',', 'veracity', 'variability'), ('veracity', 'variability', '('), ('variability', '(', 'Gandomi'), ('(', 'Gandomi', ','), ('Gandomi', ',', 'A.'), (',', 'A.', 'Haider'), ('A.', 'Haider', ','), ('Haider', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2015'), (',', '2015', ')'), ('2015', ')', 'shown'), (')', 'shown', 'Figure'), ('shown', 'Figure', '10'), ('Figure', '10', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('two', 'CD'), ('dimensions', 'NNS'), ('often', 'RB'), ('added', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), (',', ','), ('veracity', 'NN'), ('variability', 'NN'), ('(', '('), ('Gandomi', 'NNP'), (',', ','), ('A.', 'NNP'), ('Haider', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('shown', 'VBN'), ('Figure', 'NNP'), ('10', 'CD'), ('.', '.')]

 (S
  A/DT
  two/CD
  (NP dimensions/NNS)
  often/RB
  added/VBD
  (NP big/JJ data/NNS characteristics/NNS)
  ,/,
  (NP veracity/NN variability/NN)
  (/(
  (NP Gandomi/NNP)
  ,/,
  (NP A./NNP Haider/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2015/CD
  )/)
  shown/VBN
  (NP Figure/NNP)
  10/CD
  ./.) 


>> Noun Phrases are: 
 ['dimensions', 'big data characteristics', 'veracity variability', 'Gandomi', 'A. Haider', 'M.', 'Figure']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('two', 'two'), ('dimensions', 'dimens'), ('often', 'often'), ('added', 'ad'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('veracity', 'verac'), ('variability', 'variabl'), ('(', '('), ('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), (')', ')'), ('shown', 'shown'), ('Figure', 'figur'), ('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('two', 'two'), ('dimensions', 'dimens'), ('often', 'often'), ('added', 'ad'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('veracity', 'verac'), ('variability', 'variabl'), ('(', '('), ('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), (')', ')'), ('shown', 'shown'), ('Figure', 'figur'), ('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('two', 'two'), ('dimensions', 'dimension'), ('often', 'often'), ('added', 'added'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), (',', ','), ('veracity', 'veracity'), ('variability', 'variability'), ('(', '('), ('Gandomi', 'Gandomi'), (',', ','), ('A.', 'A.'), ('Haider', 'Haider'), (',', ','), ('M.', 'M.'), (',', ','), ('2015', '2015'), (')', ')'), ('shown', 'shown'), ('Figure', 'Figure'), ('10', '10'), ('.', '.')]



============================ Sentence 179 =============================

The five V's reflect the growing   popularity of big data. 


>> Tokens are: 
 ['The', 'five', 'V', "'s", 'reflect', 'growing', 'popularity', 'big', 'data', '.']

>> Bigrams are: 
 [('The', 'five'), ('five', 'V'), ('V', "'s"), ("'s", 'reflect'), ('reflect', 'growing'), ('growing', 'popularity'), ('popularity', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'five', 'V'), ('five', 'V', "'s"), ('V', "'s", 'reflect'), ("'s", 'reflect', 'growing'), ('reflect', 'growing', 'popularity'), ('growing', 'popularity', 'big'), ('popularity', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('five', 'CD'), ('V', 'NNP'), ("'s", 'POS'), ('reflect', 'NN'), ('growing', 'VBG'), ('popularity', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  The/DT
  five/CD
  (NP V/NNP)
  's/POS
  (NP reflect/NN)
  growing/VBG
  (NP popularity/NN)
  (NP big/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['V', 'reflect', 'popularity', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('five', 'five'), ('V', 'v'), ("'s", "'s"), ('reflect', 'reflect'), ('growing', 'grow'), ('popularity', 'popular'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('five', 'five'), ('V', 'v'), ("'s", "'s"), ('reflect', 'reflect'), ('growing', 'grow'), ('popularity', 'popular'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('five', 'five'), ('V', 'V'), ("'s", "'s"), ('reflect', 'reflect'), ('growing', 'growing'), ('popularity', 'popularity'), ('big', 'big'), ('data', 'data'), ('.', '.')]



============================ Sentence 180 =============================

The first V is, as always, volume, which is related to the amount of generated   data (Grover and Kar, 2017). 


>> Tokens are: 
 ['The', 'first', 'V', ',', 'always', ',', 'volume', ',', 'related', 'amount', 'generated', 'data', '(', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('The', 'first'), ('first', 'V'), ('V', ','), (',', 'always'), ('always', ','), (',', 'volume'), ('volume', ','), (',', 'related'), ('related', 'amount'), ('amount', 'generated'), ('generated', 'data'), ('data', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'first', 'V'), ('first', 'V', ','), ('V', ',', 'always'), (',', 'always', ','), ('always', ',', 'volume'), (',', 'volume', ','), ('volume', ',', 'related'), (',', 'related', 'amount'), ('related', 'amount', 'generated'), ('amount', 'generated', 'data'), ('generated', 'data', '('), ('data', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('first', 'JJ'), ('V', 'NNP'), (',', ','), ('always', 'RB'), (',', ','), ('volume', 'NN'), (',', ','), ('related', 'JJ'), ('amount', 'NN'), ('generated', 'VBN'), ('data', 'NNS'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT first/JJ V/NNP)
  ,/,
  always/RB
  ,/,
  (NP volume/NN)
  ,/,
  (NP related/JJ amount/NN)
  generated/VBN
  (NP data/NNS)
  (/(
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The first V', 'volume', 'related amount', 'data', 'Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('first', 'first'), ('V', 'v'), (',', ','), ('always', 'alway'), (',', ','), ('volume', 'volum'), (',', ','), ('related', 'relat'), ('amount', 'amount'), ('generated', 'gener'), ('data', 'data'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('first', 'first'), ('V', 'v'), (',', ','), ('always', 'alway'), (',', ','), ('volume', 'volum'), (',', ','), ('related', 'relat'), ('amount', 'amount'), ('generated', 'generat'), ('data', 'data'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('first', 'first'), ('V', 'V'), (',', ','), ('always', 'always'), (',', ','), ('volume', 'volume'), (',', ','), ('related', 'related'), ('amount', 'amount'), ('generated', 'generated'), ('data', 'data'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 181 =============================

The second V is for the velocity (big data timeliness), as all data   collection and analysis should be conducted in a timely manner (Chen, M., Mao, S. and Liu, Y.,   2014). 


>> Tokens are: 
 ['The', 'second', 'V', 'velocity', '(', 'big', 'data', 'timeliness', ')', ',', 'data', 'collection', 'analysis', 'conducted', 'timely', 'manner', '(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('The', 'second'), ('second', 'V'), ('V', 'velocity'), ('velocity', '('), ('(', 'big'), ('big', 'data'), ('data', 'timeliness'), ('timeliness', ')'), (')', ','), (',', 'data'), ('data', 'collection'), ('collection', 'analysis'), ('analysis', 'conducted'), ('conducted', 'timely'), ('timely', 'manner'), ('manner', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'second', 'V'), ('second', 'V', 'velocity'), ('V', 'velocity', '('), ('velocity', '(', 'big'), ('(', 'big', 'data'), ('big', 'data', 'timeliness'), ('data', 'timeliness', ')'), ('timeliness', ')', ','), (')', ',', 'data'), (',', 'data', 'collection'), ('data', 'collection', 'analysis'), ('collection', 'analysis', 'conducted'), ('analysis', 'conducted', 'timely'), ('conducted', 'timely', 'manner'), ('timely', 'manner', '('), ('manner', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('V', 'NNP'), ('velocity', 'NN'), ('(', '('), ('big', 'JJ'), ('data', 'NNS'), ('timeliness', 'NN'), (')', ')'), (',', ','), ('data', 'NNS'), ('collection', 'NN'), ('analysis', 'NN'), ('conducted', 'VBN'), ('timely', 'JJ'), ('manner', 'NN'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT second/JJ V/NNP velocity/NN)
  (/(
  (NP big/JJ data/NNS timeliness/NN)
  )/)
  ,/,
  (NP data/NNS collection/NN analysis/NN)
  conducted/VBN
  (NP timely/JJ manner/NN)
  (/(
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Mao/NNP)
  ,/,
  (NP S./NNP Liu/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The second V velocity', 'big data timeliness', 'data collection analysis', 'timely manner', 'Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('V', 'v'), ('velocity', 'veloc'), ('(', '('), ('big', 'big'), ('data', 'data'), ('timeliness', 'timeli'), (')', ')'), (',', ','), ('data', 'data'), ('collection', 'collect'), ('analysis', 'analysi'), ('conducted', 'conduct'), ('timely', 'time'), ('manner', 'manner'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('V', 'v'), ('velocity', 'veloc'), ('(', '('), ('big', 'big'), ('data', 'data'), ('timeliness', 'timeli'), (')', ')'), (',', ','), ('data', 'data'), ('collection', 'collect'), ('analysis', 'analysi'), ('conducted', 'conduct'), ('timely', 'time'), ('manner', 'manner'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('V', 'V'), ('velocity', 'velocity'), ('(', '('), ('big', 'big'), ('data', 'data'), ('timeliness', 'timeliness'), (')', ')'), (',', ','), ('data', 'data'), ('collection', 'collection'), ('analysis', 'analysis'), ('conducted', 'conducted'), ('timely', 'timely'), ('manner', 'manner'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 182 =============================

The third V refers to variety, as big data comes in many different formats and structures   such as ERP data, emails and tweets, or audio and video (Russom, 2011; Elragal, 2014; Watson,   2014; Watson, 2019). 


>> Tokens are: 
 ['The', 'third', 'V', 'refers', 'variety', ',', 'big', 'data', 'comes', 'many', 'different', 'formats', 'structures', 'ERP', 'data', ',', 'emails', 'tweets', ',', 'audio', 'video', '(', 'Russom', ',', '2011', ';', 'Elragal', ',', '2014', ';', 'Watson', ',', '2014', ';', 'Watson', ',', '2019', ')', '.']

>> Bigrams are: 
 [('The', 'third'), ('third', 'V'), ('V', 'refers'), ('refers', 'variety'), ('variety', ','), (',', 'big'), ('big', 'data'), ('data', 'comes'), ('comes', 'many'), ('many', 'different'), ('different', 'formats'), ('formats', 'structures'), ('structures', 'ERP'), ('ERP', 'data'), ('data', ','), (',', 'emails'), ('emails', 'tweets'), ('tweets', ','), (',', 'audio'), ('audio', 'video'), ('video', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Watson'), ('Watson', ','), (',', '2014'), ('2014', ';'), (';', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'third', 'V'), ('third', 'V', 'refers'), ('V', 'refers', 'variety'), ('refers', 'variety', ','), ('variety', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'comes'), ('data', 'comes', 'many'), ('comes', 'many', 'different'), ('many', 'different', 'formats'), ('different', 'formats', 'structures'), ('formats', 'structures', 'ERP'), ('structures', 'ERP', 'data'), ('ERP', 'data', ','), ('data', ',', 'emails'), (',', 'emails', 'tweets'), ('emails', 'tweets', ','), ('tweets', ',', 'audio'), (',', 'audio', 'video'), ('audio', 'video', '('), ('video', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elragal'), (';', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Watson'), (';', 'Watson', ','), ('Watson', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Watson'), (';', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('V', 'NNP'), ('refers', 'NNS'), ('variety', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('comes', 'VBZ'), ('many', 'JJ'), ('different', 'JJ'), ('formats', 'NNS'), ('structures', 'VBZ'), ('ERP', 'NNP'), ('data', 'NNS'), (',', ','), ('emails', 'JJ'), ('tweets', 'NNS'), (',', ','), ('audio', 'JJ'), ('video', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Watson', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT third/JJ V/NNP refers/NNS variety/NN)
  ,/,
  (NP big/JJ data/NNS)
  comes/VBZ
  (NP many/JJ different/JJ formats/NNS)
  structures/VBZ
  (NP ERP/NNP data/NNS)
  ,/,
  (NP emails/JJ tweets/NNS)
  ,/,
  (NP audio/JJ video/NN)
  (/(
  (NP Russom/NNP)
  ,/,
  2011/CD
  ;/:
  (NP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Watson/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The third V refers variety', 'big data', 'many different formats', 'ERP data', 'emails tweets', 'audio video', 'Russom', 'Elragal', 'Watson', 'Watson']

>> Named Entities are: 
 [('ORGANIZATION', 'ERP'), ('GPE', 'Russom'), ('GPE', 'Elragal'), ('PERSON', 'Watson'), ('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('V', 'v'), ('refers', 'refer'), ('variety', 'varieti'), (',', ','), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('formats', 'format'), ('structures', 'structur'), ('ERP', 'erp'), ('data', 'data'), (',', ','), ('emails', 'email'), ('tweets', 'tweet'), (',', ','), ('audio', 'audio'), ('video', 'video'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('V', 'v'), ('refers', 'refer'), ('variety', 'varieti'), (',', ','), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('formats', 'format'), ('structures', 'structur'), ('ERP', 'erp'), ('data', 'data'), (',', ','), ('emails', 'email'), ('tweets', 'tweet'), (',', ','), ('audio', 'audio'), ('video', 'video'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('V', 'V'), ('refers', 'refers'), ('variety', 'variety'), (',', ','), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'many'), ('different', 'different'), ('formats', 'format'), ('structures', 'structure'), ('ERP', 'ERP'), ('data', 'data'), (',', ','), ('emails', 'email'), ('tweets', 'tweet'), (',', ','), ('audio', 'audio'), ('video', 'video'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'Watson'), (',', ','), ('2014', '2014'), (';', ';'), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 183 =============================

The fourth V refers to big data’s “huge value but very low density”, causing   critical problems in terms of extracting value from datasets (Elragal, 2014; Chen et al., 2014;   Raghupathi and Raghupathi, 2014). 


>> Tokens are: 
 ['The', 'fourth', 'V', 'refers', 'big', 'data', '’', '“', 'huge', 'value', 'low', 'density', '”', ',', 'causing', 'critical', 'problems', 'terms', 'extracting', 'value', 'datasets', '(', 'Elragal', ',', '2014', ';', 'Chen', 'et', 'al.', ',', '2014', ';', 'Raghupathi', 'Raghupathi', ',', '2014', ')', '.']

>> Bigrams are: 
 [('The', 'fourth'), ('fourth', 'V'), ('V', 'refers'), ('refers', 'big'), ('big', 'data'), ('data', '’'), ('’', '“'), ('“', 'huge'), ('huge', 'value'), ('value', 'low'), ('low', 'density'), ('density', '”'), ('”', ','), (',', 'causing'), ('causing', 'critical'), ('critical', 'problems'), ('problems', 'terms'), ('terms', 'extracting'), ('extracting', 'value'), ('value', 'datasets'), ('datasets', '('), ('(', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), ('Raghupathi', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'fourth', 'V'), ('fourth', 'V', 'refers'), ('V', 'refers', 'big'), ('refers', 'big', 'data'), ('big', 'data', '’'), ('data', '’', '“'), ('’', '“', 'huge'), ('“', 'huge', 'value'), ('huge', 'value', 'low'), ('value', 'low', 'density'), ('low', 'density', '”'), ('density', '”', ','), ('”', ',', 'causing'), (',', 'causing', 'critical'), ('causing', 'critical', 'problems'), ('critical', 'problems', 'terms'), ('problems', 'terms', 'extracting'), ('terms', 'extracting', 'value'), ('extracting', 'value', 'datasets'), ('value', 'datasets', '('), ('datasets', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Chen'), (';', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Raghupathi'), (';', 'Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi', ','), ('Raghupathi', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('fourth', 'JJ'), ('V', 'NNP'), ('refers', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'VBZ'), ('“', 'NNP'), ('huge', 'JJ'), ('value', 'NN'), ('low', 'JJ'), ('density', 'NN'), ('”', 'NNP'), (',', ','), ('causing', 'VBG'), ('critical', 'JJ'), ('problems', 'NNS'), ('terms', 'NNS'), ('extracting', 'VBG'), ('value', 'NN'), ('datasets', 'NNS'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Chen', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT fourth/JJ V/NNP refers/NNS)
  (NP big/JJ data/NNS)
  ’/VBZ
  (NP “/NNP)
  (NP huge/JJ value/NN)
  (NP low/JJ density/NN ”/NNP)
  ,/,
  causing/VBG
  (NP critical/JJ problems/NNS terms/NNS)
  extracting/VBG
  (NP value/NN datasets/NNS)
  (/(
  (NP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Chen/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2014/CD
  ;/:
  (NP Raghupathi/NNP Raghupathi/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The fourth V refers', 'big data', '“', 'huge value', 'low density ”', 'critical problems terms', 'value datasets', 'Elragal', 'Chen', 'al.', 'Raghupathi Raghupathi']

>> Named Entities are: 
 [('ORGANIZATION', 'Elragal'), ('GPE', 'Chen'), ('PERSON', 'Raghupathi Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('fourth', 'fourth'), ('V', 'v'), ('refers', 'refer'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('“', '“'), ('huge', 'huge'), ('value', 'valu'), ('low', 'low'), ('density', 'densiti'), ('”', '”'), (',', ','), ('causing', 'caus'), ('critical', 'critic'), ('problems', 'problem'), ('terms', 'term'), ('extracting', 'extract'), ('value', 'valu'), ('datasets', 'dataset'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('fourth', 'fourth'), ('V', 'v'), ('refers', 'refer'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('“', '“'), ('huge', 'huge'), ('value', 'valu'), ('low', 'low'), ('density', 'densiti'), ('”', '”'), (',', ','), ('causing', 'caus'), ('critical', 'critic'), ('problems', 'problem'), ('terms', 'term'), ('extracting', 'extract'), ('value', 'valu'), ('datasets', 'dataset'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('fourth', 'fourth'), ('V', 'V'), ('refers', 'refers'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('“', '“'), ('huge', 'huge'), ('value', 'value'), ('low', 'low'), ('density', 'density'), ('”', '”'), (',', ','), ('causing', 'causing'), ('critical', 'critical'), ('problems', 'problem'), ('terms', 'term'), ('extracting', 'extracting'), ('value', 'value'), ('datasets', 'datasets'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 184 =============================

The fifth V references veracity, and questions big data   credibility where sources are external, as in most cases (Addo-Tenkorang and Helo, 2016; Grover   and Kar, 2017; Al-Barashdi and Al-Karousi, 2019 ). 


>> Tokens are: 
 ['The', 'fifth', 'V', 'references', 'veracity', ',', 'questions', 'big', 'data', 'credibility', 'sources', 'external', ',', 'cases', '(', 'Addo-Tenkorang', 'Helo', ',', '2016', ';', 'Grover', 'Kar', ',', '2017', ';', 'Al-Barashdi', 'Al-Karousi', ',', '2019', ')', '.']

>> Bigrams are: 
 [('The', 'fifth'), ('fifth', 'V'), ('V', 'references'), ('references', 'veracity'), ('veracity', ','), (',', 'questions'), ('questions', 'big'), ('big', 'data'), ('data', 'credibility'), ('credibility', 'sources'), ('sources', 'external'), ('external', ','), (',', 'cases'), ('cases', '('), ('(', 'Addo-Tenkorang'), ('Addo-Tenkorang', 'Helo'), ('Helo', ','), (',', '2016'), ('2016', ';'), (';', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ';'), (';', 'Al-Barashdi'), ('Al-Barashdi', 'Al-Karousi'), ('Al-Karousi', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'fifth', 'V'), ('fifth', 'V', 'references'), ('V', 'references', 'veracity'), ('references', 'veracity', ','), ('veracity', ',', 'questions'), (',', 'questions', 'big'), ('questions', 'big', 'data'), ('big', 'data', 'credibility'), ('data', 'credibility', 'sources'), ('credibility', 'sources', 'external'), ('sources', 'external', ','), ('external', ',', 'cases'), (',', 'cases', '('), ('cases', '(', 'Addo-Tenkorang'), ('(', 'Addo-Tenkorang', 'Helo'), ('Addo-Tenkorang', 'Helo', ','), ('Helo', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Grover'), (';', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Al-Barashdi'), (';', 'Al-Barashdi', 'Al-Karousi'), ('Al-Barashdi', 'Al-Karousi', ','), ('Al-Karousi', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('fifth', 'JJ'), ('V', 'NNP'), ('references', 'NNS'), ('veracity', 'NN'), (',', ','), ('questions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('credibility', 'NN'), ('sources', 'NNS'), ('external', 'JJ'), (',', ','), ('cases', 'NNS'), ('(', '('), ('Addo-Tenkorang', 'NNP'), ('Helo', 'NNP'), (',', ','), ('2016', 'CD'), (';', ':'), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (';', ':'), ('Al-Barashdi', 'JJ'), ('Al-Karousi', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT fifth/JJ V/NNP references/NNS veracity/NN)
  ,/,
  (NP questions/NNS)
  (NP big/JJ data/NNS credibility/NN sources/NNS)
  external/JJ
  ,/,
  (NP cases/NNS)
  (/(
  (NP Addo-Tenkorang/NNP Helo/NNP)
  ,/,
  2016/CD
  ;/:
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  ;/:
  (NP Al-Barashdi/JJ Al-Karousi/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The fifth V references veracity', 'questions', 'big data credibility sources', 'cases', 'Addo-Tenkorang Helo', 'Grover Kar', 'Al-Barashdi Al-Karousi']

>> Named Entities are: 
 [('PERSON', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('fifth', 'fifth'), ('V', 'v'), ('references', 'refer'), ('veracity', 'verac'), (',', ','), ('questions', 'question'), ('big', 'big'), ('data', 'data'), ('credibility', 'credibl'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('cases', 'case'), ('(', '('), ('Addo-Tenkorang', 'addo-tenkorang'), ('Helo', 'helo'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (';', ';'), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('fifth', 'fifth'), ('V', 'v'), ('references', 'refer'), ('veracity', 'verac'), (',', ','), ('questions', 'question'), ('big', 'big'), ('data', 'data'), ('credibility', 'credibl'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('cases', 'case'), ('(', '('), ('Addo-Tenkorang', 'addo-tenkorang'), ('Helo', 'helo'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (';', ';'), ('Al-Barashdi', 'al-barashdi'), ('Al-Karousi', 'al-karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('fifth', 'fifth'), ('V', 'V'), ('references', 'reference'), ('veracity', 'veracity'), (',', ','), ('questions', 'question'), ('big', 'big'), ('data', 'data'), ('credibility', 'credibility'), ('sources', 'source'), ('external', 'external'), (',', ','), ('cases', 'case'), ('(', '('), ('Addo-Tenkorang', 'Addo-Tenkorang'), ('Helo', 'Helo'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (';', ';'), ('Al-Barashdi', 'Al-Barashdi'), ('Al-Karousi', 'Al-Karousi'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 185 =============================

Veracity is related to credibility, the data   source’s accuracy, and how suitable the data is for the proposed of use (Elragal, A, 2014). 


>> Tokens are: 
 ['Veracity', 'related', 'credibility', ',', 'data', 'source', '’', 'accuracy', ',', 'suitable', 'data', 'proposed', 'use', '(', 'Elragal', ',', 'A', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Veracity', 'related'), ('related', 'credibility'), ('credibility', ','), (',', 'data'), ('data', 'source'), ('source', '’'), ('’', 'accuracy'), ('accuracy', ','), (',', 'suitable'), ('suitable', 'data'), ('data', 'proposed'), ('proposed', 'use'), ('use', '('), ('(', 'Elragal'), ('Elragal', ','), (',', 'A'), ('A', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Veracity', 'related', 'credibility'), ('related', 'credibility', ','), ('credibility', ',', 'data'), (',', 'data', 'source'), ('data', 'source', '’'), ('source', '’', 'accuracy'), ('’', 'accuracy', ','), ('accuracy', ',', 'suitable'), (',', 'suitable', 'data'), ('suitable', 'data', 'proposed'), ('data', 'proposed', 'use'), ('proposed', 'use', '('), ('use', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', 'A'), (',', 'A', ','), ('A', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Veracity', 'NNP'), ('related', 'JJ'), ('credibility', 'NN'), (',', ','), ('data', 'NNS'), ('source', 'NN'), ('’', 'NN'), ('accuracy', 'NN'), (',', ','), ('suitable', 'JJ'), ('data', 'NNS'), ('proposed', 'VBN'), ('use', 'NN'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('A', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Veracity/NNP)
  (NP related/JJ credibility/NN)
  ,/,
  (NP data/NNS source/NN ’/NN accuracy/NN)
  ,/,
  (NP suitable/JJ data/NNS)
  proposed/VBN
  (NP use/NN)
  (/(
  (NP Elragal/NNP)
  ,/,
  (NP A/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Veracity', 'related credibility', 'data source ’ accuracy', 'suitable data', 'use', 'Elragal', 'A']

>> Named Entities are: 
 [('GPE', 'Veracity'), ('ORGANIZATION', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Veracity', 'verac'), ('related', 'relat'), ('credibility', 'credibl'), (',', ','), ('data', 'data'), ('source', 'sourc'), ('’', '’'), ('accuracy', 'accuraci'), (',', ','), ('suitable', 'suitabl'), ('data', 'data'), ('proposed', 'propos'), ('use', 'use'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Veracity', 'verac'), ('related', 'relat'), ('credibility', 'credibl'), (',', ','), ('data', 'data'), ('source', 'sourc'), ('’', '’'), ('accuracy', 'accuraci'), (',', ','), ('suitable', 'suitabl'), ('data', 'data'), ('proposed', 'propos'), ('use', 'use'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Veracity', 'Veracity'), ('related', 'related'), ('credibility', 'credibility'), (',', ','), ('data', 'data'), ('source', 'source'), ('’', '’'), ('accuracy', 'accuracy'), (',', ','), ('suitable', 'suitable'), ('data', 'data'), ('proposed', 'proposed'), ('use', 'use'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('A', 'A'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 186 =============================

Using big data requires the correct technical architecture, analytics, and tools to enable insights to   emerge from hidden knowledge to generate value for business, and these depend on the data scale,   distribution, diversity, and velocity (Russom, 2011). 


>> Tokens are: 
 ['Using', 'big', 'data', 'requires', 'correct', 'technical', 'architecture', ',', 'analytics', ',', 'tools', 'enable', 'insights', 'emerge', 'hidden', 'knowledge', 'generate', 'value', 'business', ',', 'depend', 'data', 'scale', ',', 'distribution', ',', 'diversity', ',', 'velocity', '(', 'Russom', ',', '2011', ')', '.']

>> Bigrams are: 
 [('Using', 'big'), ('big', 'data'), ('data', 'requires'), ('requires', 'correct'), ('correct', 'technical'), ('technical', 'architecture'), ('architecture', ','), (',', 'analytics'), ('analytics', ','), (',', 'tools'), ('tools', 'enable'), ('enable', 'insights'), ('insights', 'emerge'), ('emerge', 'hidden'), ('hidden', 'knowledge'), ('knowledge', 'generate'), ('generate', 'value'), ('value', 'business'), ('business', ','), (',', 'depend'), ('depend', 'data'), ('data', 'scale'), ('scale', ','), (',', 'distribution'), ('distribution', ','), (',', 'diversity'), ('diversity', ','), (',', 'velocity'), ('velocity', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('Using', 'big', 'data'), ('big', 'data', 'requires'), ('data', 'requires', 'correct'), ('requires', 'correct', 'technical'), ('correct', 'technical', 'architecture'), ('technical', 'architecture', ','), ('architecture', ',', 'analytics'), (',', 'analytics', ','), ('analytics', ',', 'tools'), (',', 'tools', 'enable'), ('tools', 'enable', 'insights'), ('enable', 'insights', 'emerge'), ('insights', 'emerge', 'hidden'), ('emerge', 'hidden', 'knowledge'), ('hidden', 'knowledge', 'generate'), ('knowledge', 'generate', 'value'), ('generate', 'value', 'business'), ('value', 'business', ','), ('business', ',', 'depend'), (',', 'depend', 'data'), ('depend', 'data', 'scale'), ('data', 'scale', ','), ('scale', ',', 'distribution'), (',', 'distribution', ','), ('distribution', ',', 'diversity'), (',', 'diversity', ','), ('diversity', ',', 'velocity'), (',', 'velocity', '('), ('velocity', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('Using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('requires', 'VBZ'), ('correct', 'JJ'), ('technical', 'JJ'), ('architecture', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('tools', 'NNS'), ('enable', 'JJ'), ('insights', 'NNS'), ('emerge', 'VBP'), ('hidden', 'JJ'), ('knowledge', 'NN'), ('generate', 'NN'), ('value', 'NN'), ('business', 'NN'), (',', ','), ('depend', 'VBP'), ('data', 'NNS'), ('scale', 'NN'), (',', ','), ('distribution', 'NN'), (',', ','), ('diversity', 'NN'), (',', ','), ('velocity', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), ('.', '.')]

 (S
  Using/VBG
  (NP big/JJ data/NNS)
  requires/VBZ
  (NP correct/JJ technical/JJ architecture/NN)
  ,/,
  (NP analytics/NNS)
  ,/,
  (NP tools/NNS)
  (NP enable/JJ insights/NNS)
  emerge/VBP
  (NP hidden/JJ knowledge/NN generate/NN value/NN business/NN)
  ,/,
  depend/VBP
  (NP data/NNS scale/NN)
  ,/,
  (NP distribution/NN)
  ,/,
  (NP diversity/NN)
  ,/,
  (NP velocity/NN)
  (/(
  (NP Russom/NNP)
  ,/,
  2011/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'correct technical architecture', 'analytics', 'tools', 'enable insights', 'hidden knowledge generate value business', 'data scale', 'distribution', 'diversity', 'velocity', 'Russom']

>> Named Entities are: 
 [('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('big', 'big'), ('data', 'data'), ('requires', 'requir'), ('correct', 'correct'), ('technical', 'technic'), ('architecture', 'architectur'), (',', ','), ('analytics', 'analyt'), (',', ','), ('tools', 'tool'), ('enable', 'enabl'), ('insights', 'insight'), ('emerge', 'emerg'), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('generate', 'gener'), ('value', 'valu'), ('business', 'busi'), (',', ','), ('depend', 'depend'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('distribution', 'distribut'), (',', ','), ('diversity', 'divers'), (',', ','), ('velocity', 'veloc'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('big', 'big'), ('data', 'data'), ('requires', 'requir'), ('correct', 'correct'), ('technical', 'technic'), ('architecture', 'architectur'), (',', ','), ('analytics', 'analyt'), (',', ','), ('tools', 'tool'), ('enable', 'enabl'), ('insights', 'insight'), ('emerge', 'emerg'), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('generate', 'generat'), ('value', 'valu'), ('business', 'busi'), (',', ','), ('depend', 'depend'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('distribution', 'distribut'), (',', ','), ('diversity', 'divers'), (',', ','), ('velocity', 'veloc'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Using', 'Using'), ('big', 'big'), ('data', 'data'), ('requires', 'requires'), ('correct', 'correct'), ('technical', 'technical'), ('architecture', 'architecture'), (',', ','), ('analytics', 'analytics'), (',', ','), ('tools', 'tool'), ('enable', 'enable'), ('insights', 'insight'), ('emerge', 'emerge'), ('hidden', 'hidden'), ('knowledge', 'knowledge'), ('generate', 'generate'), ('value', 'value'), ('business', 'business'), (',', ','), ('depend', 'depend'), ('data', 'data'), ('scale', 'scale'), (',', ','), ('distribution', 'distribution'), (',', ','), ('diversity', 'diversity'), (',', ','), ('velocity', 'velocity'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]



============================ Sentence 187 =============================

Big data is most easily characterised by its   three main features, however: Data Volume (size), Velocity (data change rate) and Variety (data   formats and types as well the data analysis types required) (Elgendy and Elragal, 2014; Schelén,   Elragal, and Haddara, 2015; Chen and Guo, 2016; Elragal and Klischewski, 2017). 


>> Tokens are: 
 ['Big', 'data', 'easily', 'characterised', 'three', 'main', 'features', ',', 'however', ':', 'Data', 'Volume', '(', 'size', ')', ',', 'Velocity', '(', 'data', 'change', 'rate', ')', 'Variety', '(', 'data', 'formats', 'types', 'well', 'data', 'analysis', 'types', 'required', ')', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Schelén', ',', 'Elragal', ',', 'Haddara', ',', '2015', ';', 'Chen', 'Guo', ',', '2016', ';', 'Elragal', 'Klischewski', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'easily'), ('easily', 'characterised'), ('characterised', 'three'), ('three', 'main'), ('main', 'features'), ('features', ','), (',', 'however'), ('however', ':'), (':', 'Data'), ('Data', 'Volume'), ('Volume', '('), ('(', 'size'), ('size', ')'), (')', ','), (',', 'Velocity'), ('Velocity', '('), ('(', 'data'), ('data', 'change'), ('change', 'rate'), ('rate', ')'), (')', 'Variety'), ('Variety', '('), ('(', 'data'), ('data', 'formats'), ('formats', 'types'), ('types', 'well'), ('well', 'data'), ('data', 'analysis'), ('analysis', 'types'), ('types', 'required'), ('required', ')'), (')', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Schelén'), ('Schelén', ','), (',', 'Elragal'), ('Elragal', ','), (',', 'Haddara'), ('Haddara', ','), (',', '2015'), ('2015', ';'), (';', 'Chen'), ('Chen', 'Guo'), ('Guo', ','), (',', '2016'), ('2016', ';'), (';', 'Elragal'), ('Elragal', 'Klischewski'), ('Klischewski', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'easily'), ('data', 'easily', 'characterised'), ('easily', 'characterised', 'three'), ('characterised', 'three', 'main'), ('three', 'main', 'features'), ('main', 'features', ','), ('features', ',', 'however'), (',', 'however', ':'), ('however', ':', 'Data'), (':', 'Data', 'Volume'), ('Data', 'Volume', '('), ('Volume', '(', 'size'), ('(', 'size', ')'), ('size', ')', ','), (')', ',', 'Velocity'), (',', 'Velocity', '('), ('Velocity', '(', 'data'), ('(', 'data', 'change'), ('data', 'change', 'rate'), ('change', 'rate', ')'), ('rate', ')', 'Variety'), (')', 'Variety', '('), ('Variety', '(', 'data'), ('(', 'data', 'formats'), ('data', 'formats', 'types'), ('formats', 'types', 'well'), ('types', 'well', 'data'), ('well', 'data', 'analysis'), ('data', 'analysis', 'types'), ('analysis', 'types', 'required'), ('types', 'required', ')'), ('required', ')', '('), (')', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Schelén'), (';', 'Schelén', ','), ('Schelén', ',', 'Elragal'), (',', 'Elragal', ','), ('Elragal', ',', 'Haddara'), (',', 'Haddara', ','), ('Haddara', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Chen'), (';', 'Chen', 'Guo'), ('Chen', 'Guo', ','), ('Guo', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Elragal'), (';', 'Elragal', 'Klischewski'), ('Elragal', 'Klischewski', ','), ('Klischewski', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('easily', 'RB'), ('characterised', 'VBD'), ('three', 'CD'), ('main', 'JJ'), ('features', 'NNS'), (',', ','), ('however', 'RB'), (':', ':'), ('Data', 'NNS'), ('Volume', 'NN'), ('(', '('), ('size', 'NN'), (')', ')'), (',', ','), ('Velocity', 'NNP'), ('(', '('), ('data', 'NNS'), ('change', 'NN'), ('rate', 'NN'), (')', ')'), ('Variety', 'NNP'), ('(', '('), ('data', 'NNS'), ('formats', 'NNS'), ('types', 'VBP'), ('well', 'RB'), ('data', 'NNS'), ('analysis', 'NN'), ('types', 'NNS'), ('required', 'VBN'), (')', ')'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Schelén', 'NNP'), (',', ','), ('Elragal', 'NNP'), (',', ','), ('Haddara', 'NNP'), (',', ','), ('2015', 'CD'), (';', ':'), ('Chen', 'NNP'), ('Guo', 'NNP'), (',', ','), ('2016', 'CD'), (';', ':'), ('Elragal', 'NNP'), ('Klischewski', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  easily/RB
  characterised/VBD
  three/CD
  (NP main/JJ features/NNS)
  ,/,
  however/RB
  :/:
  (NP Data/NNS Volume/NN)
  (/(
  (NP size/NN)
  )/)
  ,/,
  (NP Velocity/NNP)
  (/(
  (NP data/NNS change/NN rate/NN)
  )/)
  (NP Variety/NNP)
  (/(
  (NP data/NNS formats/NNS)
  types/VBP
  well/RB
  (NP data/NNS analysis/NN types/NNS)
  required/VBN
  )/)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Schelén/NNP)
  ,/,
  (NP Elragal/NNP)
  ,/,
  (NP Haddara/NNP)
  ,/,
  2015/CD
  ;/:
  (NP Chen/NNP Guo/NNP)
  ,/,
  2016/CD
  ;/:
  (NP Elragal/NNP Klischewski/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'main features', 'Data Volume', 'size', 'Velocity', 'data change rate', 'Variety', 'data formats', 'data analysis types', 'Elgendy Elragal', 'Schelén', 'Elragal', 'Haddara', 'Chen Guo', 'Elragal Klischewski']

>> Named Entities are: 
 [('GPE', 'Volume'), ('GPE', 'Velocity'), ('GPE', 'Variety'), ('PERSON', 'Elgendy Elragal'), ('PERSON', 'Schelén'), ('GPE', 'Elragal'), ('GPE', 'Haddara'), ('PERSON', 'Chen Guo'), ('PERSON', 'Elragal Klischewski')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('easily', 'easili'), ('characterised', 'characteris'), ('three', 'three'), ('main', 'main'), ('features', 'featur'), (',', ','), ('however', 'howev'), (':', ':'), ('Data', 'data'), ('Volume', 'volum'), ('(', '('), ('size', 'size'), (')', ')'), (',', ','), ('Velocity', 'veloc'), ('(', '('), ('data', 'data'), ('change', 'chang'), ('rate', 'rate'), (')', ')'), ('Variety', 'varieti'), ('(', '('), ('data', 'data'), ('formats', 'format'), ('types', 'type'), ('well', 'well'), ('data', 'data'), ('analysis', 'analysi'), ('types', 'type'), ('required', 'requir'), (')', ')'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Schelén', 'schelén'), (',', ','), ('Elragal', 'elrag'), (',', ','), ('Haddara', 'haddara'), (',', ','), ('2015', '2015'), (';', ';'), ('Chen', 'chen'), ('Guo', 'guo'), (',', ','), ('2016', '2016'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('easily', 'easili'), ('characterised', 'characteris'), ('three', 'three'), ('main', 'main'), ('features', 'featur'), (',', ','), ('however', 'howev'), (':', ':'), ('Data', 'data'), ('Volume', 'volum'), ('(', '('), ('size', 'size'), (')', ')'), (',', ','), ('Velocity', 'veloc'), ('(', '('), ('data', 'data'), ('change', 'chang'), ('rate', 'rate'), (')', ')'), ('Variety', 'varieti'), ('(', '('), ('data', 'data'), ('formats', 'format'), ('types', 'type'), ('well', 'well'), ('data', 'data'), ('analysis', 'analysi'), ('types', 'type'), ('required', 'requir'), (')', ')'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Schelén', 'schelén'), (',', ','), ('Elragal', 'elrag'), (',', ','), ('Haddara', 'haddara'), (',', ','), ('2015', '2015'), (';', ';'), ('Chen', 'chen'), ('Guo', 'guo'), (',', ','), ('2016', '2016'), (';', ';'), ('Elragal', 'elrag'), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('easily', 'easily'), ('characterised', 'characterised'), ('three', 'three'), ('main', 'main'), ('features', 'feature'), (',', ','), ('however', 'however'), (':', ':'), ('Data', 'Data'), ('Volume', 'Volume'), ('(', '('), ('size', 'size'), (')', ')'), (',', ','), ('Velocity', 'Velocity'), ('(', '('), ('data', 'data'), ('change', 'change'), ('rate', 'rate'), (')', ')'), ('Variety', 'Variety'), ('(', '('), ('data', 'data'), ('formats', 'format'), ('types', 'type'), ('well', 'well'), ('data', 'data'), ('analysis', 'analysis'), ('types', 'type'), ('required', 'required'), (')', ')'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Schelén', 'Schelén'), (',', ','), ('Elragal', 'Elragal'), (',', ','), ('Haddara', 'Haddara'), (',', ','), ('2015', '2015'), (';', ';'), ('Chen', 'Chen'), ('Guo', 'Guo'), (',', ','), ('2016', '2016'), (';', ';'), ('Elragal', 'Elragal'), ('Klischewski', 'Klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 188 =============================

Streaming data is the leading edge of big data, as it can be collected in real-time from multiple   websites. 


>> Tokens are: 
 ['Streaming', 'data', 'leading', 'edge', 'big', 'data', ',', 'collected', 'real-time', 'multiple', 'websites', '.']

>> Bigrams are: 
 [('Streaming', 'data'), ('data', 'leading'), ('leading', 'edge'), ('edge', 'big'), ('big', 'data'), ('data', ','), (',', 'collected'), ('collected', 'real-time'), ('real-time', 'multiple'), ('multiple', 'websites'), ('websites', '.')]

>> Trigrams are: 
 [('Streaming', 'data', 'leading'), ('data', 'leading', 'edge'), ('leading', 'edge', 'big'), ('edge', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'collected'), (',', 'collected', 'real-time'), ('collected', 'real-time', 'multiple'), ('real-time', 'multiple', 'websites'), ('multiple', 'websites', '.')]

>> POS Tags are: 
 [('Streaming', 'VBG'), ('data', 'NNS'), ('leading', 'VBG'), ('edge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('collected', 'VBD'), ('real-time', 'JJ'), ('multiple', 'JJ'), ('websites', 'NNS'), ('.', '.')]

 (S
  Streaming/VBG
  (NP data/NNS)
  leading/VBG
  (NP edge/NN)
  (NP big/JJ data/NNS)
  ,/,
  collected/VBD
  (NP real-time/JJ multiple/JJ websites/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data', 'edge', 'big data', 'real-time multiple websites']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Streaming', 'stream'), ('data', 'data'), ('leading', 'lead'), ('edge', 'edg'), ('big', 'big'), ('data', 'data'), (',', ','), ('collected', 'collect'), ('real-time', 'real-tim'), ('multiple', 'multipl'), ('websites', 'websit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Streaming', 'stream'), ('data', 'data'), ('leading', 'lead'), ('edge', 'edg'), ('big', 'big'), ('data', 'data'), (',', ','), ('collected', 'collect'), ('real-time', 'real-tim'), ('multiple', 'multipl'), ('websites', 'websit'), ('.', '.')]

>> Lemmatization: 
 [('Streaming', 'Streaming'), ('data', 'data'), ('leading', 'leading'), ('edge', 'edge'), ('big', 'big'), ('data', 'data'), (',', ','), ('collected', 'collected'), ('real-time', 'real-time'), ('multiple', 'multiple'), ('websites', 'website'), ('.', '.')]



============================ Sentence 189 =============================

The addition of the final V, veracity, has been discussed by several researchers and   organisations in this context. 


>> Tokens are: 
 ['The', 'addition', 'final', 'V', ',', 'veracity', ',', 'discussed', 'several', 'researchers', 'organisations', 'context', '.']

>> Bigrams are: 
 [('The', 'addition'), ('addition', 'final'), ('final', 'V'), ('V', ','), (',', 'veracity'), ('veracity', ','), (',', 'discussed'), ('discussed', 'several'), ('several', 'researchers'), ('researchers', 'organisations'), ('organisations', 'context'), ('context', '.')]

>> Trigrams are: 
 [('The', 'addition', 'final'), ('addition', 'final', 'V'), ('final', 'V', ','), ('V', ',', 'veracity'), (',', 'veracity', ','), ('veracity', ',', 'discussed'), (',', 'discussed', 'several'), ('discussed', 'several', 'researchers'), ('several', 'researchers', 'organisations'), ('researchers', 'organisations', 'context'), ('organisations', 'context', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('addition', 'NN'), ('final', 'JJ'), ('V', 'NNP'), (',', ','), ('veracity', 'NN'), (',', ','), ('discussed', 'VBD'), ('several', 'JJ'), ('researchers', 'NNS'), ('organisations', 'NNS'), ('context', 'NN'), ('.', '.')]

 (S
  (NP The/DT addition/NN)
  (NP final/JJ V/NNP)
  ,/,
  (NP veracity/NN)
  ,/,
  discussed/VBD
  (NP several/JJ researchers/NNS organisations/NNS context/NN)
  ./.) 


>> Noun Phrases are: 
 ['The addition', 'final V', 'veracity', 'several researchers organisations context']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('addition', 'addit'), ('final', 'final'), ('V', 'v'), (',', ','), ('veracity', 'verac'), (',', ','), ('discussed', 'discuss'), ('several', 'sever'), ('researchers', 'research'), ('organisations', 'organis'), ('context', 'context'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('addition', 'addit'), ('final', 'final'), ('V', 'v'), (',', ','), ('veracity', 'verac'), (',', ','), ('discussed', 'discuss'), ('several', 'sever'), ('researchers', 'research'), ('organisations', 'organis'), ('context', 'context'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('addition', 'addition'), ('final', 'final'), ('V', 'V'), (',', ','), ('veracity', 'veracity'), (',', ','), ('discussed', 'discussed'), ('several', 'several'), ('researchers', 'researcher'), ('organisations', 'organisation'), ('context', 'context'), ('.', '.')]



============================ Sentence 190 =============================

Veracity focuses on the quality of the data, which may be good, bad,   or undefined due to data inconsistency, incompleteness, ambiguity, latency, deception, or   approximations. 


>> Tokens are: 
 ['Veracity', 'focuses', 'quality', 'data', ',', 'may', 'good', ',', 'bad', ',', 'undefined', 'due', 'data', 'inconsistency', ',', 'incompleteness', ',', 'ambiguity', ',', 'latency', ',', 'deception', ',', 'approximations', '.']

>> Bigrams are: 
 [('Veracity', 'focuses'), ('focuses', 'quality'), ('quality', 'data'), ('data', ','), (',', 'may'), ('may', 'good'), ('good', ','), (',', 'bad'), ('bad', ','), (',', 'undefined'), ('undefined', 'due'), ('due', 'data'), ('data', 'inconsistency'), ('inconsistency', ','), (',', 'incompleteness'), ('incompleteness', ','), (',', 'ambiguity'), ('ambiguity', ','), (',', 'latency'), ('latency', ','), (',', 'deception'), ('deception', ','), (',', 'approximations'), ('approximations', '.')]

>> Trigrams are: 
 [('Veracity', 'focuses', 'quality'), ('focuses', 'quality', 'data'), ('quality', 'data', ','), ('data', ',', 'may'), (',', 'may', 'good'), ('may', 'good', ','), ('good', ',', 'bad'), (',', 'bad', ','), ('bad', ',', 'undefined'), (',', 'undefined', 'due'), ('undefined', 'due', 'data'), ('due', 'data', 'inconsistency'), ('data', 'inconsistency', ','), ('inconsistency', ',', 'incompleteness'), (',', 'incompleteness', ','), ('incompleteness', ',', 'ambiguity'), (',', 'ambiguity', ','), ('ambiguity', ',', 'latency'), (',', 'latency', ','), ('latency', ',', 'deception'), (',', 'deception', ','), ('deception', ',', 'approximations'), (',', 'approximations', '.')]

>> POS Tags are: 
 [('Veracity', 'NN'), ('focuses', 'VBZ'), ('quality', 'NN'), ('data', 'NNS'), (',', ','), ('may', 'MD'), ('good', 'VB'), (',', ','), ('bad', 'JJ'), (',', ','), ('undefined', 'JJ'), ('due', 'JJ'), ('data', 'NNS'), ('inconsistency', 'NN'), (',', ','), ('incompleteness', 'NN'), (',', ','), ('ambiguity', 'NN'), (',', ','), ('latency', 'NN'), (',', ','), ('deception', 'NN'), (',', ','), ('approximations', 'NNS'), ('.', '.')]

 (S
  (NP Veracity/NN)
  focuses/VBZ
  (NP quality/NN data/NNS)
  ,/,
  may/MD
  good/VB
  ,/,
  bad/JJ
  ,/,
  (NP undefined/JJ due/JJ data/NNS inconsistency/NN)
  ,/,
  (NP incompleteness/NN)
  ,/,
  (NP ambiguity/NN)
  ,/,
  (NP latency/NN)
  ,/,
  (NP deception/NN)
  ,/,
  (NP approximations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Veracity', 'quality data', 'undefined due data inconsistency', 'incompleteness', 'ambiguity', 'latency', 'deception', 'approximations']

>> Named Entities are: 
 [('GPE', 'Veracity')] 

>> Stemming using Porter Stemmer: 
 [('Veracity', 'verac'), ('focuses', 'focus'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('may', 'may'), ('good', 'good'), (',', ','), ('bad', 'bad'), (',', ','), ('undefined', 'undefin'), ('due', 'due'), ('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ','), ('approximations', 'approxim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Veracity', 'verac'), ('focuses', 'focus'), ('quality', 'qualiti'), ('data', 'data'), (',', ','), ('may', 'may'), ('good', 'good'), (',', ','), ('bad', 'bad'), (',', ','), ('undefined', 'undefin'), ('due', 'due'), ('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ','), ('approximations', 'approxim'), ('.', '.')]

>> Lemmatization: 
 [('Veracity', 'Veracity'), ('focuses', 'focus'), ('quality', 'quality'), ('data', 'data'), (',', ','), ('may', 'may'), ('good', 'good'), (',', ','), ('bad', 'bad'), (',', ','), ('undefined', 'undefined'), ('due', 'due'), ('data', 'data'), ('inconsistency', 'inconsistency'), (',', ','), ('incompleteness', 'incompleteness'), (',', ','), ('ambiguity', 'ambiguity'), (',', ','), ('latency', 'latency'), (',', ','), ('deception', 'deception'), (',', ','), ('approximations', 'approximation'), ('.', '.')]



============================ Sentence 191 =============================

As most big data sources are external, they lack governance and have little   homogeneity (Elragal, 2014; Elgendy and Elragal, 2014; Russom, 2011). 


>> Tokens are: 
 ['As', 'big', 'data', 'sources', 'external', ',', 'lack', 'governance', 'little', 'homogeneity', '(', 'Elragal', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2014', ';', 'Russom', ',', '2011', ')', '.']

>> Bigrams are: 
 [('As', 'big'), ('big', 'data'), ('data', 'sources'), ('sources', 'external'), ('external', ','), (',', 'lack'), ('lack', 'governance'), ('governance', 'little'), ('little', 'homogeneity'), ('homogeneity', '('), ('(', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ')'), (')', '.')]

>> Trigrams are: 
 [('As', 'big', 'data'), ('big', 'data', 'sources'), ('data', 'sources', 'external'), ('sources', 'external', ','), ('external', ',', 'lack'), (',', 'lack', 'governance'), ('lack', 'governance', 'little'), ('governance', 'little', 'homogeneity'), ('little', 'homogeneity', '('), ('homogeneity', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Russom'), (';', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ')'), ('2011', ')', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('big', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('external', 'JJ'), (',', ','), ('lack', 'JJ'), ('governance', 'NN'), ('little', 'JJ'), ('homogeneity', 'NN'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), ('.', '.')]

 (S
  As/IN
  (NP big/JJ data/NNS sources/NNS)
  external/JJ
  ,/,
  (NP lack/JJ governance/NN)
  (NP little/JJ homogeneity/NN)
  (/(
  (NP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Russom/NNP)
  ,/,
  2011/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['big data sources', 'lack governance', 'little homogeneity', 'Elragal', 'Elgendy Elragal', 'Russom']

>> Named Entities are: 
 [('ORGANIZATION', 'Elragal'), ('PERSON', 'Elgendy Elragal'), ('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('lack', 'lack'), ('governance', 'govern'), ('little', 'littl'), ('homogeneity', 'homogen'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('external', 'extern'), (',', ','), ('lack', 'lack'), ('governance', 'govern'), ('little', 'littl'), ('homogeneity', 'homogen'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('big', 'big'), ('data', 'data'), ('sources', 'source'), ('external', 'external'), (',', ','), ('lack', 'lack'), ('governance', 'governance'), ('little', 'little'), ('homogeneity', 'homogeneity'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (')', ')'), ('.', '.')]



============================ Sentence 192 =============================

The important thing for modern organisations seeking competitive advantages is how to manage   and extract the value from data. 


>> Tokens are: 
 ['The', 'important', 'thing', 'modern', 'organisations', 'seeking', 'competitive', 'advantages', 'manage', 'extract', 'value', 'data', '.']

>> Bigrams are: 
 [('The', 'important'), ('important', 'thing'), ('thing', 'modern'), ('modern', 'organisations'), ('organisations', 'seeking'), ('seeking', 'competitive'), ('competitive', 'advantages'), ('advantages', 'manage'), ('manage', 'extract'), ('extract', 'value'), ('value', 'data'), ('data', '.')]

>> Trigrams are: 
 [('The', 'important', 'thing'), ('important', 'thing', 'modern'), ('thing', 'modern', 'organisations'), ('modern', 'organisations', 'seeking'), ('organisations', 'seeking', 'competitive'), ('seeking', 'competitive', 'advantages'), ('competitive', 'advantages', 'manage'), ('advantages', 'manage', 'extract'), ('manage', 'extract', 'value'), ('extract', 'value', 'data'), ('value', 'data', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('important', 'JJ'), ('thing', 'NN'), ('modern', 'JJ'), ('organisations', 'NNS'), ('seeking', 'VBG'), ('competitive', 'JJ'), ('advantages', 'NNS'), ('manage', 'VBP'), ('extract', 'JJ'), ('value', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP The/DT important/JJ thing/NN)
  (NP modern/JJ organisations/NNS)
  seeking/VBG
  (NP competitive/JJ advantages/NNS)
  manage/VBP
  (NP extract/JJ value/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The important thing', 'modern organisations', 'competitive advantages', 'extract value data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('important', 'import'), ('thing', 'thing'), ('modern', 'modern'), ('organisations', 'organis'), ('seeking', 'seek'), ('competitive', 'competit'), ('advantages', 'advantag'), ('manage', 'manag'), ('extract', 'extract'), ('value', 'valu'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('important', 'import'), ('thing', 'thing'), ('modern', 'modern'), ('organisations', 'organis'), ('seeking', 'seek'), ('competitive', 'competit'), ('advantages', 'advantag'), ('manage', 'manag'), ('extract', 'extract'), ('value', 'valu'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('important', 'important'), ('thing', 'thing'), ('modern', 'modern'), ('organisations', 'organisation'), ('seeking', 'seeking'), ('competitive', 'competitive'), ('advantages', 'advantage'), ('manage', 'manage'), ('extract', 'extract'), ('value', 'value'), ('data', 'data'), ('.', '.')]



============================ Sentence 193 =============================

Big data combines technical challenges with multiple   opportunities, and thus extracting business value represents both challenge and opportunity at the   same time. 


>> Tokens are: 
 ['Big', 'data', 'combines', 'technical', 'challenges', 'multiple', 'opportunities', ',', 'thus', 'extracting', 'business', 'value', 'represents', 'challenge', 'opportunity', 'time', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'combines'), ('combines', 'technical'), ('technical', 'challenges'), ('challenges', 'multiple'), ('multiple', 'opportunities'), ('opportunities', ','), (',', 'thus'), ('thus', 'extracting'), ('extracting', 'business'), ('business', 'value'), ('value', 'represents'), ('represents', 'challenge'), ('challenge', 'opportunity'), ('opportunity', 'time'), ('time', '.')]

>> Trigrams are: 
 [('Big', 'data', 'combines'), ('data', 'combines', 'technical'), ('combines', 'technical', 'challenges'), ('technical', 'challenges', 'multiple'), ('challenges', 'multiple', 'opportunities'), ('multiple', 'opportunities', ','), ('opportunities', ',', 'thus'), (',', 'thus', 'extracting'), ('thus', 'extracting', 'business'), ('extracting', 'business', 'value'), ('business', 'value', 'represents'), ('value', 'represents', 'challenge'), ('represents', 'challenge', 'opportunity'), ('challenge', 'opportunity', 'time'), ('opportunity', 'time', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('combines', 'NNS'), ('technical', 'JJ'), ('challenges', 'NNS'), ('multiple', 'JJ'), ('opportunities', 'NNS'), (',', ','), ('thus', 'RB'), ('extracting', 'VBG'), ('business', 'NN'), ('value', 'NN'), ('represents', 'VBZ'), ('challenge', 'VB'), ('opportunity', 'NN'), ('time', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS combines/NNS)
  (NP technical/JJ challenges/NNS)
  (NP multiple/JJ opportunities/NNS)
  ,/,
  thus/RB
  extracting/VBG
  (NP business/NN value/NN)
  represents/VBZ
  challenge/VB
  (NP opportunity/NN time/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data combines', 'technical challenges', 'multiple opportunities', 'business value', 'opportunity time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('combines', 'combin'), ('technical', 'technic'), ('challenges', 'challeng'), ('multiple', 'multipl'), ('opportunities', 'opportun'), (',', ','), ('thus', 'thu'), ('extracting', 'extract'), ('business', 'busi'), ('value', 'valu'), ('represents', 'repres'), ('challenge', 'challeng'), ('opportunity', 'opportun'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('combines', 'combin'), ('technical', 'technic'), ('challenges', 'challeng'), ('multiple', 'multipl'), ('opportunities', 'opportun'), (',', ','), ('thus', 'thus'), ('extracting', 'extract'), ('business', 'busi'), ('value', 'valu'), ('represents', 'repres'), ('challenge', 'challeng'), ('opportunity', 'opportun'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('combines', 'combine'), ('technical', 'technical'), ('challenges', 'challenge'), ('multiple', 'multiple'), ('opportunities', 'opportunity'), (',', ','), ('thus', 'thus'), ('extracting', 'extracting'), ('business', 'business'), ('value', 'value'), ('represents', 'represents'), ('challenge', 'challenge'), ('opportunity', 'opportunity'), ('time', 'time'), ('.', '.')]



============================ Sentence 194 =============================

This puts big data business perspective side-by-side with technical aspects and showing   how big data adds value to organisational objectives has become a crucial aspect of research in   this field. 


>> Tokens are: 
 ['This', 'puts', 'big', 'data', 'business', 'perspective', 'side-by-side', 'technical', 'aspects', 'showing', 'big', 'data', 'adds', 'value', 'organisational', 'objectives', 'become', 'crucial', 'aspect', 'research', 'field', '.']

>> Bigrams are: 
 [('This', 'puts'), ('puts', 'big'), ('big', 'data'), ('data', 'business'), ('business', 'perspective'), ('perspective', 'side-by-side'), ('side-by-side', 'technical'), ('technical', 'aspects'), ('aspects', 'showing'), ('showing', 'big'), ('big', 'data'), ('data', 'adds'), ('adds', 'value'), ('value', 'organisational'), ('organisational', 'objectives'), ('objectives', 'become'), ('become', 'crucial'), ('crucial', 'aspect'), ('aspect', 'research'), ('research', 'field'), ('field', '.')]

>> Trigrams are: 
 [('This', 'puts', 'big'), ('puts', 'big', 'data'), ('big', 'data', 'business'), ('data', 'business', 'perspective'), ('business', 'perspective', 'side-by-side'), ('perspective', 'side-by-side', 'technical'), ('side-by-side', 'technical', 'aspects'), ('technical', 'aspects', 'showing'), ('aspects', 'showing', 'big'), ('showing', 'big', 'data'), ('big', 'data', 'adds'), ('data', 'adds', 'value'), ('adds', 'value', 'organisational'), ('value', 'organisational', 'objectives'), ('organisational', 'objectives', 'become'), ('objectives', 'become', 'crucial'), ('become', 'crucial', 'aspect'), ('crucial', 'aspect', 'research'), ('aspect', 'research', 'field'), ('research', 'field', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('puts', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('business', 'NN'), ('perspective', 'JJ'), ('side-by-side', 'JJ'), ('technical', 'JJ'), ('aspects', 'NNS'), ('showing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('adds', 'VBZ'), ('value', 'NN'), ('organisational', 'JJ'), ('objectives', 'VBZ'), ('become', 'VBN'), ('crucial', 'JJ'), ('aspect', 'JJ'), ('research', 'NN'), ('field', 'NN'), ('.', '.')]

 (S
  This/DT
  puts/VBZ
  (NP big/JJ data/NNS business/NN)
  (NP perspective/JJ side-by-side/JJ technical/JJ aspects/NNS)
  showing/VBG
  (NP big/JJ data/NNS)
  adds/VBZ
  (NP value/NN)
  organisational/JJ
  objectives/VBZ
  become/VBN
  (NP crucial/JJ aspect/JJ research/NN field/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data business', 'perspective side-by-side technical aspects', 'big data', 'value', 'crucial aspect research field']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('puts', 'put'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('perspective', 'perspect'), ('side-by-side', 'side-by-sid'), ('technical', 'technic'), ('aspects', 'aspect'), ('showing', 'show'), ('big', 'big'), ('data', 'data'), ('adds', 'add'), ('value', 'valu'), ('organisational', 'organis'), ('objectives', 'object'), ('become', 'becom'), ('crucial', 'crucial'), ('aspect', 'aspect'), ('research', 'research'), ('field', 'field'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('puts', 'put'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('perspective', 'perspect'), ('side-by-side', 'side-by-sid'), ('technical', 'technic'), ('aspects', 'aspect'), ('showing', 'show'), ('big', 'big'), ('data', 'data'), ('adds', 'add'), ('value', 'valu'), ('organisational', 'organis'), ('objectives', 'object'), ('become', 'becom'), ('crucial', 'crucial'), ('aspect', 'aspect'), ('research', 'research'), ('field', 'field'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('puts', 'put'), ('big', 'big'), ('data', 'data'), ('business', 'business'), ('perspective', 'perspective'), ('side-by-side', 'side-by-side'), ('technical', 'technical'), ('aspects', 'aspect'), ('showing', 'showing'), ('big', 'big'), ('data', 'data'), ('adds', 'add'), ('value', 'value'), ('organisational', 'organisational'), ('objectives', 'objective'), ('become', 'become'), ('crucial', 'crucial'), ('aspect', 'aspect'), ('research', 'research'), ('field', 'field'), ('.', '.')]



============================ Sentence 195 =============================

Manyika et al. 


>> Tokens are: 
 ['Manyika', 'et', 'al', '.']

>> Bigrams are: 
 [('Manyika', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Manyika', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Manyika', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Manyika/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Manyika', 'al']

>> Named Entities are: 
 [('GPE', 'Manyika')] 

>> Stemming using Porter Stemmer: 
 [('Manyika', 'manyika'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Manyika', 'manyika'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Manyika', 'Manyika'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 196 =============================

(2011) clarified how big data can generate value-add for organisations by   ➢ making information clear and applicable more frequently;  ➢ allowing organisations to create and store transactional data in digital form, making it   easier for them to gather more precise information about inventories and products;   ➢ using sophisticated big data analytics to improve decision making quality;     Sarah Al-Shiakhli   16      ➢ utilising big data to shape the next generation of products and services (Elragal, A, 2014). 


>> Tokens are: 
 ['(', '2011', ')', 'clarified', 'big', 'data', 'generate', 'value-add', 'organisations', '➢', 'making', 'information', 'clear', 'applicable', 'frequently', ';', '➢', 'allowing', 'organisations', 'create', 'store', 'transactional', 'data', 'digital', 'form', ',', 'making', 'easier', 'gather', 'precise', 'information', 'inventories', 'products', ';', '➢', 'using', 'sophisticated', 'big', 'data', 'analytics', 'improve', 'decision', 'making', 'quality', ';', 'Sarah', 'Al-Shiakhli', '16', '➢', 'utilising', 'big', 'data', 'shape', 'next', 'generation', 'products', 'services', '(', 'Elragal', ',', 'A', ',', '2014', ')', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', 'clarified'), ('clarified', 'big'), ('big', 'data'), ('data', 'generate'), ('generate', 'value-add'), ('value-add', 'organisations'), ('organisations', '➢'), ('➢', 'making'), ('making', 'information'), ('information', 'clear'), ('clear', 'applicable'), ('applicable', 'frequently'), ('frequently', ';'), (';', '➢'), ('➢', 'allowing'), ('allowing', 'organisations'), ('organisations', 'create'), ('create', 'store'), ('store', 'transactional'), ('transactional', 'data'), ('data', 'digital'), ('digital', 'form'), ('form', ','), (',', 'making'), ('making', 'easier'), ('easier', 'gather'), ('gather', 'precise'), ('precise', 'information'), ('information', 'inventories'), ('inventories', 'products'), ('products', ';'), (';', '➢'), ('➢', 'using'), ('using', 'sophisticated'), ('sophisticated', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'improve'), ('improve', 'decision'), ('decision', 'making'), ('making', 'quality'), ('quality', ';'), (';', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '16'), ('16', '➢'), ('➢', 'utilising'), ('utilising', 'big'), ('big', 'data'), ('data', 'shape'), ('shape', 'next'), ('next', 'generation'), ('generation', 'products'), ('products', 'services'), ('services', '('), ('(', 'Elragal'), ('Elragal', ','), (',', 'A'), ('A', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', 'clarified'), (')', 'clarified', 'big'), ('clarified', 'big', 'data'), ('big', 'data', 'generate'), ('data', 'generate', 'value-add'), ('generate', 'value-add', 'organisations'), ('value-add', 'organisations', '➢'), ('organisations', '➢', 'making'), ('➢', 'making', 'information'), ('making', 'information', 'clear'), ('information', 'clear', 'applicable'), ('clear', 'applicable', 'frequently'), ('applicable', 'frequently', ';'), ('frequently', ';', '➢'), (';', '➢', 'allowing'), ('➢', 'allowing', 'organisations'), ('allowing', 'organisations', 'create'), ('organisations', 'create', 'store'), ('create', 'store', 'transactional'), ('store', 'transactional', 'data'), ('transactional', 'data', 'digital'), ('data', 'digital', 'form'), ('digital', 'form', ','), ('form', ',', 'making'), (',', 'making', 'easier'), ('making', 'easier', 'gather'), ('easier', 'gather', 'precise'), ('gather', 'precise', 'information'), ('precise', 'information', 'inventories'), ('information', 'inventories', 'products'), ('inventories', 'products', ';'), ('products', ';', '➢'), (';', '➢', 'using'), ('➢', 'using', 'sophisticated'), ('using', 'sophisticated', 'big'), ('sophisticated', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'improve'), ('analytics', 'improve', 'decision'), ('improve', 'decision', 'making'), ('decision', 'making', 'quality'), ('making', 'quality', ';'), ('quality', ';', 'Sarah'), (';', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '16'), ('Al-Shiakhli', '16', '➢'), ('16', '➢', 'utilising'), ('➢', 'utilising', 'big'), ('utilising', 'big', 'data'), ('big', 'data', 'shape'), ('data', 'shape', 'next'), ('shape', 'next', 'generation'), ('next', 'generation', 'products'), ('generation', 'products', 'services'), ('products', 'services', '('), ('services', '(', 'Elragal'), ('(', 'Elragal', ','), ('Elragal', ',', 'A'), (',', 'A', ','), ('A', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('clarified', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('generate', 'NN'), ('value-add', 'JJ'), ('organisations', 'NNS'), ('➢', 'VBP'), ('making', 'VBG'), ('information', 'NN'), ('clear', 'JJ'), ('applicable', 'JJ'), ('frequently', 'RB'), (';', ':'), ('➢', 'CC'), ('allowing', 'VBG'), ('organisations', 'NNS'), ('create', 'VBP'), ('store', 'VBP'), ('transactional', 'JJ'), ('data', 'NNS'), ('digital', 'JJ'), ('form', 'NN'), (',', ','), ('making', 'VBG'), ('easier', 'JJR'), ('gather', 'NN'), ('precise', 'NN'), ('information', 'NN'), ('inventories', 'NNS'), ('products', 'NNS'), (';', ':'), ('➢', 'NNP'), ('using', 'VBG'), ('sophisticated', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('improve', 'VBP'), ('decision', 'NN'), ('making', 'NN'), ('quality', 'NN'), (';', ':'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('16', 'CD'), ('➢', 'NNP'), ('utilising', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('shape', 'NN'), ('next', 'IN'), ('generation', 'NN'), ('products', 'NNS'), ('services', 'NNS'), ('(', '('), ('Elragal', 'NNP'), (',', ','), ('A', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (/(
  2011/CD
  )/)
  clarified/VBD
  (NP big/JJ data/NNS generate/NN)
  (NP value-add/JJ organisations/NNS)
  ➢/VBP
  making/VBG
  (NP information/NN)
  clear/JJ
  applicable/JJ
  frequently/RB
  ;/:
  ➢/CC
  allowing/VBG
  (NP organisations/NNS)
  create/VBP
  store/VBP
  (NP transactional/JJ data/NNS)
  (NP digital/JJ form/NN)
  ,/,
  making/VBG
  easier/JJR
  (NP
    gather/NN
    precise/NN
    information/NN
    inventories/NNS
    products/NNS)
  ;/:
  (NP ➢/NNP)
  using/VBG
  (NP sophisticated/JJ big/JJ data/NNS analytics/NNS)
  improve/VBP
  (NP decision/NN making/NN quality/NN)
  ;/:
  (NP Sarah/NNP Al-Shiakhli/NNP)
  16/CD
  (NP ➢/NNP)
  utilising/VBG
  (NP big/JJ data/NNS shape/NN)
  next/IN
  (NP generation/NN products/NNS services/NNS)
  (/(
  (NP Elragal/NNP)
  ,/,
  (NP A/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['big data generate', 'value-add organisations', 'information', 'organisations', 'transactional data', 'digital form', 'gather precise information inventories products', '➢', 'sophisticated big data analytics', 'decision making quality', 'Sarah Al-Shiakhli', '➢', 'big data shape', 'generation products services', 'Elragal', 'A']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('clarified', 'clarifi'), ('big', 'big'), ('data', 'data'), ('generate', 'gener'), ('value-add', 'value-add'), ('organisations', 'organis'), ('➢', '➢'), ('making', 'make'), ('information', 'inform'), ('clear', 'clear'), ('applicable', 'applic'), ('frequently', 'frequent'), (';', ';'), ('➢', '➢'), ('allowing', 'allow'), ('organisations', 'organis'), ('create', 'creat'), ('store', 'store'), ('transactional', 'transact'), ('data', 'data'), ('digital', 'digit'), ('form', 'form'), (',', ','), ('making', 'make'), ('easier', 'easier'), ('gather', 'gather'), ('precise', 'precis'), ('information', 'inform'), ('inventories', 'inventori'), ('products', 'product'), (';', ';'), ('➢', '➢'), ('using', 'use'), ('sophisticated', 'sophist'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('decision', 'decis'), ('making', 'make'), ('quality', 'qualiti'), (';', ';'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('16', '16'), ('➢', '➢'), ('utilising', 'utilis'), ('big', 'big'), ('data', 'data'), ('shape', 'shape'), ('next', 'next'), ('generation', 'gener'), ('products', 'product'), ('services', 'servic'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('clarified', 'clarifi'), ('big', 'big'), ('data', 'data'), ('generate', 'generat'), ('value-add', 'value-add'), ('organisations', 'organis'), ('➢', '➢'), ('making', 'make'), ('information', 'inform'), ('clear', 'clear'), ('applicable', 'applic'), ('frequently', 'frequent'), (';', ';'), ('➢', '➢'), ('allowing', 'allow'), ('organisations', 'organis'), ('create', 'creat'), ('store', 'store'), ('transactional', 'transact'), ('data', 'data'), ('digital', 'digit'), ('form', 'form'), (',', ','), ('making', 'make'), ('easier', 'easier'), ('gather', 'gather'), ('precise', 'precis'), ('information', 'inform'), ('inventories', 'inventori'), ('products', 'product'), (';', ';'), ('➢', '➢'), ('using', 'use'), ('sophisticated', 'sophist'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('decision', 'decis'), ('making', 'make'), ('quality', 'qualiti'), (';', ';'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('16', '16'), ('➢', '➢'), ('utilising', 'utilis'), ('big', 'big'), ('data', 'data'), ('shape', 'shape'), ('next', 'next'), ('generation', 'generat'), ('products', 'product'), ('services', 'servic'), ('(', '('), ('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('clarified', 'clarified'), ('big', 'big'), ('data', 'data'), ('generate', 'generate'), ('value-add', 'value-add'), ('organisations', 'organisation'), ('➢', '➢'), ('making', 'making'), ('information', 'information'), ('clear', 'clear'), ('applicable', 'applicable'), ('frequently', 'frequently'), (';', ';'), ('➢', '➢'), ('allowing', 'allowing'), ('organisations', 'organisation'), ('create', 'create'), ('store', 'store'), ('transactional', 'transactional'), ('data', 'data'), ('digital', 'digital'), ('form', 'form'), (',', ','), ('making', 'making'), ('easier', 'easier'), ('gather', 'gather'), ('precise', 'precise'), ('information', 'information'), ('inventories', 'inventory'), ('products', 'product'), (';', ';'), ('➢', '➢'), ('using', 'using'), ('sophisticated', 'sophisticated'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('improve', 'improve'), ('decision', 'decision'), ('making', 'making'), ('quality', 'quality'), (';', ';'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('16', '16'), ('➢', '➢'), ('utilising', 'utilising'), ('big', 'big'), ('data', 'data'), ('shape', 'shape'), ('next', 'next'), ('generation', 'generation'), ('products', 'product'), ('services', 'service'), ('(', '('), ('Elragal', 'Elragal'), (',', ','), ('A', 'A'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 197 =============================

Quantifying big data can be done in terms of storage size, number of records, transactions, tables,   or files. 


>> Tokens are: 
 ['Quantifying', 'big', 'data', 'done', 'terms', 'storage', 'size', ',', 'number', 'records', ',', 'transactions', ',', 'tables', ',', 'files', '.']

>> Bigrams are: 
 [('Quantifying', 'big'), ('big', 'data'), ('data', 'done'), ('done', 'terms'), ('terms', 'storage'), ('storage', 'size'), ('size', ','), (',', 'number'), ('number', 'records'), ('records', ','), (',', 'transactions'), ('transactions', ','), (',', 'tables'), ('tables', ','), (',', 'files'), ('files', '.')]

>> Trigrams are: 
 [('Quantifying', 'big', 'data'), ('big', 'data', 'done'), ('data', 'done', 'terms'), ('done', 'terms', 'storage'), ('terms', 'storage', 'size'), ('storage', 'size', ','), ('size', ',', 'number'), (',', 'number', 'records'), ('number', 'records', ','), ('records', ',', 'transactions'), (',', 'transactions', ','), ('transactions', ',', 'tables'), (',', 'tables', ','), ('tables', ',', 'files'), (',', 'files', '.')]

>> POS Tags are: 
 [('Quantifying', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('done', 'VBN'), ('terms', 'NNS'), ('storage', 'NN'), ('size', 'NN'), (',', ','), ('number', 'NN'), ('records', 'NNS'), (',', ','), ('transactions', 'NNS'), (',', ','), ('tables', 'NNS'), (',', ','), ('files', 'NNS'), ('.', '.')]

 (S
  Quantifying/VBG
  (NP big/JJ data/NNS)
  done/VBN
  (NP terms/NNS storage/NN size/NN)
  ,/,
  (NP number/NN records/NNS)
  ,/,
  (NP transactions/NNS)
  ,/,
  (NP tables/NNS)
  ,/,
  (NP files/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'terms storage size', 'number records', 'transactions', 'tables', 'files']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Quantifying', 'quantifi'), ('big', 'big'), ('data', 'data'), ('done', 'done'), ('terms', 'term'), ('storage', 'storag'), ('size', 'size'), (',', ','), ('number', 'number'), ('records', 'record'), (',', ','), ('transactions', 'transact'), (',', ','), ('tables', 'tabl'), (',', ','), ('files', 'file'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Quantifying', 'quantifi'), ('big', 'big'), ('data', 'data'), ('done', 'done'), ('terms', 'term'), ('storage', 'storag'), ('size', 'size'), (',', ','), ('number', 'number'), ('records', 'record'), (',', ','), ('transactions', 'transact'), (',', ','), ('tables', 'tabl'), (',', ','), ('files', 'file'), ('.', '.')]

>> Lemmatization: 
 [('Quantifying', 'Quantifying'), ('big', 'big'), ('data', 'data'), ('done', 'done'), ('terms', 'term'), ('storage', 'storage'), ('size', 'size'), (',', ','), ('number', 'number'), ('records', 'record'), (',', ','), ('transactions', 'transaction'), (',', ','), ('tables', 'table'), (',', ','), ('files', 'file'), ('.', '.')]



============================ Sentence 198 =============================

Big data comes from multiple diverse sources collected for many purposes (Constantiou   and Kallinikos, 2015), including IoT data, logs, clickstreams, and social media. 


>> Tokens are: 
 ['Big', 'data', 'comes', 'multiple', 'diverse', 'sources', 'collected', 'many', 'purposes', '(', 'Constantiou', 'Kallinikos', ',', '2015', ')', ',', 'including', 'IoT', 'data', ',', 'logs', ',', 'clickstreams', ',', 'social', 'media', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'comes'), ('comes', 'multiple'), ('multiple', 'diverse'), ('diverse', 'sources'), ('sources', 'collected'), ('collected', 'many'), ('many', 'purposes'), ('purposes', '('), ('(', 'Constantiou'), ('Constantiou', 'Kallinikos'), ('Kallinikos', ','), (',', '2015'), ('2015', ')'), (')', ','), (',', 'including'), ('including', 'IoT'), ('IoT', 'data'), ('data', ','), (',', 'logs'), ('logs', ','), (',', 'clickstreams'), ('clickstreams', ','), (',', 'social'), ('social', 'media'), ('media', '.')]

>> Trigrams are: 
 [('Big', 'data', 'comes'), ('data', 'comes', 'multiple'), ('comes', 'multiple', 'diverse'), ('multiple', 'diverse', 'sources'), ('diverse', 'sources', 'collected'), ('sources', 'collected', 'many'), ('collected', 'many', 'purposes'), ('many', 'purposes', '('), ('purposes', '(', 'Constantiou'), ('(', 'Constantiou', 'Kallinikos'), ('Constantiou', 'Kallinikos', ','), ('Kallinikos', ',', '2015'), (',', '2015', ')'), ('2015', ')', ','), (')', ',', 'including'), (',', 'including', 'IoT'), ('including', 'IoT', 'data'), ('IoT', 'data', ','), ('data', ',', 'logs'), (',', 'logs', ','), ('logs', ',', 'clickstreams'), (',', 'clickstreams', ','), ('clickstreams', ',', 'social'), (',', 'social', 'media'), ('social', 'media', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('comes', 'VBZ'), ('multiple', 'JJ'), ('diverse', 'JJ'), ('sources', 'NNS'), ('collected', 'VBD'), ('many', 'JJ'), ('purposes', 'NNS'), ('(', '('), ('Constantiou', 'NNP'), ('Kallinikos', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), (',', ','), ('including', 'VBG'), ('IoT', 'NNP'), ('data', 'NN'), (',', ','), ('logs', 'NNS'), (',', ','), ('clickstreams', 'NNS'), (',', ','), ('social', 'JJ'), ('media', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  comes/VBZ
  (NP multiple/JJ diverse/JJ sources/NNS)
  collected/VBD
  (NP many/JJ purposes/NNS)
  (/(
  (NP Constantiou/NNP Kallinikos/NNP)
  ,/,
  2015/CD
  )/)
  ,/,
  including/VBG
  (NP IoT/NNP data/NN)
  ,/,
  (NP logs/NNS)
  ,/,
  (NP clickstreams/NNS)
  ,/,
  (NP social/JJ media/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'multiple diverse sources', 'many purposes', 'Constantiou Kallinikos', 'IoT data', 'logs', 'clickstreams', 'social media']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou Kallinikos'), ('ORGANIZATION', 'IoT')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('comes', 'come'), ('multiple', 'multipl'), ('diverse', 'divers'), ('sources', 'sourc'), ('collected', 'collect'), ('many', 'mani'), ('purposes', 'purpos'), ('(', '('), ('Constantiou', 'constanti'), ('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (',', ','), ('including', 'includ'), ('IoT', 'iot'), ('data', 'data'), (',', ','), ('logs', 'log'), (',', ','), ('clickstreams', 'clickstream'), (',', ','), ('social', 'social'), ('media', 'media'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('comes', 'come'), ('multiple', 'multipl'), ('diverse', 'divers'), ('sources', 'sourc'), ('collected', 'collect'), ('many', 'mani'), ('purposes', 'purpos'), ('(', '('), ('Constantiou', 'constantiou'), ('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (',', ','), ('including', 'includ'), ('IoT', 'iot'), ('data', 'data'), (',', ','), ('logs', 'log'), (',', ','), ('clickstreams', 'clickstream'), (',', ','), ('social', 'social'), ('media', 'media'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('comes', 'come'), ('multiple', 'multiple'), ('diverse', 'diverse'), ('sources', 'source'), ('collected', 'collected'), ('many', 'many'), ('purposes', 'purpose'), ('(', '('), ('Constantiou', 'Constantiou'), ('Kallinikos', 'Kallinikos'), (',', ','), ('2015', '2015'), (')', ')'), (',', ','), ('including', 'including'), ('IoT', 'IoT'), ('data', 'data'), (',', ','), ('logs', 'log'), (',', ','), ('clickstreams', 'clickstreams'), (',', ','), ('social', 'social'), ('media', 'medium'), ('.', '.')]



============================ Sentence 199 =============================

For all of those   sources to be used for analytics requires joining up unstructured data (such as texts in natural   language) and semi-structured data (such as extensible mark-up language (XML), JSON or rich   site summary (RSS) feeds) to a common structured data framework (Elgendy and Elragal, 2014;   Elragal, 2014). 


>> Tokens are: 
 ['For', 'sources', 'used', 'analytics', 'requires', 'joining', 'unstructured', 'data', '(', 'texts', 'natural', 'language', ')', 'semi-structured', 'data', '(', 'extensible', 'mark-up', 'language', '(', 'XML', ')', ',', 'JSON', 'rich', 'site', 'summary', '(', 'RSS', ')', 'feeds', ')', 'common', 'structured', 'data', 'framework', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('For', 'sources'), ('sources', 'used'), ('used', 'analytics'), ('analytics', 'requires'), ('requires', 'joining'), ('joining', 'unstructured'), ('unstructured', 'data'), ('data', '('), ('(', 'texts'), ('texts', 'natural'), ('natural', 'language'), ('language', ')'), (')', 'semi-structured'), ('semi-structured', 'data'), ('data', '('), ('(', 'extensible'), ('extensible', 'mark-up'), ('mark-up', 'language'), ('language', '('), ('(', 'XML'), ('XML', ')'), (')', ','), (',', 'JSON'), ('JSON', 'rich'), ('rich', 'site'), ('site', 'summary'), ('summary', '('), ('(', 'RSS'), ('RSS', ')'), (')', 'feeds'), ('feeds', ')'), (')', 'common'), ('common', 'structured'), ('structured', 'data'), ('data', 'framework'), ('framework', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('For', 'sources', 'used'), ('sources', 'used', 'analytics'), ('used', 'analytics', 'requires'), ('analytics', 'requires', 'joining'), ('requires', 'joining', 'unstructured'), ('joining', 'unstructured', 'data'), ('unstructured', 'data', '('), ('data', '(', 'texts'), ('(', 'texts', 'natural'), ('texts', 'natural', 'language'), ('natural', 'language', ')'), ('language', ')', 'semi-structured'), (')', 'semi-structured', 'data'), ('semi-structured', 'data', '('), ('data', '(', 'extensible'), ('(', 'extensible', 'mark-up'), ('extensible', 'mark-up', 'language'), ('mark-up', 'language', '('), ('language', '(', 'XML'), ('(', 'XML', ')'), ('XML', ')', ','), (')', ',', 'JSON'), (',', 'JSON', 'rich'), ('JSON', 'rich', 'site'), ('rich', 'site', 'summary'), ('site', 'summary', '('), ('summary', '(', 'RSS'), ('(', 'RSS', ')'), ('RSS', ')', 'feeds'), (')', 'feeds', ')'), ('feeds', ')', 'common'), (')', 'common', 'structured'), ('common', 'structured', 'data'), ('structured', 'data', 'framework'), ('data', 'framework', '('), ('framework', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elragal'), (';', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('sources', 'NNS'), ('used', 'VBN'), ('analytics', 'NNS'), ('requires', 'VBZ'), ('joining', 'VBG'), ('unstructured', 'JJ'), ('data', 'NNS'), ('(', '('), ('texts', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), (')', ')'), ('semi-structured', 'JJ'), ('data', 'NNS'), ('(', '('), ('extensible', 'JJ'), ('mark-up', 'JJ'), ('language', 'NN'), ('(', '('), ('XML', 'NNP'), (')', ')'), (',', ','), ('JSON', 'NNP'), ('rich', 'JJ'), ('site', 'NN'), ('summary', 'NN'), ('(', '('), ('RSS', 'NNP'), (')', ')'), ('feeds', 'NNS'), (')', ')'), ('common', 'JJ'), ('structured', 'VBN'), ('data', 'NNS'), ('framework', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  For/IN
  (NP sources/NNS)
  used/VBN
  (NP analytics/NNS)
  requires/VBZ
  joining/VBG
  (NP unstructured/JJ data/NNS)
  (/(
  (NP texts/JJ natural/JJ language/NN)
  )/)
  (NP semi-structured/JJ data/NNS)
  (/(
  (NP extensible/JJ mark-up/JJ language/NN)
  (/(
  (NP XML/NNP)
  )/)
  ,/,
  (NP JSON/NNP)
  (NP rich/JJ site/NN summary/NN)
  (/(
  (NP RSS/NNP)
  )/)
  (NP feeds/NNS)
  )/)
  common/JJ
  structured/VBN
  (NP data/NNS framework/NN)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['sources', 'analytics', 'unstructured data', 'texts natural language', 'semi-structured data', 'extensible mark-up language', 'XML', 'JSON', 'rich site summary', 'RSS', 'feeds', 'data framework', 'Elgendy Elragal', 'Elragal']

>> Named Entities are: 
 [('ORGANIZATION', 'XML'), ('ORGANIZATION', 'JSON'), ('ORGANIZATION', 'RSS'), ('PERSON', 'Elgendy Elragal'), ('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('sources', 'sourc'), ('used', 'use'), ('analytics', 'analyt'), ('requires', 'requir'), ('joining', 'join'), ('unstructured', 'unstructur'), ('data', 'data'), ('(', '('), ('texts', 'text'), ('natural', 'natur'), ('language', 'languag'), (')', ')'), ('semi-structured', 'semi-structur'), ('data', 'data'), ('(', '('), ('extensible', 'extens'), ('mark-up', 'mark-up'), ('language', 'languag'), ('(', '('), ('XML', 'xml'), (')', ')'), (',', ','), ('JSON', 'json'), ('rich', 'rich'), ('site', 'site'), ('summary', 'summari'), ('(', '('), ('RSS', 'rss'), (')', ')'), ('feeds', 'feed'), (')', ')'), ('common', 'common'), ('structured', 'structur'), ('data', 'data'), ('framework', 'framework'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('sources', 'sourc'), ('used', 'use'), ('analytics', 'analyt'), ('requires', 'requir'), ('joining', 'join'), ('unstructured', 'unstructur'), ('data', 'data'), ('(', '('), ('texts', 'text'), ('natural', 'natur'), ('language', 'languag'), (')', ')'), ('semi-structured', 'semi-structur'), ('data', 'data'), ('(', '('), ('extensible', 'extens'), ('mark-up', 'mark-up'), ('language', 'languag'), ('(', '('), ('XML', 'xml'), (')', ')'), (',', ','), ('JSON', 'json'), ('rich', 'rich'), ('site', 'site'), ('summary', 'summari'), ('(', '('), ('RSS', 'rss'), (')', ')'), ('feeds', 'feed'), (')', ')'), ('common', 'common'), ('structured', 'structur'), ('data', 'data'), ('framework', 'framework'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('sources', 'source'), ('used', 'used'), ('analytics', 'analytics'), ('requires', 'requires'), ('joining', 'joining'), ('unstructured', 'unstructured'), ('data', 'data'), ('(', '('), ('texts', 'text'), ('natural', 'natural'), ('language', 'language'), (')', ')'), ('semi-structured', 'semi-structured'), ('data', 'data'), ('(', '('), ('extensible', 'extensible'), ('mark-up', 'mark-up'), ('language', 'language'), ('(', '('), ('XML', 'XML'), (')', ')'), (',', ','), ('JSON', 'JSON'), ('rich', 'rich'), ('site', 'site'), ('summary', 'summary'), ('(', '('), ('RSS', 'RSS'), (')', ')'), ('feeds', 'feed'), (')', ')'), ('common', 'common'), ('structured', 'structured'), ('data', 'data'), ('framework', 'framework'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 200 =============================

Figure 10: Big data in terms of the 5 V's. 


>> Tokens are: 
 ['Figure', '10', ':', 'Big', 'data', 'terms', '5', 'V', "'s", '.']

>> Bigrams are: 
 [('Figure', '10'), ('10', ':'), (':', 'Big'), ('Big', 'data'), ('data', 'terms'), ('terms', '5'), ('5', 'V'), ('V', "'s"), ("'s", '.')]

>> Trigrams are: 
 [('Figure', '10', ':'), ('10', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', 'terms'), ('data', 'terms', '5'), ('terms', '5', 'V'), ('5', 'V', "'s"), ('V', "'s", '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('10', 'CD'), (':', ':'), ('Big', 'JJ'), ('data', 'NNS'), ('terms', 'NNS'), ('5', 'CD'), ('V', 'NNP'), ("'s", 'POS'), ('.', '.')]

 (S
  (NP Figure/NN)
  10/CD
  :/:
  (NP Big/JJ data/NNS terms/NNS)
  5/CD
  (NP V/NNP)
  's/POS
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Big data terms', 'V']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('10', '10'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('terms', 'term'), ('5', '5'), ('V', 'v'), ("'s", "'s"), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('10', '10'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('terms', 'term'), ('5', '5'), ('V', 'v'), ("'s", "'s"), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('10', '10'), (':', ':'), ('Big', 'Big'), ('data', 'data'), ('terms', 'term'), ('5', '5'), ('V', 'V'), ("'s", "'s"), ('.', '.')]



============================ Sentence 201 =============================

Multi-dimensional data can be used to add historical context to big data. 


>> Tokens are: 
 ['Multi-dimensional', 'data', 'used', 'add', 'historical', 'context', 'big', 'data', '.']

>> Bigrams are: 
 [('Multi-dimensional', 'data'), ('data', 'used'), ('used', 'add'), ('add', 'historical'), ('historical', 'context'), ('context', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Multi-dimensional', 'data', 'used'), ('data', 'used', 'add'), ('used', 'add', 'historical'), ('add', 'historical', 'context'), ('historical', 'context', 'big'), ('context', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Multi-dimensional', 'JJ'), ('data', 'NNS'), ('used', 'VBN'), ('add', 'JJ'), ('historical', 'JJ'), ('context', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Multi-dimensional/JJ data/NNS)
  used/VBN
  (NP add/JJ historical/JJ context/NN)
  (NP big/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Multi-dimensional data', 'add historical context', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Multi-dimensional', 'multi-dimension'), ('data', 'data'), ('used', 'use'), ('add', 'add'), ('historical', 'histor'), ('context', 'context'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Multi-dimensional', 'multi-dimension'), ('data', 'data'), ('used', 'use'), ('add', 'add'), ('historical', 'histor'), ('context', 'context'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Multi-dimensional', 'Multi-dimensional'), ('data', 'data'), ('used', 'used'), ('add', 'add'), ('historical', 'historical'), ('context', 'context'), ('big', 'big'), ('data', 'data'), ('.', '.')]



============================ Sentence 202 =============================

The variety of big data is   as important as its volume, while velocity or speed can describe how difficult big data may be to     Sarah Al-Shiakhli   17      handle. 


>> Tokens are: 
 ['The', 'variety', 'big', 'data', 'important', 'volume', ',', 'velocity', 'speed', 'describe', 'difficult', 'big', 'data', 'may', 'Sarah', 'Al-Shiakhli', '17', 'handle', '.']

>> Bigrams are: 
 [('The', 'variety'), ('variety', 'big'), ('big', 'data'), ('data', 'important'), ('important', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', 'speed'), ('speed', 'describe'), ('describe', 'difficult'), ('difficult', 'big'), ('big', 'data'), ('data', 'may'), ('may', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '17'), ('17', 'handle'), ('handle', '.')]

>> Trigrams are: 
 [('The', 'variety', 'big'), ('variety', 'big', 'data'), ('big', 'data', 'important'), ('data', 'important', 'volume'), ('important', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', 'speed'), ('velocity', 'speed', 'describe'), ('speed', 'describe', 'difficult'), ('describe', 'difficult', 'big'), ('difficult', 'big', 'data'), ('big', 'data', 'may'), ('data', 'may', 'Sarah'), ('may', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '17'), ('Al-Shiakhli', '17', 'handle'), ('17', 'handle', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('variety', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('important', 'JJ'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), ('speed', 'NN'), ('describe', 'NN'), ('difficult', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('may', 'MD'), ('Sarah', 'VB'), ('Al-Shiakhli', 'NNP'), ('17', 'CD'), ('handle', 'NN'), ('.', '.')]

 (S
  (NP The/DT variety/NN)
  (NP big/JJ data/NNS)
  (NP important/JJ volume/NN)
  ,/,
  (NP velocity/NN speed/NN describe/NN)
  (NP difficult/JJ big/JJ data/NNS)
  may/MD
  Sarah/VB
  (NP Al-Shiakhli/NNP)
  17/CD
  (NP handle/NN)
  ./.) 


>> Noun Phrases are: 
 ['The variety', 'big data', 'important volume', 'velocity speed describe', 'difficult big data', 'Al-Shiakhli', 'handle']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('variety', 'varieti'), ('big', 'big'), ('data', 'data'), ('important', 'import'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('speed', 'speed'), ('describe', 'describ'), ('difficult', 'difficult'), ('big', 'big'), ('data', 'data'), ('may', 'may'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('17', '17'), ('handle', 'handl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('variety', 'varieti'), ('big', 'big'), ('data', 'data'), ('important', 'import'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('speed', 'speed'), ('describe', 'describ'), ('difficult', 'difficult'), ('big', 'big'), ('data', 'data'), ('may', 'may'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('17', '17'), ('handle', 'handl'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('variety', 'variety'), ('big', 'big'), ('data', 'data'), ('important', 'important'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), ('speed', 'speed'), ('describe', 'describe'), ('difficult', 'difficult'), ('big', 'big'), ('data', 'data'), ('may', 'may'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('17', '17'), ('handle', 'handle'), ('.', '.')]



============================ Sentence 203 =============================

Velocity may refer to data generation frequency or data delivery frequency. 


>> Tokens are: 
 ['Velocity', 'may', 'refer', 'data', 'generation', 'frequency', 'data', 'delivery', 'frequency', '.']

>> Bigrams are: 
 [('Velocity', 'may'), ('may', 'refer'), ('refer', 'data'), ('data', 'generation'), ('generation', 'frequency'), ('frequency', 'data'), ('data', 'delivery'), ('delivery', 'frequency'), ('frequency', '.')]

>> Trigrams are: 
 [('Velocity', 'may', 'refer'), ('may', 'refer', 'data'), ('refer', 'data', 'generation'), ('data', 'generation', 'frequency'), ('generation', 'frequency', 'data'), ('frequency', 'data', 'delivery'), ('data', 'delivery', 'frequency'), ('delivery', 'frequency', '.')]

>> POS Tags are: 
 [('Velocity', 'NN'), ('may', 'MD'), ('refer', 'VB'), ('data', 'NNS'), ('generation', 'NN'), ('frequency', 'NN'), ('data', 'NNS'), ('delivery', 'NN'), ('frequency', 'NN'), ('.', '.')]

 (S
  (NP Velocity/NN)
  may/MD
  refer/VB
  (NP
    data/NNS
    generation/NN
    frequency/NN
    data/NNS
    delivery/NN
    frequency/NN)
  ./.) 


>> Noun Phrases are: 
 ['Velocity', 'data generation frequency data delivery frequency']

>> Named Entities are: 
 [('GPE', 'Velocity')] 

>> Stemming using Porter Stemmer: 
 [('Velocity', 'veloc'), ('may', 'may'), ('refer', 'refer'), ('data', 'data'), ('generation', 'gener'), ('frequency', 'frequenc'), ('data', 'data'), ('delivery', 'deliveri'), ('frequency', 'frequenc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Velocity', 'veloc'), ('may', 'may'), ('refer', 'refer'), ('data', 'data'), ('generation', 'generat'), ('frequency', 'frequenc'), ('data', 'data'), ('delivery', 'deliveri'), ('frequency', 'frequenc'), ('.', '.')]

>> Lemmatization: 
 [('Velocity', 'Velocity'), ('may', 'may'), ('refer', 'refer'), ('data', 'data'), ('generation', 'generation'), ('frequency', 'frequency'), ('data', 'data'), ('delivery', 'delivery'), ('frequency', 'frequency'), ('.', '.')]



============================ Sentence 204 =============================

Depending on   data inconsistency, incompleteness, ambiguity, latency, deception, and approximations, big data   quality can also be characterised as undefined, good, or bad (Data, D.B., 2012). 


>> Tokens are: 
 ['Depending', 'data', 'inconsistency', ',', 'incompleteness', ',', 'ambiguity', ',', 'latency', ',', 'deception', ',', 'approximations', ',', 'big', 'data', 'quality', 'also', 'characterised', 'undefined', ',', 'good', ',', 'bad', '(', 'Data', ',', 'D.B.', ',', '2012', ')', '.']

>> Bigrams are: 
 [('Depending', 'data'), ('data', 'inconsistency'), ('inconsistency', ','), (',', 'incompleteness'), ('incompleteness', ','), (',', 'ambiguity'), ('ambiguity', ','), (',', 'latency'), ('latency', ','), (',', 'deception'), ('deception', ','), (',', 'approximations'), ('approximations', ','), (',', 'big'), ('big', 'data'), ('data', 'quality'), ('quality', 'also'), ('also', 'characterised'), ('characterised', 'undefined'), ('undefined', ','), (',', 'good'), ('good', ','), (',', 'bad'), ('bad', '('), ('(', 'Data'), ('Data', ','), (',', 'D.B.'), ('D.B.', ','), (',', '2012'), ('2012', ')'), (')', '.')]

>> Trigrams are: 
 [('Depending', 'data', 'inconsistency'), ('data', 'inconsistency', ','), ('inconsistency', ',', 'incompleteness'), (',', 'incompleteness', ','), ('incompleteness', ',', 'ambiguity'), (',', 'ambiguity', ','), ('ambiguity', ',', 'latency'), (',', 'latency', ','), ('latency', ',', 'deception'), (',', 'deception', ','), ('deception', ',', 'approximations'), (',', 'approximations', ','), ('approximations', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'quality'), ('data', 'quality', 'also'), ('quality', 'also', 'characterised'), ('also', 'characterised', 'undefined'), ('characterised', 'undefined', ','), ('undefined', ',', 'good'), (',', 'good', ','), ('good', ',', 'bad'), (',', 'bad', '('), ('bad', '(', 'Data'), ('(', 'Data', ','), ('Data', ',', 'D.B.'), (',', 'D.B.', ','), ('D.B.', ',', '2012'), (',', '2012', ')'), ('2012', ')', '.')]

>> POS Tags are: 
 [('Depending', 'VBG'), ('data', 'NNS'), ('inconsistency', 'NN'), (',', ','), ('incompleteness', 'NN'), (',', ','), ('ambiguity', 'NN'), (',', ','), ('latency', 'NN'), (',', ','), ('deception', 'NN'), (',', ','), ('approximations', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('quality', 'NN'), ('also', 'RB'), ('characterised', 'VBD'), ('undefined', 'JJ'), (',', ','), ('good', 'JJ'), (',', ','), ('bad', 'JJ'), ('(', '('), ('Data', 'NNP'), (',', ','), ('D.B.', 'NNP'), (',', ','), ('2012', 'CD'), (')', ')'), ('.', '.')]

 (S
  Depending/VBG
  (NP data/NNS inconsistency/NN)
  ,/,
  (NP incompleteness/NN)
  ,/,
  (NP ambiguity/NN)
  ,/,
  (NP latency/NN)
  ,/,
  (NP deception/NN)
  ,/,
  (NP approximations/NNS)
  ,/,
  (NP big/JJ data/NNS quality/NN)
  also/RB
  characterised/VBD
  undefined/JJ
  ,/,
  good/JJ
  ,/,
  bad/JJ
  (/(
  (NP Data/NNP)
  ,/,
  (NP D.B./NNP)
  ,/,
  2012/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['data inconsistency', 'incompleteness', 'ambiguity', 'latency', 'deception', 'approximations', 'big data quality', 'Data', 'D.B.']

>> Named Entities are: 
 [('ORGANIZATION', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Depending', 'depend'), ('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ','), ('approximations', 'approxim'), (',', ','), ('big', 'big'), ('data', 'data'), ('quality', 'qualiti'), ('also', 'also'), ('characterised', 'characteris'), ('undefined', 'undefin'), (',', ','), ('good', 'good'), (',', ','), ('bad', 'bad'), ('(', '('), ('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Depending', 'depend'), ('data', 'data'), ('inconsistency', 'inconsist'), (',', ','), ('incompleteness', 'incomplet'), (',', ','), ('ambiguity', 'ambigu'), (',', ','), ('latency', 'latenc'), (',', ','), ('deception', 'decept'), (',', ','), ('approximations', 'approxim'), (',', ','), ('big', 'big'), ('data', 'data'), ('quality', 'qualiti'), ('also', 'also'), ('characterised', 'characteris'), ('undefined', 'undefin'), (',', ','), ('good', 'good'), (',', ','), ('bad', 'bad'), ('(', '('), ('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Depending', 'Depending'), ('data', 'data'), ('inconsistency', 'inconsistency'), (',', ','), ('incompleteness', 'incompleteness'), (',', ','), ('ambiguity', 'ambiguity'), (',', ','), ('latency', 'latency'), (',', ','), ('deception', 'deception'), (',', ','), ('approximations', 'approximation'), (',', ','), ('big', 'big'), ('data', 'data'), ('quality', 'quality'), ('also', 'also'), ('characterised', 'characterised'), ('undefined', 'undefined'), (',', ','), ('good', 'good'), (',', ','), ('bad', 'bad'), ('(', '('), ('Data', 'Data'), (',', ','), ('D.B.', 'D.B.'), (',', ','), ('2012', '2012'), (')', ')'), ('.', '.')]



============================ Sentence 205 =============================

According to Mikalef et al. 


>> Tokens are: 
 ['According', 'Mikalef', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'Mikalef', 'et'), ('Mikalef', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Mikalef', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

 (S According/VBG (NP Mikalef/NNP et/NN al/NN) ./.) 


>> Noun Phrases are: 
 ['Mikalef et al']

>> Named Entities are: 
 [('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 206 =============================

(2018), various researchers focus on different aspects of big data, as   shown in Table 3. 


>> Tokens are: 
 ['(', '2018', ')', ',', 'various', 'researchers', 'focus', 'different', 'aspects', 'big', 'data', ',', 'shown', 'Table', '3', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', ','), (',', 'various'), ('various', 'researchers'), ('researchers', 'focus'), ('focus', 'different'), ('different', 'aspects'), ('aspects', 'big'), ('big', 'data'), ('data', ','), (',', 'shown'), ('shown', 'Table'), ('Table', '3'), ('3', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', ','), (')', ',', 'various'), (',', 'various', 'researchers'), ('various', 'researchers', 'focus'), ('researchers', 'focus', 'different'), ('focus', 'different', 'aspects'), ('different', 'aspects', 'big'), ('aspects', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'shown'), (',', 'shown', 'Table'), ('shown', 'Table', '3'), ('Table', '3', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), (',', ','), ('various', 'JJ'), ('researchers', 'NNS'), ('focus', 'VBP'), ('different', 'JJ'), ('aspects', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('shown', 'VBN'), ('Table', 'JJ'), ('3', 'CD'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  ,/,
  (NP various/JJ researchers/NNS)
  focus/VBP
  (NP different/JJ aspects/NNS)
  (NP big/JJ data/NNS)
  ,/,
  shown/VBN
  Table/JJ
  3/CD
  ./.) 


>> Noun Phrases are: 
 ['various researchers', 'different aspects', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), (',', ','), ('various', 'variou'), ('researchers', 'research'), ('focus', 'focu'), ('different', 'differ'), ('aspects', 'aspect'), ('big', 'big'), ('data', 'data'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), (',', ','), ('various', 'various'), ('researchers', 'research'), ('focus', 'focus'), ('different', 'differ'), ('aspects', 'aspect'), ('big', 'big'), ('data', 'data'), (',', ','), ('shown', 'shown'), ('Table', 'tabl'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), (',', ','), ('various', 'various'), ('researchers', 'researcher'), ('focus', 'focus'), ('different', 'different'), ('aspects', 'aspect'), ('big', 'big'), ('data', 'data'), (',', ','), ('shown', 'shown'), ('Table', 'Table'), ('3', '3'), ('.', '.')]



============================ Sentence 207 =============================

Table 3: Defining characteristics of big data, adopted from (Mikalef et al., 2018)         Sarah Al-Shiakhli   18      7. 


>> Tokens are: 
 ['Table', '3', ':', 'Defining', 'characteristics', 'big', 'data', ',', 'adopted', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')', 'Sarah', 'Al-Shiakhli', '18', '7', '.']

>> Bigrams are: 
 [('Table', '3'), ('3', ':'), (':', 'Defining'), ('Defining', 'characteristics'), ('characteristics', 'big'), ('big', 'data'), ('data', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '18'), ('18', '7'), ('7', '.')]

>> Trigrams are: 
 [('Table', '3', ':'), ('3', ':', 'Defining'), (':', 'Defining', 'characteristics'), ('Defining', 'characteristics', 'big'), ('characteristics', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', 'Sarah'), (')', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '18'), ('Al-Shiakhli', '18', '7'), ('18', '7', '.')]

>> POS Tags are: 
 [('Table', 'JJ'), ('3', 'CD'), (':', ':'), ('Defining', 'NN'), ('characteristics', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('18', 'CD'), ('7', 'CD'), ('.', '.')]

 (S
  Table/JJ
  3/CD
  :/:
  (NP Defining/NN characteristics/NNS)
  (NP big/JJ data/NNS)
  ,/,
  adopted/VBN
  (/(
  (NP Mikalef/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  (NP Sarah/NNP Al-Shiakhli/NNP)
  18/CD
  7/CD
  ./.) 


>> Noun Phrases are: 
 ['Defining characteristics', 'big data', 'Mikalef', 'Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Mikalef'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Table', 'tabl'), ('3', '3'), (':', ':'), ('Defining', 'defin'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('18', '18'), ('7', '7'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Table', 'tabl'), ('3', '3'), (':', ':'), ('Defining', 'defin'), ('characteristics', 'characterist'), ('big', 'big'), ('data', 'data'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('18', '18'), ('7', '7'), ('.', '.')]

>> Lemmatization: 
 [('Table', 'Table'), ('3', '3'), (':', ':'), ('Defining', 'Defining'), ('characteristics', 'characteristic'), ('big', 'big'), ('data', 'data'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('18', '18'), ('7', '7'), ('.', '.')]



============================ Sentence 208 =============================

Big data analytics (BDA): tools and methods   7.1. 


>> Tokens are: 
 ['Big', 'data', 'analytics', '(', 'BDA', ')', ':', 'tools', 'methods', '7.1', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', '('), ('(', 'BDA'), ('BDA', ')'), (')', ':'), (':', 'tools'), ('tools', 'methods'), ('methods', '7.1'), ('7.1', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', '('), ('analytics', '(', 'BDA'), ('(', 'BDA', ')'), ('BDA', ')', ':'), (')', ':', 'tools'), (':', 'tools', 'methods'), ('tools', 'methods', '7.1'), ('methods', '7.1', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('(', '('), ('BDA', 'NNP'), (')', ')'), (':', ':'), ('tools', 'NNS'), ('methods', 'NNS'), ('7.1', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  (/(
  (NP BDA/NNP)
  )/)
  :/:
  (NP tools/NNS methods/NNS)
  7.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'BDA', 'tools methods']

>> Named Entities are: 
 [('ORGANIZATION', 'BDA')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('7.1', '7.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('BDA', 'bda'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('7.1', '7.1'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('(', '('), ('BDA', 'BDA'), (')', ')'), (':', ':'), ('tools', 'tool'), ('methods', 'method'), ('7.1', '7.1'), ('.', '.')]



============================ Sentence 209 =============================

Big data storage and management   The most difficult problem that needs to be solved to handle big data effectively is storage; it is   not necessarily easy to deal with large quantities and varieties of data (Elgendy and Elragal, 2014;   Zhong, et al., 2016; Lv, Z. et al., 2017). 


>> Tokens are: 
 ['Big', 'data', 'storage', 'management', 'The', 'difficult', 'problem', 'needs', 'solved', 'handle', 'big', 'data', 'effectively', 'storage', ';', 'necessarily', 'easy', 'deal', 'large', 'quantities', 'varieties', 'data', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Zhong', ',', 'et', 'al.', ',', '2016', ';', 'Lv', ',', 'Z.', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'storage'), ('storage', 'management'), ('management', 'The'), ('The', 'difficult'), ('difficult', 'problem'), ('problem', 'needs'), ('needs', 'solved'), ('solved', 'handle'), ('handle', 'big'), ('big', 'data'), ('data', 'effectively'), ('effectively', 'storage'), ('storage', ';'), (';', 'necessarily'), ('necessarily', 'easy'), ('easy', 'deal'), ('deal', 'large'), ('large', 'quantities'), ('quantities', 'varieties'), ('varieties', 'data'), ('data', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Zhong'), ('Zhong', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Lv'), ('Lv', ','), (',', 'Z.'), ('Z.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'storage'), ('data', 'storage', 'management'), ('storage', 'management', 'The'), ('management', 'The', 'difficult'), ('The', 'difficult', 'problem'), ('difficult', 'problem', 'needs'), ('problem', 'needs', 'solved'), ('needs', 'solved', 'handle'), ('solved', 'handle', 'big'), ('handle', 'big', 'data'), ('big', 'data', 'effectively'), ('data', 'effectively', 'storage'), ('effectively', 'storage', ';'), ('storage', ';', 'necessarily'), (';', 'necessarily', 'easy'), ('necessarily', 'easy', 'deal'), ('easy', 'deal', 'large'), ('deal', 'large', 'quantities'), ('large', 'quantities', 'varieties'), ('quantities', 'varieties', 'data'), ('varieties', 'data', '('), ('data', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Zhong'), (';', 'Zhong', ','), ('Zhong', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Lv'), (';', 'Lv', ','), ('Lv', ',', 'Z.'), (',', 'Z.', 'et'), ('Z.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), ('management', 'NN'), ('The', 'DT'), ('difficult', 'JJ'), ('problem', 'NN'), ('needs', 'VBZ'), ('solved', 'VBN'), ('handle', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('effectively', 'RB'), ('storage', 'NN'), (';', ':'), ('necessarily', 'RB'), ('easy', 'JJ'), ('deal', 'NN'), ('large', 'JJ'), ('quantities', 'NNS'), ('varieties', 'NNS'), ('data', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Zhong', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (';', ':'), ('Lv', 'NNP'), (',', ','), ('Z.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS storage/NN management/NN)
  (NP The/DT difficult/JJ problem/NN)
  needs/VBZ
  solved/VBN
  (NP handle/JJ big/JJ data/NNS)
  effectively/RB
  (NP storage/NN)
  ;/:
  necessarily/RB
  (NP easy/JJ deal/NN)
  (NP large/JJ quantities/NNS varieties/NNS data/NNS)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Zhong/NNP)
  ,/,
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  ;/:
  (NP Lv/NNP)
  ,/,
  (NP Z./NNP)
  et/FW
  (NP al./NN)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data storage management', 'The difficult problem', 'handle big data', 'storage', 'easy deal', 'large quantities varieties data', 'Elgendy Elragal', 'Zhong', 'al.', 'Lv', 'Z.', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('GPE', 'Zhong')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('The', 'the'), ('difficult', 'difficult'), ('problem', 'problem'), ('needs', 'need'), ('solved', 'solv'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('effectively', 'effect'), ('storage', 'storag'), (';', ';'), ('necessarily', 'necessarili'), ('easy', 'easi'), ('deal', 'deal'), ('large', 'larg'), ('quantities', 'quantiti'), ('varieties', 'varieti'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Zhong', 'zhong'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Lv', 'lv'), (',', ','), ('Z.', 'z.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('The', 'the'), ('difficult', 'difficult'), ('problem', 'problem'), ('needs', 'need'), ('solved', 'solv'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('effectively', 'effect'), ('storage', 'storag'), (';', ';'), ('necessarily', 'necessarili'), ('easy', 'easi'), ('deal', 'deal'), ('large', 'larg'), ('quantities', 'quantiti'), ('varieties', 'varieti'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Zhong', 'zhong'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Lv', 'lv'), (',', ','), ('Z.', 'z.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('storage', 'storage'), ('management', 'management'), ('The', 'The'), ('difficult', 'difficult'), ('problem', 'problem'), ('needs', 'need'), ('solved', 'solved'), ('handle', 'handle'), ('big', 'big'), ('data', 'data'), ('effectively', 'effectively'), ('storage', 'storage'), (';', ';'), ('necessarily', 'necessarily'), ('easy', 'easy'), ('deal', 'deal'), ('large', 'large'), ('quantities', 'quantity'), ('varieties', 'variety'), ('data', 'data'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Zhong', 'Zhong'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Lv', 'Lv'), (',', ','), ('Z.', 'Z.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 210 =============================

There are many big data storage and analysis models. 


>> Tokens are: 
 ['There', 'many', 'big', 'data', 'storage', 'analysis', 'models', '.']

>> Bigrams are: 
 [('There', 'many'), ('many', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'analysis'), ('analysis', 'models'), ('models', '.')]

>> Trigrams are: 
 [('There', 'many', 'big'), ('many', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'analysis'), ('storage', 'analysis', 'models'), ('analysis', 'models', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('many', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('analysis', 'NN'), ('models', 'NNS'), ('.', '.')]

 (S
  There/EX
  (NP many/JJ big/JJ data/NNS storage/NN analysis/NN models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['many big data storage analysis models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('many', 'mani'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('analysis', 'analysi'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('many', 'mani'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('analysis', 'analysi'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('many', 'many'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('analysis', 'analysis'), ('models', 'model'), ('.', '.')]



============================ Sentence 211 =============================

Where the large amount of data is caused by   the sheer variety of users and devices, a data centre may be necessary for storing and processing   the data. 


>> Tokens are: 
 ['Where', 'large', 'amount', 'data', 'caused', 'sheer', 'variety', 'users', 'devices', ',', 'data', 'centre', 'may', 'necessary', 'storing', 'processing', 'data', '.']

>> Bigrams are: 
 [('Where', 'large'), ('large', 'amount'), ('amount', 'data'), ('data', 'caused'), ('caused', 'sheer'), ('sheer', 'variety'), ('variety', 'users'), ('users', 'devices'), ('devices', ','), (',', 'data'), ('data', 'centre'), ('centre', 'may'), ('may', 'necessary'), ('necessary', 'storing'), ('storing', 'processing'), ('processing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Where', 'large', 'amount'), ('large', 'amount', 'data'), ('amount', 'data', 'caused'), ('data', 'caused', 'sheer'), ('caused', 'sheer', 'variety'), ('sheer', 'variety', 'users'), ('variety', 'users', 'devices'), ('users', 'devices', ','), ('devices', ',', 'data'), (',', 'data', 'centre'), ('data', 'centre', 'may'), ('centre', 'may', 'necessary'), ('may', 'necessary', 'storing'), ('necessary', 'storing', 'processing'), ('storing', 'processing', 'data'), ('processing', 'data', '.')]

>> POS Tags are: 
 [('Where', 'WRB'), ('large', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('caused', 'VBD'), ('sheer', 'NN'), ('variety', 'NN'), ('users', 'NNS'), ('devices', 'NNS'), (',', ','), ('data', 'NNS'), ('centre', 'NN'), ('may', 'MD'), ('necessary', 'JJ'), ('storing', 'VBG'), ('processing', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  Where/WRB
  (NP large/JJ amount/NN data/NNS)
  caused/VBD
  (NP sheer/NN variety/NN users/NNS devices/NNS)
  ,/,
  (NP data/NNS centre/NN)
  may/MD
  necessary/JJ
  storing/VBG
  (NP processing/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['large amount data', 'sheer variety users devices', 'data centre', 'processing data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('large', 'larg'), ('amount', 'amount'), ('data', 'data'), ('caused', 'caus'), ('sheer', 'sheer'), ('variety', 'varieti'), ('users', 'user'), ('devices', 'devic'), (',', ','), ('data', 'data'), ('centre', 'centr'), ('may', 'may'), ('necessary', 'necessari'), ('storing', 'store'), ('processing', 'process'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('large', 'larg'), ('amount', 'amount'), ('data', 'data'), ('caused', 'caus'), ('sheer', 'sheer'), ('variety', 'varieti'), ('users', 'user'), ('devices', 'devic'), (',', ','), ('data', 'data'), ('centre', 'centr'), ('may', 'may'), ('necessary', 'necessari'), ('storing', 'store'), ('processing', 'process'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Where', 'Where'), ('large', 'large'), ('amount', 'amount'), ('data', 'data'), ('caused', 'caused'), ('sheer', 'sheer'), ('variety', 'variety'), ('users', 'user'), ('devices', 'device'), (',', ','), ('data', 'data'), ('centre', 'centre'), ('may', 'may'), ('necessary', 'necessary'), ('storing', 'storing'), ('processing', 'processing'), ('data', 'data'), ('.', '.')]



============================ Sentence 212 =============================

Establishing network infrastructure is necessary to help gather this rapidly generated data,   which is then sent to the data centre before being accessed by users (Lv et al., 2017). 


>> Tokens are: 
 ['Establishing', 'network', 'infrastructure', 'necessary', 'help', 'gather', 'rapidly', 'generated', 'data', ',', 'sent', 'data', 'centre', 'accessed', 'users', '(', 'Lv', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Establishing', 'network'), ('network', 'infrastructure'), ('infrastructure', 'necessary'), ('necessary', 'help'), ('help', 'gather'), ('gather', 'rapidly'), ('rapidly', 'generated'), ('generated', 'data'), ('data', ','), (',', 'sent'), ('sent', 'data'), ('data', 'centre'), ('centre', 'accessed'), ('accessed', 'users'), ('users', '('), ('(', 'Lv'), ('Lv', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Establishing', 'network', 'infrastructure'), ('network', 'infrastructure', 'necessary'), ('infrastructure', 'necessary', 'help'), ('necessary', 'help', 'gather'), ('help', 'gather', 'rapidly'), ('gather', 'rapidly', 'generated'), ('rapidly', 'generated', 'data'), ('generated', 'data', ','), ('data', ',', 'sent'), (',', 'sent', 'data'), ('sent', 'data', 'centre'), ('data', 'centre', 'accessed'), ('centre', 'accessed', 'users'), ('accessed', 'users', '('), ('users', '(', 'Lv'), ('(', 'Lv', 'et'), ('Lv', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Establishing', 'VBG'), ('network', 'NN'), ('infrastructure', 'NN'), ('necessary', 'JJ'), ('help', 'NN'), ('gather', 'VB'), ('rapidly', 'RB'), ('generated', 'VBN'), ('data', 'NNS'), (',', ','), ('sent', 'VBD'), ('data', 'NNS'), ('centre', 'NNS'), ('accessed', 'VBD'), ('users', 'NNS'), ('(', '('), ('Lv', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  Establishing/VBG
  (NP network/NN infrastructure/NN)
  (NP necessary/JJ help/NN)
  gather/VB
  rapidly/RB
  generated/VBN
  (NP data/NNS)
  ,/,
  sent/VBD
  (NP data/NNS centre/NNS)
  accessed/VBD
  (NP users/NNS)
  (/(
  (NP Lv/NNP)
  et/RB
  al./RB
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['network infrastructure', 'necessary help', 'data', 'data centre', 'users', 'Lv']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Establishing', 'establish'), ('network', 'network'), ('infrastructure', 'infrastructur'), ('necessary', 'necessari'), ('help', 'help'), ('gather', 'gather'), ('rapidly', 'rapidli'), ('generated', 'gener'), ('data', 'data'), (',', ','), ('sent', 'sent'), ('data', 'data'), ('centre', 'centr'), ('accessed', 'access'), ('users', 'user'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Establishing', 'establish'), ('network', 'network'), ('infrastructure', 'infrastructur'), ('necessary', 'necessari'), ('help', 'help'), ('gather', 'gather'), ('rapidly', 'rapid'), ('generated', 'generat'), ('data', 'data'), (',', ','), ('sent', 'sent'), ('data', 'data'), ('centre', 'centr'), ('accessed', 'access'), ('users', 'user'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Establishing', 'Establishing'), ('network', 'network'), ('infrastructure', 'infrastructure'), ('necessary', 'necessary'), ('help', 'help'), ('gather', 'gather'), ('rapidly', 'rapidly'), ('generated', 'generated'), ('data', 'data'), (',', ','), ('sent', 'sent'), ('data', 'data'), ('centre', 'centre'), ('accessed', 'accessed'), ('users', 'user'), ('(', '('), ('Lv', 'Lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 213 =============================

Research by Yi et al. 


>> Tokens are: 
 ['Research', 'Yi', 'et', 'al', '.']

>> Bigrams are: 
 [('Research', 'Yi'), ('Yi', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Research', 'Yi', 'et'), ('Yi', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Research', 'NNP'), ('Yi', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S (NP Research/NNP Yi/NNP) et/FW (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Research Yi', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Yi', 'yi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Yi', 'yi'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Yi', 'Yi'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 214 =============================

(2014) identifies the components of the network that must be established,   such as an original data network, the bridges used for connecting and transmitting to data centres,   and at least one data centre. 


>> Tokens are: 
 ['(', '2014', ')', 'identifies', 'components', 'network', 'must', 'established', ',', 'original', 'data', 'network', ',', 'bridges', 'used', 'connecting', 'transmitting', 'data', 'centres', ',', 'least', 'one', 'data', 'centre', '.']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'identifies'), ('identifies', 'components'), ('components', 'network'), ('network', 'must'), ('must', 'established'), ('established', ','), (',', 'original'), ('original', 'data'), ('data', 'network'), ('network', ','), (',', 'bridges'), ('bridges', 'used'), ('used', 'connecting'), ('connecting', 'transmitting'), ('transmitting', 'data'), ('data', 'centres'), ('centres', ','), (',', 'least'), ('least', 'one'), ('one', 'data'), ('data', 'centre'), ('centre', '.')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'identifies'), (')', 'identifies', 'components'), ('identifies', 'components', 'network'), ('components', 'network', 'must'), ('network', 'must', 'established'), ('must', 'established', ','), ('established', ',', 'original'), (',', 'original', 'data'), ('original', 'data', 'network'), ('data', 'network', ','), ('network', ',', 'bridges'), (',', 'bridges', 'used'), ('bridges', 'used', 'connecting'), ('used', 'connecting', 'transmitting'), ('connecting', 'transmitting', 'data'), ('transmitting', 'data', 'centres'), ('data', 'centres', ','), ('centres', ',', 'least'), (',', 'least', 'one'), ('least', 'one', 'data'), ('one', 'data', 'centre'), ('data', 'centre', '.')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('identifies', 'VBZ'), ('components', 'NNS'), ('network', 'NN'), ('must', 'MD'), ('established', 'VB'), (',', ','), ('original', 'JJ'), ('data', 'NN'), ('network', 'NN'), (',', ','), ('bridges', 'NNS'), ('used', 'VBD'), ('connecting', 'VBG'), ('transmitting', 'VBG'), ('data', 'NNS'), ('centres', 'NNS'), (',', ','), ('least', 'JJS'), ('one', 'CD'), ('data', 'NN'), ('centre', 'NN'), ('.', '.')]

 (S
  (/(
  2014/CD
  )/)
  identifies/VBZ
  (NP components/NNS network/NN)
  must/MD
  established/VB
  ,/,
  (NP original/JJ data/NN network/NN)
  ,/,
  (NP bridges/NNS)
  used/VBD
  connecting/VBG
  transmitting/VBG
  (NP data/NNS centres/NNS)
  ,/,
  least/JJS
  one/CD
  (NP data/NN centre/NN)
  ./.) 


>> Noun Phrases are: 
 ['components network', 'original data network', 'bridges', 'data centres', 'data centre']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('identifies', 'identifi'), ('components', 'compon'), ('network', 'network'), ('must', 'must'), ('established', 'establish'), (',', ','), ('original', 'origin'), ('data', 'data'), ('network', 'network'), (',', ','), ('bridges', 'bridg'), ('used', 'use'), ('connecting', 'connect'), ('transmitting', 'transmit'), ('data', 'data'), ('centres', 'centr'), (',', ','), ('least', 'least'), ('one', 'one'), ('data', 'data'), ('centre', 'centr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('identifies', 'identifi'), ('components', 'compon'), ('network', 'network'), ('must', 'must'), ('established', 'establish'), (',', ','), ('original', 'origin'), ('data', 'data'), ('network', 'network'), (',', ','), ('bridges', 'bridg'), ('used', 'use'), ('connecting', 'connect'), ('transmitting', 'transmit'), ('data', 'data'), ('centres', 'centr'), (',', ','), ('least', 'least'), ('one', 'one'), ('data', 'data'), ('centre', 'centr'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('identifies', 'identifies'), ('components', 'component'), ('network', 'network'), ('must', 'must'), ('established', 'established'), (',', ','), ('original', 'original'), ('data', 'data'), ('network', 'network'), (',', ','), ('bridges', 'bridge'), ('used', 'used'), ('connecting', 'connecting'), ('transmitting', 'transmitting'), ('data', 'data'), ('centres', 'centre'), (',', ','), ('least', 'least'), ('one', 'one'), ('data', 'data'), ('centre', 'centre'), ('.', '.')]



============================ Sentence 215 =============================

Another study (H. Eszter, 2015) highlighted the issues in using big data through specific locations   and showed that the users could not select data through the data network. 


>> Tokens are: 
 ['Another', 'study', '(', 'H.', 'Eszter', ',', '2015', ')', 'highlighted', 'issues', 'using', 'big', 'data', 'specific', 'locations', 'showed', 'users', 'could', 'select', 'data', 'data', 'network', '.']

>> Bigrams are: 
 [('Another', 'study'), ('study', '('), ('(', 'H.'), ('H.', 'Eszter'), ('Eszter', ','), (',', '2015'), ('2015', ')'), (')', 'highlighted'), ('highlighted', 'issues'), ('issues', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'specific'), ('specific', 'locations'), ('locations', 'showed'), ('showed', 'users'), ('users', 'could'), ('could', 'select'), ('select', 'data'), ('data', 'data'), ('data', 'network'), ('network', '.')]

>> Trigrams are: 
 [('Another', 'study', '('), ('study', '(', 'H.'), ('(', 'H.', 'Eszter'), ('H.', 'Eszter', ','), ('Eszter', ',', '2015'), (',', '2015', ')'), ('2015', ')', 'highlighted'), (')', 'highlighted', 'issues'), ('highlighted', 'issues', 'using'), ('issues', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'specific'), ('data', 'specific', 'locations'), ('specific', 'locations', 'showed'), ('locations', 'showed', 'users'), ('showed', 'users', 'could'), ('users', 'could', 'select'), ('could', 'select', 'data'), ('select', 'data', 'data'), ('data', 'data', 'network'), ('data', 'network', '.')]

>> POS Tags are: 
 [('Another', 'DT'), ('study', 'NN'), ('(', '('), ('H.', 'NNP'), ('Eszter', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('highlighted', 'VBD'), ('issues', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('specific', 'JJ'), ('locations', 'NNS'), ('showed', 'VBD'), ('users', 'NNS'), ('could', 'MD'), ('select', 'VB'), ('data', 'NNS'), ('data', 'NNS'), ('network', 'NN'), ('.', '.')]

 (S
  (NP Another/DT study/NN)
  (/(
  (NP H./NNP Eszter/NNP)
  ,/,
  2015/CD
  )/)
  highlighted/VBD
  (NP issues/NNS)
  using/VBG
  (NP big/JJ data/NNS)
  (NP specific/JJ locations/NNS)
  showed/VBD
  (NP users/NNS)
  could/MD
  select/VB
  (NP data/NNS data/NNS network/NN)
  ./.) 


>> Noun Phrases are: 
 ['Another study', 'H. Eszter', 'issues', 'big data', 'specific locations', 'users', 'data data network']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('(', '('), ('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), (')', ')'), ('highlighted', 'highlight'), ('issues', 'issu'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('specific', 'specif'), ('locations', 'locat'), ('showed', 'show'), ('users', 'user'), ('could', 'could'), ('select', 'select'), ('data', 'data'), ('data', 'data'), ('network', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Another', 'anoth'), ('study', 'studi'), ('(', '('), ('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), (')', ')'), ('highlighted', 'highlight'), ('issues', 'issu'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('specific', 'specif'), ('locations', 'locat'), ('showed', 'show'), ('users', 'user'), ('could', 'could'), ('select', 'select'), ('data', 'data'), ('data', 'data'), ('network', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Another', 'Another'), ('study', 'study'), ('(', '('), ('H.', 'H.'), ('Eszter', 'Eszter'), (',', ','), ('2015', '2015'), (')', ')'), ('highlighted', 'highlighted'), ('issues', 'issue'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('specific', 'specific'), ('locations', 'location'), ('showed', 'showed'), ('users', 'user'), ('could', 'could'), ('select', 'select'), ('data', 'data'), ('data', 'data'), ('network', 'network'), ('.', '.')]



============================ Sentence 216 =============================

For storage models, the   most important challenge is how to deal with the sheer amount of data, as ultra-scalable solutions   can block the processing of certain data sources, causing inefficiency. 


>> Tokens are: 
 ['For', 'storage', 'models', ',', 'important', 'challenge', 'deal', 'sheer', 'amount', 'data', ',', 'ultra-scalable', 'solutions', 'block', 'processing', 'certain', 'data', 'sources', ',', 'causing', 'inefficiency', '.']

>> Bigrams are: 
 [('For', 'storage'), ('storage', 'models'), ('models', ','), (',', 'important'), ('important', 'challenge'), ('challenge', 'deal'), ('deal', 'sheer'), ('sheer', 'amount'), ('amount', 'data'), ('data', ','), (',', 'ultra-scalable'), ('ultra-scalable', 'solutions'), ('solutions', 'block'), ('block', 'processing'), ('processing', 'certain'), ('certain', 'data'), ('data', 'sources'), ('sources', ','), (',', 'causing'), ('causing', 'inefficiency'), ('inefficiency', '.')]

>> Trigrams are: 
 [('For', 'storage', 'models'), ('storage', 'models', ','), ('models', ',', 'important'), (',', 'important', 'challenge'), ('important', 'challenge', 'deal'), ('challenge', 'deal', 'sheer'), ('deal', 'sheer', 'amount'), ('sheer', 'amount', 'data'), ('amount', 'data', ','), ('data', ',', 'ultra-scalable'), (',', 'ultra-scalable', 'solutions'), ('ultra-scalable', 'solutions', 'block'), ('solutions', 'block', 'processing'), ('block', 'processing', 'certain'), ('processing', 'certain', 'data'), ('certain', 'data', 'sources'), ('data', 'sources', ','), ('sources', ',', 'causing'), (',', 'causing', 'inefficiency'), ('causing', 'inefficiency', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('storage', 'NN'), ('models', 'NNS'), (',', ','), ('important', 'JJ'), ('challenge', 'NN'), ('deal', 'NN'), ('sheer', 'NN'), ('amount', 'NN'), ('data', 'NNS'), (',', ','), ('ultra-scalable', 'JJ'), ('solutions', 'NNS'), ('block', 'NN'), ('processing', 'NN'), ('certain', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), (',', ','), ('causing', 'VBG'), ('inefficiency', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP storage/NN models/NNS)
  ,/,
  (NP important/JJ challenge/NN deal/NN sheer/NN amount/NN data/NNS)
  ,/,
  (NP ultra-scalable/JJ solutions/NNS block/NN processing/NN)
  (NP certain/JJ data/NNS sources/NNS)
  ,/,
  causing/VBG
  (NP inefficiency/NN)
  ./.) 


>> Noun Phrases are: 
 ['storage models', 'important challenge deal sheer amount data', 'ultra-scalable solutions block processing', 'certain data sources', 'inefficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('storage', 'storag'), ('models', 'model'), (',', ','), ('important', 'import'), ('challenge', 'challeng'), ('deal', 'deal'), ('sheer', 'sheer'), ('amount', 'amount'), ('data', 'data'), (',', ','), ('ultra-scalable', 'ultra-scal'), ('solutions', 'solut'), ('block', 'block'), ('processing', 'process'), ('certain', 'certain'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('causing', 'caus'), ('inefficiency', 'ineffici'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('storage', 'storag'), ('models', 'model'), (',', ','), ('important', 'import'), ('challenge', 'challeng'), ('deal', 'deal'), ('sheer', 'sheer'), ('amount', 'amount'), ('data', 'data'), (',', ','), ('ultra-scalable', 'ultra-scal'), ('solutions', 'solut'), ('block', 'block'), ('processing', 'process'), ('certain', 'certain'), ('data', 'data'), ('sources', 'sourc'), (',', ','), ('causing', 'caus'), ('inefficiency', 'ineffici'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('storage', 'storage'), ('models', 'model'), (',', ','), ('important', 'important'), ('challenge', 'challenge'), ('deal', 'deal'), ('sheer', 'sheer'), ('amount', 'amount'), ('data', 'data'), (',', ','), ('ultra-scalable', 'ultra-scalable'), ('solutions', 'solution'), ('block', 'block'), ('processing', 'processing'), ('certain', 'certain'), ('data', 'data'), ('sources', 'source'), (',', ','), ('causing', 'causing'), ('inefficiency', 'inefficiency'), ('.', '.')]



============================ Sentence 217 =============================

Building more scalable big   data technology is a challenge, and any new technology must offer data gathering and distribution   among nodes spread through the world (Lv et al., 2017). 


>> Tokens are: 
 ['Building', 'scalable', 'big', 'data', 'technology', 'challenge', ',', 'new', 'technology', 'must', 'offer', 'data', 'gathering', 'distribution', 'among', 'nodes', 'spread', 'world', '(', 'Lv', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Building', 'scalable'), ('scalable', 'big'), ('big', 'data'), ('data', 'technology'), ('technology', 'challenge'), ('challenge', ','), (',', 'new'), ('new', 'technology'), ('technology', 'must'), ('must', 'offer'), ('offer', 'data'), ('data', 'gathering'), ('gathering', 'distribution'), ('distribution', 'among'), ('among', 'nodes'), ('nodes', 'spread'), ('spread', 'world'), ('world', '('), ('(', 'Lv'), ('Lv', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Building', 'scalable', 'big'), ('scalable', 'big', 'data'), ('big', 'data', 'technology'), ('data', 'technology', 'challenge'), ('technology', 'challenge', ','), ('challenge', ',', 'new'), (',', 'new', 'technology'), ('new', 'technology', 'must'), ('technology', 'must', 'offer'), ('must', 'offer', 'data'), ('offer', 'data', 'gathering'), ('data', 'gathering', 'distribution'), ('gathering', 'distribution', 'among'), ('distribution', 'among', 'nodes'), ('among', 'nodes', 'spread'), ('nodes', 'spread', 'world'), ('spread', 'world', '('), ('world', '(', 'Lv'), ('(', 'Lv', 'et'), ('Lv', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Building', 'VBG'), ('scalable', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('technology', 'NN'), ('challenge', 'NN'), (',', ','), ('new', 'JJ'), ('technology', 'NN'), ('must', 'MD'), ('offer', 'VB'), ('data', 'NNS'), ('gathering', 'VBG'), ('distribution', 'NN'), ('among', 'IN'), ('nodes', 'NNS'), ('spread', 'JJ'), ('world', 'NN'), ('(', '('), ('Lv', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  Building/VBG
  (NP scalable/JJ big/JJ data/NNS technology/NN challenge/NN)
  ,/,
  (NP new/JJ technology/NN)
  must/MD
  offer/VB
  (NP data/NNS)
  gathering/VBG
  (NP distribution/NN)
  among/IN
  (NP nodes/NNS)
  (NP spread/JJ world/NN)
  (/(
  (NP Lv/NNP)
  et/RB
  al./RB
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['scalable big data technology challenge', 'new technology', 'data', 'distribution', 'nodes', 'spread world', 'Lv']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Building', 'build'), ('scalable', 'scalabl'), ('big', 'big'), ('data', 'data'), ('technology', 'technolog'), ('challenge', 'challeng'), (',', ','), ('new', 'new'), ('technology', 'technolog'), ('must', 'must'), ('offer', 'offer'), ('data', 'data'), ('gathering', 'gather'), ('distribution', 'distribut'), ('among', 'among'), ('nodes', 'node'), ('spread', 'spread'), ('world', 'world'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Building', 'build'), ('scalable', 'scalabl'), ('big', 'big'), ('data', 'data'), ('technology', 'technolog'), ('challenge', 'challeng'), (',', ','), ('new', 'new'), ('technology', 'technolog'), ('must', 'must'), ('offer', 'offer'), ('data', 'data'), ('gathering', 'gather'), ('distribution', 'distribut'), ('among', 'among'), ('nodes', 'node'), ('spread', 'spread'), ('world', 'world'), ('(', '('), ('Lv', 'lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Building', 'Building'), ('scalable', 'scalable'), ('big', 'big'), ('data', 'data'), ('technology', 'technology'), ('challenge', 'challenge'), (',', ','), ('new', 'new'), ('technology', 'technology'), ('must', 'must'), ('offer', 'offer'), ('data', 'data'), ('gathering', 'gathering'), ('distribution', 'distribution'), ('among', 'among'), ('nodes', 'node'), ('spread', 'spread'), ('world', 'world'), ('(', '('), ('Lv', 'Lv'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 218 =============================

Structured data storage and retrieval methods include “relational databases, data marts, and data   warehouses” (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 ['Structured', 'data', 'storage', 'retrieval', 'methods', 'include', '“', 'relational', 'databases', ',', 'data', 'marts', ',', 'data', 'warehouses', '”', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Structured', 'data'), ('data', 'storage'), ('storage', 'retrieval'), ('retrieval', 'methods'), ('methods', 'include'), ('include', '“'), ('“', 'relational'), ('relational', 'databases'), ('databases', ','), (',', 'data'), ('data', 'marts'), ('marts', ','), (',', 'data'), ('data', 'warehouses'), ('warehouses', '”'), ('”', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Structured', 'data', 'storage'), ('data', 'storage', 'retrieval'), ('storage', 'retrieval', 'methods'), ('retrieval', 'methods', 'include'), ('methods', 'include', '“'), ('include', '“', 'relational'), ('“', 'relational', 'databases'), ('relational', 'databases', ','), ('databases', ',', 'data'), (',', 'data', 'marts'), ('data', 'marts', ','), ('marts', ',', 'data'), (',', 'data', 'warehouses'), ('data', 'warehouses', '”'), ('warehouses', '”', '('), ('”', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Structured', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), ('retrieval', 'NN'), ('methods', 'NNS'), ('include', 'VBP'), ('“', 'JJ'), ('relational', 'JJ'), ('databases', 'NNS'), (',', ','), ('data', 'NNS'), ('marts', 'NNS'), (',', ','), ('data', 'NNS'), ('warehouses', 'NNS'), ('”', 'NNP'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Structured/NNP data/NNS storage/NN retrieval/NN methods/NNS)
  include/VBP
  (NP “/JJ relational/JJ databases/NNS)
  ,/,
  (NP data/NNS marts/NNS)
  ,/,
  (NP data/NNS warehouses/NNS ”/NNP)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Structured data storage retrieval methods', '“ relational databases', 'data marts', 'data warehouses ”', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('GPE', 'Structured'), ('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Structured', 'structur'), ('data', 'data'), ('storage', 'storag'), ('retrieval', 'retriev'), ('methods', 'method'), ('include', 'includ'), ('“', '“'), ('relational', 'relat'), ('databases', 'databas'), (',', ','), ('data', 'data'), ('marts', 'mart'), (',', ','), ('data', 'data'), ('warehouses', 'warehous'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Structured', 'structur'), ('data', 'data'), ('storage', 'storag'), ('retrieval', 'retriev'), ('methods', 'method'), ('include', 'includ'), ('“', '“'), ('relational', 'relat'), ('databases', 'databas'), (',', ','), ('data', 'data'), ('marts', 'mart'), (',', ','), ('data', 'data'), ('warehouses', 'warehous'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Structured', 'Structured'), ('data', 'data'), ('storage', 'storage'), ('retrieval', 'retrieval'), ('methods', 'method'), ('include', 'include'), ('“', '“'), ('relational', 'relational'), ('databases', 'database'), (',', ','), ('data', 'data'), ('marts', 'mart'), (',', ','), ('data', 'data'), ('warehouses', 'warehouse'), ('”', '”'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 219 =============================

Data is extracted from outside sources, then   transformed to fit operational needs, and finally loaded into the database. 


>> Tokens are: 
 ['Data', 'extracted', 'outside', 'sources', ',', 'transformed', 'fit', 'operational', 'needs', ',', 'finally', 'loaded', 'database', '.']

>> Bigrams are: 
 [('Data', 'extracted'), ('extracted', 'outside'), ('outside', 'sources'), ('sources', ','), (',', 'transformed'), ('transformed', 'fit'), ('fit', 'operational'), ('operational', 'needs'), ('needs', ','), (',', 'finally'), ('finally', 'loaded'), ('loaded', 'database'), ('database', '.')]

>> Trigrams are: 
 [('Data', 'extracted', 'outside'), ('extracted', 'outside', 'sources'), ('outside', 'sources', ','), ('sources', ',', 'transformed'), (',', 'transformed', 'fit'), ('transformed', 'fit', 'operational'), ('fit', 'operational', 'needs'), ('operational', 'needs', ','), ('needs', ',', 'finally'), (',', 'finally', 'loaded'), ('finally', 'loaded', 'database'), ('loaded', 'database', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('extracted', 'VBD'), ('outside', 'JJ'), ('sources', 'NNS'), (',', ','), ('transformed', 'VBD'), ('fit', 'JJ'), ('operational', 'JJ'), ('needs', 'NNS'), (',', ','), ('finally', 'RB'), ('loaded', 'JJ'), ('database', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP)
  extracted/VBD
  (NP outside/JJ sources/NNS)
  ,/,
  transformed/VBD
  (NP fit/JJ operational/JJ needs/NNS)
  ,/,
  finally/RB
  (NP loaded/JJ database/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data', 'outside sources', 'fit operational needs', 'loaded database']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('extracted', 'extract'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ','), ('transformed', 'transform'), ('fit', 'fit'), ('operational', 'oper'), ('needs', 'need'), (',', ','), ('finally', 'final'), ('loaded', 'load'), ('database', 'databas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('extracted', 'extract'), ('outside', 'outsid'), ('sources', 'sourc'), (',', ','), ('transformed', 'transform'), ('fit', 'fit'), ('operational', 'oper'), ('needs', 'need'), (',', ','), ('finally', 'final'), ('loaded', 'load'), ('database', 'databas'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('extracted', 'extracted'), ('outside', 'outside'), ('sources', 'source'), (',', ','), ('transformed', 'transformed'), ('fit', 'fit'), ('operational', 'operational'), ('needs', 'need'), (',', ','), ('finally', 'finally'), ('loaded', 'loaded'), ('database', 'database'), ('.', '.')]



============================ Sentence 220 =============================

The data is then uploaded   from the operational data store to longer-term storage using Extract, Transform, Load (ETL) or   Extract, Load, Transform (ELT) tools. 


>> Tokens are: 
 ['The', 'data', 'uploaded', 'operational', 'data', 'store', 'longer-term', 'storage', 'using', 'Extract', ',', 'Transform', ',', 'Load', '(', 'ETL', ')', 'Extract', ',', 'Load', ',', 'Transform', '(', 'ELT', ')', 'tools', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'uploaded'), ('uploaded', 'operational'), ('operational', 'data'), ('data', 'store'), ('store', 'longer-term'), ('longer-term', 'storage'), ('storage', 'using'), ('using', 'Extract'), ('Extract', ','), (',', 'Transform'), ('Transform', ','), (',', 'Load'), ('Load', '('), ('(', 'ETL'), ('ETL', ')'), (')', 'Extract'), ('Extract', ','), (',', 'Load'), ('Load', ','), (',', 'Transform'), ('Transform', '('), ('(', 'ELT'), ('ELT', ')'), (')', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('The', 'data', 'uploaded'), ('data', 'uploaded', 'operational'), ('uploaded', 'operational', 'data'), ('operational', 'data', 'store'), ('data', 'store', 'longer-term'), ('store', 'longer-term', 'storage'), ('longer-term', 'storage', 'using'), ('storage', 'using', 'Extract'), ('using', 'Extract', ','), ('Extract', ',', 'Transform'), (',', 'Transform', ','), ('Transform', ',', 'Load'), (',', 'Load', '('), ('Load', '(', 'ETL'), ('(', 'ETL', ')'), ('ETL', ')', 'Extract'), (')', 'Extract', ','), ('Extract', ',', 'Load'), (',', 'Load', ','), ('Load', ',', 'Transform'), (',', 'Transform', '('), ('Transform', '(', 'ELT'), ('(', 'ELT', ')'), ('ELT', ')', 'tools'), (')', 'tools', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('uploaded', 'VBD'), ('operational', 'JJ'), ('data', 'NNS'), ('store', 'RB'), ('longer-term', 'JJ'), ('storage', 'NN'), ('using', 'VBG'), ('Extract', 'NNP'), (',', ','), ('Transform', 'NNP'), (',', ','), ('Load', 'NNP'), ('(', '('), ('ETL', 'NNP'), (')', ')'), ('Extract', 'NNP'), (',', ','), ('Load', 'NNP'), (',', ','), ('Transform', 'NNP'), ('(', '('), ('ELT', 'NNP'), (')', ')'), ('tools', 'NNS'), ('.', '.')]

 (S
  (NP The/DT data/NN)
  uploaded/VBD
  (NP operational/JJ data/NNS)
  store/RB
  (NP longer-term/JJ storage/NN)
  using/VBG
  (NP Extract/NNP)
  ,/,
  (NP Transform/NNP)
  ,/,
  (NP Load/NNP)
  (/(
  (NP ETL/NNP)
  )/)
  (NP Extract/NNP)
  ,/,
  (NP Load/NNP)
  ,/,
  (NP Transform/NNP)
  (/(
  (NP ELT/NNP)
  )/)
  (NP tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The data', 'operational data', 'longer-term storage', 'Extract', 'Transform', 'Load', 'ETL', 'Extract', 'Load', 'Transform', 'ELT', 'tools']

>> Named Entities are: 
 [('PERSON', 'Extract'), ('PERSON', 'Transform'), ('GPE', 'Load'), ('ORGANIZATION', 'ETL'), ('PERSON', 'Extract'), ('PERSON', 'Load'), ('GPE', 'Transform'), ('ORGANIZATION', 'ELT')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('uploaded', 'upload'), ('operational', 'oper'), ('data', 'data'), ('store', 'store'), ('longer-term', 'longer-term'), ('storage', 'storag'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('(', '('), ('ETL', 'etl'), (')', ')'), ('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ','), ('Transform', 'transform'), ('(', '('), ('ELT', 'elt'), (')', ')'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('uploaded', 'upload'), ('operational', 'oper'), ('data', 'data'), ('store', 'store'), ('longer-term', 'longer-term'), ('storage', 'storag'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('(', '('), ('ETL', 'etl'), (')', ')'), ('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ','), ('Transform', 'transform'), ('(', '('), ('ELT', 'elt'), (')', ')'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('uploaded', 'uploaded'), ('operational', 'operational'), ('data', 'data'), ('store', 'store'), ('longer-term', 'longer-term'), ('storage', 'storage'), ('using', 'using'), ('Extract', 'Extract'), (',', ','), ('Transform', 'Transform'), (',', ','), ('Load', 'Load'), ('(', '('), ('ETL', 'ETL'), (')', ')'), ('Extract', 'Extract'), (',', ','), ('Load', 'Load'), (',', ','), ('Transform', 'Transform'), ('(', '('), ('ELT', 'ELT'), (')', ')'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 221 =============================

The data is then cleaned, transformed, and catalogued   before use (Bakshi, 2012; Elgendy and Elragal, 2014). 


>> Tokens are: 
 ['The', 'data', 'cleaned', ',', 'transformed', ',', 'catalogued', 'use', '(', 'Bakshi', ',', '2012', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'cleaned'), ('cleaned', ','), (',', 'transformed'), ('transformed', ','), (',', 'catalogued'), ('catalogued', 'use'), ('use', '('), ('(', 'Bakshi'), ('Bakshi', ','), (',', '2012'), ('2012', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'data', 'cleaned'), ('data', 'cleaned', ','), ('cleaned', ',', 'transformed'), (',', 'transformed', ','), ('transformed', ',', 'catalogued'), (',', 'catalogued', 'use'), ('catalogued', 'use', '('), ('use', '(', 'Bakshi'), ('(', 'Bakshi', ','), ('Bakshi', ',', '2012'), (',', '2012', ';'), ('2012', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NN'), ('cleaned', 'VBD'), (',', ','), ('transformed', 'VBD'), (',', ','), ('catalogued', 'VBN'), ('use', 'NN'), ('(', '('), ('Bakshi', 'NNP'), (',', ','), ('2012', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT data/NN)
  cleaned/VBD
  ,/,
  transformed/VBD
  ,/,
  catalogued/VBN
  (NP use/NN)
  (/(
  (NP Bakshi/NNP)
  ,/,
  2012/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The data', 'use', 'Bakshi', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Bakshi'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('cleaned', 'clean'), (',', ','), ('transformed', 'transform'), (',', ','), ('catalogued', 'catalogu'), ('use', 'use'), ('(', '('), ('Bakshi', 'bakshi'), (',', ','), ('2012', '2012'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('cleaned', 'clean'), (',', ','), ('transformed', 'transform'), (',', ','), ('catalogued', 'catalogu'), ('use', 'use'), ('(', '('), ('Bakshi', 'bakshi'), (',', ','), ('2012', '2012'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('cleaned', 'cleaned'), (',', ','), ('transformed', 'transformed'), (',', ','), ('catalogued', 'catalogued'), ('use', 'use'), ('(', '('), ('Bakshi', 'Bakshi'), (',', ','), ('2012', '2012'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 222 =============================

A big data environment requires analysis skills, unlike the Enterprise Data Warehouse (EDW)   traditional environment (Hartmann, T. et al., 2019). 


>> Tokens are: 
 ['A', 'big', 'data', 'environment', 'requires', 'analysis', 'skills', ',', 'unlike', 'Enterprise', 'Data', 'Warehouse', '(', 'EDW', ')', 'traditional', 'environment', '(', 'Hartmann', ',', 'T.', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('A', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', 'requires'), ('requires', 'analysis'), ('analysis', 'skills'), ('skills', ','), (',', 'unlike'), ('unlike', 'Enterprise'), ('Enterprise', 'Data'), ('Data', 'Warehouse'), ('Warehouse', '('), ('(', 'EDW'), ('EDW', ')'), (')', 'traditional'), ('traditional', 'environment'), ('environment', '('), ('(', 'Hartmann'), ('Hartmann', ','), (',', 'T.'), ('T.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('A', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', 'requires'), ('environment', 'requires', 'analysis'), ('requires', 'analysis', 'skills'), ('analysis', 'skills', ','), ('skills', ',', 'unlike'), (',', 'unlike', 'Enterprise'), ('unlike', 'Enterprise', 'Data'), ('Enterprise', 'Data', 'Warehouse'), ('Data', 'Warehouse', '('), ('Warehouse', '(', 'EDW'), ('(', 'EDW', ')'), ('EDW', ')', 'traditional'), (')', 'traditional', 'environment'), ('traditional', 'environment', '('), ('environment', '(', 'Hartmann'), ('(', 'Hartmann', ','), ('Hartmann', ',', 'T.'), (',', 'T.', 'et'), ('T.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('big', 'JJ'), ('data', 'NN'), ('environment', 'NN'), ('requires', 'VBZ'), ('analysis', 'NN'), ('skills', 'NNS'), (',', ','), ('unlike', 'IN'), ('Enterprise', 'NNP'), ('Data', 'NNP'), ('Warehouse', 'NNP'), ('(', '('), ('EDW', 'NNP'), (')', ')'), ('traditional', 'JJ'), ('environment', 'NN'), ('(', '('), ('Hartmann', 'NNP'), (',', ','), ('T.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP A/DT big/JJ data/NN environment/NN)
  requires/VBZ
  (NP analysis/NN skills/NNS)
  ,/,
  unlike/IN
  (NP Enterprise/NNP Data/NNP Warehouse/NNP)
  (/(
  (NP EDW/NNP)
  )/)
  (NP traditional/JJ environment/NN)
  (/(
  (NP Hartmann/NNP)
  ,/,
  (NP T./NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['A big data environment', 'analysis skills', 'Enterprise Data Warehouse', 'EDW', 'traditional environment', 'Hartmann', 'T.', 'al.']

>> Named Entities are: 
 [('PERSON', 'Enterprise Data Warehouse'), ('ORGANIZATION', 'EDW'), ('ORGANIZATION', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('requires', 'requir'), ('analysis', 'analysi'), ('skills', 'skill'), (',', ','), ('unlike', 'unlik'), ('Enterprise', 'enterpris'), ('Data', 'data'), ('Warehouse', 'warehous'), ('(', '('), ('EDW', 'edw'), (')', ')'), ('traditional', 'tradit'), ('environment', 'environ'), ('(', '('), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('requires', 'requir'), ('analysis', 'analysi'), ('skills', 'skill'), (',', ','), ('unlike', 'unlik'), ('Enterprise', 'enterpris'), ('Data', 'data'), ('Warehouse', 'warehous'), ('(', '('), ('EDW', 'edw'), (')', ')'), ('traditional', 'tradit'), ('environment', 'environ'), ('(', '('), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('requires', 'requires'), ('analysis', 'analysis'), ('skills', 'skill'), (',', ','), ('unlike', 'unlike'), ('Enterprise', 'Enterprise'), ('Data', 'Data'), ('Warehouse', 'Warehouse'), ('(', '('), ('EDW', 'EDW'), (')', ')'), ('traditional', 'traditional'), ('environment', 'environment'), ('(', '('), ('Hartmann', 'Hartmann'), (',', ','), ('T.', 'T.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 223 =============================

➢ The big data environment accepts and demands all possible data sources. 


>> Tokens are: 
 ['➢', 'The', 'big', 'data', 'environment', 'accepts', 'demands', 'possible', 'data', 'sources', '.']

>> Bigrams are: 
 [('➢', 'The'), ('The', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', 'accepts'), ('accepts', 'demands'), ('demands', 'possible'), ('possible', 'data'), ('data', 'sources'), ('sources', '.')]

>> Trigrams are: 
 [('➢', 'The', 'big'), ('The', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', 'accepts'), ('environment', 'accepts', 'demands'), ('accepts', 'demands', 'possible'), ('demands', 'possible', 'data'), ('possible', 'data', 'sources'), ('data', 'sources', '.')]

>> POS Tags are: 
 [('➢', 'IN'), ('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('environment', 'NN'), ('accepts', 'NNS'), ('demands', 'VBZ'), ('possible', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('.', '.')]

 (S
  ➢/IN
  (NP The/DT big/JJ data/NNS environment/NN accepts/NNS)
  demands/VBZ
  (NP possible/JJ data/NNS sources/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The big data environment accepts', 'possible data sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('accepts', 'accept'), ('demands', 'demand'), ('possible', 'possibl'), ('data', 'data'), ('sources', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('The', 'the'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('accepts', 'accept'), ('demands', 'demand'), ('possible', 'possibl'), ('data', 'data'), ('sources', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('The', 'The'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('accepts', 'accepts'), ('demands', 'demand'), ('possible', 'possible'), ('data', 'data'), ('sources', 'source'), ('.', '.')]



============================ Sentence 224 =============================

On the other  hand, EDW approaches data sources with caution, as it is more streamlined towards   supporting structured data (Elgendy and Elragal, 2014; Hartmann et al., 2019). 


>> Tokens are: 
 ['On', 'hand', ',', 'EDW', 'approaches', 'data', 'sources', 'caution', ',', 'streamlined', 'towards', 'supporting', 'structured', 'data', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Hartmann', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('On', 'hand'), ('hand', ','), (',', 'EDW'), ('EDW', 'approaches'), ('approaches', 'data'), ('data', 'sources'), ('sources', 'caution'), ('caution', ','), (',', 'streamlined'), ('streamlined', 'towards'), ('towards', 'supporting'), ('supporting', 'structured'), ('structured', 'data'), ('data', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Hartmann'), ('Hartmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('On', 'hand', ','), ('hand', ',', 'EDW'), (',', 'EDW', 'approaches'), ('EDW', 'approaches', 'data'), ('approaches', 'data', 'sources'), ('data', 'sources', 'caution'), ('sources', 'caution', ','), ('caution', ',', 'streamlined'), (',', 'streamlined', 'towards'), ('streamlined', 'towards', 'supporting'), ('towards', 'supporting', 'structured'), ('supporting', 'structured', 'data'), ('structured', 'data', '('), ('data', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Hartmann'), (';', 'Hartmann', 'et'), ('Hartmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('hand', 'NN'), (',', ','), ('EDW', 'NNP'), ('approaches', 'VBZ'), ('data', 'NNS'), ('sources', 'NNS'), ('caution', 'NN'), (',', ','), ('streamlined', 'VBD'), ('towards', 'NNS'), ('supporting', 'VBG'), ('structured', 'VBN'), ('data', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Hartmann', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  On/IN
  (NP hand/NN)
  ,/,
  (NP EDW/NNP)
  approaches/VBZ
  (NP data/NNS sources/NNS caution/NN)
  ,/,
  streamlined/VBD
  (NP towards/NNS)
  supporting/VBG
  structured/VBN
  (NP data/NNS)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Hartmann/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['hand', 'EDW', 'data sources caution', 'towards', 'data', 'Elgendy Elragal', 'Hartmann', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'EDW'), ('PERSON', 'Elgendy Elragal'), ('PERSON', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('hand', 'hand'), (',', ','), ('EDW', 'edw'), ('approaches', 'approach'), ('data', 'data'), ('sources', 'sourc'), ('caution', 'caution'), (',', ','), ('streamlined', 'streamlin'), ('towards', 'toward'), ('supporting', 'support'), ('structured', 'structur'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('hand', 'hand'), (',', ','), ('EDW', 'edw'), ('approaches', 'approach'), ('data', 'data'), ('sources', 'sourc'), ('caution', 'caution'), (',', ','), ('streamlined', 'streamlin'), ('towards', 'toward'), ('supporting', 'support'), ('structured', 'structur'), ('data', 'data'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('hand', 'hand'), (',', ','), ('EDW', 'EDW'), ('approaches', 'approach'), ('data', 'data'), ('sources', 'source'), ('caution', 'caution'), (',', ','), ('streamlined', 'streamlined'), ('towards', 'towards'), ('supporting', 'supporting'), ('structured', 'structured'), ('data', 'data'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'Hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 225 =============================

➢ Due to increasing number of data sources and data analyses possible, big data storage  requires agile databases to give analysts the opportunity to produce and adapt to data easily   and quickly (Elgendy and Elragal, 2014; Hartmann et al., 2019). 


>> Tokens are: 
 ['➢', 'Due', 'increasing', 'number', 'data', 'sources', 'data', 'analyses', 'possible', ',', 'big', 'data', 'storage', 'requires', 'agile', 'databases', 'give', 'analysts', 'opportunity', 'produce', 'adapt', 'data', 'easily', 'quickly', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Hartmann', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('➢', 'Due'), ('Due', 'increasing'), ('increasing', 'number'), ('number', 'data'), ('data', 'sources'), ('sources', 'data'), ('data', 'analyses'), ('analyses', 'possible'), ('possible', ','), (',', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'requires'), ('requires', 'agile'), ('agile', 'databases'), ('databases', 'give'), ('give', 'analysts'), ('analysts', 'opportunity'), ('opportunity', 'produce'), ('produce', 'adapt'), ('adapt', 'data'), ('data', 'easily'), ('easily', 'quickly'), ('quickly', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Hartmann'), ('Hartmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('➢', 'Due', 'increasing'), ('Due', 'increasing', 'number'), ('increasing', 'number', 'data'), ('number', 'data', 'sources'), ('data', 'sources', 'data'), ('sources', 'data', 'analyses'), ('data', 'analyses', 'possible'), ('analyses', 'possible', ','), ('possible', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'requires'), ('storage', 'requires', 'agile'), ('requires', 'agile', 'databases'), ('agile', 'databases', 'give'), ('databases', 'give', 'analysts'), ('give', 'analysts', 'opportunity'), ('analysts', 'opportunity', 'produce'), ('opportunity', 'produce', 'adapt'), ('produce', 'adapt', 'data'), ('adapt', 'data', 'easily'), ('data', 'easily', 'quickly'), ('easily', 'quickly', '('), ('quickly', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Hartmann'), (';', 'Hartmann', 'et'), ('Hartmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('➢', 'NNS'), ('Due', 'NNP'), ('increasing', 'VBG'), ('number', 'NN'), ('data', 'NNS'), ('sources', 'NNS'), ('data', 'VBP'), ('analyses', 'NNS'), ('possible', 'JJ'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('requires', 'VBZ'), ('agile', 'JJ'), ('databases', 'NNS'), ('give', 'VBP'), ('analysts', 'NNS'), ('opportunity', 'NN'), ('produce', 'VBP'), ('adapt', 'JJ'), ('data', 'NNS'), ('easily', 'RB'), ('quickly', 'RB'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Hartmann', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP ➢/NNS Due/NNP)
  increasing/VBG
  (NP number/NN data/NNS sources/NNS)
  data/VBP
  (NP analyses/NNS)
  possible/JJ
  ,/,
  (NP big/JJ data/NNS storage/NN)
  requires/VBZ
  (NP agile/JJ databases/NNS)
  give/VBP
  (NP analysts/NNS opportunity/NN)
  produce/VBP
  (NP adapt/JJ data/NNS)
  easily/RB
  quickly/RB
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Hartmann/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['➢ Due', 'number data sources', 'analyses', 'big data storage', 'agile databases', 'analysts opportunity', 'adapt data', 'Elgendy Elragal', 'Hartmann', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('Due', 'due'), ('increasing', 'increas'), ('number', 'number'), ('data', 'data'), ('sources', 'sourc'), ('data', 'data'), ('analyses', 'analys'), ('possible', 'possibl'), (',', ','), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('requires', 'requir'), ('agile', 'agil'), ('databases', 'databas'), ('give', 'give'), ('analysts', 'analyst'), ('opportunity', 'opportun'), ('produce', 'produc'), ('adapt', 'adapt'), ('data', 'data'), ('easily', 'easili'), ('quickly', 'quickli'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('Due', 'due'), ('increasing', 'increas'), ('number', 'number'), ('data', 'data'), ('sources', 'sourc'), ('data', 'data'), ('analyses', 'analys'), ('possible', 'possibl'), (',', ','), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('requires', 'requir'), ('agile', 'agil'), ('databases', 'databas'), ('give', 'give'), ('analysts', 'analyst'), ('opportunity', 'opportun'), ('produce', 'produc'), ('adapt', 'adapt'), ('data', 'data'), ('easily', 'easili'), ('quickly', 'quick'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('Due', 'Due'), ('increasing', 'increasing'), ('number', 'number'), ('data', 'data'), ('sources', 'source'), ('data', 'data'), ('analyses', 'analysis'), ('possible', 'possible'), (',', ','), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('requires', 'requires'), ('agile', 'agile'), ('databases', 'database'), ('give', 'give'), ('analysts', 'analyst'), ('opportunity', 'opportunity'), ('produce', 'produce'), ('adapt', 'adapt'), ('data', 'data'), ('easily', 'easily'), ('quickly', 'quickly'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'Hartmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 226 =============================

➢ A big data repository must be deep, allowing analysts to analyse the datasets deeply by  using complex statistical methods (Elgendy and Elragal, 2014; Hartmann, T. et al., 2019). 


>> Tokens are: 
 ['➢', 'A', 'big', 'data', 'repository', 'must', 'deep', ',', 'allowing', 'analysts', 'analyse', 'datasets', 'deeply', 'using', 'complex', 'statistical', 'methods', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Hartmann', ',', 'T.', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('➢', 'A'), ('A', 'big'), ('big', 'data'), ('data', 'repository'), ('repository', 'must'), ('must', 'deep'), ('deep', ','), (',', 'allowing'), ('allowing', 'analysts'), ('analysts', 'analyse'), ('analyse', 'datasets'), ('datasets', 'deeply'), ('deeply', 'using'), ('using', 'complex'), ('complex', 'statistical'), ('statistical', 'methods'), ('methods', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Hartmann'), ('Hartmann', ','), (',', 'T.'), ('T.', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('➢', 'A', 'big'), ('A', 'big', 'data'), ('big', 'data', 'repository'), ('data', 'repository', 'must'), ('repository', 'must', 'deep'), ('must', 'deep', ','), ('deep', ',', 'allowing'), (',', 'allowing', 'analysts'), ('allowing', 'analysts', 'analyse'), ('analysts', 'analyse', 'datasets'), ('analyse', 'datasets', 'deeply'), ('datasets', 'deeply', 'using'), ('deeply', 'using', 'complex'), ('using', 'complex', 'statistical'), ('complex', 'statistical', 'methods'), ('statistical', 'methods', '('), ('methods', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Hartmann'), (';', 'Hartmann', ','), ('Hartmann', ',', 'T.'), (',', 'T.', 'et'), ('T.', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('➢', 'VB'), ('A', 'DT'), ('big', 'JJ'), ('data', 'NN'), ('repository', 'NN'), ('must', 'MD'), ('deep', 'VB'), (',', ','), ('allowing', 'VBG'), ('analysts', 'NNS'), ('analyse', 'VBP'), ('datasets', 'NNS'), ('deeply', 'RB'), ('using', 'VBG'), ('complex', 'JJ'), ('statistical', 'JJ'), ('methods', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Hartmann', 'NNP'), (',', ','), ('T.', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  ➢/VB
  (NP A/DT big/JJ data/NN repository/NN)
  must/MD
  deep/VB
  ,/,
  allowing/VBG
  (NP analysts/NNS)
  analyse/VBP
  (NP datasets/NNS)
  deeply/RB
  using/VBG
  (NP complex/JJ statistical/JJ methods/NNS)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Hartmann/NNP)
  ,/,
  (NP T./NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['A big data repository', 'analysts', 'datasets', 'complex statistical methods', 'Elgendy Elragal', 'Hartmann', 'T.', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Hartmann')] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('A', 'a'), ('big', 'big'), ('data', 'data'), ('repository', 'repositori'), ('must', 'must'), ('deep', 'deep'), (',', ','), ('allowing', 'allow'), ('analysts', 'analyst'), ('analyse', 'analys'), ('datasets', 'dataset'), ('deeply', 'deepli'), ('using', 'use'), ('complex', 'complex'), ('statistical', 'statist'), ('methods', 'method'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('A', 'a'), ('big', 'big'), ('data', 'data'), ('repository', 'repositori'), ('must', 'must'), ('deep', 'deep'), (',', ','), ('allowing', 'allow'), ('analysts', 'analyst'), ('analyse', 'analys'), ('datasets', 'dataset'), ('deeply', 'deepli'), ('using', 'use'), ('complex', 'complex'), ('statistical', 'statist'), ('methods', 'method'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('A', 'A'), ('big', 'big'), ('data', 'data'), ('repository', 'repository'), ('must', 'must'), ('deep', 'deep'), (',', ','), ('allowing', 'allowing'), ('analysts', 'analyst'), ('analyse', 'analyse'), ('datasets', 'datasets'), ('deeply', 'deeply'), ('using', 'using'), ('complex', 'complex'), ('statistical', 'statistical'), ('methods', 'method'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Hartmann', 'Hartmann'), (',', ','), ('T.', 'T.'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 227 =============================

Hadoop is a popular big data analytics framework. 


>> Tokens are: 
 ['Hadoop', 'popular', 'big', 'data', 'analytics', 'framework', '.']

>> Bigrams are: 
 [('Hadoop', 'popular'), ('popular', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'framework'), ('framework', '.')]

>> Trigrams are: 
 [('Hadoop', 'popular', 'big'), ('popular', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'framework'), ('analytics', 'framework', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('popular', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('framework', 'NN'), ('.', '.')]

 (S
  (NP Hadoop/NNP)
  (NP popular/JJ big/JJ data/NNS analytics/NNS framework/NN)
  ./.) 


>> Noun Phrases are: 
 ['Hadoop', 'popular big data analytics framework']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('framework', 'framework'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('popular', 'popular'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('framework', 'framework'), ('.', '.')]



============================ Sentence 228 =============================

Hadoop “provides reliability, scalability, and   manageability by providing an implementation for the MapReduce paradigm as well as gluing the   storage and analytics together” (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 ['Hadoop', '“', 'provides', 'reliability', ',', 'scalability', ',', 'manageability', 'providing', 'implementation', 'MapReduce', 'paradigm', 'well', 'gluing', 'storage', 'analytics', 'together', '”', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Hadoop', '“'), ('“', 'provides'), ('provides', 'reliability'), ('reliability', ','), (',', 'scalability'), ('scalability', ','), (',', 'manageability'), ('manageability', 'providing'), ('providing', 'implementation'), ('implementation', 'MapReduce'), ('MapReduce', 'paradigm'), ('paradigm', 'well'), ('well', 'gluing'), ('gluing', 'storage'), ('storage', 'analytics'), ('analytics', 'together'), ('together', '”'), ('”', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Hadoop', '“', 'provides'), ('“', 'provides', 'reliability'), ('provides', 'reliability', ','), ('reliability', ',', 'scalability'), (',', 'scalability', ','), ('scalability', ',', 'manageability'), (',', 'manageability', 'providing'), ('manageability', 'providing', 'implementation'), ('providing', 'implementation', 'MapReduce'), ('implementation', 'MapReduce', 'paradigm'), ('MapReduce', 'paradigm', 'well'), ('paradigm', 'well', 'gluing'), ('well', 'gluing', 'storage'), ('gluing', 'storage', 'analytics'), ('storage', 'analytics', 'together'), ('analytics', 'together', '”'), ('together', '”', '('), ('”', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('“', 'NNP'), ('provides', 'VBZ'), ('reliability', 'NN'), (',', ','), ('scalability', 'NN'), (',', ','), ('manageability', 'NN'), ('providing', 'VBG'), ('implementation', 'NN'), ('MapReduce', 'NNP'), ('paradigm', 'NN'), ('well', 'RB'), ('gluing', 'VBG'), ('storage', 'NN'), ('analytics', 'NNS'), ('together', 'RB'), ('”', 'NNP'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Hadoop/NNP “/NNP)
  provides/VBZ
  (NP reliability/NN)
  ,/,
  (NP scalability/NN)
  ,/,
  (NP manageability/NN)
  providing/VBG
  (NP implementation/NN MapReduce/NNP paradigm/NN)
  well/RB
  gluing/VBG
  (NP storage/NN analytics/NNS)
  together/RB
  (NP ”/NNP)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Hadoop “', 'reliability', 'scalability', 'manageability', 'implementation MapReduce paradigm', 'storage analytics', '”', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('ORGANIZATION', 'MapReduce'), ('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('“', '“'), ('provides', 'provid'), ('reliability', 'reliabl'), (',', ','), ('scalability', 'scalabl'), (',', ','), ('manageability', 'manag'), ('providing', 'provid'), ('implementation', 'implement'), ('MapReduce', 'mapreduc'), ('paradigm', 'paradigm'), ('well', 'well'), ('gluing', 'glu'), ('storage', 'storag'), ('analytics', 'analyt'), ('together', 'togeth'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('“', '“'), ('provides', 'provid'), ('reliability', 'reliabl'), (',', ','), ('scalability', 'scalabl'), (',', ','), ('manageability', 'manag'), ('providing', 'provid'), ('implementation', 'implement'), ('MapReduce', 'mapreduc'), ('paradigm', 'paradigm'), ('well', 'well'), ('gluing', 'glu'), ('storage', 'storag'), ('analytics', 'analyt'), ('together', 'togeth'), ('”', '”'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('“', '“'), ('provides', 'provides'), ('reliability', 'reliability'), (',', ','), ('scalability', 'scalability'), (',', ','), ('manageability', 'manageability'), ('providing', 'providing'), ('implementation', 'implementation'), ('MapReduce', 'MapReduce'), ('paradigm', 'paradigm'), ('well', 'well'), ('gluing', 'gluing'), ('storage', 'storage'), ('analytics', 'analytics'), ('together', 'together'), ('”', '”'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 229 =============================

Hadoop includes HDFS which     Sarah Al-Shiakhli   19      is for the big data storage and MapReduce for big data analytics, and it can process extremely large   amount of data by dividing the data into smaller blocks, then specifying datasets to be distributed   across cluster nodes (Raghupathi and Raghupathi, 2014; Elgendy and Elragal, 2014). 


>> Tokens are: 
 ['Hadoop', 'includes', 'HDFS', 'Sarah', 'Al-Shiakhli', '19', 'big', 'data', 'storage', 'MapReduce', 'big', 'data', 'analytics', ',', 'process', 'extremely', 'large', 'amount', 'data', 'dividing', 'data', 'smaller', 'blocks', ',', 'specifying', 'datasets', 'distributed', 'across', 'cluster', 'nodes', '(', 'Raghupathi', 'Raghupathi', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Hadoop', 'includes'), ('includes', 'HDFS'), ('HDFS', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '19'), ('19', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'MapReduce'), ('MapReduce', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'process'), ('process', 'extremely'), ('extremely', 'large'), ('large', 'amount'), ('amount', 'data'), ('data', 'dividing'), ('dividing', 'data'), ('data', 'smaller'), ('smaller', 'blocks'), ('blocks', ','), (',', 'specifying'), ('specifying', 'datasets'), ('datasets', 'distributed'), ('distributed', 'across'), ('across', 'cluster'), ('cluster', 'nodes'), ('nodes', '('), ('(', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), ('Raghupathi', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Hadoop', 'includes', 'HDFS'), ('includes', 'HDFS', 'Sarah'), ('HDFS', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '19'), ('Al-Shiakhli', '19', 'big'), ('19', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'MapReduce'), ('storage', 'MapReduce', 'big'), ('MapReduce', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'process'), (',', 'process', 'extremely'), ('process', 'extremely', 'large'), ('extremely', 'large', 'amount'), ('large', 'amount', 'data'), ('amount', 'data', 'dividing'), ('data', 'dividing', 'data'), ('dividing', 'data', 'smaller'), ('data', 'smaller', 'blocks'), ('smaller', 'blocks', ','), ('blocks', ',', 'specifying'), (',', 'specifying', 'datasets'), ('specifying', 'datasets', 'distributed'), ('datasets', 'distributed', 'across'), ('distributed', 'across', 'cluster'), ('across', 'cluster', 'nodes'), ('cluster', 'nodes', '('), ('nodes', '(', 'Raghupathi'), ('(', 'Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi', ','), ('Raghupathi', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('includes', 'VBZ'), ('HDFS', 'NNP'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('19', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('MapReduce', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('process', 'NN'), ('extremely', 'RB'), ('large', 'JJ'), ('amount', 'NN'), ('data', 'NNS'), ('dividing', 'VBG'), ('data', 'NNS'), ('smaller', 'JJR'), ('blocks', 'NNS'), (',', ','), ('specifying', 'VBG'), ('datasets', 'NNS'), ('distributed', 'VBN'), ('across', 'IN'), ('cluster', 'NN'), ('nodes', 'NNS'), ('(', '('), ('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Hadoop/NNP)
  includes/VBZ
  (NP HDFS/NNP Sarah/NNP Al-Shiakhli/NNP)
  19/CD
  (NP big/JJ data/NNS storage/NN MapReduce/NNP)
  (NP big/JJ data/NNS analytics/NNS)
  ,/,
  (NP process/NN)
  extremely/RB
  (NP large/JJ amount/NN data/NNS)
  dividing/VBG
  (NP data/NNS)
  smaller/JJR
  (NP blocks/NNS)
  ,/,
  specifying/VBG
  (NP datasets/NNS)
  distributed/VBN
  across/IN
  (NP cluster/NN nodes/NNS)
  (/(
  (NP Raghupathi/NNP Raghupathi/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Hadoop', 'HDFS Sarah Al-Shiakhli', 'big data storage MapReduce', 'big data analytics', 'process', 'large amount data', 'data', 'blocks', 'datasets', 'cluster nodes', 'Raghupathi Raghupathi', 'Elgendy Elragal']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('ORGANIZATION', 'HDFS Sarah'), ('ORGANIZATION', 'MapReduce'), ('ORGANIZATION', 'Raghupathi Raghupathi'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('includes', 'includ'), ('HDFS', 'hdf'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('19', '19'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('MapReduce', 'mapreduc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg'), ('amount', 'amount'), ('data', 'data'), ('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('blocks', 'block'), (',', ','), ('specifying', 'specifi'), ('datasets', 'dataset'), ('distributed', 'distribut'), ('across', 'across'), ('cluster', 'cluster'), ('nodes', 'node'), ('(', '('), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('includes', 'includ'), ('HDFS', 'hdfs'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('19', '19'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('MapReduce', 'mapreduc'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg'), ('amount', 'amount'), ('data', 'data'), ('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('blocks', 'block'), (',', ','), ('specifying', 'specifi'), ('datasets', 'dataset'), ('distributed', 'distribut'), ('across', 'across'), ('cluster', 'cluster'), ('nodes', 'node'), ('(', '('), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('includes', 'includes'), ('HDFS', 'HDFS'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('19', '19'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('MapReduce', 'MapReduce'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('process', 'process'), ('extremely', 'extremely'), ('large', 'large'), ('amount', 'amount'), ('data', 'data'), ('dividing', 'dividing'), ('data', 'data'), ('smaller', 'smaller'), ('blocks', 'block'), (',', ','), ('specifying', 'specifying'), ('datasets', 'datasets'), ('distributed', 'distributed'), ('across', 'across'), ('cluster', 'cluster'), ('nodes', 'node'), ('(', '('), ('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 230 =============================

Hadoop   incorporates several technologies: “Hive is a data warehouse implementation for Hadoop,   MapReduce is a programming model in Hadoop, and Pig is a querying language for Hadoop   which has similarities to the SQL language for relational databases” (Zuech et al., 2015). 


>> Tokens are: 
 ['Hadoop', 'incorporates', 'several', 'technologies', ':', '“', 'Hive', 'data', 'warehouse', 'implementation', 'Hadoop', ',', 'MapReduce', 'programming', 'model', 'Hadoop', ',', 'Pig', 'querying', 'language', 'Hadoop', 'similarities', 'SQL', 'language', 'relational', 'databases', '”', '(', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Hadoop', 'incorporates'), ('incorporates', 'several'), ('several', 'technologies'), ('technologies', ':'), (':', '“'), ('“', 'Hive'), ('Hive', 'data'), ('data', 'warehouse'), ('warehouse', 'implementation'), ('implementation', 'Hadoop'), ('Hadoop', ','), (',', 'MapReduce'), ('MapReduce', 'programming'), ('programming', 'model'), ('model', 'Hadoop'), ('Hadoop', ','), (',', 'Pig'), ('Pig', 'querying'), ('querying', 'language'), ('language', 'Hadoop'), ('Hadoop', 'similarities'), ('similarities', 'SQL'), ('SQL', 'language'), ('language', 'relational'), ('relational', 'databases'), ('databases', '”'), ('”', '('), ('(', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Hadoop', 'incorporates', 'several'), ('incorporates', 'several', 'technologies'), ('several', 'technologies', ':'), ('technologies', ':', '“'), (':', '“', 'Hive'), ('“', 'Hive', 'data'), ('Hive', 'data', 'warehouse'), ('data', 'warehouse', 'implementation'), ('warehouse', 'implementation', 'Hadoop'), ('implementation', 'Hadoop', ','), ('Hadoop', ',', 'MapReduce'), (',', 'MapReduce', 'programming'), ('MapReduce', 'programming', 'model'), ('programming', 'model', 'Hadoop'), ('model', 'Hadoop', ','), ('Hadoop', ',', 'Pig'), (',', 'Pig', 'querying'), ('Pig', 'querying', 'language'), ('querying', 'language', 'Hadoop'), ('language', 'Hadoop', 'similarities'), ('Hadoop', 'similarities', 'SQL'), ('similarities', 'SQL', 'language'), ('SQL', 'language', 'relational'), ('language', 'relational', 'databases'), ('relational', 'databases', '”'), ('databases', '”', '('), ('”', '(', 'Zuech'), ('(', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('incorporates', 'VBZ'), ('several', 'JJ'), ('technologies', 'NNS'), (':', ':'), ('“', 'VB'), ('Hive', 'NNP'), ('data', 'NNS'), ('warehouse', 'NN'), ('implementation', 'NN'), ('Hadoop', 'NNP'), (',', ','), ('MapReduce', 'NNP'), ('programming', 'VBG'), ('model', 'NN'), ('Hadoop', 'NNP'), (',', ','), ('Pig', 'NNP'), ('querying', 'VBG'), ('language', 'NN'), ('Hadoop', 'NNP'), ('similarities', 'VBZ'), ('SQL', 'NNP'), ('language', 'NN'), ('relational', 'JJ'), ('databases', 'NNS'), ('”', 'VBP'), ('(', '('), ('Zuech', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Hadoop/NNP)
  incorporates/VBZ
  (NP several/JJ technologies/NNS)
  :/:
  “/VB
  (NP Hive/NNP data/NNS warehouse/NN implementation/NN Hadoop/NNP)
  ,/,
  (NP MapReduce/NNP)
  programming/VBG
  (NP model/NN Hadoop/NNP)
  ,/,
  (NP Pig/NNP)
  querying/VBG
  (NP language/NN Hadoop/NNP)
  similarities/VBZ
  (NP SQL/NNP language/NN)
  (NP relational/JJ databases/NNS)
  ”/VBP
  (/(
  (NP Zuech/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Hadoop', 'several technologies', 'Hive data warehouse implementation Hadoop', 'MapReduce', 'model Hadoop', 'Pig', 'language Hadoop', 'SQL language', 'relational databases', 'Zuech']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('PERSON', 'Hadoop'), ('ORGANIZATION', 'MapReduce'), ('PERSON', 'Hadoop'), ('PERSON', 'Pig'), ('PERSON', 'Hadoop'), ('ORGANIZATION', 'SQL'), ('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('incorporates', 'incorpor'), ('several', 'sever'), ('technologies', 'technolog'), (':', ':'), ('“', '“'), ('Hive', 'hive'), ('data', 'data'), ('warehouse', 'warehous'), ('implementation', 'implement'), ('Hadoop', 'hadoop'), (',', ','), ('MapReduce', 'mapreduc'), ('programming', 'program'), ('model', 'model'), ('Hadoop', 'hadoop'), (',', ','), ('Pig', 'pig'), ('querying', 'queri'), ('language', 'languag'), ('Hadoop', 'hadoop'), ('similarities', 'similar'), ('SQL', 'sql'), ('language', 'languag'), ('relational', 'relat'), ('databases', 'databas'), ('”', '”'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('incorporates', 'incorpor'), ('several', 'sever'), ('technologies', 'technolog'), (':', ':'), ('“', '“'), ('Hive', 'hive'), ('data', 'data'), ('warehouse', 'warehous'), ('implementation', 'implement'), ('Hadoop', 'hadoop'), (',', ','), ('MapReduce', 'mapreduc'), ('programming', 'program'), ('model', 'model'), ('Hadoop', 'hadoop'), (',', ','), ('Pig', 'pig'), ('querying', 'queri'), ('language', 'languag'), ('Hadoop', 'hadoop'), ('similarities', 'similar'), ('SQL', 'sql'), ('language', 'languag'), ('relational', 'relat'), ('databases', 'databas'), ('”', '”'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('incorporates', 'incorporates'), ('several', 'several'), ('technologies', 'technology'), (':', ':'), ('“', '“'), ('Hive', 'Hive'), ('data', 'data'), ('warehouse', 'warehouse'), ('implementation', 'implementation'), ('Hadoop', 'Hadoop'), (',', ','), ('MapReduce', 'MapReduce'), ('programming', 'programming'), ('model', 'model'), ('Hadoop', 'Hadoop'), (',', ','), ('Pig', 'Pig'), ('querying', 'querying'), ('language', 'language'), ('Hadoop', 'Hadoop'), ('similarities', 'similarity'), ('SQL', 'SQL'), ('language', 'language'), ('relational', 'relational'), ('databases', 'database'), ('”', '”'), ('(', '('), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 231 =============================

First-generation technology generated the Apache Spark project in software terms (Watson, 2019),   but Hadoop has a great deal more power, which offers advantages to analytics in terms of memory. 


>> Tokens are: 
 ['First-generation', 'technology', 'generated', 'Apache', 'Spark', 'project', 'software', 'terms', '(', 'Watson', ',', '2019', ')', ',', 'Hadoop', 'great', 'deal', 'power', ',', 'offers', 'advantages', 'analytics', 'terms', 'memory', '.']

>> Bigrams are: 
 [('First-generation', 'technology'), ('technology', 'generated'), ('generated', 'Apache'), ('Apache', 'Spark'), ('Spark', 'project'), ('project', 'software'), ('software', 'terms'), ('terms', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'Hadoop'), ('Hadoop', 'great'), ('great', 'deal'), ('deal', 'power'), ('power', ','), (',', 'offers'), ('offers', 'advantages'), ('advantages', 'analytics'), ('analytics', 'terms'), ('terms', 'memory'), ('memory', '.')]

>> Trigrams are: 
 [('First-generation', 'technology', 'generated'), ('technology', 'generated', 'Apache'), ('generated', 'Apache', 'Spark'), ('Apache', 'Spark', 'project'), ('Spark', 'project', 'software'), ('project', 'software', 'terms'), ('software', 'terms', '('), ('terms', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'Hadoop'), (',', 'Hadoop', 'great'), ('Hadoop', 'great', 'deal'), ('great', 'deal', 'power'), ('deal', 'power', ','), ('power', ',', 'offers'), (',', 'offers', 'advantages'), ('offers', 'advantages', 'analytics'), ('advantages', 'analytics', 'terms'), ('analytics', 'terms', 'memory'), ('terms', 'memory', '.')]

>> POS Tags are: 
 [('First-generation', 'NNP'), ('technology', 'NN'), ('generated', 'VBD'), ('Apache', 'NNP'), ('Spark', 'NNP'), ('project', 'NN'), ('software', 'NN'), ('terms', 'NNS'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('Hadoop', 'NNP'), ('great', 'JJ'), ('deal', 'NN'), ('power', 'NN'), (',', ','), ('offers', 'VBZ'), ('advantages', 'NNS'), ('analytics', 'NNS'), ('terms', 'NNS'), ('memory', 'NN'), ('.', '.')]

 (S
  (NP First-generation/NNP technology/NN)
  generated/VBD
  (NP Apache/NNP Spark/NNP project/NN software/NN terms/NNS)
  (/(
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  ,/,
  (NP Hadoop/NNP)
  (NP great/JJ deal/NN power/NN)
  ,/,
  offers/VBZ
  (NP advantages/NNS analytics/NNS terms/NNS memory/NN)
  ./.) 


>> Noun Phrases are: 
 ['First-generation technology', 'Apache Spark project software terms', 'Watson', 'Hadoop', 'great deal power', 'advantages analytics terms memory']

>> Named Entities are: 
 [('PERSON', 'Apache Spark'), ('PERSON', 'Watson'), ('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('First-generation', 'first-gener'), ('technology', 'technolog'), ('generated', 'gener'), ('Apache', 'apach'), ('Spark', 'spark'), ('project', 'project'), ('software', 'softwar'), ('terms', 'term'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('Hadoop', 'hadoop'), ('great', 'great'), ('deal', 'deal'), ('power', 'power'), (',', ','), ('offers', 'offer'), ('advantages', 'advantag'), ('analytics', 'analyt'), ('terms', 'term'), ('memory', 'memori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('First-generation', 'first-gener'), ('technology', 'technolog'), ('generated', 'generat'), ('Apache', 'apach'), ('Spark', 'spark'), ('project', 'project'), ('software', 'softwar'), ('terms', 'term'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('Hadoop', 'hadoop'), ('great', 'great'), ('deal', 'deal'), ('power', 'power'), (',', ','), ('offers', 'offer'), ('advantages', 'advantag'), ('analytics', 'analyt'), ('terms', 'term'), ('memory', 'memori'), ('.', '.')]

>> Lemmatization: 
 [('First-generation', 'First-generation'), ('technology', 'technology'), ('generated', 'generated'), ('Apache', 'Apache'), ('Spark', 'Spark'), ('project', 'project'), ('software', 'software'), ('terms', 'term'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('Hadoop', 'Hadoop'), ('great', 'great'), ('deal', 'deal'), ('power', 'power'), (',', ','), ('offers', 'offer'), ('advantages', 'advantage'), ('analytics', 'analytics'), ('terms', 'term'), ('memory', 'memory'), ('.', '.')]



============================ Sentence 232 =============================

It can work with both batch and real-time workloads, is easy to program with Java code, and can   connect to Apache projects and other software within a closed ecosystem. 


>> Tokens are: 
 ['It', 'work', 'batch', 'real-time', 'workloads', ',', 'easy', 'program', 'Java', 'code', ',', 'connect', 'Apache', 'projects', 'software', 'within', 'closed', 'ecosystem', '.']

>> Bigrams are: 
 [('It', 'work'), ('work', 'batch'), ('batch', 'real-time'), ('real-time', 'workloads'), ('workloads', ','), (',', 'easy'), ('easy', 'program'), ('program', 'Java'), ('Java', 'code'), ('code', ','), (',', 'connect'), ('connect', 'Apache'), ('Apache', 'projects'), ('projects', 'software'), ('software', 'within'), ('within', 'closed'), ('closed', 'ecosystem'), ('ecosystem', '.')]

>> Trigrams are: 
 [('It', 'work', 'batch'), ('work', 'batch', 'real-time'), ('batch', 'real-time', 'workloads'), ('real-time', 'workloads', ','), ('workloads', ',', 'easy'), (',', 'easy', 'program'), ('easy', 'program', 'Java'), ('program', 'Java', 'code'), ('Java', 'code', ','), ('code', ',', 'connect'), (',', 'connect', 'Apache'), ('connect', 'Apache', 'projects'), ('Apache', 'projects', 'software'), ('projects', 'software', 'within'), ('software', 'within', 'closed'), ('within', 'closed', 'ecosystem'), ('closed', 'ecosystem', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('work', 'VBD'), ('batch', 'RB'), ('real-time', 'JJ'), ('workloads', 'NNS'), (',', ','), ('easy', 'JJ'), ('program', 'NN'), ('Java', 'NNP'), ('code', 'NN'), (',', ','), ('connect', 'VBP'), ('Apache', 'NNP'), ('projects', 'NNS'), ('software', 'NN'), ('within', 'IN'), ('closed', 'JJ'), ('ecosystem', 'NN'), ('.', '.')]

 (S
  It/PRP
  work/VBD
  batch/RB
  (NP real-time/JJ workloads/NNS)
  ,/,
  (NP easy/JJ program/NN Java/NNP code/NN)
  ,/,
  connect/VBP
  (NP Apache/NNP projects/NNS software/NN)
  within/IN
  (NP closed/JJ ecosystem/NN)
  ./.) 


>> Noun Phrases are: 
 ['real-time workloads', 'easy program Java code', 'Apache projects software', 'closed ecosystem']

>> Named Entities are: 
 [('PERSON', 'Java'), ('GPE', 'Apache')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('work', 'work'), ('batch', 'batch'), ('real-time', 'real-tim'), ('workloads', 'workload'), (',', ','), ('easy', 'easi'), ('program', 'program'), ('Java', 'java'), ('code', 'code'), (',', ','), ('connect', 'connect'), ('Apache', 'apach'), ('projects', 'project'), ('software', 'softwar'), ('within', 'within'), ('closed', 'close'), ('ecosystem', 'ecosystem'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('work', 'work'), ('batch', 'batch'), ('real-time', 'real-tim'), ('workloads', 'workload'), (',', ','), ('easy', 'easi'), ('program', 'program'), ('Java', 'java'), ('code', 'code'), (',', ','), ('connect', 'connect'), ('Apache', 'apach'), ('projects', 'project'), ('software', 'softwar'), ('within', 'within'), ('closed', 'close'), ('ecosystem', 'ecosystem'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('work', 'work'), ('batch', 'batch'), ('real-time', 'real-time'), ('workloads', 'workload'), (',', ','), ('easy', 'easy'), ('program', 'program'), ('Java', 'Java'), ('code', 'code'), (',', ','), ('connect', 'connect'), ('Apache', 'Apache'), ('projects', 'project'), ('software', 'software'), ('within', 'within'), ('closed', 'closed'), ('ecosystem', 'ecosystem'), ('.', '.')]



============================ Sentence 233 =============================

Hadoop’s components   are shown in Figure 11 (Watson, 2019):    1. 


>> Tokens are: 
 ['Hadoop', '’', 'components', 'shown', 'Figure', '11', '(', 'Watson', ',', '2019', ')', ':', '1', '.']

>> Bigrams are: 
 [('Hadoop', '’'), ('’', 'components'), ('components', 'shown'), ('shown', 'Figure'), ('Figure', '11'), ('11', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', ':'), (':', '1'), ('1', '.')]

>> Trigrams are: 
 [('Hadoop', '’', 'components'), ('’', 'components', 'shown'), ('components', 'shown', 'Figure'), ('shown', 'Figure', '11'), ('Figure', '11', '('), ('11', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', ':'), (')', ':', '1'), (':', '1', '.')]

>> POS Tags are: 
 [('Hadoop', 'NNP'), ('’', 'NNP'), ('components', 'NNS'), ('shown', 'VBN'), ('Figure', 'NNP'), ('11', 'CD'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), (':', ':'), ('1', 'CD'), ('.', '.')]

 (S
  (NP Hadoop/NNP ’/NNP components/NNS)
  shown/VBN
  (NP Figure/NNP)
  11/CD
  (/(
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  :/:
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['Hadoop ’ components', 'Figure', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Hadoop', 'hadoop'), ('’', '’'), ('components', 'compon'), ('shown', 'shown'), ('Figure', 'figur'), ('11', '11'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (':', ':'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hadoop', 'hadoop'), ('’', '’'), ('components', 'compon'), ('shown', 'shown'), ('Figure', 'figur'), ('11', '11'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (':', ':'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Hadoop', 'Hadoop'), ('’', '’'), ('components', 'component'), ('shown', 'shown'), ('Figure', 'Figure'), ('11', '11'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), (':', ':'), ('1', '1'), ('.', '.')]



============================ Sentence 234 =============================

Spark SQL runs SQL-like queries on structured data. 


>> Tokens are: 
 ['Spark', 'SQL', 'runs', 'SQL-like', 'queries', 'structured', 'data', '.']

>> Bigrams are: 
 [('Spark', 'SQL'), ('SQL', 'runs'), ('runs', 'SQL-like'), ('SQL-like', 'queries'), ('queries', 'structured'), ('structured', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Spark', 'SQL', 'runs'), ('SQL', 'runs', 'SQL-like'), ('runs', 'SQL-like', 'queries'), ('SQL-like', 'queries', 'structured'), ('queries', 'structured', 'data'), ('structured', 'data', '.')]

>> POS Tags are: 
 [('Spark', 'NNP'), ('SQL', 'NNP'), ('runs', 'VBZ'), ('SQL-like', 'JJ'), ('queries', 'NNS'), ('structured', 'VBN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Spark/NNP SQL/NNP)
  runs/VBZ
  (NP SQL-like/JJ queries/NNS)
  structured/VBN
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Spark SQL', 'SQL-like queries', 'data']

>> Named Entities are: 
 [('PERSON', 'Spark'), ('ORGANIZATION', 'SQL')] 

>> Stemming using Porter Stemmer: 
 [('Spark', 'spark'), ('SQL', 'sql'), ('runs', 'run'), ('SQL-like', 'sql-like'), ('queries', 'queri'), ('structured', 'structur'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spark', 'spark'), ('SQL', 'sql'), ('runs', 'run'), ('SQL-like', 'sql-like'), ('queries', 'queri'), ('structured', 'structur'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Spark', 'Spark'), ('SQL', 'SQL'), ('runs', 'run'), ('SQL-like', 'SQL-like'), ('queries', 'query'), ('structured', 'structured'), ('data', 'data'), ('.', '.')]



============================ Sentence 235 =============================

2. 


>> Tokens are: 
 ['2', '.']

>> Bigrams are: 
 [('2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2', 'CD'), ('.', '.')]

 (S 2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('.', '.')]



============================ Sentence 236 =============================

Spark streaming provides real-time data processing. 


>> Tokens are: 
 ['Spark', 'streaming', 'provides', 'real-time', 'data', 'processing', '.']

>> Bigrams are: 
 [('Spark', 'streaming'), ('streaming', 'provides'), ('provides', 'real-time'), ('real-time', 'data'), ('data', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('Spark', 'streaming', 'provides'), ('streaming', 'provides', 'real-time'), ('provides', 'real-time', 'data'), ('real-time', 'data', 'processing'), ('data', 'processing', '.')]

>> POS Tags are: 
 [('Spark', 'NNP'), ('streaming', 'VBG'), ('provides', 'VBZ'), ('real-time', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('.', '.')]

 (S
  (NP Spark/NNP)
  streaming/VBG
  provides/VBZ
  (NP real-time/JJ data/NNS processing/NN)
  ./.) 


>> Noun Phrases are: 
 ['Spark', 'real-time data processing']

>> Named Entities are: 
 [('GPE', 'Spark')] 

>> Stemming using Porter Stemmer: 
 [('Spark', 'spark'), ('streaming', 'stream'), ('provides', 'provid'), ('real-time', 'real-tim'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spark', 'spark'), ('streaming', 'stream'), ('provides', 'provid'), ('real-time', 'real-tim'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Spark', 'Spark'), ('streaming', 'streaming'), ('provides', 'provides'), ('real-time', 'real-time'), ('data', 'data'), ('processing', 'processing'), ('.', '.')]



============================ Sentence 237 =============================

3. 


>> Tokens are: 
 ['3', '.']

>> Bigrams are: 
 [('3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3', 'CD'), ('.', '.')]

 (S 3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('.', '.')]



============================ Sentence 238 =============================

MLib provides a machine learning library of algorithms and utilities. 


>> Tokens are: 
 ['MLib', 'provides', 'machine', 'learning', 'library', 'algorithms', 'utilities', '.']

>> Bigrams are: 
 [('MLib', 'provides'), ('provides', 'machine'), ('machine', 'learning'), ('learning', 'library'), ('library', 'algorithms'), ('algorithms', 'utilities'), ('utilities', '.')]

>> Trigrams are: 
 [('MLib', 'provides', 'machine'), ('provides', 'machine', 'learning'), ('machine', 'learning', 'library'), ('learning', 'library', 'algorithms'), ('library', 'algorithms', 'utilities'), ('algorithms', 'utilities', '.')]

>> POS Tags are: 
 [('MLib', 'NNP'), ('provides', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('library', 'JJ'), ('algorithms', 'NN'), ('utilities', 'NNS'), ('.', '.')]

 (S
  (NP MLib/NNP)
  provides/VBZ
  (NP machine/NN)
  learning/VBG
  (NP library/JJ algorithms/NN utilities/NNS)
  ./.) 


>> Noun Phrases are: 
 ['MLib', 'machine', 'library algorithms utilities']

>> Named Entities are: 
 [('ORGANIZATION', 'MLib')] 

>> Stemming using Porter Stemmer: 
 [('MLib', 'mlib'), ('provides', 'provid'), ('machine', 'machin'), ('learning', 'learn'), ('library', 'librari'), ('algorithms', 'algorithm'), ('utilities', 'util'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MLib', 'mlib'), ('provides', 'provid'), ('machine', 'machin'), ('learning', 'learn'), ('library', 'librari'), ('algorithms', 'algorithm'), ('utilities', 'util'), ('.', '.')]

>> Lemmatization: 
 [('MLib', 'MLib'), ('provides', 'provides'), ('machine', 'machine'), ('learning', 'learning'), ('library', 'library'), ('algorithms', 'algorithm'), ('utilities', 'utility'), ('.', '.')]



============================ Sentence 239 =============================

4. 


>> Tokens are: 
 ['4', '.']

>> Bigrams are: 
 [('4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('4', 'CD'), ('.', '.')]

 (S 4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('4', '4'), ('.', '.')]



============================ Sentence 240 =============================

Graph X provides application algorithms. 


>> Tokens are: 
 ['Graph', 'X', 'provides', 'application', 'algorithms', '.']

>> Bigrams are: 
 [('Graph', 'X'), ('X', 'provides'), ('provides', 'application'), ('application', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Graph', 'X', 'provides'), ('X', 'provides', 'application'), ('provides', 'application', 'algorithms'), ('application', 'algorithms', '.')]

>> POS Tags are: 
 [('Graph', 'NNP'), ('X', 'NNP'), ('provides', 'VBZ'), ('application', 'NN'), ('algorithms', 'NN'), ('.', '.')]

 (S
  (NP Graph/NNP X/NNP)
  provides/VBZ
  (NP application/NN algorithms/NN)
  ./.) 


>> Noun Phrases are: 
 ['Graph X', 'application algorithms']

>> Named Entities are: 
 [('PERSON', 'Graph')] 

>> Stemming using Porter Stemmer: 
 [('Graph', 'graph'), ('X', 'x'), ('provides', 'provid'), ('application', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Graph', 'graph'), ('X', 'x'), ('provides', 'provid'), ('application', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Graph', 'Graph'), ('X', 'X'), ('provides', 'provides'), ('application', 'application'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 241 =============================

Figure 11: Spark Components (Watson, 2019)         7.2. 


>> Tokens are: 
 ['Figure', '11', ':', 'Spark', 'Components', '(', 'Watson', ',', '2019', ')', '7.2', '.']

>> Bigrams are: 
 [('Figure', '11'), ('11', ':'), (':', 'Spark'), ('Spark', 'Components'), ('Components', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', '7.2'), ('7.2', '.')]

>> Trigrams are: 
 [('Figure', '11', ':'), ('11', ':', 'Spark'), (':', 'Spark', 'Components'), ('Spark', 'Components', '('), ('Components', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', '7.2'), (')', '7.2', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('11', 'CD'), (':', ':'), ('Spark', 'NN'), ('Components', 'NNS'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('7.2', 'CD'), ('.', '.')]

 (S
  (NP Figure/NN)
  11/CD
  :/:
  (NP Spark/NN Components/NNS)
  (/(
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  7.2/CD
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Spark Components', 'Watson']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('11', '11'), (':', ':'), ('Spark', 'spark'), ('Components', 'compon'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('7.2', '7.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('11', '11'), (':', ':'), ('Spark', 'spark'), ('Components', 'compon'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('7.2', '7.2'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('11', '11'), (':', ':'), ('Spark', 'Spark'), ('Components', 'Components'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), ('7.2', '7.2'), ('.', '.')]



============================ Sentence 242 =============================

Big data analytics processing   Analytics processing is the next issue after big data storage. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'processing', 'Analytics', 'processing', 'next', 'issue', 'big', 'data', 'storage', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'processing'), ('processing', 'Analytics'), ('Analytics', 'processing'), ('processing', 'next'), ('next', 'issue'), ('issue', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'processing'), ('analytics', 'processing', 'Analytics'), ('processing', 'Analytics', 'processing'), ('Analytics', 'processing', 'next'), ('processing', 'next', 'issue'), ('next', 'issue', 'big'), ('issue', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('processing', 'VBG'), ('Analytics', 'NNS'), ('processing', 'VBG'), ('next', 'JJ'), ('issue', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  processing/VBG
  (NP Analytics/NNS)
  processing/VBG
  (NP next/JJ issue/NN)
  (NP big/JJ data/NNS storage/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'Analytics', 'next issue', 'big data storage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('Analytics', 'analyt'), ('processing', 'process'), ('next', 'next'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('Analytics', 'analyt'), ('processing', 'process'), ('next', 'next'), ('issue', 'issu'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('processing', 'processing'), ('Analytics', 'Analytics'), ('processing', 'processing'), ('next', 'next'), ('issue', 'issue'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('.', '.')]



============================ Sentence 243 =============================

According to He et al. 


>> Tokens are: 
 ['According', 'He', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'He'), ('He', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'He', 'et'), ('He', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('He', 'PRP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

 (S According/VBG He/PRP et/VBZ (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('He', 'he'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('He', 'he'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('He', 'He'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 244 =============================

(2011), big   data analytics processing has four critical requirements:   a) Fast data loading: limited interference between disk and network, to speed up query  execution. 


>> Tokens are: 
 ['(', '2011', ')', ',', 'big', 'data', 'analytics', 'processing', 'four', 'critical', 'requirements', ':', ')', 'Fast', 'data', 'loading', ':', 'limited', 'interference', 'disk', 'network', ',', 'speed', 'query', 'execution', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'processing'), ('processing', 'four'), ('four', 'critical'), ('critical', 'requirements'), ('requirements', ':'), (':', ')'), (')', 'Fast'), ('Fast', 'data'), ('data', 'loading'), ('loading', ':'), (':', 'limited'), ('limited', 'interference'), ('interference', 'disk'), ('disk', 'network'), ('network', ','), (',', 'speed'), ('speed', 'query'), ('query', 'execution'), ('execution', '.')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', ','), (')', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'processing'), ('analytics', 'processing', 'four'), ('processing', 'four', 'critical'), ('four', 'critical', 'requirements'), ('critical', 'requirements', ':'), ('requirements', ':', ')'), (':', ')', 'Fast'), (')', 'Fast', 'data'), ('Fast', 'data', 'loading'), ('data', 'loading', ':'), ('loading', ':', 'limited'), (':', 'limited', 'interference'), ('limited', 'interference', 'disk'), ('interference', 'disk', 'network'), ('disk', 'network', ','), ('network', ',', 'speed'), (',', 'speed', 'query'), ('speed', 'query', 'execution'), ('query', 'execution', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('processing', 'VBG'), ('four', 'CD'), ('critical', 'JJ'), ('requirements', 'NNS'), (':', ':'), (')', ')'), ('Fast', 'NNP'), ('data', 'NN'), ('loading', 'NN'), (':', ':'), ('limited', 'JJ'), ('interference', 'NN'), ('disk', 'NN'), ('network', 'NN'), (',', ','), ('speed', 'NN'), ('query', 'NN'), ('execution', 'NN'), ('.', '.')]

 (S
  (/(
  2011/CD
  )/)
  ,/,
  (NP big/JJ data/NNS analytics/NNS)
  processing/VBG
  four/CD
  (NP critical/JJ requirements/NNS)
  :/:
  )/)
  (NP Fast/NNP data/NN loading/NN)
  :/:
  (NP limited/JJ interference/NN disk/NN network/NN)
  ,/,
  (NP speed/NN query/NN execution/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data analytics', 'critical requirements', 'Fast data loading', 'limited interference disk network', 'speed query execution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('four', 'four'), ('critical', 'critic'), ('requirements', 'requir'), (':', ':'), (')', ')'), ('Fast', 'fast'), ('data', 'data'), ('loading', 'load'), (':', ':'), ('limited', 'limit'), ('interference', 'interfer'), ('disk', 'disk'), ('network', 'network'), (',', ','), ('speed', 'speed'), ('query', 'queri'), ('execution', 'execut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('processing', 'process'), ('four', 'four'), ('critical', 'critic'), ('requirements', 'requir'), (':', ':'), (')', ')'), ('Fast', 'fast'), ('data', 'data'), ('loading', 'load'), (':', ':'), ('limited', 'limit'), ('interference', 'interfer'), ('disk', 'disk'), ('network', 'network'), (',', ','), ('speed', 'speed'), ('query', 'queri'), ('execution', 'execut'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('processing', 'processing'), ('four', 'four'), ('critical', 'critical'), ('requirements', 'requirement'), (':', ':'), (')', ')'), ('Fast', 'Fast'), ('data', 'data'), ('loading', 'loading'), (':', ':'), ('limited', 'limited'), ('interference', 'interference'), ('disk', 'disk'), ('network', 'network'), (',', ','), ('speed', 'speed'), ('query', 'query'), ('execution', 'execution'), ('.', '.')]



============================ Sentence 245 =============================

b) Fast query processing: workloads are heavy, therefore real-time requests should be  processed as quickly as possible to satisfy user requirements. 


>> Tokens are: 
 ['b', ')', 'Fast', 'query', 'processing', ':', 'workloads', 'heavy', ',', 'therefore', 'real-time', 'requests', 'processed', 'quickly', 'possible', 'satisfy', 'user', 'requirements', '.']

>> Bigrams are: 
 [('b', ')'), (')', 'Fast'), ('Fast', 'query'), ('query', 'processing'), ('processing', ':'), (':', 'workloads'), ('workloads', 'heavy'), ('heavy', ','), (',', 'therefore'), ('therefore', 'real-time'), ('real-time', 'requests'), ('requests', 'processed'), ('processed', 'quickly'), ('quickly', 'possible'), ('possible', 'satisfy'), ('satisfy', 'user'), ('user', 'requirements'), ('requirements', '.')]

>> Trigrams are: 
 [('b', ')', 'Fast'), (')', 'Fast', 'query'), ('Fast', 'query', 'processing'), ('query', 'processing', ':'), ('processing', ':', 'workloads'), (':', 'workloads', 'heavy'), ('workloads', 'heavy', ','), ('heavy', ',', 'therefore'), (',', 'therefore', 'real-time'), ('therefore', 'real-time', 'requests'), ('real-time', 'requests', 'processed'), ('requests', 'processed', 'quickly'), ('processed', 'quickly', 'possible'), ('quickly', 'possible', 'satisfy'), ('possible', 'satisfy', 'user'), ('satisfy', 'user', 'requirements'), ('user', 'requirements', '.')]

>> POS Tags are: 
 [('b', 'NN'), (')', ')'), ('Fast', 'NNP'), ('query', 'NN'), ('processing', 'NN'), (':', ':'), ('workloads', 'NNS'), ('heavy', 'VBP'), (',', ','), ('therefore', 'RB'), ('real-time', 'JJ'), ('requests', 'NNS'), ('processed', 'VBD'), ('quickly', 'RB'), ('possible', 'JJ'), ('satisfy', 'NN'), ('user', 'NN'), ('requirements', 'NNS'), ('.', '.')]

 (S
  (NP b/NN)
  )/)
  (NP Fast/NNP query/NN processing/NN)
  :/:
  (NP workloads/NNS)
  heavy/VBP
  ,/,
  therefore/RB
  (NP real-time/JJ requests/NNS)
  processed/VBD
  quickly/RB
  (NP possible/JJ satisfy/NN user/NN requirements/NNS)
  ./.) 


>> Noun Phrases are: 
 ['b', 'Fast query processing', 'workloads', 'real-time requests', 'possible satisfy user requirements']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('b', 'b'), (')', ')'), ('Fast', 'fast'), ('query', 'queri'), ('processing', 'process'), (':', ':'), ('workloads', 'workload'), ('heavy', 'heavi'), (',', ','), ('therefore', 'therefor'), ('real-time', 'real-tim'), ('requests', 'request'), ('processed', 'process'), ('quickly', 'quickli'), ('possible', 'possibl'), ('satisfy', 'satisfi'), ('user', 'user'), ('requirements', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('b', 'b'), (')', ')'), ('Fast', 'fast'), ('query', 'queri'), ('processing', 'process'), (':', ':'), ('workloads', 'workload'), ('heavy', 'heavi'), (',', ','), ('therefore', 'therefor'), ('real-time', 'real-tim'), ('requests', 'request'), ('processed', 'process'), ('quickly', 'quick'), ('possible', 'possibl'), ('satisfy', 'satisfi'), ('user', 'user'), ('requirements', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('b', 'b'), (')', ')'), ('Fast', 'Fast'), ('query', 'query'), ('processing', 'processing'), (':', ':'), ('workloads', 'workload'), ('heavy', 'heavy'), (',', ','), ('therefore', 'therefore'), ('real-time', 'real-time'), ('requests', 'request'), ('processed', 'processed'), ('quickly', 'quickly'), ('possible', 'possible'), ('satisfy', 'satisfy'), ('user', 'user'), ('requirements', 'requirement'), ('.', '.')]



============================ Sentence 246 =============================

The data placement structure   should also have the ability process multiple queries as query volumes increase. 


>> Tokens are: 
 ['The', 'data', 'placement', 'structure', 'also', 'ability', 'process', 'multiple', 'queries', 'query', 'volumes', 'increase', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'placement'), ('placement', 'structure'), ('structure', 'also'), ('also', 'ability'), ('ability', 'process'), ('process', 'multiple'), ('multiple', 'queries'), ('queries', 'query'), ('query', 'volumes'), ('volumes', 'increase'), ('increase', '.')]

>> Trigrams are: 
 [('The', 'data', 'placement'), ('data', 'placement', 'structure'), ('placement', 'structure', 'also'), ('structure', 'also', 'ability'), ('also', 'ability', 'process'), ('ability', 'process', 'multiple'), ('process', 'multiple', 'queries'), ('multiple', 'queries', 'query'), ('queries', 'query', 'volumes'), ('query', 'volumes', 'increase'), ('volumes', 'increase', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('placement', 'NN'), ('structure', 'NN'), ('also', 'RB'), ('ability', 'NN'), ('process', 'NN'), ('multiple', 'JJ'), ('queries', 'NNS'), ('query', 'VBP'), ('volumes', 'JJ'), ('increase', 'NN'), ('.', '.')]

 (S
  (NP The/DT data/NNS placement/NN structure/NN)
  also/RB
  (NP ability/NN process/NN)
  (NP multiple/JJ queries/NNS)
  query/VBP
  (NP volumes/JJ increase/NN)
  ./.) 


>> Noun Phrases are: 
 ['The data placement structure', 'ability process', 'multiple queries', 'volumes increase']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur'), ('also', 'also'), ('ability', 'abil'), ('process', 'process'), ('multiple', 'multipl'), ('queries', 'queri'), ('query', 'queri'), ('volumes', 'volum'), ('increase', 'increas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur'), ('also', 'also'), ('ability', 'abil'), ('process', 'process'), ('multiple', 'multipl'), ('queries', 'queri'), ('query', 'queri'), ('volumes', 'volum'), ('increase', 'increas'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structure'), ('also', 'also'), ('ability', 'ability'), ('process', 'process'), ('multiple', 'multiple'), ('queries', 'query'), ('query', 'query'), ('volumes', 'volume'), ('increase', 'increase'), ('.', '.')]



============================ Sentence 247 =============================

Sarah Al-Shiakhli   20      c) Highly efficient utilization of storage space: as user activities grow rapidly, they need  scalable storage capacity and computing power. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '20', 'c', ')', 'Highly', 'efficient', 'utilization', 'storage', 'space', ':', 'user', 'activities', 'grow', 'rapidly', ',', 'need', 'scalable', 'storage', 'capacity', 'computing', 'power', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '20'), ('20', 'c'), ('c', ')'), (')', 'Highly'), ('Highly', 'efficient'), ('efficient', 'utilization'), ('utilization', 'storage'), ('storage', 'space'), ('space', ':'), (':', 'user'), ('user', 'activities'), ('activities', 'grow'), ('grow', 'rapidly'), ('rapidly', ','), (',', 'need'), ('need', 'scalable'), ('scalable', 'storage'), ('storage', 'capacity'), ('capacity', 'computing'), ('computing', 'power'), ('power', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '20'), ('Al-Shiakhli', '20', 'c'), ('20', 'c', ')'), ('c', ')', 'Highly'), (')', 'Highly', 'efficient'), ('Highly', 'efficient', 'utilization'), ('efficient', 'utilization', 'storage'), ('utilization', 'storage', 'space'), ('storage', 'space', ':'), ('space', ':', 'user'), (':', 'user', 'activities'), ('user', 'activities', 'grow'), ('activities', 'grow', 'rapidly'), ('grow', 'rapidly', ','), ('rapidly', ',', 'need'), (',', 'need', 'scalable'), ('need', 'scalable', 'storage'), ('scalable', 'storage', 'capacity'), ('storage', 'capacity', 'computing'), ('capacity', 'computing', 'power'), ('computing', 'power', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('20', 'CD'), ('c', 'NN'), (')', ')'), ('Highly', 'NNP'), ('efficient', 'JJ'), ('utilization', 'NN'), ('storage', 'NN'), ('space', 'NN'), (':', ':'), ('user', 'NN'), ('activities', 'NNS'), ('grow', 'VBP'), ('rapidly', 'RB'), (',', ','), ('need', 'VBP'), ('scalable', 'JJ'), ('storage', 'NN'), ('capacity', 'NN'), ('computing', 'VBG'), ('power', 'NN'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  20/CD
  (NP c/NN)
  )/)
  (NP Highly/NNP)
  (NP efficient/JJ utilization/NN storage/NN space/NN)
  :/:
  (NP user/NN activities/NNS)
  grow/VBP
  rapidly/RB
  ,/,
  need/VBP
  (NP scalable/JJ storage/NN capacity/NN)
  computing/VBG
  (NP power/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'c', 'Highly', 'efficient utilization storage space', 'user activities', 'scalable storage capacity', 'power']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('20', '20'), ('c', 'c'), (')', ')'), ('Highly', 'highli'), ('efficient', 'effici'), ('utilization', 'util'), ('storage', 'storag'), ('space', 'space'), (':', ':'), ('user', 'user'), ('activities', 'activ'), ('grow', 'grow'), ('rapidly', 'rapidli'), (',', ','), ('need', 'need'), ('scalable', 'scalabl'), ('storage', 'storag'), ('capacity', 'capac'), ('computing', 'comput'), ('power', 'power'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('20', '20'), ('c', 'c'), (')', ')'), ('Highly', 'high'), ('efficient', 'effici'), ('utilization', 'util'), ('storage', 'storag'), ('space', 'space'), (':', ':'), ('user', 'user'), ('activities', 'activ'), ('grow', 'grow'), ('rapidly', 'rapid'), (',', ','), ('need', 'need'), ('scalable', 'scalabl'), ('storage', 'storag'), ('capacity', 'capac'), ('computing', 'comput'), ('power', 'power'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('20', '20'), ('c', 'c'), (')', ')'), ('Highly', 'Highly'), ('efficient', 'efficient'), ('utilization', 'utilization'), ('storage', 'storage'), ('space', 'space'), (':', ':'), ('user', 'user'), ('activities', 'activity'), ('grow', 'grow'), ('rapidly', 'rapidly'), (',', ','), ('need', 'need'), ('scalable', 'scalable'), ('storage', 'storage'), ('capacity', 'capacity'), ('computing', 'computing'), ('power', 'power'), ('.', '.')]



============================ Sentence 248 =============================

As disk space is limited, it is necessary to   manage data storage during processing and address the space issues adaptively. 


>> Tokens are: 
 ['As', 'disk', 'space', 'limited', ',', 'necessary', 'manage', 'data', 'storage', 'processing', 'address', 'space', 'issues', 'adaptively', '.']

>> Bigrams are: 
 [('As', 'disk'), ('disk', 'space'), ('space', 'limited'), ('limited', ','), (',', 'necessary'), ('necessary', 'manage'), ('manage', 'data'), ('data', 'storage'), ('storage', 'processing'), ('processing', 'address'), ('address', 'space'), ('space', 'issues'), ('issues', 'adaptively'), ('adaptively', '.')]

>> Trigrams are: 
 [('As', 'disk', 'space'), ('disk', 'space', 'limited'), ('space', 'limited', ','), ('limited', ',', 'necessary'), (',', 'necessary', 'manage'), ('necessary', 'manage', 'data'), ('manage', 'data', 'storage'), ('data', 'storage', 'processing'), ('storage', 'processing', 'address'), ('processing', 'address', 'space'), ('address', 'space', 'issues'), ('space', 'issues', 'adaptively'), ('issues', 'adaptively', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('disk', 'NN'), ('space', 'NN'), ('limited', 'VBD'), (',', ','), ('necessary', 'JJ'), ('manage', 'NN'), ('data', 'NNS'), ('storage', 'NN'), ('processing', 'NN'), ('address', 'JJ'), ('space', 'NN'), ('issues', 'NNS'), ('adaptively', 'RB'), ('.', '.')]

 (S
  As/IN
  (NP disk/NN space/NN)
  limited/VBD
  ,/,
  (NP necessary/JJ manage/NN data/NNS storage/NN processing/NN)
  (NP address/JJ space/NN issues/NNS)
  adaptively/RB
  ./.) 


>> Noun Phrases are: 
 ['disk space', 'necessary manage data storage processing', 'address space issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('disk', 'disk'), ('space', 'space'), ('limited', 'limit'), (',', ','), ('necessary', 'necessari'), ('manage', 'manag'), ('data', 'data'), ('storage', 'storag'), ('processing', 'process'), ('address', 'address'), ('space', 'space'), ('issues', 'issu'), ('adaptively', 'adapt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('disk', 'disk'), ('space', 'space'), ('limited', 'limit'), (',', ','), ('necessary', 'necessari'), ('manage', 'manag'), ('data', 'data'), ('storage', 'storag'), ('processing', 'process'), ('address', 'address'), ('space', 'space'), ('issues', 'issu'), ('adaptively', 'adapt'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('disk', 'disk'), ('space', 'space'), ('limited', 'limited'), (',', ','), ('necessary', 'necessary'), ('manage', 'manage'), ('data', 'data'), ('storage', 'storage'), ('processing', 'processing'), ('address', 'address'), ('space', 'space'), ('issues', 'issue'), ('adaptively', 'adaptively'), ('.', '.')]



============================ Sentence 249 =============================

d) Strong adaptivity to highly dynamic workload patterns: the underlying system should be  highly adaptive, as data processes have different workload patterns and the analysing of   big datasets has many different applications and users, with different purposes and methods   (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 [')', 'Strong', 'adaptivity', 'highly', 'dynamic', 'workload', 'patterns', ':', 'underlying', 'system', 'highly', 'adaptive', ',', 'data', 'processes', 'different', 'workload', 'patterns', 'analysing', 'big', 'datasets', 'many', 'different', 'applications', 'users', ',', 'different', 'purposes', 'methods', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [(')', 'Strong'), ('Strong', 'adaptivity'), ('adaptivity', 'highly'), ('highly', 'dynamic'), ('dynamic', 'workload'), ('workload', 'patterns'), ('patterns', ':'), (':', 'underlying'), ('underlying', 'system'), ('system', 'highly'), ('highly', 'adaptive'), ('adaptive', ','), (',', 'data'), ('data', 'processes'), ('processes', 'different'), ('different', 'workload'), ('workload', 'patterns'), ('patterns', 'analysing'), ('analysing', 'big'), ('big', 'datasets'), ('datasets', 'many'), ('many', 'different'), ('different', 'applications'), ('applications', 'users'), ('users', ','), (',', 'different'), ('different', 'purposes'), ('purposes', 'methods'), ('methods', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [(')', 'Strong', 'adaptivity'), ('Strong', 'adaptivity', 'highly'), ('adaptivity', 'highly', 'dynamic'), ('highly', 'dynamic', 'workload'), ('dynamic', 'workload', 'patterns'), ('workload', 'patterns', ':'), ('patterns', ':', 'underlying'), (':', 'underlying', 'system'), ('underlying', 'system', 'highly'), ('system', 'highly', 'adaptive'), ('highly', 'adaptive', ','), ('adaptive', ',', 'data'), (',', 'data', 'processes'), ('data', 'processes', 'different'), ('processes', 'different', 'workload'), ('different', 'workload', 'patterns'), ('workload', 'patterns', 'analysing'), ('patterns', 'analysing', 'big'), ('analysing', 'big', 'datasets'), ('big', 'datasets', 'many'), ('datasets', 'many', 'different'), ('many', 'different', 'applications'), ('different', 'applications', 'users'), ('applications', 'users', ','), ('users', ',', 'different'), (',', 'different', 'purposes'), ('different', 'purposes', 'methods'), ('purposes', 'methods', '('), ('methods', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [(')', ')'), ('Strong', 'NNP'), ('adaptivity', 'NN'), ('highly', 'RB'), ('dynamic', 'JJ'), ('workload', 'NN'), ('patterns', 'NNS'), (':', ':'), ('underlying', 'VBG'), ('system', 'NN'), ('highly', 'RB'), ('adaptive', 'JJ'), (',', ','), ('data', 'JJ'), ('processes', 'NNS'), ('different', 'JJ'), ('workload', 'NN'), ('patterns', 'NNS'), ('analysing', 'VBG'), ('big', 'JJ'), ('datasets', 'NNS'), ('many', 'JJ'), ('different', 'JJ'), ('applications', 'NNS'), ('users', 'NNS'), (',', ','), ('different', 'JJ'), ('purposes', 'NNS'), ('methods', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  )/)
  (NP Strong/NNP adaptivity/NN)
  highly/RB
  (NP dynamic/JJ workload/NN patterns/NNS)
  :/:
  underlying/VBG
  (NP system/NN)
  highly/RB
  adaptive/JJ
  ,/,
  (NP data/JJ processes/NNS)
  (NP different/JJ workload/NN patterns/NNS)
  analysing/VBG
  (NP big/JJ datasets/NNS)
  (NP many/JJ different/JJ applications/NNS users/NNS)
  ,/,
  (NP different/JJ purposes/NNS methods/NNS)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Strong adaptivity', 'dynamic workload patterns', 'system', 'data processes', 'different workload patterns', 'big datasets', 'many different applications users', 'different purposes methods', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('GPE', 'Strong'), ('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [(')', ')'), ('Strong', 'strong'), ('adaptivity', 'adapt'), ('highly', 'highli'), ('dynamic', 'dynam'), ('workload', 'workload'), ('patterns', 'pattern'), (':', ':'), ('underlying', 'underli'), ('system', 'system'), ('highly', 'highli'), ('adaptive', 'adapt'), (',', ','), ('data', 'data'), ('processes', 'process'), ('different', 'differ'), ('workload', 'workload'), ('patterns', 'pattern'), ('analysing', 'analys'), ('big', 'big'), ('datasets', 'dataset'), ('many', 'mani'), ('different', 'differ'), ('applications', 'applic'), ('users', 'user'), (',', ','), ('different', 'differ'), ('purposes', 'purpos'), ('methods', 'method'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(')', ')'), ('Strong', 'strong'), ('adaptivity', 'adapt'), ('highly', 'high'), ('dynamic', 'dynam'), ('workload', 'workload'), ('patterns', 'pattern'), (':', ':'), ('underlying', 'under'), ('system', 'system'), ('highly', 'high'), ('adaptive', 'adapt'), (',', ','), ('data', 'data'), ('processes', 'process'), ('different', 'differ'), ('workload', 'workload'), ('patterns', 'pattern'), ('analysing', 'analys'), ('big', 'big'), ('datasets', 'dataset'), ('many', 'mani'), ('different', 'differ'), ('applications', 'applic'), ('users', 'user'), (',', ','), ('different', 'differ'), ('purposes', 'purpos'), ('methods', 'method'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [(')', ')'), ('Strong', 'Strong'), ('adaptivity', 'adaptivity'), ('highly', 'highly'), ('dynamic', 'dynamic'), ('workload', 'workload'), ('patterns', 'pattern'), (':', ':'), ('underlying', 'underlying'), ('system', 'system'), ('highly', 'highly'), ('adaptive', 'adaptive'), (',', ','), ('data', 'data'), ('processes', 'process'), ('different', 'different'), ('workload', 'workload'), ('patterns', 'pattern'), ('analysing', 'analysing'), ('big', 'big'), ('datasets', 'datasets'), ('many', 'many'), ('different', 'different'), ('applications', 'application'), ('users', 'user'), (',', ','), ('different', 'different'), ('purposes', 'purpose'), ('methods', 'method'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 250 =============================

The work presented by García et al. 


>> Tokens are: 
 ['The', 'work', 'presented', 'García', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'work'), ('work', 'presented'), ('presented', 'García'), ('García', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'work', 'presented'), ('work', 'presented', 'García'), ('presented', 'García', 'et'), ('García', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('work', 'NN'), ('presented', 'VBD'), ('García', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S
  (NP The/DT work/NN)
  presented/VBD
  (NP García/NNP)
  et/CC
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['The work', 'García', 'al']

>> Named Entities are: 
 [('PERSON', 'García')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('work', 'work'), ('presented', 'present'), ('García', 'garcía'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('work', 'work'), ('presented', 'present'), ('García', 'garcía'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('work', 'work'), ('presented', 'presented'), ('García', 'García'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 251 =============================

(2016) shows that using big data frameworks for storing,   processing, and analysing data has changed the context of knowledge discovery from data,   mainly in terms of data mining processes and pre-processing, with a particular focus on the   rise of data pre-processing in cloud computing. 


>> Tokens are: 
 ['(', '2016', ')', 'shows', 'using', 'big', 'data', 'frameworks', 'storing', ',', 'processing', ',', 'analysing', 'data', 'changed', 'context', 'knowledge', 'discovery', 'data', ',', 'mainly', 'terms', 'data', 'mining', 'processes', 'pre-processing', ',', 'particular', 'focus', 'rise', 'data', 'pre-processing', 'cloud', 'computing', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'shows'), ('shows', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'frameworks'), ('frameworks', 'storing'), ('storing', ','), (',', 'processing'), ('processing', ','), (',', 'analysing'), ('analysing', 'data'), ('data', 'changed'), ('changed', 'context'), ('context', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'data'), ('data', ','), (',', 'mainly'), ('mainly', 'terms'), ('terms', 'data'), ('data', 'mining'), ('mining', 'processes'), ('processes', 'pre-processing'), ('pre-processing', ','), (',', 'particular'), ('particular', 'focus'), ('focus', 'rise'), ('rise', 'data'), ('data', 'pre-processing'), ('pre-processing', 'cloud'), ('cloud', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'shows'), (')', 'shows', 'using'), ('shows', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'frameworks'), ('data', 'frameworks', 'storing'), ('frameworks', 'storing', ','), ('storing', ',', 'processing'), (',', 'processing', ','), ('processing', ',', 'analysing'), (',', 'analysing', 'data'), ('analysing', 'data', 'changed'), ('data', 'changed', 'context'), ('changed', 'context', 'knowledge'), ('context', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'data'), ('discovery', 'data', ','), ('data', ',', 'mainly'), (',', 'mainly', 'terms'), ('mainly', 'terms', 'data'), ('terms', 'data', 'mining'), ('data', 'mining', 'processes'), ('mining', 'processes', 'pre-processing'), ('processes', 'pre-processing', ','), ('pre-processing', ',', 'particular'), (',', 'particular', 'focus'), ('particular', 'focus', 'rise'), ('focus', 'rise', 'data'), ('rise', 'data', 'pre-processing'), ('data', 'pre-processing', 'cloud'), ('pre-processing', 'cloud', 'computing'), ('cloud', 'computing', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('shows', 'VBZ'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('frameworks', 'NNS'), ('storing', 'VBG'), (',', ','), ('processing', 'NN'), (',', ','), ('analysing', 'VBG'), ('data', 'NNS'), ('changed', 'VBD'), ('context', 'NN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('data', 'NNS'), (',', ','), ('mainly', 'RB'), ('terms', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), ('processes', 'VBZ'), ('pre-processing', 'NN'), (',', ','), ('particular', 'JJ'), ('focus', 'NN'), ('rise', 'NN'), ('data', 'NNS'), ('pre-processing', 'JJ'), ('cloud', 'NN'), ('computing', 'NN'), ('.', '.')]

 (S
  (/(
  2016/CD
  )/)
  shows/VBZ
  using/VBG
  (NP big/JJ data/NNS frameworks/NNS)
  storing/VBG
  ,/,
  (NP processing/NN)
  ,/,
  analysing/VBG
  (NP data/NNS)
  changed/VBD
  (NP context/NN knowledge/NN discovery/NN data/NNS)
  ,/,
  mainly/RB
  (NP terms/NNS data/NNS mining/NN)
  processes/VBZ
  (NP pre-processing/NN)
  ,/,
  (NP particular/JJ focus/NN rise/NN data/NNS)
  (NP pre-processing/JJ cloud/NN computing/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data frameworks', 'processing', 'data', 'context knowledge discovery data', 'terms data mining', 'pre-processing', 'particular focus rise data', 'pre-processing cloud computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('frameworks', 'framework'), ('storing', 'store'), (',', ','), ('processing', 'process'), (',', ','), ('analysing', 'analys'), ('data', 'data'), ('changed', 'chang'), ('context', 'context'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('data', 'data'), (',', ','), ('mainly', 'mainli'), ('terms', 'term'), ('data', 'data'), ('mining', 'mine'), ('processes', 'process'), ('pre-processing', 'pre-process'), (',', ','), ('particular', 'particular'), ('focus', 'focu'), ('rise', 'rise'), ('data', 'data'), ('pre-processing', 'pre-process'), ('cloud', 'cloud'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('frameworks', 'framework'), ('storing', 'store'), (',', ','), ('processing', 'process'), (',', ','), ('analysing', 'analys'), ('data', 'data'), ('changed', 'chang'), ('context', 'context'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('data', 'data'), (',', ','), ('mainly', 'main'), ('terms', 'term'), ('data', 'data'), ('mining', 'mine'), ('processes', 'process'), ('pre-processing', 'pre-process'), (',', ','), ('particular', 'particular'), ('focus', 'focus'), ('rise', 'rise'), ('data', 'data'), ('pre-processing', 'pre-process'), ('cloud', 'cloud'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('frameworks', 'framework'), ('storing', 'storing'), (',', ','), ('processing', 'processing'), (',', ','), ('analysing', 'analysing'), ('data', 'data'), ('changed', 'changed'), ('context', 'context'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('data', 'data'), (',', ','), ('mainly', 'mainly'), ('terms', 'term'), ('data', 'data'), ('mining', 'mining'), ('processes', 'process'), ('pre-processing', 'pre-processing'), (',', ','), ('particular', 'particular'), ('focus', 'focus'), ('rise', 'rise'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('cloud', 'cloud'), ('computing', 'computing'), ('.', '.')]



============================ Sentence 252 =============================

The presented solution covered various data   pre-processing technique families with factors such as maximum size supported examined in   terms of big data and data pre-processing throughout all of the families of methods. 


>> Tokens are: 
 ['The', 'presented', 'solution', 'covered', 'various', 'data', 'pre-processing', 'technique', 'families', 'factors', 'maximum', 'size', 'supported', 'examined', 'terms', 'big', 'data', 'data', 'pre-processing', 'throughout', 'families', 'methods', '.']

>> Bigrams are: 
 [('The', 'presented'), ('presented', 'solution'), ('solution', 'covered'), ('covered', 'various'), ('various', 'data'), ('data', 'pre-processing'), ('pre-processing', 'technique'), ('technique', 'families'), ('families', 'factors'), ('factors', 'maximum'), ('maximum', 'size'), ('size', 'supported'), ('supported', 'examined'), ('examined', 'terms'), ('terms', 'big'), ('big', 'data'), ('data', 'data'), ('data', 'pre-processing'), ('pre-processing', 'throughout'), ('throughout', 'families'), ('families', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('The', 'presented', 'solution'), ('presented', 'solution', 'covered'), ('solution', 'covered', 'various'), ('covered', 'various', 'data'), ('various', 'data', 'pre-processing'), ('data', 'pre-processing', 'technique'), ('pre-processing', 'technique', 'families'), ('technique', 'families', 'factors'), ('families', 'factors', 'maximum'), ('factors', 'maximum', 'size'), ('maximum', 'size', 'supported'), ('size', 'supported', 'examined'), ('supported', 'examined', 'terms'), ('examined', 'terms', 'big'), ('terms', 'big', 'data'), ('big', 'data', 'data'), ('data', 'data', 'pre-processing'), ('data', 'pre-processing', 'throughout'), ('pre-processing', 'throughout', 'families'), ('throughout', 'families', 'methods'), ('families', 'methods', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('presented', 'JJ'), ('solution', 'NN'), ('covered', 'VBD'), ('various', 'JJ'), ('data', 'NNS'), ('pre-processing', 'NN'), ('technique', 'NN'), ('families', 'NNS'), ('factors', 'NNS'), ('maximum', 'JJ'), ('size', 'NN'), ('supported', 'VBD'), ('examined', 'JJ'), ('terms', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('data', 'NNS'), ('pre-processing', 'NN'), ('throughout', 'IN'), ('families', 'NNS'), ('methods', 'NNS'), ('.', '.')]

 (S
  (NP The/DT presented/JJ solution/NN)
  covered/VBD
  (NP
    various/JJ
    data/NNS
    pre-processing/NN
    technique/NN
    families/NNS
    factors/NNS)
  (NP maximum/JJ size/NN)
  supported/VBD
  (NP examined/JJ terms/NNS)
  (NP big/JJ data/NNS data/NNS pre-processing/NN)
  throughout/IN
  (NP families/NNS methods/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The presented solution', 'various data pre-processing technique families factors', 'maximum size', 'examined terms', 'big data data pre-processing', 'families methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('presented', 'present'), ('solution', 'solut'), ('covered', 'cover'), ('various', 'variou'), ('data', 'data'), ('pre-processing', 'pre-process'), ('technique', 'techniqu'), ('families', 'famili'), ('factors', 'factor'), ('maximum', 'maximum'), ('size', 'size'), ('supported', 'support'), ('examined', 'examin'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('pre-processing', 'pre-process'), ('throughout', 'throughout'), ('families', 'famili'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('presented', 'present'), ('solution', 'solut'), ('covered', 'cover'), ('various', 'various'), ('data', 'data'), ('pre-processing', 'pre-process'), ('technique', 'techniqu'), ('families', 'famili'), ('factors', 'factor'), ('maximum', 'maximum'), ('size', 'size'), ('supported', 'support'), ('examined', 'examin'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('pre-processing', 'pre-process'), ('throughout', 'throughout'), ('families', 'famili'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('presented', 'presented'), ('solution', 'solution'), ('covered', 'covered'), ('various', 'various'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('technique', 'technique'), ('families', 'family'), ('factors', 'factor'), ('maximum', 'maximum'), ('size', 'size'), ('supported', 'supported'), ('examined', 'examined'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('throughout', 'throughout'), ('families', 'family'), ('methods', 'method'), ('.', '.')]



============================ Sentence 253 =============================

Moreover,   various big data framework such as Hadoop, Spark, and Flink were discussed. 


>> Tokens are: 
 ['Moreover', ',', 'various', 'big', 'data', 'framework', 'Hadoop', ',', 'Spark', ',', 'Flink', 'discussed', '.']

>> Bigrams are: 
 [('Moreover', ','), (',', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'framework'), ('framework', 'Hadoop'), ('Hadoop', ','), (',', 'Spark'), ('Spark', ','), (',', 'Flink'), ('Flink', 'discussed'), ('discussed', '.')]

>> Trigrams are: 
 [('Moreover', ',', 'various'), (',', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'framework'), ('data', 'framework', 'Hadoop'), ('framework', 'Hadoop', ','), ('Hadoop', ',', 'Spark'), (',', 'Spark', ','), ('Spark', ',', 'Flink'), (',', 'Flink', 'discussed'), ('Flink', 'discussed', '.')]

>> POS Tags are: 
 [('Moreover', 'RB'), (',', ','), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('framework', 'NN'), ('Hadoop', 'NNP'), (',', ','), ('Spark', 'NNP'), (',', ','), ('Flink', 'NNP'), ('discussed', 'VBD'), ('.', '.')]

 (S
  Moreover/RB
  ,/,
  (NP various/JJ big/JJ data/NNS framework/NN Hadoop/NNP)
  ,/,
  (NP Spark/NNP)
  ,/,
  (NP Flink/NNP)
  discussed/VBD
  ./.) 


>> Noun Phrases are: 
 ['various big data framework Hadoop', 'Spark', 'Flink']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('GPE', 'Spark'), ('PERSON', 'Flink')] 

>> Stemming using Porter Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), ('Hadoop', 'hadoop'), (',', ','), ('Spark', 'spark'), (',', ','), ('Flink', 'flink'), ('discussed', 'discuss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moreover', 'moreov'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), ('Hadoop', 'hadoop'), (',', ','), ('Spark', 'spark'), (',', ','), ('Flink', 'flink'), ('discussed', 'discuss'), ('.', '.')]

>> Lemmatization: 
 [('Moreover', 'Moreover'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('framework', 'framework'), ('Hadoop', 'Hadoop'), (',', ','), ('Spark', 'Spark'), (',', ','), ('Flink', 'Flink'), ('discussed', 'discussed'), ('.', '.')]



============================ Sentence 254 =============================

7.3. 


>> Tokens are: 
 ['7.3', '.']

>> Bigrams are: 
 [('7.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.3', 'CD'), ('.', '.')]

 (S 7.3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.3', '7.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.3', '7.3'), ('.', '.')]

>> Lemmatization: 
 [('7.3', '7.3'), ('.', '.')]



============================ Sentence 255 =============================

Big data analytics   Big data growth continues apace, and many organisations are now interested in managing and   analysing data. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'Big', 'data', 'growth', 'continues', 'apace', ',', 'many', 'organisations', 'interested', 'managing', 'analysing', 'data', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'Big'), ('Big', 'data'), ('data', 'growth'), ('growth', 'continues'), ('continues', 'apace'), ('apace', ','), (',', 'many'), ('many', 'organisations'), ('organisations', 'interested'), ('interested', 'managing'), ('managing', 'analysing'), ('analysing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'Big'), ('analytics', 'Big', 'data'), ('Big', 'data', 'growth'), ('data', 'growth', 'continues'), ('growth', 'continues', 'apace'), ('continues', 'apace', ','), ('apace', ',', 'many'), (',', 'many', 'organisations'), ('many', 'organisations', 'interested'), ('organisations', 'interested', 'managing'), ('interested', 'managing', 'analysing'), ('managing', 'analysing', 'data'), ('analysing', 'data', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('Big', 'NNP'), ('data', 'NNS'), ('growth', 'NN'), ('continues', 'VBZ'), ('apace', 'NN'), (',', ','), ('many', 'JJ'), ('organisations', 'NNS'), ('interested', 'JJ'), ('managing', 'VBG'), ('analysing', 'VBG'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS Big/NNP data/NNS growth/NN)
  continues/VBZ
  (NP apace/NN)
  ,/,
  (NP many/JJ organisations/NNS)
  interested/JJ
  managing/VBG
  analysing/VBG
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics Big data growth', 'apace', 'many organisations', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('Big', 'big'), ('data', 'data'), ('growth', 'growth'), ('continues', 'continu'), ('apace', 'apac'), (',', ','), ('many', 'mani'), ('organisations', 'organis'), ('interested', 'interest'), ('managing', 'manag'), ('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('Big', 'big'), ('data', 'data'), ('growth', 'growth'), ('continues', 'continu'), ('apace', 'apac'), (',', ','), ('many', 'mani'), ('organisations', 'organis'), ('interested', 'interest'), ('managing', 'manag'), ('analysing', 'analys'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('Big', 'Big'), ('data', 'data'), ('growth', 'growth'), ('continues', 'continues'), ('apace', 'apace'), (',', ','), ('many', 'many'), ('organisations', 'organisation'), ('interested', 'interested'), ('managing', 'managing'), ('analysing', 'analysing'), ('data', 'data'), ('.', '.')]



============================ Sentence 256 =============================

Organisations trying to benefit from big data are adopting big data analytics to   facilitate faster and better decisions, as it is not easy to analyse datasets with analysis techniques   and infrastructure based on traditional data management (Constantiou et al., 2015). 


>> Tokens are: 
 ['Organisations', 'trying', 'benefit', 'big', 'data', 'adopting', 'big', 'data', 'analytics', 'facilitate', 'faster', 'better', 'decisions', ',', 'easy', 'analyse', 'datasets', 'analysis', 'techniques', 'infrastructure', 'based', 'traditional', 'data', 'management', '(', 'Constantiou', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Organisations', 'trying'), ('trying', 'benefit'), ('benefit', 'big'), ('big', 'data'), ('data', 'adopting'), ('adopting', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'facilitate'), ('facilitate', 'faster'), ('faster', 'better'), ('better', 'decisions'), ('decisions', ','), (',', 'easy'), ('easy', 'analyse'), ('analyse', 'datasets'), ('datasets', 'analysis'), ('analysis', 'techniques'), ('techniques', 'infrastructure'), ('infrastructure', 'based'), ('based', 'traditional'), ('traditional', 'data'), ('data', 'management'), ('management', '('), ('(', 'Constantiou'), ('Constantiou', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Organisations', 'trying', 'benefit'), ('trying', 'benefit', 'big'), ('benefit', 'big', 'data'), ('big', 'data', 'adopting'), ('data', 'adopting', 'big'), ('adopting', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'facilitate'), ('analytics', 'facilitate', 'faster'), ('facilitate', 'faster', 'better'), ('faster', 'better', 'decisions'), ('better', 'decisions', ','), ('decisions', ',', 'easy'), (',', 'easy', 'analyse'), ('easy', 'analyse', 'datasets'), ('analyse', 'datasets', 'analysis'), ('datasets', 'analysis', 'techniques'), ('analysis', 'techniques', 'infrastructure'), ('techniques', 'infrastructure', 'based'), ('infrastructure', 'based', 'traditional'), ('based', 'traditional', 'data'), ('traditional', 'data', 'management'), ('data', 'management', '('), ('management', '(', 'Constantiou'), ('(', 'Constantiou', 'et'), ('Constantiou', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('trying', 'VBG'), ('benefit', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('adopting', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('facilitate', 'VBP'), ('faster', 'RBR'), ('better', 'JJR'), ('decisions', 'NNS'), (',', ','), ('easy', 'JJ'), ('analyse', 'JJ'), ('datasets', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('infrastructure', 'NN'), ('based', 'VBN'), ('traditional', 'JJ'), ('data', 'NNS'), ('management', 'NN'), ('(', '('), ('Constantiou', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Organisations/NNS)
  trying/VBG
  (NP benefit/NN)
  (NP big/JJ data/NNS)
  adopting/VBG
  (NP big/JJ data/NNS analytics/NNS)
  facilitate/VBP
  faster/RBR
  better/JJR
  (NP decisions/NNS)
  ,/,
  (NP
    easy/JJ
    analyse/JJ
    datasets/NNS
    analysis/NN
    techniques/NNS
    infrastructure/NN)
  based/VBN
  (NP traditional/JJ data/NNS management/NN)
  (/(
  (NP Constantiou/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Organisations', 'benefit', 'big data', 'big data analytics', 'decisions', 'easy analyse datasets analysis techniques infrastructure', 'traditional data management', 'Constantiou']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('trying', 'tri'), ('benefit', 'benefit'), ('big', 'big'), ('data', 'data'), ('adopting', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('facilitate', 'facilit'), ('faster', 'faster'), ('better', 'better'), ('decisions', 'decis'), (',', ','), ('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('infrastructure', 'infrastructur'), ('based', 'base'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('(', '('), ('Constantiou', 'constanti'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('trying', 'tri'), ('benefit', 'benefit'), ('big', 'big'), ('data', 'data'), ('adopting', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('facilitate', 'facilit'), ('faster', 'faster'), ('better', 'better'), ('decisions', 'decis'), (',', ','), ('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('infrastructure', 'infrastructur'), ('based', 'base'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('(', '('), ('Constantiou', 'constantiou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('trying', 'trying'), ('benefit', 'benefit'), ('big', 'big'), ('data', 'data'), ('adopting', 'adopting'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('facilitate', 'facilitate'), ('faster', 'faster'), ('better', 'better'), ('decisions', 'decision'), (',', ','), ('easy', 'easy'), ('analyse', 'analyse'), ('datasets', 'datasets'), ('analysis', 'analysis'), ('techniques', 'technique'), ('infrastructure', 'infrastructure'), ('based', 'based'), ('traditional', 'traditional'), ('data', 'data'), ('management', 'management'), ('(', '('), ('Constantiou', 'Constantiou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 257 =============================

The need for   new tools and methods specialised for big data analytics is thus also growing. 


>> Tokens are: 
 ['The', 'need', 'new', 'tools', 'methods', 'specialised', 'big', 'data', 'analytics', 'thus', 'also', 'growing', '.']

>> Bigrams are: 
 [('The', 'need'), ('need', 'new'), ('new', 'tools'), ('tools', 'methods'), ('methods', 'specialised'), ('specialised', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'thus'), ('thus', 'also'), ('also', 'growing'), ('growing', '.')]

>> Trigrams are: 
 [('The', 'need', 'new'), ('need', 'new', 'tools'), ('new', 'tools', 'methods'), ('tools', 'methods', 'specialised'), ('methods', 'specialised', 'big'), ('specialised', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'thus'), ('analytics', 'thus', 'also'), ('thus', 'also', 'growing'), ('also', 'growing', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('need', 'NN'), ('new', 'JJ'), ('tools', 'NNS'), ('methods', 'NNS'), ('specialised', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('thus', 'RB'), ('also', 'RB'), ('growing', 'VBG'), ('.', '.')]

 (S
  (NP The/DT need/NN)
  (NP new/JJ tools/NNS methods/NNS)
  specialised/VBD
  (NP big/JJ data/NNS analytics/NNS)
  thus/RB
  also/RB
  growing/VBG
  ./.) 


>> Noun Phrases are: 
 ['The need', 'new tools methods', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('need', 'need'), ('new', 'new'), ('tools', 'tool'), ('methods', 'method'), ('specialised', 'specialis'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thu'), ('also', 'also'), ('growing', 'grow'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('need', 'need'), ('new', 'new'), ('tools', 'tool'), ('methods', 'method'), ('specialised', 'specialis'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thus'), ('also', 'also'), ('growing', 'grow'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('need', 'need'), ('new', 'new'), ('tools', 'tool'), ('methods', 'method'), ('specialised', 'specialised'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('thus', 'thus'), ('also', 'also'), ('growing', 'growing'), ('.', '.')]



============================ Sentence 258 =============================

The emergence of   big data is affecting everything from data itself to its collection and processing, and, finally, the   extracted decisions. 


>> Tokens are: 
 ['The', 'emergence', 'big', 'data', 'affecting', 'everything', 'data', 'collection', 'processing', ',', ',', 'finally', ',', 'extracted', 'decisions', '.']

>> Bigrams are: 
 [('The', 'emergence'), ('emergence', 'big'), ('big', 'data'), ('data', 'affecting'), ('affecting', 'everything'), ('everything', 'data'), ('data', 'collection'), ('collection', 'processing'), ('processing', ','), (',', ','), (',', 'finally'), ('finally', ','), (',', 'extracted'), ('extracted', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('The', 'emergence', 'big'), ('emergence', 'big', 'data'), ('big', 'data', 'affecting'), ('data', 'affecting', 'everything'), ('affecting', 'everything', 'data'), ('everything', 'data', 'collection'), ('data', 'collection', 'processing'), ('collection', 'processing', ','), ('processing', ',', ','), (',', ',', 'finally'), (',', 'finally', ','), ('finally', ',', 'extracted'), (',', 'extracted', 'decisions'), ('extracted', 'decisions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('emergence', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('affecting', 'VBG'), ('everything', 'NN'), ('data', 'NNS'), ('collection', 'NN'), ('processing', 'NN'), (',', ','), (',', ','), ('finally', 'RB'), (',', ','), ('extracted', 'VBD'), ('decisions', 'NNS'), ('.', '.')]

 (S
  (NP The/DT emergence/NN)
  (NP big/JJ data/NNS)
  affecting/VBG
  (NP everything/NN data/NNS collection/NN processing/NN)
  ,/,
  ,/,
  finally/RB
  ,/,
  extracted/VBD
  (NP decisions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The emergence', 'big data', 'everything data collection processing', 'decisions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('emergence', 'emerg'), ('big', 'big'), ('data', 'data'), ('affecting', 'affect'), ('everything', 'everyth'), ('data', 'data'), ('collection', 'collect'), ('processing', 'process'), (',', ','), (',', ','), ('finally', 'final'), (',', ','), ('extracted', 'extract'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('emergence', 'emerg'), ('big', 'big'), ('data', 'data'), ('affecting', 'affect'), ('everything', 'everyth'), ('data', 'data'), ('collection', 'collect'), ('processing', 'process'), (',', ','), (',', ','), ('finally', 'final'), (',', ','), ('extracted', 'extract'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('emergence', 'emergence'), ('big', 'big'), ('data', 'data'), ('affecting', 'affecting'), ('everything', 'everything'), ('data', 'data'), ('collection', 'collection'), ('processing', 'processing'), (',', ','), (',', ','), ('finally', 'finally'), (',', ','), ('extracted', 'extracted'), ('decisions', 'decision'), ('.', '.')]



============================ Sentence 259 =============================

Providing big data tools and technologies can help in managing the growth of   network-produced data, which is otherwise exponential, as well as in increasing the capability of   organisations to scale and capture the required data to reduce database performance problems   (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 ['Providing', 'big', 'data', 'tools', 'technologies', 'help', 'managing', 'growth', 'network-produced', 'data', ',', 'otherwise', 'exponential', ',', 'well', 'increasing', 'capability', 'organisations', 'scale', 'capture', 'required', 'data', 'reduce', 'database', 'performance', 'problems', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Providing', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'technologies'), ('technologies', 'help'), ('help', 'managing'), ('managing', 'growth'), ('growth', 'network-produced'), ('network-produced', 'data'), ('data', ','), (',', 'otherwise'), ('otherwise', 'exponential'), ('exponential', ','), (',', 'well'), ('well', 'increasing'), ('increasing', 'capability'), ('capability', 'organisations'), ('organisations', 'scale'), ('scale', 'capture'), ('capture', 'required'), ('required', 'data'), ('data', 'reduce'), ('reduce', 'database'), ('database', 'performance'), ('performance', 'problems'), ('problems', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Providing', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'technologies'), ('tools', 'technologies', 'help'), ('technologies', 'help', 'managing'), ('help', 'managing', 'growth'), ('managing', 'growth', 'network-produced'), ('growth', 'network-produced', 'data'), ('network-produced', 'data', ','), ('data', ',', 'otherwise'), (',', 'otherwise', 'exponential'), ('otherwise', 'exponential', ','), ('exponential', ',', 'well'), (',', 'well', 'increasing'), ('well', 'increasing', 'capability'), ('increasing', 'capability', 'organisations'), ('capability', 'organisations', 'scale'), ('organisations', 'scale', 'capture'), ('scale', 'capture', 'required'), ('capture', 'required', 'data'), ('required', 'data', 'reduce'), ('data', 'reduce', 'database'), ('reduce', 'database', 'performance'), ('database', 'performance', 'problems'), ('performance', 'problems', '('), ('problems', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Providing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('tools', 'NNS'), ('technologies', 'NNS'), ('help', 'VBP'), ('managing', 'VBG'), ('growth', 'NN'), ('network-produced', 'JJ'), ('data', 'NNS'), (',', ','), ('otherwise', 'RB'), ('exponential', 'JJ'), (',', ','), ('well', 'RB'), ('increasing', 'VBG'), ('capability', 'NN'), ('organisations', 'NNS'), ('scale', 'JJ'), ('capture', 'NN'), ('required', 'VBN'), ('data', 'NNS'), ('reduce', 'VB'), ('database', 'NN'), ('performance', 'NN'), ('problems', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  Providing/VBG
  (NP big/JJ data/NNS tools/NNS technologies/NNS)
  help/VBP
  managing/VBG
  (NP growth/NN)
  (NP network-produced/JJ data/NNS)
  ,/,
  otherwise/RB
  exponential/JJ
  ,/,
  well/RB
  increasing/VBG
  (NP capability/NN organisations/NNS)
  (NP scale/JJ capture/NN)
  required/VBN
  (NP data/NNS)
  reduce/VB
  (NP database/NN performance/NN problems/NNS)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['big data tools technologies', 'growth', 'network-produced data', 'capability organisations', 'scale capture', 'data', 'database performance problems', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Providing', 'provid'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('technologies', 'technolog'), ('help', 'help'), ('managing', 'manag'), ('growth', 'growth'), ('network-produced', 'network-produc'), ('data', 'data'), (',', ','), ('otherwise', 'otherwis'), ('exponential', 'exponenti'), (',', ','), ('well', 'well'), ('increasing', 'increas'), ('capability', 'capabl'), ('organisations', 'organis'), ('scale', 'scale'), ('capture', 'captur'), ('required', 'requir'), ('data', 'data'), ('reduce', 'reduc'), ('database', 'databas'), ('performance', 'perform'), ('problems', 'problem'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Providing', 'provid'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('technologies', 'technolog'), ('help', 'help'), ('managing', 'manag'), ('growth', 'growth'), ('network-produced', 'network-produc'), ('data', 'data'), (',', ','), ('otherwise', 'otherwis'), ('exponential', 'exponenti'), (',', ','), ('well', 'well'), ('increasing', 'increas'), ('capability', 'capabl'), ('organisations', 'organis'), ('scale', 'scale'), ('capture', 'captur'), ('required', 'requir'), ('data', 'data'), ('reduce', 'reduc'), ('database', 'databas'), ('performance', 'perform'), ('problems', 'problem'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Providing', 'Providing'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('technologies', 'technology'), ('help', 'help'), ('managing', 'managing'), ('growth', 'growth'), ('network-produced', 'network-produced'), ('data', 'data'), (',', ','), ('otherwise', 'otherwise'), ('exponential', 'exponential'), (',', ','), ('well', 'well'), ('increasing', 'increasing'), ('capability', 'capability'), ('organisations', 'organisation'), ('scale', 'scale'), ('capture', 'capture'), ('required', 'required'), ('data', 'data'), ('reduce', 'reduce'), ('database', 'database'), ('performance', 'performance'), ('problems', 'problem'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 260 =============================

Further big data analytics definitions are clarified in Table 4. 


>> Tokens are: 
 ['Further', 'big', 'data', 'analytics', 'definitions', 'clarified', 'Table', '4', '.']

>> Bigrams are: 
 [('Further', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'definitions'), ('definitions', 'clarified'), ('clarified', 'Table'), ('Table', '4'), ('4', '.')]

>> Trigrams are: 
 [('Further', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'definitions'), ('analytics', 'definitions', 'clarified'), ('definitions', 'clarified', 'Table'), ('clarified', 'Table', '4'), ('Table', '4', '.')]

>> POS Tags are: 
 [('Further', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('definitions', 'NNS'), ('clarified', 'VBD'), ('Table', 'JJ'), ('4', 'CD'), ('.', '.')]

 (S
  Further/RB
  (NP big/JJ data/NNS analytics/NNS definitions/NNS)
  clarified/VBD
  Table/JJ
  4/CD
  ./.) 


>> Noun Phrases are: 
 ['big data analytics definitions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Further', 'further'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('definitions', 'definit'), ('clarified', 'clarifi'), ('Table', 'tabl'), ('4', '4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Further', 'further'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('definitions', 'definit'), ('clarified', 'clarifi'), ('Table', 'tabl'), ('4', '4'), ('.', '.')]

>> Lemmatization: 
 [('Further', 'Further'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('definitions', 'definition'), ('clarified', 'clarified'), ('Table', 'Table'), ('4', '4'), ('.', '.')]



============================ Sentence 261 =============================

Opening any popular scientific or business publication today, whether online or in the physical   world, generally involves running into a reference to data science, analytics, big data, or some   combination of these terms (Agarwal and Dhar, 2014). 


>> Tokens are: 
 ['Opening', 'popular', 'scientific', 'business', 'publication', 'today', ',', 'whether', 'online', 'physical', 'world', ',', 'generally', 'involves', 'running', 'reference', 'data', 'science', ',', 'analytics', ',', 'big', 'data', ',', 'combination', 'terms', '(', 'Agarwal', 'Dhar', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Opening', 'popular'), ('popular', 'scientific'), ('scientific', 'business'), ('business', 'publication'), ('publication', 'today'), ('today', ','), (',', 'whether'), ('whether', 'online'), ('online', 'physical'), ('physical', 'world'), ('world', ','), (',', 'generally'), ('generally', 'involves'), ('involves', 'running'), ('running', 'reference'), ('reference', 'data'), ('data', 'science'), ('science', ','), (',', 'analytics'), ('analytics', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'combination'), ('combination', 'terms'), ('terms', '('), ('(', 'Agarwal'), ('Agarwal', 'Dhar'), ('Dhar', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Opening', 'popular', 'scientific'), ('popular', 'scientific', 'business'), ('scientific', 'business', 'publication'), ('business', 'publication', 'today'), ('publication', 'today', ','), ('today', ',', 'whether'), (',', 'whether', 'online'), ('whether', 'online', 'physical'), ('online', 'physical', 'world'), ('physical', 'world', ','), ('world', ',', 'generally'), (',', 'generally', 'involves'), ('generally', 'involves', 'running'), ('involves', 'running', 'reference'), ('running', 'reference', 'data'), ('reference', 'data', 'science'), ('data', 'science', ','), ('science', ',', 'analytics'), (',', 'analytics', ','), ('analytics', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'combination'), (',', 'combination', 'terms'), ('combination', 'terms', '('), ('terms', '(', 'Agarwal'), ('(', 'Agarwal', 'Dhar'), ('Agarwal', 'Dhar', ','), ('Dhar', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Opening', 'VBG'), ('popular', 'JJ'), ('scientific', 'JJ'), ('business', 'NN'), ('publication', 'NN'), ('today', 'NN'), (',', ','), ('whether', 'IN'), ('online', 'JJ'), ('physical', 'JJ'), ('world', 'NN'), (',', ','), ('generally', 'RB'), ('involves', 'VBZ'), ('running', 'VBG'), ('reference', 'NN'), ('data', 'NNS'), ('science', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('combination', 'NN'), ('terms', 'NNS'), ('(', '('), ('Agarwal', 'NNP'), ('Dhar', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  Opening/VBG
  (NP popular/JJ scientific/JJ business/NN publication/NN today/NN)
  ,/,
  whether/IN
  (NP online/JJ physical/JJ world/NN)
  ,/,
  generally/RB
  involves/VBZ
  running/VBG
  (NP reference/NN data/NNS science/NN)
  ,/,
  (NP analytics/NNS)
  ,/,
  (NP big/JJ data/NNS)
  ,/,
  (NP combination/NN terms/NNS)
  (/(
  (NP Agarwal/NNP Dhar/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['popular scientific business publication today', 'online physical world', 'reference data science', 'analytics', 'big data', 'combination terms', 'Agarwal Dhar']

>> Named Entities are: 
 [('ORGANIZATION', 'Agarwal Dhar')] 

>> Stemming using Porter Stemmer: 
 [('Opening', 'open'), ('popular', 'popular'), ('scientific', 'scientif'), ('business', 'busi'), ('publication', 'public'), ('today', 'today'), (',', ','), ('whether', 'whether'), ('online', 'onlin'), ('physical', 'physic'), ('world', 'world'), (',', ','), ('generally', 'gener'), ('involves', 'involv'), ('running', 'run'), ('reference', 'refer'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('combination', 'combin'), ('terms', 'term'), ('(', '('), ('Agarwal', 'agarw'), ('Dhar', 'dhar'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Opening', 'open'), ('popular', 'popular'), ('scientific', 'scientif'), ('business', 'busi'), ('publication', 'public'), ('today', 'today'), (',', ','), ('whether', 'whether'), ('online', 'onlin'), ('physical', 'physic'), ('world', 'world'), (',', ','), ('generally', 'general'), ('involves', 'involv'), ('running', 'run'), ('reference', 'refer'), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('combination', 'combin'), ('terms', 'term'), ('(', '('), ('Agarwal', 'agarw'), ('Dhar', 'dhar'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Opening', 'Opening'), ('popular', 'popular'), ('scientific', 'scientific'), ('business', 'business'), ('publication', 'publication'), ('today', 'today'), (',', ','), ('whether', 'whether'), ('online', 'online'), ('physical', 'physical'), ('world', 'world'), (',', ','), ('generally', 'generally'), ('involves', 'involves'), ('running', 'running'), ('reference', 'reference'), ('data', 'data'), ('science', 'science'), (',', ','), ('analytics', 'analytics'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('combination', 'combination'), ('terms', 'term'), ('(', '('), ('Agarwal', 'Agarwal'), ('Dhar', 'Dhar'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 262 =============================

Some researchers are focusing on big data   definitions (Akter et al., 2016; Mikalef et al., 2018), while others analyse the tools, techniques,   and procedures required for analysis (Russom, 2011), and others seek to explain big data analytics’   impact on business value ( Mikalef et al., 2018). 


>> Tokens are: 
 ['Some', 'researchers', 'focusing', 'big', 'data', 'definitions', '(', 'Akter', 'et', 'al.', ',', '2016', ';', 'Mikalef', 'et', 'al.', ',', '2018', ')', ',', 'others', 'analyse', 'tools', ',', 'techniques', ',', 'procedures', 'required', 'analysis', '(', 'Russom', ',', '2011', ')', ',', 'others', 'seek', 'explain', 'big', 'data', 'analytics', '’', 'impact', 'business', 'value', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Some', 'researchers'), ('researchers', 'focusing'), ('focusing', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', '('), ('(', 'Akter'), ('Akter', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', ','), (',', 'others'), ('others', 'analyse'), ('analyse', 'tools'), ('tools', ','), (',', 'techniques'), ('techniques', ','), (',', 'procedures'), ('procedures', 'required'), ('required', 'analysis'), ('analysis', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ')'), (')', ','), (',', 'others'), ('others', 'seek'), ('seek', 'explain'), ('explain', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '’'), ('’', 'impact'), ('impact', 'business'), ('business', 'value'), ('value', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Some', 'researchers', 'focusing'), ('researchers', 'focusing', 'big'), ('focusing', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', '('), ('definitions', '(', 'Akter'), ('(', 'Akter', 'et'), ('Akter', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Mikalef'), (';', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', ','), (')', ',', 'others'), (',', 'others', 'analyse'), ('others', 'analyse', 'tools'), ('analyse', 'tools', ','), ('tools', ',', 'techniques'), (',', 'techniques', ','), ('techniques', ',', 'procedures'), (',', 'procedures', 'required'), ('procedures', 'required', 'analysis'), ('required', 'analysis', '('), ('analysis', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ')'), ('2011', ')', ','), (')', ',', 'others'), (',', 'others', 'seek'), ('others', 'seek', 'explain'), ('seek', 'explain', 'big'), ('explain', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '’'), ('analytics', '’', 'impact'), ('’', 'impact', 'business'), ('impact', 'business', 'value'), ('business', 'value', '('), ('value', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('researchers', 'NNS'), ('focusing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('(', '('), ('Akter', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (';', ':'), ('Mikalef', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), (',', ','), ('others', 'NNS'), ('analyse', 'VBP'), ('tools', 'NNS'), (',', ','), ('techniques', 'NNS'), (',', ','), ('procedures', 'NNS'), ('required', 'VBN'), ('analysis', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (')', ')'), (',', ','), ('others', 'NNS'), ('seek', 'VBP'), ('explain', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('’', 'JJ'), ('impact', 'NN'), ('business', 'NN'), ('value', 'NN'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Some/DT researchers/NNS)
  focusing/VBG
  (NP big/JJ data/NNS definitions/NNS)
  (/(
  (NP Akter/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  ;/:
  (NP Mikalef/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2018/CD
  )/)
  ,/,
  (NP others/NNS)
  analyse/VBP
  (NP tools/NNS)
  ,/,
  (NP techniques/NNS)
  ,/,
  (NP procedures/NNS)
  required/VBN
  (NP analysis/NN)
  (/(
  (NP Russom/NNP)
  ,/,
  2011/CD
  )/)
  ,/,
  (NP others/NNS)
  seek/VBP
  explain/VB
  (NP big/JJ data/NNS analytics/NNS)
  (NP ’/JJ impact/NN business/NN value/NN)
  (/(
  (NP Mikalef/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Some researchers', 'big data definitions', 'Akter', 'Mikalef', 'al.', 'others', 'tools', 'techniques', 'procedures', 'analysis', 'Russom', 'others', 'big data analytics', '’ impact business value', 'Mikalef']

>> Named Entities are: 
 [('PERSON', 'Mikalef'), ('GPE', 'Russom'), ('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('researchers', 'research'), ('focusing', 'focus'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('(', '('), ('Akter', 'akter'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('others', 'other'), ('analyse', 'analys'), ('tools', 'tool'), (',', ','), ('techniques', 'techniqu'), (',', ','), ('procedures', 'procedur'), ('required', 'requir'), ('analysis', 'analysi'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), (',', ','), ('others', 'other'), ('seek', 'seek'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’'), ('impact', 'impact'), ('business', 'busi'), ('value', 'valu'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('researchers', 'research'), ('focusing', 'focus'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('(', '('), ('Akter', 'akter'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('others', 'other'), ('analyse', 'analys'), ('tools', 'tool'), (',', ','), ('techniques', 'techniqu'), (',', ','), ('procedures', 'procedur'), ('required', 'requir'), ('analysis', 'analysi'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (')', ')'), (',', ','), ('others', 'other'), ('seek', 'seek'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('’', '’'), ('impact', 'impact'), ('business', 'busi'), ('value', 'valu'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('researchers', 'researcher'), ('focusing', 'focusing'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('(', '('), ('Akter', 'Akter'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), (',', ','), ('others', 'others'), ('analyse', 'analyse'), ('tools', 'tool'), (',', ','), ('techniques', 'technique'), (',', ','), ('procedures', 'procedure'), ('required', 'required'), ('analysis', 'analysis'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (')', ')'), (',', ','), ('others', 'others'), ('seek', 'seek'), ('explain', 'explain'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('’', '’'), ('impact', 'impact'), ('business', 'business'), ('value', 'value'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 263 =============================

Sarah Al-Shiakhli   21      Table 4: Sample definitions of big data analytics, adopted from (Mikalef et al., 2018)         People now aim to both to collect data and understand its importance and meaning for use in   making decisions. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '21', 'Table', '4', ':', 'Sample', 'definitions', 'big', 'data', 'analytics', ',', 'adopted', '(', 'Mikalef', 'et', 'al.', ',', '2018', ')', 'People', 'aim', 'collect', 'data', 'understand', 'importance', 'meaning', 'use', 'making', 'decisions', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '21'), ('21', 'Table'), ('Table', '4'), ('4', ':'), (':', 'Sample'), ('Sample', 'definitions'), ('definitions', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Mikalef'), ('Mikalef', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', 'People'), ('People', 'aim'), ('aim', 'collect'), ('collect', 'data'), ('data', 'understand'), ('understand', 'importance'), ('importance', 'meaning'), ('meaning', 'use'), ('use', 'making'), ('making', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '21'), ('Al-Shiakhli', '21', 'Table'), ('21', 'Table', '4'), ('Table', '4', ':'), ('4', ':', 'Sample'), (':', 'Sample', 'definitions'), ('Sample', 'definitions', 'big'), ('definitions', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Mikalef'), ('(', 'Mikalef', 'et'), ('Mikalef', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', 'People'), (')', 'People', 'aim'), ('People', 'aim', 'collect'), ('aim', 'collect', 'data'), ('collect', 'data', 'understand'), ('data', 'understand', 'importance'), ('understand', 'importance', 'meaning'), ('importance', 'meaning', 'use'), ('meaning', 'use', 'making'), ('use', 'making', 'decisions'), ('making', 'decisions', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('21', 'CD'), ('Table', 'JJ'), ('4', 'CD'), (':', ':'), ('Sample', 'JJ'), ('definitions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Mikalef', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('People', 'NNPS'), ('aim', 'VBP'), ('collect', 'VB'), ('data', 'NNS'), ('understand', 'JJ'), ('importance', 'NN'), ('meaning', 'NN'), ('use', 'NN'), ('making', 'NN'), ('decisions', 'NNS'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  21/CD
  Table/JJ
  4/CD
  :/:
  (NP Sample/JJ definitions/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  ,/,
  adopted/VBN
  (/(
  (NP Mikalef/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  People/NNPS
  aim/VBP
  collect/VB
  (NP data/NNS)
  (NP
    understand/JJ
    importance/NN
    meaning/NN
    use/NN
    making/NN
    decisions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Sample definitions', 'big data analytics', 'Mikalef', 'data', 'understand importance meaning use making decisions']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Mikalef')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('21', '21'), ('Table', 'tabl'), ('4', '4'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('People', 'peopl'), ('aim', 'aim'), ('collect', 'collect'), ('data', 'data'), ('understand', 'understand'), ('importance', 'import'), ('meaning', 'mean'), ('use', 'use'), ('making', 'make'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('21', '21'), ('Table', 'tabl'), ('4', '4'), (':', ':'), ('Sample', 'sampl'), ('definitions', 'definit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Mikalef', 'mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('People', 'peopl'), ('aim', 'aim'), ('collect', 'collect'), ('data', 'data'), ('understand', 'understand'), ('importance', 'import'), ('meaning', 'mean'), ('use', 'use'), ('making', 'make'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('21', '21'), ('Table', 'Table'), ('4', '4'), (':', ':'), ('Sample', 'Sample'), ('definitions', 'definition'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Mikalef', 'Mikalef'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('People', 'People'), ('aim', 'aim'), ('collect', 'collect'), ('data', 'data'), ('understand', 'understand'), ('importance', 'importance'), ('meaning', 'meaning'), ('use', 'use'), ('making', 'making'), ('decisions', 'decision'), ('.', '.')]



============================ Sentence 264 =============================

The data to be analysed is large in volume and consists of various types. 


>> Tokens are: 
 ['The', 'data', 'analysed', 'large', 'volume', 'consists', 'various', 'types', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'analysed'), ('analysed', 'large'), ('large', 'volume'), ('volume', 'consists'), ('consists', 'various'), ('various', 'types'), ('types', '.')]

>> Trigrams are: 
 [('The', 'data', 'analysed'), ('data', 'analysed', 'large'), ('analysed', 'large', 'volume'), ('large', 'volume', 'consists'), ('volume', 'consists', 'various'), ('consists', 'various', 'types'), ('various', 'types', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('analysed', 'VBD'), ('large', 'JJ'), ('volume', 'NN'), ('consists', 'VBZ'), ('various', 'JJ'), ('types', 'NNS'), ('.', '.')]

 (S
  (NP The/DT data/NNS)
  analysed/VBD
  (NP large/JJ volume/NN)
  consists/VBZ
  (NP various/JJ types/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The data', 'large volume', 'various types']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('analysed', 'analys'), ('large', 'larg'), ('volume', 'volum'), ('consists', 'consist'), ('various', 'variou'), ('types', 'type'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('analysed', 'analys'), ('large', 'larg'), ('volume', 'volum'), ('consists', 'consist'), ('various', 'various'), ('types', 'type'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('analysed', 'analysed'), ('large', 'large'), ('volume', 'volume'), ('consists', 'consists'), ('various', 'various'), ('types', 'type'), ('.', '.')]



============================ Sentence 265 =============================

"Massive, high dimensional, heterogeneous, complex, unstructured, incomplete, noisy, and   erroneous" (Ma et al., 2014), are features of big data that require changes in statistical and data   analysis approaches. 


>> Tokens are: 
 ['``', 'Massive', ',', 'high', 'dimensional', ',', 'heterogeneous', ',', 'complex', ',', 'unstructured', ',', 'incomplete', ',', 'noisy', ',', 'erroneous', "''", '(', 'Ma', 'et', 'al.', ',', '2014', ')', ',', 'features', 'big', 'data', 'require', 'changes', 'statistical', 'data', 'analysis', 'approaches', '.']

>> Bigrams are: 
 [('``', 'Massive'), ('Massive', ','), (',', 'high'), ('high', 'dimensional'), ('dimensional', ','), (',', 'heterogeneous'), ('heterogeneous', ','), (',', 'complex'), ('complex', ','), (',', 'unstructured'), ('unstructured', ','), (',', 'incomplete'), ('incomplete', ','), (',', 'noisy'), ('noisy', ','), (',', 'erroneous'), ('erroneous', "''"), ("''", '('), ('(', 'Ma'), ('Ma', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', ','), (',', 'features'), ('features', 'big'), ('big', 'data'), ('data', 'require'), ('require', 'changes'), ('changes', 'statistical'), ('statistical', 'data'), ('data', 'analysis'), ('analysis', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('``', 'Massive', ','), ('Massive', ',', 'high'), (',', 'high', 'dimensional'), ('high', 'dimensional', ','), ('dimensional', ',', 'heterogeneous'), (',', 'heterogeneous', ','), ('heterogeneous', ',', 'complex'), (',', 'complex', ','), ('complex', ',', 'unstructured'), (',', 'unstructured', ','), ('unstructured', ',', 'incomplete'), (',', 'incomplete', ','), ('incomplete', ',', 'noisy'), (',', 'noisy', ','), ('noisy', ',', 'erroneous'), (',', 'erroneous', "''"), ('erroneous', "''", '('), ("''", '(', 'Ma'), ('(', 'Ma', 'et'), ('Ma', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ','), (')', ',', 'features'), (',', 'features', 'big'), ('features', 'big', 'data'), ('big', 'data', 'require'), ('data', 'require', 'changes'), ('require', 'changes', 'statistical'), ('changes', 'statistical', 'data'), ('statistical', 'data', 'analysis'), ('data', 'analysis', 'approaches'), ('analysis', 'approaches', '.')]

>> POS Tags are: 
 [('``', '``'), ('Massive', 'NNP'), (',', ','), ('high', 'JJ'), ('dimensional', 'NN'), (',', ','), ('heterogeneous', 'JJ'), (',', ','), ('complex', 'JJ'), (',', ','), ('unstructured', 'JJ'), (',', ','), ('incomplete', 'JJ'), (',', ','), ('noisy', 'JJ'), (',', ','), ('erroneous', 'JJ'), ("''", "''"), ('(', '('), ('Ma', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), (',', ','), ('features', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('require', 'VBP'), ('changes', 'NNS'), ('statistical', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('approaches', 'NNS'), ('.', '.')]

 (S
  ``/``
  (NP Massive/NNP)
  ,/,
  (NP high/JJ dimensional/NN)
  ,/,
  heterogeneous/JJ
  ,/,
  complex/JJ
  ,/,
  unstructured/JJ
  ,/,
  incomplete/JJ
  ,/,
  noisy/JJ
  ,/,
  erroneous/JJ
  ''/''
  (/(
  (NP Ma/NNP)
  et/RB
  al./RB
  ,/,
  2014/CD
  )/)
  ,/,
  features/VBZ
  (NP big/JJ data/NNS)
  require/VBP
  (NP changes/NNS)
  (NP statistical/JJ data/NNS analysis/NN approaches/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Massive', 'high dimensional', 'Ma', 'big data', 'changes', 'statistical data analysis approaches']

>> Named Entities are: 
 [('PERSON', 'Massive')] 

>> Stemming using Porter Stemmer: 
 [('``', '``'), ('Massive', 'massiv'), (',', ','), ('high', 'high'), ('dimensional', 'dimension'), (',', ','), ('heterogeneous', 'heterogen'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructur'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('noisy', 'noisi'), (',', ','), ('erroneous', 'erron'), ("''", "''"), ('(', '('), ('Ma', 'ma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('changes', 'chang'), ('statistical', 'statist'), ('data', 'data'), ('analysis', 'analysi'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('``', '``'), ('Massive', 'massiv'), (',', ','), ('high', 'high'), ('dimensional', 'dimension'), (',', ','), ('heterogeneous', 'heterogen'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructur'), (',', ','), ('incomplete', 'incomplet'), (',', ','), ('noisy', 'noisi'), (',', ','), ('erroneous', 'erron'), ("''", "''"), ('(', '('), ('Ma', 'ma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('changes', 'chang'), ('statistical', 'statist'), ('data', 'data'), ('analysis', 'analysi'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('``', '``'), ('Massive', 'Massive'), (',', ','), ('high', 'high'), ('dimensional', 'dimensional'), (',', ','), ('heterogeneous', 'heterogeneous'), (',', ','), ('complex', 'complex'), (',', ','), ('unstructured', 'unstructured'), (',', ','), ('incomplete', 'incomplete'), (',', ','), ('noisy', 'noisy'), (',', ','), ('erroneous', 'erroneous'), ("''", "''"), ('(', '('), ('Ma', 'Ma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('features', 'feature'), ('big', 'big'), ('data', 'data'), ('require', 'require'), ('changes', 'change'), ('statistical', 'statistical'), ('data', 'data'), ('analysis', 'analysis'), ('approaches', 'approach'), ('.', '.')]



============================ Sentence 266 =============================

It is also important to understand the content of big data. 


>> Tokens are: 
 ['It', 'also', 'important', 'understand', 'content', 'big', 'data', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'important'), ('important', 'understand'), ('understand', 'content'), ('content', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('It', 'also', 'important'), ('also', 'important', 'understand'), ('important', 'understand', 'content'), ('understand', 'content', 'big'), ('content', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('important', 'JJ'), ('understand', 'NN'), ('content', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  It/PRP
  also/RB
  (NP important/JJ understand/NN content/NN)
  (NP big/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['important understand content', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('important', 'import'), ('understand', 'understand'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('important', 'import'), ('understand', 'understand'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('important', 'important'), ('understand', 'understand'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('.', '.')]



============================ Sentence 267 =============================

The process of applying algorithms to   analyse the content of big data is part of data analytics, which is used for 1) analysing sets of data   information and their relationships, 2) extracting previously unknown valid patterns, and 3) for   detecting important relationships between stored variables. 


>> Tokens are: 
 ['The', 'process', 'applying', 'algorithms', 'analyse', 'content', 'big', 'data', 'part', 'data', 'analytics', ',', 'used', '1', ')', 'analysing', 'sets', 'data', 'information', 'relationships', ',', '2', ')', 'extracting', 'previously', 'unknown', 'valid', 'patterns', ',', '3', ')', 'detecting', 'important', 'relationships', 'stored', 'variables', '.']

>> Bigrams are: 
 [('The', 'process'), ('process', 'applying'), ('applying', 'algorithms'), ('algorithms', 'analyse'), ('analyse', 'content'), ('content', 'big'), ('big', 'data'), ('data', 'part'), ('part', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'used'), ('used', '1'), ('1', ')'), (')', 'analysing'), ('analysing', 'sets'), ('sets', 'data'), ('data', 'information'), ('information', 'relationships'), ('relationships', ','), (',', '2'), ('2', ')'), (')', 'extracting'), ('extracting', 'previously'), ('previously', 'unknown'), ('unknown', 'valid'), ('valid', 'patterns'), ('patterns', ','), (',', '3'), ('3', ')'), (')', 'detecting'), ('detecting', 'important'), ('important', 'relationships'), ('relationships', 'stored'), ('stored', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('The', 'process', 'applying'), ('process', 'applying', 'algorithms'), ('applying', 'algorithms', 'analyse'), ('algorithms', 'analyse', 'content'), ('analyse', 'content', 'big'), ('content', 'big', 'data'), ('big', 'data', 'part'), ('data', 'part', 'data'), ('part', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'used'), (',', 'used', '1'), ('used', '1', ')'), ('1', ')', 'analysing'), (')', 'analysing', 'sets'), ('analysing', 'sets', 'data'), ('sets', 'data', 'information'), ('data', 'information', 'relationships'), ('information', 'relationships', ','), ('relationships', ',', '2'), (',', '2', ')'), ('2', ')', 'extracting'), (')', 'extracting', 'previously'), ('extracting', 'previously', 'unknown'), ('previously', 'unknown', 'valid'), ('unknown', 'valid', 'patterns'), ('valid', 'patterns', ','), ('patterns', ',', '3'), (',', '3', ')'), ('3', ')', 'detecting'), (')', 'detecting', 'important'), ('detecting', 'important', 'relationships'), ('important', 'relationships', 'stored'), ('relationships', 'stored', 'variables'), ('stored', 'variables', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('process', 'NN'), ('applying', 'VBG'), ('algorithms', 'JJ'), ('analyse', 'NN'), ('content', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('part', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('used', 'VBD'), ('1', 'CD'), (')', ')'), ('analysing', 'VBG'), ('sets', 'NNS'), ('data', 'NNS'), ('information', 'NN'), ('relationships', 'NNS'), (',', ','), ('2', 'CD'), (')', ')'), ('extracting', 'VBG'), ('previously', 'RB'), ('unknown', 'JJ'), ('valid', 'JJ'), ('patterns', 'NNS'), (',', ','), ('3', 'CD'), (')', ')'), ('detecting', 'VBG'), ('important', 'JJ'), ('relationships', 'NNS'), ('stored', 'VBD'), ('variables', 'NNS'), ('.', '.')]

 (S
  (NP The/DT process/NN)
  applying/VBG
  (NP algorithms/JJ analyse/NN content/NN)
  (NP big/JJ data/NNS part/NN data/NNS analytics/NNS)
  ,/,
  used/VBD
  1/CD
  )/)
  analysing/VBG
  (NP sets/NNS data/NNS information/NN relationships/NNS)
  ,/,
  2/CD
  )/)
  extracting/VBG
  previously/RB
  (NP unknown/JJ valid/JJ patterns/NNS)
  ,/,
  3/CD
  )/)
  detecting/VBG
  (NP important/JJ relationships/NNS)
  stored/VBD
  (NP variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The process', 'algorithms analyse content', 'big data part data analytics', 'sets data information relationships', 'unknown valid patterns', 'important relationships', 'variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('process', 'process'), ('applying', 'appli'), ('algorithms', 'algorithm'), ('analyse', 'analys'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('part', 'part'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('used', 'use'), ('1', '1'), (')', ')'), ('analysing', 'analys'), ('sets', 'set'), ('data', 'data'), ('information', 'inform'), ('relationships', 'relationship'), (',', ','), ('2', '2'), (')', ')'), ('extracting', 'extract'), ('previously', 'previous'), ('unknown', 'unknown'), ('valid', 'valid'), ('patterns', 'pattern'), (',', ','), ('3', '3'), (')', ')'), ('detecting', 'detect'), ('important', 'import'), ('relationships', 'relationship'), ('stored', 'store'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('process', 'process'), ('applying', 'appli'), ('algorithms', 'algorithm'), ('analyse', 'analys'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('part', 'part'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('used', 'use'), ('1', '1'), (')', ')'), ('analysing', 'analys'), ('sets', 'set'), ('data', 'data'), ('information', 'inform'), ('relationships', 'relationship'), (',', ','), ('2', '2'), (')', ')'), ('extracting', 'extract'), ('previously', 'previous'), ('unknown', 'unknown'), ('valid', 'valid'), ('patterns', 'pattern'), (',', ','), ('3', '3'), (')', ')'), ('detecting', 'detect'), ('important', 'import'), ('relationships', 'relationship'), ('stored', 'store'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('process', 'process'), ('applying', 'applying'), ('algorithms', 'algorithm'), ('analyse', 'analyse'), ('content', 'content'), ('big', 'big'), ('data', 'data'), ('part', 'part'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('used', 'used'), ('1', '1'), (')', ')'), ('analysing', 'analysing'), ('sets', 'set'), ('data', 'data'), ('information', 'information'), ('relationships', 'relationship'), (',', ','), ('2', '2'), (')', ')'), ('extracting', 'extracting'), ('previously', 'previously'), ('unknown', 'unknown'), ('valid', 'valid'), ('patterns', 'pattern'), (',', ','), ('3', '3'), (')', ')'), ('detecting', 'detecting'), ('important', 'important'), ('relationships', 'relationship'), ('stored', 'stored'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 268 =============================

In this section, various big data analyses will be discussed, beginning with the data analysis   techniques available and some of the common big data analytics suites, finally discussing several   big data platforms and tools. 


>> Tokens are: 
 ['In', 'section', ',', 'various', 'big', 'data', 'analyses', 'discussed', ',', 'beginning', 'data', 'analysis', 'techniques', 'available', 'common', 'big', 'data', 'analytics', 'suites', ',', 'finally', 'discussing', 'several', 'big', 'data', 'platforms', 'tools', '.']

>> Bigrams are: 
 [('In', 'section'), ('section', ','), (',', 'various'), ('various', 'big'), ('big', 'data'), ('data', 'analyses'), ('analyses', 'discussed'), ('discussed', ','), (',', 'beginning'), ('beginning', 'data'), ('data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'available'), ('available', 'common'), ('common', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'suites'), ('suites', ','), (',', 'finally'), ('finally', 'discussing'), ('discussing', 'several'), ('several', 'big'), ('big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('In', 'section', ','), ('section', ',', 'various'), (',', 'various', 'big'), ('various', 'big', 'data'), ('big', 'data', 'analyses'), ('data', 'analyses', 'discussed'), ('analyses', 'discussed', ','), ('discussed', ',', 'beginning'), (',', 'beginning', 'data'), ('beginning', 'data', 'analysis'), ('data', 'analysis', 'techniques'), ('analysis', 'techniques', 'available'), ('techniques', 'available', 'common'), ('available', 'common', 'big'), ('common', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'suites'), ('analytics', 'suites', ','), ('suites', ',', 'finally'), (',', 'finally', 'discussing'), ('finally', 'discussing', 'several'), ('discussing', 'several', 'big'), ('several', 'big', 'data'), ('big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('section', 'NN'), (',', ','), ('various', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analyses', 'NNS'), ('discussed', 'VBD'), (',', ','), ('beginning', 'VBG'), ('data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('available', 'JJ'), ('common', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('suites', 'NNS'), (',', ','), ('finally', 'RB'), ('discussing', 'VBG'), ('several', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP section/NN)
  ,/,
  (NP various/JJ big/JJ data/NNS analyses/NNS)
  discussed/VBD
  ,/,
  beginning/VBG
  (NP data/NNS analysis/NN techniques/NNS)
  (NP
    available/JJ
    common/JJ
    big/JJ
    data/NNS
    analytics/NNS
    suites/NNS)
  ,/,
  finally/RB
  discussing/VBG
  (NP several/JJ big/JJ data/NNS platforms/NNS tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['section', 'various big data analyses', 'data analysis techniques', 'available common big data analytics suites', 'several big data platforms tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('various', 'variou'), ('big', 'big'), ('data', 'data'), ('analyses', 'analys'), ('discussed', 'discuss'), (',', ','), ('beginning', 'begin'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('available', 'avail'), ('common', 'common'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('suites', 'suit'), (',', ','), ('finally', 'final'), ('discussing', 'discuss'), ('several', 'sever'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('section', 'section'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analyses', 'analys'), ('discussed', 'discuss'), (',', ','), ('beginning', 'begin'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('available', 'avail'), ('common', 'common'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('suites', 'suit'), (',', ','), ('finally', 'final'), ('discussing', 'discuss'), ('several', 'sever'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('section', 'section'), (',', ','), ('various', 'various'), ('big', 'big'), ('data', 'data'), ('analyses', 'analysis'), ('discussed', 'discussed'), (',', ','), ('beginning', 'beginning'), ('data', 'data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('available', 'available'), ('common', 'common'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('suites', 'suite'), (',', ','), ('finally', 'finally'), ('discussing', 'discussing'), ('several', 'several'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 269 =============================

Data analysis techniques can be characterised into four types, as   shown in Figure 12:        Sarah Al-Shiakhli   22         Figure 12: Data analysis techniques         7.1.1. 


>> Tokens are: 
 ['Data', 'analysis', 'techniques', 'characterised', 'four', 'types', ',', 'shown', 'Figure', '12', ':', 'Sarah', 'Al-Shiakhli', '22', 'Figure', '12', ':', 'Data', 'analysis', 'techniques', '7.1.1', '.']

>> Bigrams are: 
 [('Data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'characterised'), ('characterised', 'four'), ('four', 'types'), ('types', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '12'), ('12', ':'), (':', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '22'), ('22', 'Figure'), ('Figure', '12'), ('12', ':'), (':', 'Data'), ('Data', 'analysis'), ('analysis', 'techniques'), ('techniques', '7.1.1'), ('7.1.1', '.')]

>> Trigrams are: 
 [('Data', 'analysis', 'techniques'), ('analysis', 'techniques', 'characterised'), ('techniques', 'characterised', 'four'), ('characterised', 'four', 'types'), ('four', 'types', ','), ('types', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '12'), ('Figure', '12', ':'), ('12', ':', 'Sarah'), (':', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '22'), ('Al-Shiakhli', '22', 'Figure'), ('22', 'Figure', '12'), ('Figure', '12', ':'), ('12', ':', 'Data'), (':', 'Data', 'analysis'), ('Data', 'analysis', 'techniques'), ('analysis', 'techniques', '7.1.1'), ('techniques', '7.1.1', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('analysis', 'NN'), ('techniques', 'NNS'), ('characterised', 'VBD'), ('four', 'CD'), ('types', 'NNS'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('12', 'CD'), (':', ':'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('22', 'CD'), ('Figure', 'NNP'), ('12', 'CD'), (':', ':'), ('Data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('7.1.1', 'CD'), ('.', '.')]

 (S
  (NP Data/NNP analysis/NN techniques/NNS)
  characterised/VBD
  four/CD
  (NP types/NNS)
  ,/,
  shown/VBN
  (NP Figure/NN)
  12/CD
  :/:
  (NP Sarah/NNP Al-Shiakhli/NNP)
  22/CD
  (NP Figure/NNP)
  12/CD
  :/:
  (NP Data/NNS analysis/NN techniques/NNS)
  7.1.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Data analysis techniques', 'types', 'Figure', 'Sarah Al-Shiakhli', 'Figure', 'Data analysis techniques']

>> Named Entities are: 
 [('GPE', 'Data'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('types', 'type'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('12', '12'), (':', ':'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('22', '22'), ('Figure', 'figur'), ('12', '12'), (':', ':'), ('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('7.1.1', '7.1.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('types', 'type'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('12', '12'), (':', ':'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('22', '22'), ('Figure', 'figur'), ('12', '12'), (':', ':'), ('Data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('7.1.1', '7.1.1'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('characterised', 'characterised'), ('four', 'four'), ('types', 'type'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('12', '12'), (':', ':'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('22', '22'), ('Figure', 'Figure'), ('12', '12'), (':', ':'), ('Data', 'Data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('7.1.1', '7.1.1'), ('.', '.')]



============================ Sentence 270 =============================

Supervised techniques     A supervised technique refers to where data are trained and tested, and the training data is labelled. 


>> Tokens are: 
 ['Supervised', 'techniques', 'A', 'supervised', 'technique', 'refers', 'data', 'trained', 'tested', ',', 'training', 'data', 'labelled', '.']

>> Bigrams are: 
 [('Supervised', 'techniques'), ('techniques', 'A'), ('A', 'supervised'), ('supervised', 'technique'), ('technique', 'refers'), ('refers', 'data'), ('data', 'trained'), ('trained', 'tested'), ('tested', ','), (',', 'training'), ('training', 'data'), ('data', 'labelled'), ('labelled', '.')]

>> Trigrams are: 
 [('Supervised', 'techniques', 'A'), ('techniques', 'A', 'supervised'), ('A', 'supervised', 'technique'), ('supervised', 'technique', 'refers'), ('technique', 'refers', 'data'), ('refers', 'data', 'trained'), ('data', 'trained', 'tested'), ('trained', 'tested', ','), ('tested', ',', 'training'), (',', 'training', 'data'), ('training', 'data', 'labelled'), ('data', 'labelled', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('techniques', 'NNS'), ('A', 'NNP'), ('supervised', 'VBD'), ('technique', 'NN'), ('refers', 'NNS'), ('data', 'NNS'), ('trained', 'VBD'), ('tested', 'VBN'), (',', ','), ('training', 'VBG'), ('data', 'NNS'), ('labelled', 'VBN'), ('.', '.')]

 (S
  Supervised/VBN
  (NP techniques/NNS A/NNP)
  supervised/VBD
  (NP technique/NN refers/NNS data/NNS)
  trained/VBD
  tested/VBN
  ,/,
  training/VBG
  (NP data/NNS)
  labelled/VBN
  ./.) 


>> Noun Phrases are: 
 ['techniques A', 'technique refers data', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu'), ('A', 'a'), ('supervised', 'supervis'), ('technique', 'techniqu'), ('refers', 'refer'), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), (',', ','), ('training', 'train'), ('data', 'data'), ('labelled', 'label'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('techniques', 'techniqu'), ('A', 'a'), ('supervised', 'supervis'), ('technique', 'techniqu'), ('refers', 'refer'), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), (',', ','), ('training', 'train'), ('data', 'data'), ('labelled', 'label'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('techniques', 'technique'), ('A', 'A'), ('supervised', 'supervised'), ('technique', 'technique'), ('refers', 'refers'), ('data', 'data'), ('trained', 'trained'), ('tested', 'tested'), (',', ','), ('training', 'training'), ('data', 'data'), ('labelled', 'labelled'), ('.', '.')]



============================ Sentence 271 =============================

Labelled means that the full history of what has happened to the data is known, and thus the history   for the data variables is known. 


>> Tokens are: 
 ['Labelled', 'means', 'full', 'history', 'happened', 'data', 'known', ',', 'thus', 'history', 'data', 'variables', 'known', '.']

>> Bigrams are: 
 [('Labelled', 'means'), ('means', 'full'), ('full', 'history'), ('history', 'happened'), ('happened', 'data'), ('data', 'known'), ('known', ','), (',', 'thus'), ('thus', 'history'), ('history', 'data'), ('data', 'variables'), ('variables', 'known'), ('known', '.')]

>> Trigrams are: 
 [('Labelled', 'means', 'full'), ('means', 'full', 'history'), ('full', 'history', 'happened'), ('history', 'happened', 'data'), ('happened', 'data', 'known'), ('data', 'known', ','), ('known', ',', 'thus'), (',', 'thus', 'history'), ('thus', 'history', 'data'), ('history', 'data', 'variables'), ('data', 'variables', 'known'), ('variables', 'known', '.')]

>> POS Tags are: 
 [('Labelled', 'VBN'), ('means', 'NNS'), ('full', 'JJ'), ('history', 'NN'), ('happened', 'VBD'), ('data', 'NNS'), ('known', 'VBN'), (',', ','), ('thus', 'RB'), ('history', 'NN'), ('data', 'NNS'), ('variables', 'NNS'), ('known', 'VBN'), ('.', '.')]

 (S
  Labelled/VBN
  (NP means/NNS)
  (NP full/JJ history/NN)
  happened/VBD
  (NP data/NNS)
  known/VBN
  ,/,
  thus/RB
  (NP history/NN data/NNS variables/NNS)
  known/VBN
  ./.) 


>> Noun Phrases are: 
 ['means', 'full history', 'data', 'history data variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Labelled', 'label'), ('means', 'mean'), ('full', 'full'), ('history', 'histori'), ('happened', 'happen'), ('data', 'data'), ('known', 'known'), (',', ','), ('thus', 'thu'), ('history', 'histori'), ('data', 'data'), ('variables', 'variabl'), ('known', 'known'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Labelled', 'label'), ('means', 'mean'), ('full', 'full'), ('history', 'histori'), ('happened', 'happen'), ('data', 'data'), ('known', 'known'), (',', ','), ('thus', 'thus'), ('history', 'histori'), ('data', 'data'), ('variables', 'variabl'), ('known', 'known'), ('.', '.')]

>> Lemmatization: 
 [('Labelled', 'Labelled'), ('means', 'mean'), ('full', 'full'), ('history', 'history'), ('happened', 'happened'), ('data', 'data'), ('known', 'known'), (',', ','), ('thus', 'thus'), ('history', 'history'), ('data', 'data'), ('variables', 'variable'), ('known', 'known'), ('.', '.')]



============================ Sentence 272 =============================

Supervised learning involves training a system based on labelled data and this requires a supervisor   with the ability to expect the output from each input that can train the system according to its   expectations. 


>> Tokens are: 
 ['Supervised', 'learning', 'involves', 'training', 'system', 'based', 'labelled', 'data', 'requires', 'supervisor', 'ability', 'expect', 'output', 'input', 'train', 'system', 'according', 'expectations', '.']

>> Bigrams are: 
 [('Supervised', 'learning'), ('learning', 'involves'), ('involves', 'training'), ('training', 'system'), ('system', 'based'), ('based', 'labelled'), ('labelled', 'data'), ('data', 'requires'), ('requires', 'supervisor'), ('supervisor', 'ability'), ('ability', 'expect'), ('expect', 'output'), ('output', 'input'), ('input', 'train'), ('train', 'system'), ('system', 'according'), ('according', 'expectations'), ('expectations', '.')]

>> Trigrams are: 
 [('Supervised', 'learning', 'involves'), ('learning', 'involves', 'training'), ('involves', 'training', 'system'), ('training', 'system', 'based'), ('system', 'based', 'labelled'), ('based', 'labelled', 'data'), ('labelled', 'data', 'requires'), ('data', 'requires', 'supervisor'), ('requires', 'supervisor', 'ability'), ('supervisor', 'ability', 'expect'), ('ability', 'expect', 'output'), ('expect', 'output', 'input'), ('output', 'input', 'train'), ('input', 'train', 'system'), ('train', 'system', 'according'), ('system', 'according', 'expectations'), ('according', 'expectations', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('learning', 'VBG'), ('involves', 'NNS'), ('training', 'VBG'), ('system', 'NN'), ('based', 'VBN'), ('labelled', 'VBN'), ('data', 'NNS'), ('requires', 'VBZ'), ('supervisor', 'JJ'), ('ability', 'NN'), ('expect', 'VBP'), ('output', 'NN'), ('input', 'NN'), ('train', 'NN'), ('system', 'NN'), ('according', 'VBG'), ('expectations', 'NNS'), ('.', '.')]

 (S
  Supervised/VBN
  learning/VBG
  (NP involves/NNS)
  training/VBG
  (NP system/NN)
  based/VBN
  labelled/VBN
  (NP data/NNS)
  requires/VBZ
  (NP supervisor/JJ ability/NN)
  expect/VBP
  (NP output/NN input/NN train/NN system/NN)
  according/VBG
  (NP expectations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['involves', 'system', 'data', 'supervisor ability', 'output input train system', 'expectations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('involves', 'involv'), ('training', 'train'), ('system', 'system'), ('based', 'base'), ('labelled', 'label'), ('data', 'data'), ('requires', 'requir'), ('supervisor', 'supervisor'), ('ability', 'abil'), ('expect', 'expect'), ('output', 'output'), ('input', 'input'), ('train', 'train'), ('system', 'system'), ('according', 'accord'), ('expectations', 'expect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('learning', 'learn'), ('involves', 'involv'), ('training', 'train'), ('system', 'system'), ('based', 'base'), ('labelled', 'label'), ('data', 'data'), ('requires', 'requir'), ('supervisor', 'supervisor'), ('ability', 'abil'), ('expect', 'expect'), ('output', 'output'), ('input', 'input'), ('train', 'train'), ('system', 'system'), ('according', 'accord'), ('expectations', 'expect'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('learning', 'learning'), ('involves', 'involves'), ('training', 'training'), ('system', 'system'), ('based', 'based'), ('labelled', 'labelled'), ('data', 'data'), ('requires', 'requires'), ('supervisor', 'supervisor'), ('ability', 'ability'), ('expect', 'expect'), ('output', 'output'), ('input', 'input'), ('train', 'train'), ('system', 'system'), ('according', 'according'), ('expectations', 'expectation'), ('.', '.')]



============================ Sentence 273 =============================

When the system is trained, it can give predictions within “many applications of   classification and fault detection and channel coding and decoding” (Kotsiantis, et al., 2007; Cui,   et al., 2019). 


>> Tokens are: 
 ['When', 'system', 'trained', ',', 'give', 'predictions', 'within', '“', 'many', 'applications', 'classification', 'fault', 'detection', 'channel', 'coding', 'decoding', '”', '(', 'Kotsiantis', ',', 'et', 'al.', ',', '2007', ';', 'Cui', ',', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('When', 'system'), ('system', 'trained'), ('trained', ','), (',', 'give'), ('give', 'predictions'), ('predictions', 'within'), ('within', '“'), ('“', 'many'), ('many', 'applications'), ('applications', 'classification'), ('classification', 'fault'), ('fault', 'detection'), ('detection', 'channel'), ('channel', 'coding'), ('coding', 'decoding'), ('decoding', '”'), ('”', '('), ('(', 'Kotsiantis'), ('Kotsiantis', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2007'), ('2007', ';'), (';', 'Cui'), ('Cui', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('When', 'system', 'trained'), ('system', 'trained', ','), ('trained', ',', 'give'), (',', 'give', 'predictions'), ('give', 'predictions', 'within'), ('predictions', 'within', '“'), ('within', '“', 'many'), ('“', 'many', 'applications'), ('many', 'applications', 'classification'), ('applications', 'classification', 'fault'), ('classification', 'fault', 'detection'), ('fault', 'detection', 'channel'), ('detection', 'channel', 'coding'), ('channel', 'coding', 'decoding'), ('coding', 'decoding', '”'), ('decoding', '”', '('), ('”', '(', 'Kotsiantis'), ('(', 'Kotsiantis', ','), ('Kotsiantis', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2007'), (',', '2007', ';'), ('2007', ';', 'Cui'), (';', 'Cui', ','), ('Cui', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('When', 'WRB'), ('system', 'NN'), ('trained', 'VBD'), (',', ','), ('give', 'JJ'), ('predictions', 'NNS'), ('within', 'IN'), ('“', 'NNP'), ('many', 'JJ'), ('applications', 'NNS'), ('classification', 'VBP'), ('fault', 'NN'), ('detection', 'NN'), ('channel', 'NN'), ('coding', 'VBG'), ('decoding', 'VBG'), ('”', 'NNP'), ('(', '('), ('Kotsiantis', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2007', 'CD'), (';', ':'), ('Cui', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  When/WRB
  (NP system/NN)
  trained/VBD
  ,/,
  (NP give/JJ predictions/NNS)
  within/IN
  (NP “/NNP)
  (NP many/JJ applications/NNS)
  classification/VBP
  (NP fault/NN detection/NN channel/NN)
  coding/VBG
  decoding/VBG
  (NP ”/NNP)
  (/(
  (NP Kotsiantis/NNP)
  ,/,
  et/FW
  (NP al./NN)
  ,/,
  2007/CD
  ;/:
  (NP Cui/NNP)
  ,/,
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['system', 'give predictions', '“', 'many applications', 'fault detection channel', '”', 'Kotsiantis', 'al.', 'Cui', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Kotsiantis'), ('PERSON', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('When', 'when'), ('system', 'system'), ('trained', 'train'), (',', ','), ('give', 'give'), ('predictions', 'predict'), ('within', 'within'), ('“', '“'), ('many', 'mani'), ('applications', 'applic'), ('classification', 'classif'), ('fault', 'fault'), ('detection', 'detect'), ('channel', 'channel'), ('coding', 'code'), ('decoding', 'decod'), ('”', '”'), ('(', '('), ('Kotsiantis', 'kotsianti'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2007', '2007'), (';', ';'), ('Cui', 'cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('When', 'when'), ('system', 'system'), ('trained', 'train'), (',', ','), ('give', 'give'), ('predictions', 'predict'), ('within', 'within'), ('“', '“'), ('many', 'mani'), ('applications', 'applic'), ('classification', 'classif'), ('fault', 'fault'), ('detection', 'detect'), ('channel', 'channel'), ('coding', 'code'), ('decoding', 'decod'), ('”', '”'), ('(', '('), ('Kotsiantis', 'kotsianti'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2007', '2007'), (';', ';'), ('Cui', 'cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('When', 'When'), ('system', 'system'), ('trained', 'trained'), (',', ','), ('give', 'give'), ('predictions', 'prediction'), ('within', 'within'), ('“', '“'), ('many', 'many'), ('applications', 'application'), ('classification', 'classification'), ('fault', 'fault'), ('detection', 'detection'), ('channel', 'channel'), ('coding', 'coding'), ('decoding', 'decoding'), ('”', '”'), ('(', '('), ('Kotsiantis', 'Kotsiantis'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2007', '2007'), (';', ';'), ('Cui', 'Cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 274 =============================

This technique is used for approximating a function between the input and output. 


>> Tokens are: 
 ['This', 'technique', 'used', 'approximating', 'function', 'input', 'output', '.']

>> Bigrams are: 
 [('This', 'technique'), ('technique', 'used'), ('used', 'approximating'), ('approximating', 'function'), ('function', 'input'), ('input', 'output'), ('output', '.')]

>> Trigrams are: 
 [('This', 'technique', 'used'), ('technique', 'used', 'approximating'), ('used', 'approximating', 'function'), ('approximating', 'function', 'input'), ('function', 'input', 'output'), ('input', 'output', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('technique', 'NN'), ('used', 'VBD'), ('approximating', 'VBG'), ('function', 'NN'), ('input', 'NN'), ('output', 'NN'), ('.', '.')]

 (S
  (NP This/DT technique/NN)
  used/VBD
  approximating/VBG
  (NP function/NN input/NN output/NN)
  ./.) 


>> Noun Phrases are: 
 ['This technique', 'function input output']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('technique', 'techniqu'), ('used', 'use'), ('approximating', 'approxim'), ('function', 'function'), ('input', 'input'), ('output', 'output'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('technique', 'techniqu'), ('used', 'use'), ('approximating', 'approxim'), ('function', 'function'), ('input', 'input'), ('output', 'output'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('technique', 'technique'), ('used', 'used'), ('approximating', 'approximating'), ('function', 'function'), ('input', 'input'), ('output', 'output'), ('.', '.')]



============================ Sentence 275 =============================

The idea is for the system to learn the training dataset’s classifiers (the labelled documents) then   to automatically apply this classification to an unknown dataset’s un-labelled documents. 


>> Tokens are: 
 ['The', 'idea', 'system', 'learn', 'training', 'dataset', '’', 'classifiers', '(', 'labelled', 'documents', ')', 'automatically', 'apply', 'classification', 'unknown', 'dataset', '’', 'un-labelled', 'documents', '.']

>> Bigrams are: 
 [('The', 'idea'), ('idea', 'system'), ('system', 'learn'), ('learn', 'training'), ('training', 'dataset'), ('dataset', '’'), ('’', 'classifiers'), ('classifiers', '('), ('(', 'labelled'), ('labelled', 'documents'), ('documents', ')'), (')', 'automatically'), ('automatically', 'apply'), ('apply', 'classification'), ('classification', 'unknown'), ('unknown', 'dataset'), ('dataset', '’'), ('’', 'un-labelled'), ('un-labelled', 'documents'), ('documents', '.')]

>> Trigrams are: 
 [('The', 'idea', 'system'), ('idea', 'system', 'learn'), ('system', 'learn', 'training'), ('learn', 'training', 'dataset'), ('training', 'dataset', '’'), ('dataset', '’', 'classifiers'), ('’', 'classifiers', '('), ('classifiers', '(', 'labelled'), ('(', 'labelled', 'documents'), ('labelled', 'documents', ')'), ('documents', ')', 'automatically'), (')', 'automatically', 'apply'), ('automatically', 'apply', 'classification'), ('apply', 'classification', 'unknown'), ('classification', 'unknown', 'dataset'), ('unknown', 'dataset', '’'), ('dataset', '’', 'un-labelled'), ('’', 'un-labelled', 'documents'), ('un-labelled', 'documents', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('idea', 'NN'), ('system', 'NN'), ('learn', 'JJ'), ('training', 'NN'), ('dataset', 'NN'), ('’', 'NN'), ('classifiers', 'NNS'), ('(', '('), ('labelled', 'JJ'), ('documents', 'NNS'), (')', ')'), ('automatically', 'RB'), ('apply', 'VB'), ('classification', 'NN'), ('unknown', 'JJ'), ('dataset', 'NN'), ('’', 'VBD'), ('un-labelled', 'JJ'), ('documents', 'NNS'), ('.', '.')]

 (S
  (NP The/DT idea/NN system/NN)
  (NP learn/JJ training/NN dataset/NN ’/NN classifiers/NNS)
  (/(
  (NP labelled/JJ documents/NNS)
  )/)
  automatically/RB
  apply/VB
  (NP classification/NN)
  (NP unknown/JJ dataset/NN)
  ’/VBD
  (NP un-labelled/JJ documents/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The idea system', 'learn training dataset ’ classifiers', 'labelled documents', 'classification', 'unknown dataset', 'un-labelled documents']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('idea', 'idea'), ('system', 'system'), ('learn', 'learn'), ('training', 'train'), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('(', '('), ('labelled', 'label'), ('documents', 'document'), (')', ')'), ('automatically', 'automat'), ('apply', 'appli'), ('classification', 'classif'), ('unknown', 'unknown'), ('dataset', 'dataset'), ('’', '’'), ('un-labelled', 'un-label'), ('documents', 'document'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('idea', 'idea'), ('system', 'system'), ('learn', 'learn'), ('training', 'train'), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('(', '('), ('labelled', 'label'), ('documents', 'document'), (')', ')'), ('automatically', 'automat'), ('apply', 'appli'), ('classification', 'classif'), ('unknown', 'unknown'), ('dataset', 'dataset'), ('’', '’'), ('un-labelled', 'un-label'), ('documents', 'document'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('idea', 'idea'), ('system', 'system'), ('learn', 'learn'), ('training', 'training'), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifier'), ('(', '('), ('labelled', 'labelled'), ('documents', 'document'), (')', ')'), ('automatically', 'automatically'), ('apply', 'apply'), ('classification', 'classification'), ('unknown', 'unknown'), ('dataset', 'dataset'), ('’', '’'), ('un-labelled', 'un-labelled'), ('documents', 'document'), ('.', '.')]



============================ Sentence 276 =============================

This   learning technology thus involves learning from example (Boyd-Graber et al., 2014; Müller et al.,   2016; Breed and Verster, 2019). 


>> Tokens are: 
 ['This', 'learning', 'technology', 'thus', 'involves', 'learning', 'example', '(', 'Boyd-Graber', 'et', 'al.', ',', '2014', ';', 'Müller', 'et', 'al.', ',', '2016', ';', 'Breed', 'Verster', ',', '2019', ')', '.']

>> Bigrams are: 
 [('This', 'learning'), ('learning', 'technology'), ('technology', 'thus'), ('thus', 'involves'), ('involves', 'learning'), ('learning', 'example'), ('example', '('), ('(', 'Boyd-Graber'), ('Boyd-Graber', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Müller'), ('Müller', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'learning', 'technology'), ('learning', 'technology', 'thus'), ('technology', 'thus', 'involves'), ('thus', 'involves', 'learning'), ('involves', 'learning', 'example'), ('learning', 'example', '('), ('example', '(', 'Boyd-Graber'), ('(', 'Boyd-Graber', 'et'), ('Boyd-Graber', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Müller'), (';', 'Müller', 'et'), ('Müller', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('learning', 'VBG'), ('technology', 'NN'), ('thus', 'RB'), ('involves', 'VBZ'), ('learning', 'VBG'), ('example', 'NN'), ('(', '('), ('Boyd-Graber', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Müller', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  This/DT
  learning/VBG
  (NP technology/NN)
  thus/RB
  involves/VBZ
  learning/VBG
  (NP example/NN)
  (/(
  (NP Boyd-Graber/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2014/CD
  ;/:
  (NP Müller/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  ;/:
  (NP Breed/NNP Verster/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['technology', 'example', 'Boyd-Graber', 'al.', 'Müller', 'al.', 'Breed Verster']

>> Named Entities are: 
 [('PERSON', 'Müller'), ('PERSON', 'Breed Verster')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('learning', 'learn'), ('technology', 'technolog'), ('thus', 'thu'), ('involves', 'involv'), ('learning', 'learn'), ('example', 'exampl'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('learning', 'learn'), ('technology', 'technolog'), ('thus', 'thus'), ('involves', 'involv'), ('learning', 'learn'), ('example', 'exampl'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('learning', 'learning'), ('technology', 'technology'), ('thus', 'thus'), ('involves', 'involves'), ('learning', 'learning'), ('example', 'example'), ('(', '('), ('Boyd-Graber', 'Boyd-Graber'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'Müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 277 =============================

Regression is an example of the supervised learning algorithm, as are Linear Regression, Decision   Trees (DT), Support Vector Machine (SVM), K Nearest Neighbour (K-NN), Naive Bayes   Classifier (NBC), Random Forest, and neural networks (NN). 


>> Tokens are: 
 ['Regression', 'example', 'supervised', 'learning', 'algorithm', ',', 'Linear', 'Regression', ',', 'Decision', 'Trees', '(', 'DT', ')', ',', 'Support', 'Vector', 'Machine', '(', 'SVM', ')', ',', 'K', 'Nearest', 'Neighbour', '(', 'K-NN', ')', ',', 'Naive', 'Bayes', 'Classifier', '(', 'NBC', ')', ',', 'Random', 'Forest', ',', 'neural', 'networks', '(', 'NN', ')', '.']

>> Bigrams are: 
 [('Regression', 'example'), ('example', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithm'), ('algorithm', ','), (',', 'Linear'), ('Linear', 'Regression'), ('Regression', ','), (',', 'Decision'), ('Decision', 'Trees'), ('Trees', '('), ('(', 'DT'), ('DT', ')'), (')', ','), (',', 'Support'), ('Support', 'Vector'), ('Vector', 'Machine'), ('Machine', '('), ('(', 'SVM'), ('SVM', ')'), (')', ','), (',', 'K'), ('K', 'Nearest'), ('Nearest', 'Neighbour'), ('Neighbour', '('), ('(', 'K-NN'), ('K-NN', ')'), (')', ','), (',', 'Naive'), ('Naive', 'Bayes'), ('Bayes', 'Classifier'), ('Classifier', '('), ('(', 'NBC'), ('NBC', ')'), (')', ','), (',', 'Random'), ('Random', 'Forest'), ('Forest', ','), (',', 'neural'), ('neural', 'networks'), ('networks', '('), ('(', 'NN'), ('NN', ')'), (')', '.')]

>> Trigrams are: 
 [('Regression', 'example', 'supervised'), ('example', 'supervised', 'learning'), ('supervised', 'learning', 'algorithm'), ('learning', 'algorithm', ','), ('algorithm', ',', 'Linear'), (',', 'Linear', 'Regression'), ('Linear', 'Regression', ','), ('Regression', ',', 'Decision'), (',', 'Decision', 'Trees'), ('Decision', 'Trees', '('), ('Trees', '(', 'DT'), ('(', 'DT', ')'), ('DT', ')', ','), (')', ',', 'Support'), (',', 'Support', 'Vector'), ('Support', 'Vector', 'Machine'), ('Vector', 'Machine', '('), ('Machine', '(', 'SVM'), ('(', 'SVM', ')'), ('SVM', ')', ','), (')', ',', 'K'), (',', 'K', 'Nearest'), ('K', 'Nearest', 'Neighbour'), ('Nearest', 'Neighbour', '('), ('Neighbour', '(', 'K-NN'), ('(', 'K-NN', ')'), ('K-NN', ')', ','), (')', ',', 'Naive'), (',', 'Naive', 'Bayes'), ('Naive', 'Bayes', 'Classifier'), ('Bayes', 'Classifier', '('), ('Classifier', '(', 'NBC'), ('(', 'NBC', ')'), ('NBC', ')', ','), (')', ',', 'Random'), (',', 'Random', 'Forest'), ('Random', 'Forest', ','), ('Forest', ',', 'neural'), (',', 'neural', 'networks'), ('neural', 'networks', '('), ('networks', '(', 'NN'), ('(', 'NN', ')'), ('NN', ')', '.')]

>> POS Tags are: 
 [('Regression', 'NNP'), ('example', 'NN'), ('supervised', 'VBD'), ('learning', 'VBG'), ('algorithm', 'NN'), (',', ','), ('Linear', 'NNP'), ('Regression', 'NNP'), (',', ','), ('Decision', 'NNP'), ('Trees', 'NNP'), ('(', '('), ('DT', 'NNP'), (')', ')'), (',', ','), ('Support', 'NNP'), ('Vector', 'NNP'), ('Machine', 'NNP'), ('(', '('), ('SVM', 'NNP'), (')', ')'), (',', ','), ('K', 'NNP'), ('Nearest', 'NNP'), ('Neighbour', 'NNP'), ('(', '('), ('K-NN', 'NNP'), (')', ')'), (',', ','), ('Naive', 'JJ'), ('Bayes', 'NNP'), ('Classifier', 'NNP'), ('(', '('), ('NBC', 'NNP'), (')', ')'), (',', ','), ('Random', 'NNP'), ('Forest', 'NNP'), (',', ','), ('neural', 'JJ'), ('networks', 'NNS'), ('(', '('), ('NN', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Regression/NNP example/NN)
  supervised/VBD
  learning/VBG
  (NP algorithm/NN)
  ,/,
  (NP Linear/NNP Regression/NNP)
  ,/,
  (NP Decision/NNP Trees/NNP)
  (/(
  (NP DT/NNP)
  )/)
  ,/,
  (NP Support/NNP Vector/NNP Machine/NNP)
  (/(
  (NP SVM/NNP)
  )/)
  ,/,
  (NP K/NNP Nearest/NNP Neighbour/NNP)
  (/(
  (NP K-NN/NNP)
  )/)
  ,/,
  (NP Naive/JJ Bayes/NNP Classifier/NNP)
  (/(
  (NP NBC/NNP)
  )/)
  ,/,
  (NP Random/NNP Forest/NNP)
  ,/,
  (NP neural/JJ networks/NNS)
  (/(
  (NP NN/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Regression example', 'algorithm', 'Linear Regression', 'Decision Trees', 'DT', 'Support Vector Machine', 'SVM', 'K Nearest Neighbour', 'K-NN', 'Naive Bayes Classifier', 'NBC', 'Random Forest', 'neural networks', 'NN']

>> Named Entities are: 
 [('PERSON', 'Linear Regression'), ('PERSON', 'Decision Trees'), ('PERSON', 'Support Vector Machine'), ('ORGANIZATION', 'SVM'), ('PERSON', 'K Nearest Neighbour'), ('PERSON', 'Naive Bayes Classifier'), ('ORGANIZATION', 'NBC'), ('PERSON', 'Random Forest')] 

>> Stemming using Porter Stemmer: 
 [('Regression', 'regress'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm'), (',', ','), ('Linear', 'linear'), ('Regression', 'regress'), (',', ','), ('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), (',', ','), ('Support', 'support'), ('Vector', 'vector'), ('Machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), (',', ','), ('K', 'k'), ('Nearest', 'nearest'), ('Neighbour', 'neighbour'), ('(', '('), ('K-NN', 'k-nn'), (')', ')'), (',', ','), ('Naive', 'naiv'), ('Bayes', 'bay'), ('Classifier', 'classifi'), ('(', '('), ('NBC', 'nbc'), (')', ')'), (',', ','), ('Random', 'random'), ('Forest', 'forest'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('NN', 'nn'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Regression', 'regress'), ('example', 'exampl'), ('supervised', 'supervis'), ('learning', 'learn'), ('algorithm', 'algorithm'), (',', ','), ('Linear', 'linear'), ('Regression', 'regress'), (',', ','), ('Decision', 'decis'), ('Trees', 'tree'), ('(', '('), ('DT', 'dt'), (')', ')'), (',', ','), ('Support', 'support'), ('Vector', 'vector'), ('Machine', 'machin'), ('(', '('), ('SVM', 'svm'), (')', ')'), (',', ','), ('K', 'k'), ('Nearest', 'nearest'), ('Neighbour', 'neighbour'), ('(', '('), ('K-NN', 'k-nn'), (')', ')'), (',', ','), ('Naive', 'naiv'), ('Bayes', 'bay'), ('Classifier', 'classifi'), ('(', '('), ('NBC', 'nbc'), (')', ')'), (',', ','), ('Random', 'random'), ('Forest', 'forest'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('NN', 'nn'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Regression', 'Regression'), ('example', 'example'), ('supervised', 'supervised'), ('learning', 'learning'), ('algorithm', 'algorithm'), (',', ','), ('Linear', 'Linear'), ('Regression', 'Regression'), (',', ','), ('Decision', 'Decision'), ('Trees', 'Trees'), ('(', '('), ('DT', 'DT'), (')', ')'), (',', ','), ('Support', 'Support'), ('Vector', 'Vector'), ('Machine', 'Machine'), ('(', '('), ('SVM', 'SVM'), (')', ')'), (',', ','), ('K', 'K'), ('Nearest', 'Nearest'), ('Neighbour', 'Neighbour'), ('(', '('), ('K-NN', 'K-NN'), (')', ')'), (',', ','), ('Naive', 'Naive'), ('Bayes', 'Bayes'), ('Classifier', 'Classifier'), ('(', '('), ('NBC', 'NBC'), (')', ')'), (',', ','), ('Random', 'Random'), ('Forest', 'Forest'), (',', ','), ('neural', 'neural'), ('networks', 'network'), ('(', '('), ('NN', 'NN'), (')', ')'), ('.', '.')]



============================ Sentence 278 =============================

However, many of these supervised   techniques cannot be used with wireless networks, and as the learning techniques are dependent   on the data training, the results are also restricted (Cui et al., 2019). 


>> Tokens are: 
 ['However', ',', 'many', 'supervised', 'techniques', 'used', 'wireless', 'networks', ',', 'learning', 'techniques', 'dependent', 'data', 'training', ',', 'results', 'also', 'restricted', '(', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('However', ','), (',', 'many'), ('many', 'supervised'), ('supervised', 'techniques'), ('techniques', 'used'), ('used', 'wireless'), ('wireless', 'networks'), ('networks', ','), (',', 'learning'), ('learning', 'techniques'), ('techniques', 'dependent'), ('dependent', 'data'), ('data', 'training'), ('training', ','), (',', 'results'), ('results', 'also'), ('also', 'restricted'), ('restricted', '('), ('(', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('However', ',', 'many'), (',', 'many', 'supervised'), ('many', 'supervised', 'techniques'), ('supervised', 'techniques', 'used'), ('techniques', 'used', 'wireless'), ('used', 'wireless', 'networks'), ('wireless', 'networks', ','), ('networks', ',', 'learning'), (',', 'learning', 'techniques'), ('learning', 'techniques', 'dependent'), ('techniques', 'dependent', 'data'), ('dependent', 'data', 'training'), ('data', 'training', ','), ('training', ',', 'results'), (',', 'results', 'also'), ('results', 'also', 'restricted'), ('also', 'restricted', '('), ('restricted', '(', 'Cui'), ('(', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('many', 'JJ'), ('supervised', 'VBD'), ('techniques', 'NNS'), ('used', 'VBN'), ('wireless', 'NN'), ('networks', 'NNS'), (',', ','), ('learning', 'VBG'), ('techniques', 'NNS'), ('dependent', 'JJ'), ('data', 'NNS'), ('training', 'NN'), (',', ','), ('results', 'NNS'), ('also', 'RB'), ('restricted', 'VBD'), ('(', '('), ('Cui', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  However/RB
  ,/,
  many/JJ
  supervised/VBD
  (NP techniques/NNS)
  used/VBN
  (NP wireless/NN networks/NNS)
  ,/,
  learning/VBG
  (NP techniques/NNS)
  (NP dependent/JJ data/NNS training/NN)
  ,/,
  (NP results/NNS)
  also/RB
  restricted/VBD
  (/(
  (NP Cui/NNP)
  et/RB
  al./RB
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['techniques', 'wireless networks', 'techniques', 'dependent data training', 'results', 'Cui']

>> Named Entities are: 
 [('ORGANIZATION', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('many', 'mani'), ('supervised', 'supervis'), ('techniques', 'techniqu'), ('used', 'use'), ('wireless', 'wireless'), ('networks', 'network'), (',', ','), ('learning', 'learn'), ('techniques', 'techniqu'), ('dependent', 'depend'), ('data', 'data'), ('training', 'train'), (',', ','), ('results', 'result'), ('also', 'also'), ('restricted', 'restrict'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('many', 'mani'), ('supervised', 'supervis'), ('techniques', 'techniqu'), ('used', 'use'), ('wireless', 'wireless'), ('networks', 'network'), (',', ','), ('learning', 'learn'), ('techniques', 'techniqu'), ('dependent', 'depend'), ('data', 'data'), ('training', 'train'), (',', ','), ('results', 'result'), ('also', 'also'), ('restricted', 'restrict'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('many', 'many'), ('supervised', 'supervised'), ('techniques', 'technique'), ('used', 'used'), ('wireless', 'wireless'), ('networks', 'network'), (',', ','), ('learning', 'learning'), ('techniques', 'technique'), ('dependent', 'dependent'), ('data', 'data'), ('training', 'training'), (',', ','), ('results', 'result'), ('also', 'also'), ('restricted', 'restricted'), ('(', '('), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 279 =============================

Sarah Al-Shiakhli   23         Regression Analysis: is mathematical tool used to discover correlations between several variables   based on experimental or observed data. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '23', 'Regression', 'Analysis', ':', 'mathematical', 'tool', 'used', 'discover', 'correlations', 'several', 'variables', 'based', 'experimental', 'observed', 'data', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '23'), ('23', 'Regression'), ('Regression', 'Analysis'), ('Analysis', ':'), (':', 'mathematical'), ('mathematical', 'tool'), ('tool', 'used'), ('used', 'discover'), ('discover', 'correlations'), ('correlations', 'several'), ('several', 'variables'), ('variables', 'based'), ('based', 'experimental'), ('experimental', 'observed'), ('observed', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '23'), ('Al-Shiakhli', '23', 'Regression'), ('23', 'Regression', 'Analysis'), ('Regression', 'Analysis', ':'), ('Analysis', ':', 'mathematical'), (':', 'mathematical', 'tool'), ('mathematical', 'tool', 'used'), ('tool', 'used', 'discover'), ('used', 'discover', 'correlations'), ('discover', 'correlations', 'several'), ('correlations', 'several', 'variables'), ('several', 'variables', 'based'), ('variables', 'based', 'experimental'), ('based', 'experimental', 'observed'), ('experimental', 'observed', 'data'), ('observed', 'data', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('23', 'CD'), ('Regression', 'NNP'), ('Analysis', 'NN'), (':', ':'), ('mathematical', 'JJ'), ('tool', 'NN'), ('used', 'VBN'), ('discover', 'NN'), ('correlations', 'NNS'), ('several', 'JJ'), ('variables', 'NNS'), ('based', 'VBN'), ('experimental', 'JJ'), ('observed', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  23/CD
  (NP Regression/NNP Analysis/NN)
  :/:
  (NP mathematical/JJ tool/NN)
  used/VBN
  (NP discover/NN correlations/NNS)
  (NP several/JJ variables/NNS)
  based/VBN
  (NP experimental/JJ observed/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Regression Analysis', 'mathematical tool', 'discover correlations', 'several variables', 'experimental observed data']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('23', '23'), ('Regression', 'regress'), ('Analysis', 'analysi'), (':', ':'), ('mathematical', 'mathemat'), ('tool', 'tool'), ('used', 'use'), ('discover', 'discov'), ('correlations', 'correl'), ('several', 'sever'), ('variables', 'variabl'), ('based', 'base'), ('experimental', 'experiment'), ('observed', 'observ'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('23', '23'), ('Regression', 'regress'), ('Analysis', 'analysi'), (':', ':'), ('mathematical', 'mathemat'), ('tool', 'tool'), ('used', 'use'), ('discover', 'discov'), ('correlations', 'correl'), ('several', 'sever'), ('variables', 'variabl'), ('based', 'base'), ('experimental', 'experiment'), ('observed', 'observ'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('23', '23'), ('Regression', 'Regression'), ('Analysis', 'Analysis'), (':', ':'), ('mathematical', 'mathematical'), ('tool', 'tool'), ('used', 'used'), ('discover', 'discover'), ('correlations', 'correlation'), ('several', 'several'), ('variables', 'variable'), ('based', 'based'), ('experimental', 'experimental'), ('observed', 'observed'), ('data', 'data'), ('.', '.')]



============================ Sentence 280 =============================

Where analysis defines the relationships between   variables as non-random, such analysis may make the correlations between variables appear   simpler and more regular (Lei et al., 2016), as shown in Figure 13. 


>> Tokens are: 
 ['Where', 'analysis', 'defines', 'relationships', 'variables', 'non-random', ',', 'analysis', 'may', 'make', 'correlations', 'variables', 'appear', 'simpler', 'regular', '(', 'Lei', 'et', 'al.', ',', '2016', ')', ',', 'shown', 'Figure', '13', '.']

>> Bigrams are: 
 [('Where', 'analysis'), ('analysis', 'defines'), ('defines', 'relationships'), ('relationships', 'variables'), ('variables', 'non-random'), ('non-random', ','), (',', 'analysis'), ('analysis', 'may'), ('may', 'make'), ('make', 'correlations'), ('correlations', 'variables'), ('variables', 'appear'), ('appear', 'simpler'), ('simpler', 'regular'), ('regular', '('), ('(', 'Lei'), ('Lei', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '13'), ('13', '.')]

>> Trigrams are: 
 [('Where', 'analysis', 'defines'), ('analysis', 'defines', 'relationships'), ('defines', 'relationships', 'variables'), ('relationships', 'variables', 'non-random'), ('variables', 'non-random', ','), ('non-random', ',', 'analysis'), (',', 'analysis', 'may'), ('analysis', 'may', 'make'), ('may', 'make', 'correlations'), ('make', 'correlations', 'variables'), ('correlations', 'variables', 'appear'), ('variables', 'appear', 'simpler'), ('appear', 'simpler', 'regular'), ('simpler', 'regular', '('), ('regular', '(', 'Lei'), ('(', 'Lei', 'et'), ('Lei', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '13'), ('Figure', '13', '.')]

>> POS Tags are: 
 [('Where', 'WRB'), ('analysis', 'NN'), ('defines', 'VBZ'), ('relationships', 'NNS'), ('variables', 'NNS'), ('non-random', 'RB'), (',', ','), ('analysis', 'NN'), ('may', 'MD'), ('make', 'VB'), ('correlations', 'NNS'), ('variables', 'NNS'), ('appear', 'VBP'), ('simpler', 'NN'), ('regular', 'NN'), ('(', '('), ('Lei', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('13', 'CD'), ('.', '.')]

 (S
  Where/WRB
  (NP analysis/NN)
  defines/VBZ
  (NP relationships/NNS variables/NNS)
  non-random/RB
  ,/,
  (NP analysis/NN)
  may/MD
  make/VB
  (NP correlations/NNS variables/NNS)
  appear/VBP
  (NP simpler/NN regular/NN)
  (/(
  (NP Lei/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ,/,
  shown/VBN
  (NP Figure/NN)
  13/CD
  ./.) 


>> Noun Phrases are: 
 ['analysis', 'relationships variables', 'analysis', 'correlations variables', 'simpler regular', 'Lei', 'Figure']

>> Named Entities are: 
 [('ORGANIZATION', 'Lei')] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('analysis', 'analysi'), ('defines', 'defin'), ('relationships', 'relationship'), ('variables', 'variabl'), ('non-random', 'non-random'), (',', ','), ('analysis', 'analysi'), ('may', 'may'), ('make', 'make'), ('correlations', 'correl'), ('variables', 'variabl'), ('appear', 'appear'), ('simpler', 'simpler'), ('regular', 'regular'), ('(', '('), ('Lei', 'lei'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('analysis', 'analysi'), ('defines', 'defin'), ('relationships', 'relationship'), ('variables', 'variabl'), ('non-random', 'non-random'), (',', ','), ('analysis', 'analysi'), ('may', 'may'), ('make', 'make'), ('correlations', 'correl'), ('variables', 'variabl'), ('appear', 'appear'), ('simpler', 'simpler'), ('regular', 'regular'), ('(', '('), ('Lei', 'lei'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('Where', 'Where'), ('analysis', 'analysis'), ('defines', 'defines'), ('relationships', 'relationship'), ('variables', 'variable'), ('non-random', 'non-random'), (',', ','), ('analysis', 'analysis'), ('may', 'may'), ('make', 'make'), ('correlations', 'correlation'), ('variables', 'variable'), ('appear', 'appear'), ('simpler', 'simpler'), ('regular', 'regular'), ('(', '('), ('Lei', 'Lei'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('13', '13'), ('.', '.')]



============================ Sentence 281 =============================

Figure 13: Regression analysis      Structured data mostly utilises predictive analytics, and this overshadows other analytics forms for   95% of big data (Gandomi and Haider, 2015). 


>> Tokens are: 
 ['Figure', '13', ':', 'Regression', 'analysis', 'Structured', 'data', 'mostly', 'utilises', 'predictive', 'analytics', ',', 'overshadows', 'analytics', 'forms', '95', '%', 'big', 'data', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Figure', '13'), ('13', ':'), (':', 'Regression'), ('Regression', 'analysis'), ('analysis', 'Structured'), ('Structured', 'data'), ('data', 'mostly'), ('mostly', 'utilises'), ('utilises', 'predictive'), ('predictive', 'analytics'), ('analytics', ','), (',', 'overshadows'), ('overshadows', 'analytics'), ('analytics', 'forms'), ('forms', '95'), ('95', '%'), ('%', 'big'), ('big', 'data'), ('data', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '13', ':'), ('13', ':', 'Regression'), (':', 'Regression', 'analysis'), ('Regression', 'analysis', 'Structured'), ('analysis', 'Structured', 'data'), ('Structured', 'data', 'mostly'), ('data', 'mostly', 'utilises'), ('mostly', 'utilises', 'predictive'), ('utilises', 'predictive', 'analytics'), ('predictive', 'analytics', ','), ('analytics', ',', 'overshadows'), (',', 'overshadows', 'analytics'), ('overshadows', 'analytics', 'forms'), ('analytics', 'forms', '95'), ('forms', '95', '%'), ('95', '%', 'big'), ('%', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('13', 'CD'), (':', ':'), ('Regression', 'NN'), ('analysis', 'NN'), ('Structured', 'NNP'), ('data', 'NNS'), ('mostly', 'RB'), ('utilises', 'VBZ'), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('overshadows', 'VBZ'), ('analytics', 'NNS'), ('forms', 'NNS'), ('95', 'CD'), ('%', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  13/CD
  :/:
  (NP Regression/NN analysis/NN Structured/NNP data/NNS)
  mostly/RB
  utilises/VBZ
  (NP predictive/JJ analytics/NNS)
  ,/,
  overshadows/VBZ
  (NP analytics/NNS forms/NNS)
  95/CD
  (NP %/NN)
  (NP big/JJ data/NNS)
  (/(
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Regression analysis Structured data', 'predictive analytics', 'analytics forms', '%', 'big data', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('13', '13'), (':', ':'), ('Regression', 'regress'), ('analysis', 'analysi'), ('Structured', 'structur'), ('data', 'data'), ('mostly', 'mostli'), ('utilises', 'utilis'), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('overshadows', 'overshadow'), ('analytics', 'analyt'), ('forms', 'form'), ('95', '95'), ('%', '%'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('13', '13'), (':', ':'), ('Regression', 'regress'), ('analysis', 'analysi'), ('Structured', 'structur'), ('data', 'data'), ('mostly', 'most'), ('utilises', 'utilis'), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('overshadows', 'overshadow'), ('analytics', 'analyt'), ('forms', 'form'), ('95', '95'), ('%', '%'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('13', '13'), (':', ':'), ('Regression', 'Regression'), ('analysis', 'analysis'), ('Structured', 'Structured'), ('data', 'data'), ('mostly', 'mostly'), ('utilises', 'utilises'), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ','), ('overshadows', 'overshadows'), ('analytics', 'analytics'), ('forms', 'form'), ('95', '95'), ('%', '%'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 282 =============================

However, new statistical techniques for big data   have emerged which clarify the differentiation of big data from smaller data sets. 


>> Tokens are: 
 ['However', ',', 'new', 'statistical', 'techniques', 'big', 'data', 'emerged', 'clarify', 'differentiation', 'big', 'data', 'smaller', 'data', 'sets', '.']

>> Bigrams are: 
 [('However', ','), (',', 'new'), ('new', 'statistical'), ('statistical', 'techniques'), ('techniques', 'big'), ('big', 'data'), ('data', 'emerged'), ('emerged', 'clarify'), ('clarify', 'differentiation'), ('differentiation', 'big'), ('big', 'data'), ('data', 'smaller'), ('smaller', 'data'), ('data', 'sets'), ('sets', '.')]

>> Trigrams are: 
 [('However', ',', 'new'), (',', 'new', 'statistical'), ('new', 'statistical', 'techniques'), ('statistical', 'techniques', 'big'), ('techniques', 'big', 'data'), ('big', 'data', 'emerged'), ('data', 'emerged', 'clarify'), ('emerged', 'clarify', 'differentiation'), ('clarify', 'differentiation', 'big'), ('differentiation', 'big', 'data'), ('big', 'data', 'smaller'), ('data', 'smaller', 'data'), ('smaller', 'data', 'sets'), ('data', 'sets', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('new', 'JJ'), ('statistical', 'JJ'), ('techniques', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('emerged', 'VBD'), ('clarify', 'JJ'), ('differentiation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('smaller', 'JJR'), ('data', 'NNS'), ('sets', 'NNS'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP new/JJ statistical/JJ techniques/NNS)
  (NP big/JJ data/NNS)
  emerged/VBD
  (NP clarify/JJ differentiation/NN)
  (NP big/JJ data/NNS)
  smaller/JJR
  (NP data/NNS sets/NNS)
  ./.) 


>> Noun Phrases are: 
 ['new statistical techniques', 'big data', 'clarify differentiation', 'big data', 'data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('new', 'new'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('big', 'big'), ('data', 'data'), ('emerged', 'emerg'), ('clarify', 'clarifi'), ('differentiation', 'differenti'), ('big', 'big'), ('data', 'data'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('new', 'new'), ('statistical', 'statist'), ('techniques', 'techniqu'), ('big', 'big'), ('data', 'data'), ('emerged', 'emerg'), ('clarify', 'clarifi'), ('differentiation', 'differenti'), ('big', 'big'), ('data', 'data'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('new', 'new'), ('statistical', 'statistical'), ('techniques', 'technique'), ('big', 'big'), ('data', 'data'), ('emerged', 'emerged'), ('clarify', 'clarify'), ('differentiation', 'differentiation'), ('big', 'big'), ('data', 'data'), ('smaller', 'smaller'), ('data', 'data'), ('sets', 'set'), ('.', '.')]



============================ Sentence 283 =============================

In practice,   however, most statistical methods were designed for smaller datasets, in particular, samples. 


>> Tokens are: 
 ['In', 'practice', ',', 'however', ',', 'statistical', 'methods', 'designed', 'smaller', 'datasets', ',', 'particular', ',', 'samples', '.']

>> Bigrams are: 
 [('In', 'practice'), ('practice', ','), (',', 'however'), ('however', ','), (',', 'statistical'), ('statistical', 'methods'), ('methods', 'designed'), ('designed', 'smaller'), ('smaller', 'datasets'), ('datasets', ','), (',', 'particular'), ('particular', ','), (',', 'samples'), ('samples', '.')]

>> Trigrams are: 
 [('In', 'practice', ','), ('practice', ',', 'however'), (',', 'however', ','), ('however', ',', 'statistical'), (',', 'statistical', 'methods'), ('statistical', 'methods', 'designed'), ('methods', 'designed', 'smaller'), ('designed', 'smaller', 'datasets'), ('smaller', 'datasets', ','), ('datasets', ',', 'particular'), (',', 'particular', ','), ('particular', ',', 'samples'), (',', 'samples', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('practice', 'NN'), (',', ','), ('however', 'RB'), (',', ','), ('statistical', 'JJ'), ('methods', 'NNS'), ('designed', 'VBN'), ('smaller', 'JJR'), ('datasets', 'NNS'), (',', ','), ('particular', 'JJ'), (',', ','), ('samples', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP practice/NN)
  ,/,
  however/RB
  ,/,
  (NP statistical/JJ methods/NNS)
  designed/VBN
  smaller/JJR
  (NP datasets/NNS)
  ,/,
  particular/JJ
  ,/,
  (NP samples/NNS)
  ./.) 


>> Noun Phrases are: 
 ['practice', 'statistical methods', 'datasets', 'samples']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ','), ('however', 'howev'), (',', ','), ('statistical', 'statist'), ('methods', 'method'), ('designed', 'design'), ('smaller', 'smaller'), ('datasets', 'dataset'), (',', ','), ('particular', 'particular'), (',', ','), ('samples', 'sampl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('practice', 'practic'), (',', ','), ('however', 'howev'), (',', ','), ('statistical', 'statist'), ('methods', 'method'), ('designed', 'design'), ('smaller', 'smaller'), ('datasets', 'dataset'), (',', ','), ('particular', 'particular'), (',', ','), ('samples', 'sampl'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('practice', 'practice'), (',', ','), ('however', 'however'), (',', ','), ('statistical', 'statistical'), ('methods', 'method'), ('designed', 'designed'), ('smaller', 'smaller'), ('datasets', 'datasets'), (',', ','), ('particular', 'particular'), (',', ','), ('samples', 'sample'), ('.', '.')]



============================ Sentence 284 =============================

Usually, scientists make predictions based on theories in the prediction domain. 


>> Tokens are: 
 ['Usually', ',', 'scientists', 'make', 'predictions', 'based', 'theories', 'prediction', 'domain', '.']

>> Bigrams are: 
 [('Usually', ','), (',', 'scientists'), ('scientists', 'make'), ('make', 'predictions'), ('predictions', 'based'), ('based', 'theories'), ('theories', 'prediction'), ('prediction', 'domain'), ('domain', '.')]

>> Trigrams are: 
 [('Usually', ',', 'scientists'), (',', 'scientists', 'make'), ('scientists', 'make', 'predictions'), ('make', 'predictions', 'based'), ('predictions', 'based', 'theories'), ('based', 'theories', 'prediction'), ('theories', 'prediction', 'domain'), ('prediction', 'domain', '.')]

>> POS Tags are: 
 [('Usually', 'RB'), (',', ','), ('scientists', 'NNS'), ('make', 'VBP'), ('predictions', 'NNS'), ('based', 'VBN'), ('theories', 'NNS'), ('prediction', 'NN'), ('domain', 'NN'), ('.', '.')]

 (S
  Usually/RB
  ,/,
  (NP scientists/NNS)
  make/VBP
  (NP predictions/NNS)
  based/VBN
  (NP theories/NNS prediction/NN domain/NN)
  ./.) 


>> Noun Phrases are: 
 ['scientists', 'predictions', 'theories prediction domain']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Usually', 'usual'), (',', ','), ('scientists', 'scientist'), ('make', 'make'), ('predictions', 'predict'), ('based', 'base'), ('theories', 'theori'), ('prediction', 'predict'), ('domain', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Usually', 'usual'), (',', ','), ('scientists', 'scientist'), ('make', 'make'), ('predictions', 'predict'), ('based', 'base'), ('theories', 'theori'), ('prediction', 'predict'), ('domain', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('Usually', 'Usually'), (',', ','), ('scientists', 'scientist'), ('make', 'make'), ('predictions', 'prediction'), ('based', 'based'), ('theories', 'theory'), ('prediction', 'prediction'), ('domain', 'domain'), ('.', '.')]



============================ Sentence 285 =============================

However, big data   analytics can deliver predictions that depend on the sequence of data processing and execution. 


>> Tokens are: 
 ['However', ',', 'big', 'data', 'analytics', 'deliver', 'predictions', 'depend', 'sequence', 'data', 'processing', 'execution', '.']

>> Bigrams are: 
 [('However', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'deliver'), ('deliver', 'predictions'), ('predictions', 'depend'), ('depend', 'sequence'), ('sequence', 'data'), ('data', 'processing'), ('processing', 'execution'), ('execution', '.')]

>> Trigrams are: 
 [('However', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'deliver'), ('analytics', 'deliver', 'predictions'), ('deliver', 'predictions', 'depend'), ('predictions', 'depend', 'sequence'), ('depend', 'sequence', 'data'), ('sequence', 'data', 'processing'), ('data', 'processing', 'execution'), ('processing', 'execution', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('deliver', 'JJ'), ('predictions', 'NNS'), ('depend', 'VBP'), ('sequence', 'NN'), ('data', 'NNS'), ('processing', 'NN'), ('execution', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP big/JJ data/NNS analytics/NNS)
  (NP deliver/JJ predictions/NNS)
  depend/VBP
  (NP sequence/NN data/NNS processing/NN execution/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data analytics', 'deliver predictions', 'sequence data processing execution']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('deliver', 'deliv'), ('predictions', 'predict'), ('depend', 'depend'), ('sequence', 'sequenc'), ('data', 'data'), ('processing', 'process'), ('execution', 'execut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('deliver', 'deliv'), ('predictions', 'predict'), ('depend', 'depend'), ('sequence', 'sequenc'), ('data', 'data'), ('processing', 'process'), ('execution', 'execut'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('deliver', 'deliver'), ('predictions', 'prediction'), ('depend', 'depend'), ('sequence', 'sequence'), ('data', 'data'), ('processing', 'processing'), ('execution', 'execution'), ('.', '.')]



============================ Sentence 286 =============================

According to Kitchin (2014) and Müller et al. 


>> Tokens are: 
 ['According', 'Kitchin', '(', '2014', ')', 'Müller', 'et', 'al', '.']

>> Bigrams are: 
 [('According', 'Kitchin'), ('Kitchin', '('), ('(', '2014'), ('2014', ')'), (')', 'Müller'), ('Müller', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('According', 'Kitchin', '('), ('Kitchin', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'Müller'), (')', 'Müller', 'et'), ('Müller', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('According', 'VBG'), ('Kitchin', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('Müller', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S
  According/VBG
  (NP Kitchin/NNP)
  (/(
  2014/CD
  )/)
  (NP Müller/NNP)
  et/CC
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['Kitchin', 'Müller', 'al']

>> Named Entities are: 
 [('GPE', 'Kitchin'), ('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('According', 'accord'), ('Kitchin', 'kitchin'), ('(', '('), ('2014', '2014'), (')', ')'), ('Müller', 'müller'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('According', 'accord'), ('Kitchin', 'kitchin'), ('(', '('), ('2014', '2014'), (')', ')'), ('Müller', 'müller'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('According', 'According'), ('Kitchin', 'Kitchin'), ('(', '('), ('2014', '2014'), (')', ')'), ('Müller', 'Müller'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 287 =============================

(2016),   • big data brings new challenge as it is generated from different system sources. 


>> Tokens are: 
 ['(', '2016', ')', ',', '•', 'big', 'data', 'brings', 'new', 'challenge', 'generated', 'different', 'system', 'sources', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', ','), (',', '•'), ('•', 'big'), ('big', 'data'), ('data', 'brings'), ('brings', 'new'), ('new', 'challenge'), ('challenge', 'generated'), ('generated', 'different'), ('different', 'system'), ('system', 'sources'), ('sources', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', ','), (')', ',', '•'), (',', '•', 'big'), ('•', 'big', 'data'), ('big', 'data', 'brings'), ('data', 'brings', 'new'), ('brings', 'new', 'challenge'), ('new', 'challenge', 'generated'), ('challenge', 'generated', 'different'), ('generated', 'different', 'system'), ('different', 'system', 'sources'), ('system', 'sources', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), (',', ','), ('•', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('brings', 'VBZ'), ('new', 'JJ'), ('challenge', 'NN'), ('generated', 'VBN'), ('different', 'JJ'), ('system', 'NN'), ('sources', 'NNS'), ('.', '.')]

 (S
  (/(
  2016/CD
  )/)
  ,/,
  •/VBP
  (NP big/JJ data/NNS)
  brings/VBZ
  (NP new/JJ challenge/NN)
  generated/VBN
  (NP different/JJ system/NN sources/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'new challenge', 'different system sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), (',', ','), ('•', '•'), ('big', 'big'), ('data', 'data'), ('brings', 'bring'), ('new', 'new'), ('challenge', 'challeng'), ('generated', 'gener'), ('different', 'differ'), ('system', 'system'), ('sources', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), (',', ','), ('•', '•'), ('big', 'big'), ('data', 'data'), ('brings', 'bring'), ('new', 'new'), ('challenge', 'challeng'), ('generated', 'generat'), ('different', 'differ'), ('system', 'system'), ('sources', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), (',', ','), ('•', '•'), ('big', 'big'), ('data', 'data'), ('brings', 'brings'), ('new', 'new'), ('challenge', 'challenge'), ('generated', 'generated'), ('different', 'different'), ('system', 'system'), ('sources', 'source'), ('.', '.')]



============================ Sentence 288 =============================

The data  retrieved from each source system should thus be sent to a central repository;   • the relationship between operations should be defined to allow reconstruction of datasets  from multiple sources;   • the knowledge discovery process should be automated from data or datasets to make  predictions;   • generating new theories is required to create and improve models. 


>> Tokens are: 
 ['The', 'data', 'retrieved', 'source', 'system', 'thus', 'sent', 'central', 'repository', ';', '•', 'relationship', 'operations', 'defined', 'allow', 'reconstruction', 'datasets', 'multiple', 'sources', ';', '•', 'knowledge', 'discovery', 'process', 'automated', 'data', 'datasets', 'make', 'predictions', ';', '•', 'generating', 'new', 'theories', 'required', 'create', 'improve', 'models', '.']

>> Bigrams are: 
 [('The', 'data'), ('data', 'retrieved'), ('retrieved', 'source'), ('source', 'system'), ('system', 'thus'), ('thus', 'sent'), ('sent', 'central'), ('central', 'repository'), ('repository', ';'), (';', '•'), ('•', 'relationship'), ('relationship', 'operations'), ('operations', 'defined'), ('defined', 'allow'), ('allow', 'reconstruction'), ('reconstruction', 'datasets'), ('datasets', 'multiple'), ('multiple', 'sources'), ('sources', ';'), (';', '•'), ('•', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'process'), ('process', 'automated'), ('automated', 'data'), ('data', 'datasets'), ('datasets', 'make'), ('make', 'predictions'), ('predictions', ';'), (';', '•'), ('•', 'generating'), ('generating', 'new'), ('new', 'theories'), ('theories', 'required'), ('required', 'create'), ('create', 'improve'), ('improve', 'models'), ('models', '.')]

>> Trigrams are: 
 [('The', 'data', 'retrieved'), ('data', 'retrieved', 'source'), ('retrieved', 'source', 'system'), ('source', 'system', 'thus'), ('system', 'thus', 'sent'), ('thus', 'sent', 'central'), ('sent', 'central', 'repository'), ('central', 'repository', ';'), ('repository', ';', '•'), (';', '•', 'relationship'), ('•', 'relationship', 'operations'), ('relationship', 'operations', 'defined'), ('operations', 'defined', 'allow'), ('defined', 'allow', 'reconstruction'), ('allow', 'reconstruction', 'datasets'), ('reconstruction', 'datasets', 'multiple'), ('datasets', 'multiple', 'sources'), ('multiple', 'sources', ';'), ('sources', ';', '•'), (';', '•', 'knowledge'), ('•', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'process'), ('discovery', 'process', 'automated'), ('process', 'automated', 'data'), ('automated', 'data', 'datasets'), ('data', 'datasets', 'make'), ('datasets', 'make', 'predictions'), ('make', 'predictions', ';'), ('predictions', ';', '•'), (';', '•', 'generating'), ('•', 'generating', 'new'), ('generating', 'new', 'theories'), ('new', 'theories', 'required'), ('theories', 'required', 'create'), ('required', 'create', 'improve'), ('create', 'improve', 'models'), ('improve', 'models', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('data', 'NNS'), ('retrieved', 'VBN'), ('source', 'NN'), ('system', 'NN'), ('thus', 'RB'), ('sent', 'JJ'), ('central', 'JJ'), ('repository', 'NN'), (';', ':'), ('•', 'CC'), ('relationship', 'NN'), ('operations', 'NNS'), ('defined', 'VBD'), ('allow', 'JJ'), ('reconstruction', 'NN'), ('datasets', 'NNS'), ('multiple', 'JJ'), ('sources', 'NNS'), (';', ':'), ('•', 'NNP'), ('knowledge', 'VB'), ('discovery', 'NN'), ('process', 'NN'), ('automated', 'VBD'), ('data', 'NNS'), ('datasets', 'NNS'), ('make', 'VBP'), ('predictions', 'NNS'), (';', ':'), ('•', 'NNP'), ('generating', 'VBG'), ('new', 'JJ'), ('theories', 'NNS'), ('required', 'VBN'), ('create', 'VBP'), ('improve', 'JJ'), ('models', 'NNS'), ('.', '.')]

 (S
  (NP The/DT data/NNS)
  retrieved/VBN
  (NP source/NN system/NN)
  thus/RB
  (NP sent/JJ central/JJ repository/NN)
  ;/:
  •/CC
  (NP relationship/NN operations/NNS)
  defined/VBD
  (NP allow/JJ reconstruction/NN datasets/NNS)
  (NP multiple/JJ sources/NNS)
  ;/:
  (NP •/NNP)
  knowledge/VB
  (NP discovery/NN process/NN)
  automated/VBD
  (NP data/NNS datasets/NNS)
  make/VBP
  (NP predictions/NNS)
  ;/:
  (NP •/NNP)
  generating/VBG
  (NP new/JJ theories/NNS)
  required/VBN
  create/VBP
  (NP improve/JJ models/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The data', 'source system', 'sent central repository', 'relationship operations', 'allow reconstruction datasets', 'multiple sources', '•', 'discovery process', 'data datasets', 'predictions', '•', 'new theories', 'improve models']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('data', 'data'), ('retrieved', 'retriev'), ('source', 'sourc'), ('system', 'system'), ('thus', 'thu'), ('sent', 'sent'), ('central', 'central'), ('repository', 'repositori'), (';', ';'), ('•', '•'), ('relationship', 'relationship'), ('operations', 'oper'), ('defined', 'defin'), ('allow', 'allow'), ('reconstruction', 'reconstruct'), ('datasets', 'dataset'), ('multiple', 'multipl'), ('sources', 'sourc'), (';', ';'), ('•', '•'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('process', 'process'), ('automated', 'autom'), ('data', 'data'), ('datasets', 'dataset'), ('make', 'make'), ('predictions', 'predict'), (';', ';'), ('•', '•'), ('generating', 'gener'), ('new', 'new'), ('theories', 'theori'), ('required', 'requir'), ('create', 'creat'), ('improve', 'improv'), ('models', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('data', 'data'), ('retrieved', 'retriev'), ('source', 'sourc'), ('system', 'system'), ('thus', 'thus'), ('sent', 'sent'), ('central', 'central'), ('repository', 'repositori'), (';', ';'), ('•', '•'), ('relationship', 'relationship'), ('operations', 'oper'), ('defined', 'defin'), ('allow', 'allow'), ('reconstruction', 'reconstruct'), ('datasets', 'dataset'), ('multiple', 'multipl'), ('sources', 'sourc'), (';', ';'), ('•', '•'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('process', 'process'), ('automated', 'autom'), ('data', 'data'), ('datasets', 'dataset'), ('make', 'make'), ('predictions', 'predict'), (';', ';'), ('•', '•'), ('generating', 'generat'), ('new', 'new'), ('theories', 'theori'), ('required', 'requir'), ('create', 'creat'), ('improve', 'improv'), ('models', 'model'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('data', 'data'), ('retrieved', 'retrieved'), ('source', 'source'), ('system', 'system'), ('thus', 'thus'), ('sent', 'sent'), ('central', 'central'), ('repository', 'repository'), (';', ';'), ('•', '•'), ('relationship', 'relationship'), ('operations', 'operation'), ('defined', 'defined'), ('allow', 'allow'), ('reconstruction', 'reconstruction'), ('datasets', 'datasets'), ('multiple', 'multiple'), ('sources', 'source'), (';', ';'), ('•', '•'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('process', 'process'), ('automated', 'automated'), ('data', 'data'), ('datasets', 'datasets'), ('make', 'make'), ('predictions', 'prediction'), (';', ';'), ('•', '•'), ('generating', 'generating'), ('new', 'new'), ('theories', 'theory'), ('required', 'required'), ('create', 'create'), ('improve', 'improve'), ('models', 'model'), ('.', '.')]



============================ Sentence 289 =============================

Predicted target theory  generates a set of predictors; however, some theories explain the relationships between   independent and dependent predictors more effectively;   • there is a shift from theory-driven to process-driven prediction based on analysing the  BDA steps and identifying the challenges, theoretically informing future BDA needs   throughout data acquisition, pre-processing analysis, and interpretation. 


>> Tokens are: 
 ['Predicted', 'target', 'theory', 'generates', 'set', 'predictors', ';', 'however', ',', 'theories', 'explain', 'relationships', 'independent', 'dependent', 'predictors', 'effectively', ';', '•', 'shift', 'theory-driven', 'process-driven', 'prediction', 'based', 'analysing', 'BDA', 'steps', 'identifying', 'challenges', ',', 'theoretically', 'informing', 'future', 'BDA', 'needs', 'throughout', 'data', 'acquisition', ',', 'pre-processing', 'analysis', ',', 'interpretation', '.']

>> Bigrams are: 
 [('Predicted', 'target'), ('target', 'theory'), ('theory', 'generates'), ('generates', 'set'), ('set', 'predictors'), ('predictors', ';'), (';', 'however'), ('however', ','), (',', 'theories'), ('theories', 'explain'), ('explain', 'relationships'), ('relationships', 'independent'), ('independent', 'dependent'), ('dependent', 'predictors'), ('predictors', 'effectively'), ('effectively', ';'), (';', '•'), ('•', 'shift'), ('shift', 'theory-driven'), ('theory-driven', 'process-driven'), ('process-driven', 'prediction'), ('prediction', 'based'), ('based', 'analysing'), ('analysing', 'BDA'), ('BDA', 'steps'), ('steps', 'identifying'), ('identifying', 'challenges'), ('challenges', ','), (',', 'theoretically'), ('theoretically', 'informing'), ('informing', 'future'), ('future', 'BDA'), ('BDA', 'needs'), ('needs', 'throughout'), ('throughout', 'data'), ('data', 'acquisition'), ('acquisition', ','), (',', 'pre-processing'), ('pre-processing', 'analysis'), ('analysis', ','), (',', 'interpretation'), ('interpretation', '.')]

>> Trigrams are: 
 [('Predicted', 'target', 'theory'), ('target', 'theory', 'generates'), ('theory', 'generates', 'set'), ('generates', 'set', 'predictors'), ('set', 'predictors', ';'), ('predictors', ';', 'however'), (';', 'however', ','), ('however', ',', 'theories'), (',', 'theories', 'explain'), ('theories', 'explain', 'relationships'), ('explain', 'relationships', 'independent'), ('relationships', 'independent', 'dependent'), ('independent', 'dependent', 'predictors'), ('dependent', 'predictors', 'effectively'), ('predictors', 'effectively', ';'), ('effectively', ';', '•'), (';', '•', 'shift'), ('•', 'shift', 'theory-driven'), ('shift', 'theory-driven', 'process-driven'), ('theory-driven', 'process-driven', 'prediction'), ('process-driven', 'prediction', 'based'), ('prediction', 'based', 'analysing'), ('based', 'analysing', 'BDA'), ('analysing', 'BDA', 'steps'), ('BDA', 'steps', 'identifying'), ('steps', 'identifying', 'challenges'), ('identifying', 'challenges', ','), ('challenges', ',', 'theoretically'), (',', 'theoretically', 'informing'), ('theoretically', 'informing', 'future'), ('informing', 'future', 'BDA'), ('future', 'BDA', 'needs'), ('BDA', 'needs', 'throughout'), ('needs', 'throughout', 'data'), ('throughout', 'data', 'acquisition'), ('data', 'acquisition', ','), ('acquisition', ',', 'pre-processing'), (',', 'pre-processing', 'analysis'), ('pre-processing', 'analysis', ','), ('analysis', ',', 'interpretation'), (',', 'interpretation', '.')]

>> POS Tags are: 
 [('Predicted', 'VBN'), ('target', 'NN'), ('theory', 'NN'), ('generates', 'VBZ'), ('set', 'VBN'), ('predictors', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('theories', 'NNS'), ('explain', 'VBP'), ('relationships', 'NNS'), ('independent', 'JJ'), ('dependent', 'JJ'), ('predictors', 'NNS'), ('effectively', 'RB'), (';', ':'), ('•', 'JJ'), ('shift', 'VB'), ('theory-driven', 'JJ'), ('process-driven', 'JJ'), ('prediction', 'NN'), ('based', 'VBN'), ('analysing', 'VBG'), ('BDA', 'NNP'), ('steps', 'NNS'), ('identifying', 'VBG'), ('challenges', 'NNS'), (',', ','), ('theoretically', 'RB'), ('informing', 'VBG'), ('future', 'JJ'), ('BDA', 'NNP'), ('needs', 'VBZ'), ('throughout', 'IN'), ('data', 'NNS'), ('acquisition', 'NN'), (',', ','), ('pre-processing', 'JJ'), ('analysis', 'NN'), (',', ','), ('interpretation', 'NN'), ('.', '.')]

 (S
  Predicted/VBN
  (NP target/NN theory/NN)
  generates/VBZ
  set/VBN
  (NP predictors/NNS)
  ;/:
  however/RB
  ,/,
  (NP theories/NNS)
  explain/VBP
  (NP relationships/NNS)
  (NP independent/JJ dependent/JJ predictors/NNS)
  effectively/RB
  ;/:
  •/JJ
  shift/VB
  (NP theory-driven/JJ process-driven/JJ prediction/NN)
  based/VBN
  analysing/VBG
  (NP BDA/NNP steps/NNS)
  identifying/VBG
  (NP challenges/NNS)
  ,/,
  theoretically/RB
  informing/VBG
  (NP future/JJ BDA/NNP)
  needs/VBZ
  throughout/IN
  (NP data/NNS acquisition/NN)
  ,/,
  (NP pre-processing/JJ analysis/NN)
  ,/,
  (NP interpretation/NN)
  ./.) 


>> Noun Phrases are: 
 ['target theory', 'predictors', 'theories', 'relationships', 'independent dependent predictors', 'theory-driven process-driven prediction', 'BDA steps', 'challenges', 'future BDA', 'data acquisition', 'pre-processing analysis', 'interpretation']

>> Named Entities are: 
 [('ORGANIZATION', 'BDA'), ('ORGANIZATION', 'BDA')] 

>> Stemming using Porter Stemmer: 
 [('Predicted', 'predict'), ('target', 'target'), ('theory', 'theori'), ('generates', 'gener'), ('set', 'set'), ('predictors', 'predictor'), (';', ';'), ('however', 'howev'), (',', ','), ('theories', 'theori'), ('explain', 'explain'), ('relationships', 'relationship'), ('independent', 'independ'), ('dependent', 'depend'), ('predictors', 'predictor'), ('effectively', 'effect'), (';', ';'), ('•', '•'), ('shift', 'shift'), ('theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('based', 'base'), ('analysing', 'analys'), ('BDA', 'bda'), ('steps', 'step'), ('identifying', 'identifi'), ('challenges', 'challeng'), (',', ','), ('theoretically', 'theoret'), ('informing', 'inform'), ('future', 'futur'), ('BDA', 'bda'), ('needs', 'need'), ('throughout', 'throughout'), ('data', 'data'), ('acquisition', 'acquisit'), (',', ','), ('pre-processing', 'pre-process'), ('analysis', 'analysi'), (',', ','), ('interpretation', 'interpret'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Predicted', 'predict'), ('target', 'target'), ('theory', 'theori'), ('generates', 'generat'), ('set', 'set'), ('predictors', 'predictor'), (';', ';'), ('however', 'howev'), (',', ','), ('theories', 'theori'), ('explain', 'explain'), ('relationships', 'relationship'), ('independent', 'independ'), ('dependent', 'depend'), ('predictors', 'predictor'), ('effectively', 'effect'), (';', ';'), ('•', '•'), ('shift', 'shift'), ('theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('based', 'base'), ('analysing', 'analys'), ('BDA', 'bda'), ('steps', 'step'), ('identifying', 'identifi'), ('challenges', 'challeng'), (',', ','), ('theoretically', 'theoret'), ('informing', 'inform'), ('future', 'futur'), ('BDA', 'bda'), ('needs', 'need'), ('throughout', 'throughout'), ('data', 'data'), ('acquisition', 'acquisit'), (',', ','), ('pre-processing', 'pre-process'), ('analysis', 'analysi'), (',', ','), ('interpretation', 'interpret'), ('.', '.')]

>> Lemmatization: 
 [('Predicted', 'Predicted'), ('target', 'target'), ('theory', 'theory'), ('generates', 'generates'), ('set', 'set'), ('predictors', 'predictor'), (';', ';'), ('however', 'however'), (',', ','), ('theories', 'theory'), ('explain', 'explain'), ('relationships', 'relationship'), ('independent', 'independent'), ('dependent', 'dependent'), ('predictors', 'predictor'), ('effectively', 'effectively'), (';', ';'), ('•', '•'), ('shift', 'shift'), ('theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'prediction'), ('based', 'based'), ('analysing', 'analysing'), ('BDA', 'BDA'), ('steps', 'step'), ('identifying', 'identifying'), ('challenges', 'challenge'), (',', ','), ('theoretically', 'theoretically'), ('informing', 'informing'), ('future', 'future'), ('BDA', 'BDA'), ('needs', 'need'), ('throughout', 'throughout'), ('data', 'data'), ('acquisition', 'acquisition'), (',', ','), ('pre-processing', 'pre-processing'), ('analysis', 'analysis'), (',', ','), ('interpretation', 'interpretation'), ('.', '.')]



============================ Sentence 290 =============================

Sarah Al-Shiakhli   24      7.1.2. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '24', '7.1.2', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '24'), ('24', '7.1.2'), ('7.1.2', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '24'), ('Al-Shiakhli', '24', '7.1.2'), ('24', '7.1.2', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('24', 'CD'), ('7.1.2', 'CD'), ('.', '.')]

 (S (NP Sarah/NNP Al-Shiakhli/NNP) 24/CD 7.1.2/CD ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('24', '24'), ('7.1.2', '7.1.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('24', '24'), ('7.1.2', '7.1.2'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('24', '24'), ('7.1.2', '7.1.2'), ('.', '.')]



============================ Sentence 291 =============================

Un-supervised techniques     Here, the training data is unlabelled. 


>> Tokens are: 
 ['Un-supervised', 'techniques', 'Here', ',', 'training', 'data', 'unlabelled', '.']

>> Bigrams are: 
 [('Un-supervised', 'techniques'), ('techniques', 'Here'), ('Here', ','), (',', 'training'), ('training', 'data'), ('data', 'unlabelled'), ('unlabelled', '.')]

>> Trigrams are: 
 [('Un-supervised', 'techniques', 'Here'), ('techniques', 'Here', ','), ('Here', ',', 'training'), (',', 'training', 'data'), ('training', 'data', 'unlabelled'), ('data', 'unlabelled', '.')]

>> POS Tags are: 
 [('Un-supervised', 'JJ'), ('techniques', 'NNS'), ('Here', 'RB'), (',', ','), ('training', 'VBG'), ('data', 'NNS'), ('unlabelled', 'VBD'), ('.', '.')]

 (S
  (NP Un-supervised/JJ techniques/NNS)
  Here/RB
  ,/,
  training/VBG
  (NP data/NNS)
  unlabelled/VBD
  ./.) 


>> Noun Phrases are: 
 ['Un-supervised techniques', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu'), ('Here', 'here'), (',', ','), ('training', 'train'), ('data', 'data'), ('unlabelled', 'unlabel'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Un-supervised', 'un-supervis'), ('techniques', 'techniqu'), ('Here', 'here'), (',', ','), ('training', 'train'), ('data', 'data'), ('unlabelled', 'unlabel'), ('.', '.')]

>> Lemmatization: 
 [('Un-supervised', 'Un-supervised'), ('techniques', 'technique'), ('Here', 'Here'), (',', ','), ('training', 'training'), ('data', 'data'), ('unlabelled', 'unlabelled'), ('.', '.')]



============================ Sentence 292 =============================

Unlabelled means that the history of the data is missing, there   is no history available for data variables, and the data have not been trained and tested. 


>> Tokens are: 
 ['Unlabelled', 'means', 'history', 'data', 'missing', ',', 'history', 'available', 'data', 'variables', ',', 'data', 'trained', 'tested', '.']

>> Bigrams are: 
 [('Unlabelled', 'means'), ('means', 'history'), ('history', 'data'), ('data', 'missing'), ('missing', ','), (',', 'history'), ('history', 'available'), ('available', 'data'), ('data', 'variables'), ('variables', ','), (',', 'data'), ('data', 'trained'), ('trained', 'tested'), ('tested', '.')]

>> Trigrams are: 
 [('Unlabelled', 'means', 'history'), ('means', 'history', 'data'), ('history', 'data', 'missing'), ('data', 'missing', ','), ('missing', ',', 'history'), (',', 'history', 'available'), ('history', 'available', 'data'), ('available', 'data', 'variables'), ('data', 'variables', ','), ('variables', ',', 'data'), (',', 'data', 'trained'), ('data', 'trained', 'tested'), ('trained', 'tested', '.')]

>> POS Tags are: 
 [('Unlabelled', 'VBN'), ('means', 'NNS'), ('history', 'NN'), ('data', 'NNS'), ('missing', 'VBG'), (',', ','), ('history', 'NN'), ('available', 'JJ'), ('data', 'NNS'), ('variables', 'NNS'), (',', ','), ('data', 'NNS'), ('trained', 'VBD'), ('tested', 'VBN'), ('.', '.')]

 (S
  Unlabelled/VBN
  (NP means/NNS history/NN data/NNS)
  missing/VBG
  ,/,
  (NP history/NN)
  (NP available/JJ data/NNS variables/NNS)
  ,/,
  (NP data/NNS)
  trained/VBD
  tested/VBN
  ./.) 


>> Noun Phrases are: 
 ['means history data', 'history', 'available data variables', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unlabelled', 'unlabel'), ('means', 'mean'), ('history', 'histori'), ('data', 'data'), ('missing', 'miss'), (',', ','), ('history', 'histori'), ('available', 'avail'), ('data', 'data'), ('variables', 'variabl'), (',', ','), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unlabelled', 'unlabel'), ('means', 'mean'), ('history', 'histori'), ('data', 'data'), ('missing', 'miss'), (',', ','), ('history', 'histori'), ('available', 'avail'), ('data', 'data'), ('variables', 'variabl'), (',', ','), ('data', 'data'), ('trained', 'train'), ('tested', 'test'), ('.', '.')]

>> Lemmatization: 
 [('Unlabelled', 'Unlabelled'), ('means', 'mean'), ('history', 'history'), ('data', 'data'), ('missing', 'missing'), (',', ','), ('history', 'history'), ('available', 'available'), ('data', 'data'), ('variables', 'variable'), (',', ','), ('data', 'data'), ('trained', 'trained'), ('tested', 'tested'), ('.', '.')]



============================ Sentence 293 =============================

Thus,   unsupervised techniques require separate training data (Boyd-Graber et al., 2014; Müller et al.,   2016; Breed and Verster, 2019). 


>> Tokens are: 
 ['Thus', ',', 'unsupervised', 'techniques', 'require', 'separate', 'training', 'data', '(', 'Boyd-Graber', 'et', 'al.', ',', '2014', ';', 'Müller', 'et', 'al.', ',', '2016', ';', 'Breed', 'Verster', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'unsupervised'), ('unsupervised', 'techniques'), ('techniques', 'require'), ('require', 'separate'), ('separate', 'training'), ('training', 'data'), ('data', '('), ('(', 'Boyd-Graber'), ('Boyd-Graber', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Müller'), ('Müller', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Thus', ',', 'unsupervised'), (',', 'unsupervised', 'techniques'), ('unsupervised', 'techniques', 'require'), ('techniques', 'require', 'separate'), ('require', 'separate', 'training'), ('separate', 'training', 'data'), ('training', 'data', '('), ('data', '(', 'Boyd-Graber'), ('(', 'Boyd-Graber', 'et'), ('Boyd-Graber', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Müller'), (';', 'Müller', 'et'), ('Müller', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('unsupervised', 'JJ'), ('techniques', 'NNS'), ('require', 'VBP'), ('separate', 'JJ'), ('training', 'NN'), ('data', 'NNS'), ('(', '('), ('Boyd-Graber', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Müller', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  Thus/RB
  ,/,
  (NP unsupervised/JJ techniques/NNS)
  require/VBP
  (NP separate/JJ training/NN data/NNS)
  (/(
  (NP Boyd-Graber/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2014/CD
  ;/:
  (NP Müller/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  ;/:
  (NP Breed/NNP Verster/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['unsupervised techniques', 'separate training data', 'Boyd-Graber', 'al.', 'Müller', 'al.', 'Breed Verster']

>> Named Entities are: 
 [('PERSON', 'Müller'), ('PERSON', 'Breed Verster')] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('require', 'requir'), ('separate', 'separ'), ('training', 'train'), ('data', 'data'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('require', 'requir'), ('separate', 'separ'), ('training', 'train'), ('data', 'data'), ('(', '('), ('Boyd-Graber', 'boyd-grab'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('unsupervised', 'unsupervised'), ('techniques', 'technique'), ('require', 'require'), ('separate', 'separate'), ('training', 'training'), ('data', 'data'), ('(', '('), ('Boyd-Graber', 'Boyd-Graber'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Müller', 'Müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 294 =============================

Unsupervised learning requires deducing functions for presenting unknown structures from   unlabelled data. 


>> Tokens are: 
 ['Unsupervised', 'learning', 'requires', 'deducing', 'functions', 'presenting', 'unknown', 'structures', 'unlabelled', 'data', '.']

>> Bigrams are: 
 [('Unsupervised', 'learning'), ('learning', 'requires'), ('requires', 'deducing'), ('deducing', 'functions'), ('functions', 'presenting'), ('presenting', 'unknown'), ('unknown', 'structures'), ('structures', 'unlabelled'), ('unlabelled', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Unsupervised', 'learning', 'requires'), ('learning', 'requires', 'deducing'), ('requires', 'deducing', 'functions'), ('deducing', 'functions', 'presenting'), ('functions', 'presenting', 'unknown'), ('presenting', 'unknown', 'structures'), ('unknown', 'structures', 'unlabelled'), ('structures', 'unlabelled', 'data'), ('unlabelled', 'data', '.')]

>> POS Tags are: 
 [('Unsupervised', 'VBN'), ('learning', 'NN'), ('requires', 'VBZ'), ('deducing', 'VBG'), ('functions', 'NNS'), ('presenting', 'VBG'), ('unknown', 'JJ'), ('structures', 'NNS'), ('unlabelled', 'VBN'), ('data', 'NNS'), ('.', '.')]

 (S
  Unsupervised/VBN
  (NP learning/NN)
  requires/VBZ
  deducing/VBG
  (NP functions/NNS)
  presenting/VBG
  (NP unknown/JJ structures/NNS)
  unlabelled/VBN
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['learning', 'functions', 'unknown structures', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('requires', 'requir'), ('deducing', 'deduc'), ('functions', 'function'), ('presenting', 'present'), ('unknown', 'unknown'), ('structures', 'structur'), ('unlabelled', 'unlabel'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Unsupervised', 'unsupervis'), ('learning', 'learn'), ('requires', 'requir'), ('deducing', 'deduc'), ('functions', 'function'), ('presenting', 'present'), ('unknown', 'unknown'), ('structures', 'structur'), ('unlabelled', 'unlabel'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Unsupervised', 'Unsupervised'), ('learning', 'learning'), ('requires', 'requires'), ('deducing', 'deducing'), ('functions', 'function'), ('presenting', 'presenting'), ('unknown', 'unknown'), ('structures', 'structure'), ('unlabelled', 'unlabelled'), ('data', 'data'), ('.', '.')]



============================ Sentence 295 =============================

This technique does not require a supervisor, which means that the system must   have the ability to proceed independently with training based on unlabelled data input (Cui et al.,   2019). 


>> Tokens are: 
 ['This', 'technique', 'require', 'supervisor', ',', 'means', 'system', 'must', 'ability', 'proceed', 'independently', 'training', 'based', 'unlabelled', 'data', 'input', '(', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('This', 'technique'), ('technique', 'require'), ('require', 'supervisor'), ('supervisor', ','), (',', 'means'), ('means', 'system'), ('system', 'must'), ('must', 'ability'), ('ability', 'proceed'), ('proceed', 'independently'), ('independently', 'training'), ('training', 'based'), ('based', 'unlabelled'), ('unlabelled', 'data'), ('data', 'input'), ('input', '('), ('(', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'technique', 'require'), ('technique', 'require', 'supervisor'), ('require', 'supervisor', ','), ('supervisor', ',', 'means'), (',', 'means', 'system'), ('means', 'system', 'must'), ('system', 'must', 'ability'), ('must', 'ability', 'proceed'), ('ability', 'proceed', 'independently'), ('proceed', 'independently', 'training'), ('independently', 'training', 'based'), ('training', 'based', 'unlabelled'), ('based', 'unlabelled', 'data'), ('unlabelled', 'data', 'input'), ('data', 'input', '('), ('input', '(', 'Cui'), ('(', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('technique', 'NN'), ('require', 'NN'), ('supervisor', 'NN'), (',', ','), ('means', 'VBZ'), ('system', 'NN'), ('must', 'MD'), ('ability', 'NN'), ('proceed', 'VB'), ('independently', 'RB'), ('training', 'VBG'), ('based', 'VBN'), ('unlabelled', 'JJ'), ('data', 'NNS'), ('input', 'NN'), ('(', '('), ('Cui', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT technique/NN require/NN supervisor/NN)
  ,/,
  means/VBZ
  (NP system/NN)
  must/MD
  (NP ability/NN)
  proceed/VB
  independently/RB
  training/VBG
  based/VBN
  (NP unlabelled/JJ data/NNS input/NN)
  (/(
  (NP Cui/NNP)
  et/RB
  al./RB
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This technique require supervisor', 'system', 'ability', 'unlabelled data input', 'Cui']

>> Named Entities are: 
 [('ORGANIZATION', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('technique', 'techniqu'), ('require', 'requir'), ('supervisor', 'supervisor'), (',', ','), ('means', 'mean'), ('system', 'system'), ('must', 'must'), ('ability', 'abil'), ('proceed', 'proceed'), ('independently', 'independ'), ('training', 'train'), ('based', 'base'), ('unlabelled', 'unlabel'), ('data', 'data'), ('input', 'input'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('technique', 'techniqu'), ('require', 'requir'), ('supervisor', 'supervisor'), (',', ','), ('means', 'mean'), ('system', 'system'), ('must', 'must'), ('ability', 'abil'), ('proceed', 'proceed'), ('independently', 'independ'), ('training', 'train'), ('based', 'base'), ('unlabelled', 'unlabel'), ('data', 'data'), ('input', 'input'), ('(', '('), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('technique', 'technique'), ('require', 'require'), ('supervisor', 'supervisor'), (',', ','), ('means', 'mean'), ('system', 'system'), ('must', 'must'), ('ability', 'ability'), ('proceed', 'proceed'), ('independently', 'independently'), ('training', 'training'), ('based', 'based'), ('unlabelled', 'unlabelled'), ('data', 'data'), ('input', 'input'), ('(', '('), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 296 =============================

Examples of unsupervised learning algorithms include clustering algorithms, combinatorial   algorithms, A priori algorithms, Self-Organizing Maps (SOM), and applications of game theory. 


>> Tokens are: 
 ['Examples', 'unsupervised', 'learning', 'algorithms', 'include', 'clustering', 'algorithms', ',', 'combinatorial', 'algorithms', ',', 'A', 'priori', 'algorithms', ',', 'Self-Organizing', 'Maps', '(', 'SOM', ')', ',', 'applications', 'game', 'theory', '.']

>> Bigrams are: 
 [('Examples', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'algorithms'), ('algorithms', 'include'), ('include', 'clustering'), ('clustering', 'algorithms'), ('algorithms', ','), (',', 'combinatorial'), ('combinatorial', 'algorithms'), ('algorithms', ','), (',', 'A'), ('A', 'priori'), ('priori', 'algorithms'), ('algorithms', ','), (',', 'Self-Organizing'), ('Self-Organizing', 'Maps'), ('Maps', '('), ('(', 'SOM'), ('SOM', ')'), (')', ','), (',', 'applications'), ('applications', 'game'), ('game', 'theory'), ('theory', '.')]

>> Trigrams are: 
 [('Examples', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'algorithms'), ('learning', 'algorithms', 'include'), ('algorithms', 'include', 'clustering'), ('include', 'clustering', 'algorithms'), ('clustering', 'algorithms', ','), ('algorithms', ',', 'combinatorial'), (',', 'combinatorial', 'algorithms'), ('combinatorial', 'algorithms', ','), ('algorithms', ',', 'A'), (',', 'A', 'priori'), ('A', 'priori', 'algorithms'), ('priori', 'algorithms', ','), ('algorithms', ',', 'Self-Organizing'), (',', 'Self-Organizing', 'Maps'), ('Self-Organizing', 'Maps', '('), ('Maps', '(', 'SOM'), ('(', 'SOM', ')'), ('SOM', ')', ','), (')', ',', 'applications'), (',', 'applications', 'game'), ('applications', 'game', 'theory'), ('game', 'theory', '.')]

>> POS Tags are: 
 [('Examples', 'NNS'), ('unsupervised', 'VBD'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('include', 'VBP'), ('clustering', 'VBG'), ('algorithms', 'NN'), (',', ','), ('combinatorial', 'JJ'), ('algorithms', 'NN'), (',', ','), ('A', 'NNP'), ('priori', 'FW'), ('algorithms', 'NN'), (',', ','), ('Self-Organizing', 'JJ'), ('Maps', 'NNP'), ('(', '('), ('SOM', 'NNP'), (')', ')'), (',', ','), ('applications', 'NNS'), ('game', 'NN'), ('theory', 'NN'), ('.', '.')]

 (S
  (NP Examples/NNS)
  unsupervised/VBD
  learning/VBG
  algorithms/JJ
  include/VBP
  clustering/VBG
  (NP algorithms/NN)
  ,/,
  (NP combinatorial/JJ algorithms/NN)
  ,/,
  (NP A/NNP)
  priori/FW
  (NP algorithms/NN)
  ,/,
  (NP Self-Organizing/JJ Maps/NNP)
  (/(
  (NP SOM/NNP)
  )/)
  ,/,
  (NP applications/NNS game/NN theory/NN)
  ./.) 


>> Noun Phrases are: 
 ['Examples', 'algorithms', 'combinatorial algorithms', 'A', 'algorithms', 'Self-Organizing Maps', 'SOM', 'applications game theory']

>> Named Entities are: 
 [('PERSON', 'Examples'), ('ORGANIZATION', 'SOM')] 

>> Stemming using Porter Stemmer: 
 [('Examples', 'exampl'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('include', 'includ'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), (',', ','), ('combinatorial', 'combinatori'), ('algorithms', 'algorithm'), (',', ','), ('A', 'a'), ('priori', 'priori'), ('algorithms', 'algorithm'), (',', ','), ('Self-Organizing', 'self-organ'), ('Maps', 'map'), ('(', '('), ('SOM', 'som'), (')', ')'), (',', ','), ('applications', 'applic'), ('game', 'game'), ('theory', 'theori'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Examples', 'exampl'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('include', 'includ'), ('clustering', 'cluster'), ('algorithms', 'algorithm'), (',', ','), ('combinatorial', 'combinatori'), ('algorithms', 'algorithm'), (',', ','), ('A', 'a'), ('priori', 'priori'), ('algorithms', 'algorithm'), (',', ','), ('Self-Organizing', 'self-organ'), ('Maps', 'map'), ('(', '('), ('SOM', 'som'), (')', ')'), (',', ','), ('applications', 'applic'), ('game', 'game'), ('theory', 'theori'), ('.', '.')]

>> Lemmatization: 
 [('Examples', 'Examples'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('include', 'include'), ('clustering', 'clustering'), ('algorithms', 'algorithm'), (',', ','), ('combinatorial', 'combinatorial'), ('algorithms', 'algorithm'), (',', ','), ('A', 'A'), ('priori', 'priori'), ('algorithms', 'algorithm'), (',', ','), ('Self-Organizing', 'Self-Organizing'), ('Maps', 'Maps'), ('(', '('), ('SOM', 'SOM'), (')', ')'), (',', ','), ('applications', 'application'), ('game', 'game'), ('theory', 'theory'), ('.', '.')]



============================ Sentence 297 =============================

These techniques are used for classifying the input data into different clusters or classes based on   the data distribution (Jiang et al., 2017; Cui et al., 2019). 


>> Tokens are: 
 ['These', 'techniques', 'used', 'classifying', 'input', 'data', 'different', 'clusters', 'classes', 'based', 'data', 'distribution', '(', 'Jiang', 'et', 'al.', ',', '2017', ';', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('These', 'techniques'), ('techniques', 'used'), ('used', 'classifying'), ('classifying', 'input'), ('input', 'data'), ('data', 'different'), ('different', 'clusters'), ('clusters', 'classes'), ('classes', 'based'), ('based', 'data'), ('data', 'distribution'), ('distribution', '('), ('(', 'Jiang'), ('Jiang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('These', 'techniques', 'used'), ('techniques', 'used', 'classifying'), ('used', 'classifying', 'input'), ('classifying', 'input', 'data'), ('input', 'data', 'different'), ('data', 'different', 'clusters'), ('different', 'clusters', 'classes'), ('clusters', 'classes', 'based'), ('classes', 'based', 'data'), ('based', 'data', 'distribution'), ('data', 'distribution', '('), ('distribution', '(', 'Jiang'), ('(', 'Jiang', 'et'), ('Jiang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('techniques', 'NNS'), ('used', 'VBD'), ('classifying', 'VBG'), ('input', 'NN'), ('data', 'NNS'), ('different', 'JJ'), ('clusters', 'NNS'), ('classes', 'NNS'), ('based', 'VBN'), ('data', 'NNS'), ('distribution', 'NN'), ('(', '('), ('Jiang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP These/DT techniques/NNS)
  used/VBD
  classifying/VBG
  (NP input/NN data/NNS)
  (NP different/JJ clusters/NNS classes/NNS)
  based/VBN
  (NP data/NNS distribution/NN)
  (/(
  (NP Jiang/NNP)
  et/RB
  al./RB
  ,/,
  2017/CD
  ;/:
  (NP Cui/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['These techniques', 'input data', 'different clusters classes', 'data distribution', 'Jiang', 'Cui', 'al.']

>> Named Entities are: 
 [('PERSON', 'Jiang')] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('techniques', 'techniqu'), ('used', 'use'), ('classifying', 'classifi'), ('input', 'input'), ('data', 'data'), ('different', 'differ'), ('clusters', 'cluster'), ('classes', 'class'), ('based', 'base'), ('data', 'data'), ('distribution', 'distribut'), ('(', '('), ('Jiang', 'jiang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('techniques', 'techniqu'), ('used', 'use'), ('classifying', 'classifi'), ('input', 'input'), ('data', 'data'), ('different', 'differ'), ('clusters', 'cluster'), ('classes', 'class'), ('based', 'base'), ('data', 'data'), ('distribution', 'distribut'), ('(', '('), ('Jiang', 'jiang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('techniques', 'technique'), ('used', 'used'), ('classifying', 'classifying'), ('input', 'input'), ('data', 'data'), ('different', 'different'), ('clusters', 'cluster'), ('classes', 'class'), ('based', 'based'), ('data', 'data'), ('distribution', 'distribution'), ('(', '('), ('Jiang', 'Jiang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 298 =============================

Cluster Analysis: This method is based on grouping objects and classifying them depending on   shared features. 


>> Tokens are: 
 ['Cluster', 'Analysis', ':', 'This', 'method', 'based', 'grouping', 'objects', 'classifying', 'depending', 'shared', 'features', '.']

>> Bigrams are: 
 [('Cluster', 'Analysis'), ('Analysis', ':'), (':', 'This'), ('This', 'method'), ('method', 'based'), ('based', 'grouping'), ('grouping', 'objects'), ('objects', 'classifying'), ('classifying', 'depending'), ('depending', 'shared'), ('shared', 'features'), ('features', '.')]

>> Trigrams are: 
 [('Cluster', 'Analysis', ':'), ('Analysis', ':', 'This'), (':', 'This', 'method'), ('This', 'method', 'based'), ('method', 'based', 'grouping'), ('based', 'grouping', 'objects'), ('grouping', 'objects', 'classifying'), ('objects', 'classifying', 'depending'), ('classifying', 'depending', 'shared'), ('depending', 'shared', 'features'), ('shared', 'features', '.')]

>> POS Tags are: 
 [('Cluster', 'NN'), ('Analysis', 'NN'), (':', ':'), ('This', 'DT'), ('method', 'NN'), ('based', 'VBN'), ('grouping', 'VBG'), ('objects', 'NNS'), ('classifying', 'VBG'), ('depending', 'VBG'), ('shared', 'VBN'), ('features', 'NNS'), ('.', '.')]

 (S
  (NP Cluster/NN Analysis/NN)
  :/:
  (NP This/DT method/NN)
  based/VBN
  grouping/VBG
  (NP objects/NNS)
  classifying/VBG
  depending/VBG
  shared/VBN
  (NP features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Cluster Analysis', 'This method', 'objects', 'features']

>> Named Entities are: 
 [('GPE', 'Cluster'), ('PERSON', 'Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Cluster', 'cluster'), ('Analysis', 'analysi'), (':', ':'), ('This', 'thi'), ('method', 'method'), ('based', 'base'), ('grouping', 'group'), ('objects', 'object'), ('classifying', 'classifi'), ('depending', 'depend'), ('shared', 'share'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cluster', 'cluster'), ('Analysis', 'analysi'), (':', ':'), ('This', 'this'), ('method', 'method'), ('based', 'base'), ('grouping', 'group'), ('objects', 'object'), ('classifying', 'classifi'), ('depending', 'depend'), ('shared', 'share'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('Cluster', 'Cluster'), ('Analysis', 'Analysis'), (':', ':'), ('This', 'This'), ('method', 'method'), ('based', 'based'), ('grouping', 'grouping'), ('objects', 'object'), ('classifying', 'classifying'), ('depending', 'depending'), ('shared', 'shared'), ('features', 'feature'), ('.', '.')]



============================ Sentence 299 =============================

It is used for differentiation between objects to allow division into clusters. 


>> Tokens are: 
 ['It', 'used', 'differentiation', 'objects', 'allow', 'division', 'clusters', '.']

>> Bigrams are: 
 [('It', 'used'), ('used', 'differentiation'), ('differentiation', 'objects'), ('objects', 'allow'), ('allow', 'division'), ('division', 'clusters'), ('clusters', '.')]

>> Trigrams are: 
 [('It', 'used', 'differentiation'), ('used', 'differentiation', 'objects'), ('differentiation', 'objects', 'allow'), ('objects', 'allow', 'division'), ('allow', 'division', 'clusters'), ('division', 'clusters', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('used', 'VBD'), ('differentiation', 'NN'), ('objects', 'NNS'), ('allow', 'VBP'), ('division', 'NN'), ('clusters', 'NNS'), ('.', '.')]

 (S
  It/PRP
  used/VBD
  (NP differentiation/NN objects/NNS)
  allow/VBP
  (NP division/NN clusters/NNS)
  ./.) 


>> Noun Phrases are: 
 ['differentiation objects', 'division clusters']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('used', 'use'), ('differentiation', 'differenti'), ('objects', 'object'), ('allow', 'allow'), ('division', 'divis'), ('clusters', 'cluster'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('used', 'use'), ('differentiation', 'differenti'), ('objects', 'object'), ('allow', 'allow'), ('division', 'divis'), ('clusters', 'cluster'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('used', 'used'), ('differentiation', 'differentiation'), ('objects', 'object'), ('allow', 'allow'), ('division', 'division'), ('clusters', 'cluster'), ('.', '.')]



============================ Sentence 300 =============================

Thus,   data which are related to each other or have the same features will be placed in a cluster or a group   and unrelated data will be in other groups (Wu et al., 2018; Cui et al., 2019), as shown in Figure   14. 


>> Tokens are: 
 ['Thus', ',', 'data', 'related', 'features', 'placed', 'cluster', 'group', 'unrelated', 'data', 'groups', '(', 'Wu', 'et', 'al.', ',', '2018', ';', 'Cui', 'et', 'al.', ',', '2019', ')', ',', 'shown', 'Figure', '14', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'data'), ('data', 'related'), ('related', 'features'), ('features', 'placed'), ('placed', 'cluster'), ('cluster', 'group'), ('group', 'unrelated'), ('unrelated', 'data'), ('data', 'groups'), ('groups', '('), ('(', 'Wu'), ('Wu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '14'), ('14', '.')]

>> Trigrams are: 
 [('Thus', ',', 'data'), (',', 'data', 'related'), ('data', 'related', 'features'), ('related', 'features', 'placed'), ('features', 'placed', 'cluster'), ('placed', 'cluster', 'group'), ('cluster', 'group', 'unrelated'), ('group', 'unrelated', 'data'), ('unrelated', 'data', 'groups'), ('data', 'groups', '('), ('groups', '(', 'Wu'), ('(', 'Wu', 'et'), ('Wu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ';'), ('2018', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '14'), ('Figure', '14', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('data', 'NNS'), ('related', 'VBD'), ('features', 'NNS'), ('placed', 'VBN'), ('cluster', 'NN'), ('group', 'NN'), ('unrelated', 'JJ'), ('data', 'NN'), ('groups', 'NNS'), ('(', '('), ('Wu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('14', 'CD'), ('.', '.')]

 (S
  Thus/RB
  ,/,
  (NP data/NNS)
  related/VBD
  (NP features/NNS)
  placed/VBN
  (NP cluster/NN group/NN)
  (NP unrelated/JJ data/NN groups/NNS)
  (/(
  (NP Wu/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  ;/:
  (NP Cui/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ,/,
  shown/VBN
  (NP Figure/NN)
  14/CD
  ./.) 


>> Noun Phrases are: 
 ['data', 'features', 'cluster group', 'unrelated data groups', 'Wu', 'Cui', 'al.', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('data', 'data'), ('related', 'relat'), ('features', 'featur'), ('placed', 'place'), ('cluster', 'cluster'), ('group', 'group'), ('unrelated', 'unrel'), ('data', 'data'), ('groups', 'group'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('14', '14'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('data', 'data'), ('related', 'relat'), ('features', 'featur'), ('placed', 'place'), ('cluster', 'cluster'), ('group', 'group'), ('unrelated', 'unrel'), ('data', 'data'), ('groups', 'group'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('14', '14'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('data', 'data'), ('related', 'related'), ('features', 'feature'), ('placed', 'placed'), ('cluster', 'cluster'), ('group', 'group'), ('unrelated', 'unrelated'), ('data', 'data'), ('groups', 'group'), ('(', '('), ('Wu', 'Wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('14', '14'), ('.', '.')]



============================ Sentence 301 =============================

Figure 14: Cluster analysis. 


>> Tokens are: 
 ['Figure', '14', ':', 'Cluster', 'analysis', '.']

>> Bigrams are: 
 [('Figure', '14'), ('14', ':'), (':', 'Cluster'), ('Cluster', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Figure', '14', ':'), ('14', ':', 'Cluster'), (':', 'Cluster', 'analysis'), ('Cluster', 'analysis', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('14', 'CD'), (':', ':'), ('Cluster', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S (NP Figure/NN) 14/CD :/: (NP Cluster/NN analysis/NN) ./.) 


>> Noun Phrases are: 
 ['Figure', 'Cluster analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('14', '14'), (':', ':'), ('Cluster', 'cluster'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('14', '14'), (':', ':'), ('Cluster', 'cluster'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('14', '14'), (':', ':'), ('Cluster', 'Cluster'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 302 =============================

7.1.3. 


>> Tokens are: 
 ['7.1.3', '.']

>> Bigrams are: 
 [('7.1.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.3', 'CD'), ('.', '.')]

 (S 7.1.3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.3', '7.1.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.3', '7.1.3'), ('.', '.')]

>> Lemmatization: 
 [('7.1.3', '7.1.3'), ('.', '.')]



============================ Sentence 303 =============================

Semi-supervised techniques     Where some of the data is labelled and some is unlabelled, supervised and unsupervised techniques   can also be mixed. 


>> Tokens are: 
 ['Semi-supervised', 'techniques', 'Where', 'data', 'labelled', 'unlabelled', ',', 'supervised', 'unsupervised', 'techniques', 'also', 'mixed', '.']

>> Bigrams are: 
 [('Semi-supervised', 'techniques'), ('techniques', 'Where'), ('Where', 'data'), ('data', 'labelled'), ('labelled', 'unlabelled'), ('unlabelled', ','), (',', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'techniques'), ('techniques', 'also'), ('also', 'mixed'), ('mixed', '.')]

>> Trigrams are: 
 [('Semi-supervised', 'techniques', 'Where'), ('techniques', 'Where', 'data'), ('Where', 'data', 'labelled'), ('data', 'labelled', 'unlabelled'), ('labelled', 'unlabelled', ','), ('unlabelled', ',', 'supervised'), (',', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'techniques'), ('unsupervised', 'techniques', 'also'), ('techniques', 'also', 'mixed'), ('also', 'mixed', '.')]

>> POS Tags are: 
 [('Semi-supervised', 'JJ'), ('techniques', 'NNS'), ('Where', 'NNP'), ('data', 'NNS'), ('labelled', 'VBD'), ('unlabelled', 'JJ'), (',', ','), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('techniques', 'NNS'), ('also', 'RB'), ('mixed', 'VBP'), ('.', '.')]

 (S
  (NP Semi-supervised/JJ techniques/NNS Where/NNP data/NNS)
  labelled/VBD
  unlabelled/JJ
  ,/,
  supervised/VBD
  (NP unsupervised/JJ techniques/NNS)
  also/RB
  mixed/VBP
  ./.) 


>> Noun Phrases are: 
 ['Semi-supervised techniques Where data', 'unsupervised techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu'), ('Where', 'where'), ('data', 'data'), ('labelled', 'label'), ('unlabelled', 'unlabel'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('also', 'also'), ('mixed', 'mix'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Semi-supervised', 'semi-supervis'), ('techniques', 'techniqu'), ('Where', 'where'), ('data', 'data'), ('labelled', 'label'), ('unlabelled', 'unlabel'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('also', 'also'), ('mixed', 'mix'), ('.', '.')]

>> Lemmatization: 
 [('Semi-supervised', 'Semi-supervised'), ('techniques', 'technique'), ('Where', 'Where'), ('data', 'data'), ('labelled', 'labelled'), ('unlabelled', 'unlabelled'), (',', ','), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('techniques', 'technique'), ('also', 'also'), ('mixed', 'mixed'), ('.', '.')]



============================ Sentence 304 =============================

Algorithms are applied for both labelled and unlabelled data, and even with   incomplete information or missing training sets, some of the dataset’s classifiers can be learned. 


>> Tokens are: 
 ['Algorithms', 'applied', 'labelled', 'unlabelled', 'data', ',', 'even', 'incomplete', 'information', 'missing', 'training', 'sets', ',', 'dataset', '’', 'classifiers', 'learned', '.']

>> Bigrams are: 
 [('Algorithms', 'applied'), ('applied', 'labelled'), ('labelled', 'unlabelled'), ('unlabelled', 'data'), ('data', ','), (',', 'even'), ('even', 'incomplete'), ('incomplete', 'information'), ('information', 'missing'), ('missing', 'training'), ('training', 'sets'), ('sets', ','), (',', 'dataset'), ('dataset', '’'), ('’', 'classifiers'), ('classifiers', 'learned'), ('learned', '.')]

>> Trigrams are: 
 [('Algorithms', 'applied', 'labelled'), ('applied', 'labelled', 'unlabelled'), ('labelled', 'unlabelled', 'data'), ('unlabelled', 'data', ','), ('data', ',', 'even'), (',', 'even', 'incomplete'), ('even', 'incomplete', 'information'), ('incomplete', 'information', 'missing'), ('information', 'missing', 'training'), ('missing', 'training', 'sets'), ('training', 'sets', ','), ('sets', ',', 'dataset'), (',', 'dataset', '’'), ('dataset', '’', 'classifiers'), ('’', 'classifiers', 'learned'), ('classifiers', 'learned', '.')]

>> POS Tags are: 
 [('Algorithms', 'NNP'), ('applied', 'VBD'), ('labelled', 'VBN'), ('unlabelled', 'JJ'), ('data', 'NNS'), (',', ','), ('even', 'RB'), ('incomplete', 'JJ'), ('information', 'NN'), ('missing', 'VBG'), ('training', 'NN'), ('sets', 'NNS'), (',', ','), ('dataset', 'VBN'), ('’', 'NN'), ('classifiers', 'NNS'), ('learned', 'VBD'), ('.', '.')]

 (S
  (NP Algorithms/NNP)
  applied/VBD
  labelled/VBN
  (NP unlabelled/JJ data/NNS)
  ,/,
  even/RB
  (NP incomplete/JJ information/NN)
  missing/VBG
  (NP training/NN sets/NNS)
  ,/,
  dataset/VBN
  (NP ’/NN classifiers/NNS)
  learned/VBD
  ./.) 


>> Noun Phrases are: 
 ['Algorithms', 'unlabelled data', 'incomplete information', 'training sets', '’ classifiers']

>> Named Entities are: 
 [('PERSON', 'Algorithms')] 

>> Stemming using Porter Stemmer: 
 [('Algorithms', 'algorithm'), ('applied', 'appli'), ('labelled', 'label'), ('unlabelled', 'unlabel'), ('data', 'data'), (',', ','), ('even', 'even'), ('incomplete', 'incomplet'), ('information', 'inform'), ('missing', 'miss'), ('training', 'train'), ('sets', 'set'), (',', ','), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('learned', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Algorithms', 'algorithm'), ('applied', 'appli'), ('labelled', 'label'), ('unlabelled', 'unlabel'), ('data', 'data'), (',', ','), ('even', 'even'), ('incomplete', 'incomplet'), ('information', 'inform'), ('missing', 'miss'), ('training', 'train'), ('sets', 'set'), (',', ','), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifi'), ('learned', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Algorithms', 'Algorithms'), ('applied', 'applied'), ('labelled', 'labelled'), ('unlabelled', 'unlabelled'), ('data', 'data'), (',', ','), ('even', 'even'), ('incomplete', 'incomplete'), ('information', 'information'), ('missing', 'missing'), ('training', 'training'), ('sets', 'set'), (',', ','), ('dataset', 'dataset'), ('’', '’'), ('classifiers', 'classifier'), ('learned', 'learned'), ('.', '.')]



============================ Sentence 305 =============================

Sarah Al-Shiakhli   25      Both supervised and unsupervised techniques focus on one aspect (target separation or   independent variable distribution, respectively), and using them together may thus give better   results (Breed, D.G. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '25', 'Both', 'supervised', 'unsupervised', 'techniques', 'focus', 'one', 'aspect', '(', 'target', 'separation', 'independent', 'variable', 'distribution', ',', 'respectively', ')', ',', 'using', 'together', 'may', 'thus', 'give', 'better', 'results', '(', 'Breed', ',', 'D.G', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '25'), ('25', 'Both'), ('Both', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'techniques'), ('techniques', 'focus'), ('focus', 'one'), ('one', 'aspect'), ('aspect', '('), ('(', 'target'), ('target', 'separation'), ('separation', 'independent'), ('independent', 'variable'), ('variable', 'distribution'), ('distribution', ','), (',', 'respectively'), ('respectively', ')'), (')', ','), (',', 'using'), ('using', 'together'), ('together', 'may'), ('may', 'thus'), ('thus', 'give'), ('give', 'better'), ('better', 'results'), ('results', '('), ('(', 'Breed'), ('Breed', ','), (',', 'D.G'), ('D.G', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '25'), ('Al-Shiakhli', '25', 'Both'), ('25', 'Both', 'supervised'), ('Both', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'techniques'), ('unsupervised', 'techniques', 'focus'), ('techniques', 'focus', 'one'), ('focus', 'one', 'aspect'), ('one', 'aspect', '('), ('aspect', '(', 'target'), ('(', 'target', 'separation'), ('target', 'separation', 'independent'), ('separation', 'independent', 'variable'), ('independent', 'variable', 'distribution'), ('variable', 'distribution', ','), ('distribution', ',', 'respectively'), (',', 'respectively', ')'), ('respectively', ')', ','), (')', ',', 'using'), (',', 'using', 'together'), ('using', 'together', 'may'), ('together', 'may', 'thus'), ('may', 'thus', 'give'), ('thus', 'give', 'better'), ('give', 'better', 'results'), ('better', 'results', '('), ('results', '(', 'Breed'), ('(', 'Breed', ','), ('Breed', ',', 'D.G'), (',', 'D.G', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('25', 'CD'), ('Both', 'NNP'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('techniques', 'NNS'), ('focus', 'VBP'), ('one', 'CD'), ('aspect', 'NN'), ('(', '('), ('target', 'VB'), ('separation', 'NN'), ('independent', 'JJ'), ('variable', 'JJ'), ('distribution', 'NN'), (',', ','), ('respectively', 'RB'), (')', ')'), (',', ','), ('using', 'VBG'), ('together', 'RB'), ('may', 'MD'), ('thus', 'RB'), ('give', 'VB'), ('better', 'JJR'), ('results', 'NNS'), ('(', '('), ('Breed', 'NNP'), (',', ','), ('D.G', 'NNP'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  25/CD
  (NP Both/NNP)
  supervised/VBD
  (NP unsupervised/JJ techniques/NNS)
  focus/VBP
  one/CD
  (NP aspect/NN)
  (/(
  target/VB
  (NP separation/NN)
  (NP independent/JJ variable/JJ distribution/NN)
  ,/,
  respectively/RB
  )/)
  ,/,
  using/VBG
  together/RB
  may/MD
  thus/RB
  give/VB
  better/JJR
  (NP results/NNS)
  (/(
  (NP Breed/NNP)
  ,/,
  (NP D.G/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Both', 'unsupervised techniques', 'aspect', 'separation', 'independent variable distribution', 'results', 'Breed', 'D.G']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Breed')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('25', '25'), ('Both', 'both'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('focus', 'focu'), ('one', 'one'), ('aspect', 'aspect'), ('(', '('), ('target', 'target'), ('separation', 'separ'), ('independent', 'independ'), ('variable', 'variabl'), ('distribution', 'distribut'), (',', ','), ('respectively', 'respect'), (')', ')'), (',', ','), ('using', 'use'), ('together', 'togeth'), ('may', 'may'), ('thus', 'thu'), ('give', 'give'), ('better', 'better'), ('results', 'result'), ('(', '('), ('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('25', '25'), ('Both', 'both'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('techniques', 'techniqu'), ('focus', 'focus'), ('one', 'one'), ('aspect', 'aspect'), ('(', '('), ('target', 'target'), ('separation', 'separ'), ('independent', 'independ'), ('variable', 'variabl'), ('distribution', 'distribut'), (',', ','), ('respectively', 'respect'), (')', ')'), (',', ','), ('using', 'use'), ('together', 'togeth'), ('may', 'may'), ('thus', 'thus'), ('give', 'give'), ('better', 'better'), ('results', 'result'), ('(', '('), ('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('25', '25'), ('Both', 'Both'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('techniques', 'technique'), ('focus', 'focus'), ('one', 'one'), ('aspect', 'aspect'), ('(', '('), ('target', 'target'), ('separation', 'separation'), ('independent', 'independent'), ('variable', 'variable'), ('distribution', 'distribution'), (',', ','), ('respectively', 'respectively'), (')', ')'), (',', ','), ('using', 'using'), ('together', 'together'), ('may', 'may'), ('thus', 'thus'), ('give', 'give'), ('better', 'better'), ('results', 'result'), ('(', '('), ('Breed', 'Breed'), (',', ','), ('D.G', 'D.G'), ('.', '.')]



============================ Sentence 306 =============================

and Verster, T., 2019). 


>> Tokens are: 
 ['Verster', ',', 'T.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Verster', ','), (',', 'T.'), ('T.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Verster', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Verster', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S (NP Verster/NNP) ,/, (NP T./NNP) ,/, 2019/CD )/) ./.) 


>> Noun Phrases are: 
 ['Verster', 'T.']

>> Named Entities are: 
 [('PERSON', 'Verster')] 

>> Stemming using Porter Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Verster', 'Verster'), (',', ','), ('T.', 'T.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 307 =============================

7.1.4. 


>> Tokens are: 
 ['7.1.4', '.']

>> Bigrams are: 
 [('7.1.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.1.4', 'CD'), ('.', '.')]

 (S 7.1.4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.1.4', '7.1.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.1.4', '7.1.4'), ('.', '.')]

>> Lemmatization: 
 [('7.1.4', '7.1.4'), ('.', '.')]



============================ Sentence 308 =============================

Reinforcement learning (RL)     Reinforcement learning involves setting and classifying real-time data changes in a way that allows   the learning framework to adapt based on those changes (Wu et al., 2018; Cui et al., 2019). 


>> Tokens are: 
 ['Reinforcement', 'learning', '(', 'RL', ')', 'Reinforcement', 'learning', 'involves', 'setting', 'classifying', 'real-time', 'data', 'changes', 'way', 'allows', 'learning', 'framework', 'adapt', 'based', 'changes', '(', 'Wu', 'et', 'al.', ',', '2018', ';', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Reinforcement', 'learning'), ('learning', '('), ('(', 'RL'), ('RL', ')'), (')', 'Reinforcement'), ('Reinforcement', 'learning'), ('learning', 'involves'), ('involves', 'setting'), ('setting', 'classifying'), ('classifying', 'real-time'), ('real-time', 'data'), ('data', 'changes'), ('changes', 'way'), ('way', 'allows'), ('allows', 'learning'), ('learning', 'framework'), ('framework', 'adapt'), ('adapt', 'based'), ('based', 'changes'), ('changes', '('), ('(', 'Wu'), ('Wu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Reinforcement', 'learning', '('), ('learning', '(', 'RL'), ('(', 'RL', ')'), ('RL', ')', 'Reinforcement'), (')', 'Reinforcement', 'learning'), ('Reinforcement', 'learning', 'involves'), ('learning', 'involves', 'setting'), ('involves', 'setting', 'classifying'), ('setting', 'classifying', 'real-time'), ('classifying', 'real-time', 'data'), ('real-time', 'data', 'changes'), ('data', 'changes', 'way'), ('changes', 'way', 'allows'), ('way', 'allows', 'learning'), ('allows', 'learning', 'framework'), ('learning', 'framework', 'adapt'), ('framework', 'adapt', 'based'), ('adapt', 'based', 'changes'), ('based', 'changes', '('), ('changes', '(', 'Wu'), ('(', 'Wu', 'et'), ('Wu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ';'), ('2018', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Reinforcement', 'NN'), ('learning', 'NN'), ('(', '('), ('RL', 'NNP'), (')', ')'), ('Reinforcement', 'NNP'), ('learning', 'VBG'), ('involves', 'NNS'), ('setting', 'VBG'), ('classifying', 'VBG'), ('real-time', 'JJ'), ('data', 'NNS'), ('changes', 'NNS'), ('way', 'NN'), ('allows', 'VBZ'), ('learning', 'VBG'), ('framework', 'NN'), ('adapt', 'NN'), ('based', 'VBN'), ('changes', 'NNS'), ('(', '('), ('Wu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Reinforcement/NN learning/NN)
  (/(
  (NP RL/NNP)
  )/)
  (NP Reinforcement/NNP)
  learning/VBG
  (NP involves/NNS)
  setting/VBG
  classifying/VBG
  (NP real-time/JJ data/NNS changes/NNS way/NN)
  allows/VBZ
  learning/VBG
  (NP framework/NN adapt/NN)
  based/VBN
  (NP changes/NNS)
  (/(
  (NP Wu/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  ;/:
  (NP Cui/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Reinforcement learning', 'RL', 'Reinforcement', 'involves', 'real-time data changes way', 'framework adapt', 'changes', 'Wu', 'Cui', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')'), ('Reinforcement', 'reinforc'), ('learning', 'learn'), ('involves', 'involv'), ('setting', 'set'), ('classifying', 'classifi'), ('real-time', 'real-tim'), ('data', 'data'), ('changes', 'chang'), ('way', 'way'), ('allows', 'allow'), ('learning', 'learn'), ('framework', 'framework'), ('adapt', 'adapt'), ('based', 'base'), ('changes', 'chang'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Reinforcement', 'reinforc'), ('learning', 'learn'), ('(', '('), ('RL', 'rl'), (')', ')'), ('Reinforcement', 'reinforc'), ('learning', 'learn'), ('involves', 'involv'), ('setting', 'set'), ('classifying', 'classifi'), ('real-time', 'real-tim'), ('data', 'data'), ('changes', 'chang'), ('way', 'way'), ('allows', 'allow'), ('learning', 'learn'), ('framework', 'framework'), ('adapt', 'adapt'), ('based', 'base'), ('changes', 'chang'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('(', '('), ('RL', 'RL'), (')', ')'), ('Reinforcement', 'Reinforcement'), ('learning', 'learning'), ('involves', 'involves'), ('setting', 'setting'), ('classifying', 'classifying'), ('real-time', 'real-time'), ('data', 'data'), ('changes', 'change'), ('way', 'way'), ('allows', 'allows'), ('learning', 'learning'), ('framework', 'framework'), ('adapt', 'adapt'), ('based', 'based'), ('changes', 'change'), ('(', '('), ('Wu', 'Wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 309 =============================

The components of an RL algorithm are the agent; the environment; and the actions. 


>> Tokens are: 
 ['The', 'components', 'RL', 'algorithm', 'agent', ';', 'environment', ';', 'actions', '.']

>> Bigrams are: 
 [('The', 'components'), ('components', 'RL'), ('RL', 'algorithm'), ('algorithm', 'agent'), ('agent', ';'), (';', 'environment'), ('environment', ';'), (';', 'actions'), ('actions', '.')]

>> Trigrams are: 
 [('The', 'components', 'RL'), ('components', 'RL', 'algorithm'), ('RL', 'algorithm', 'agent'), ('algorithm', 'agent', ';'), ('agent', ';', 'environment'), (';', 'environment', ';'), ('environment', ';', 'actions'), (';', 'actions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('components', 'NNS'), ('RL', 'NNP'), ('algorithm', 'VBP'), ('agent', 'NN'), (';', ':'), ('environment', 'NN'), (';', ':'), ('actions', 'NNS'), ('.', '.')]

 (S
  (NP The/DT components/NNS RL/NNP)
  algorithm/VBP
  (NP agent/NN)
  ;/:
  (NP environment/NN)
  ;/:
  (NP actions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The components RL', 'agent', 'environment', 'actions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('components', 'compon'), ('RL', 'rl'), ('algorithm', 'algorithm'), ('agent', 'agent'), (';', ';'), ('environment', 'environ'), (';', ';'), ('actions', 'action'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('components', 'compon'), ('RL', 'rl'), ('algorithm', 'algorithm'), ('agent', 'agent'), (';', ';'), ('environment', 'environ'), (';', ';'), ('actions', 'action'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('components', 'component'), ('RL', 'RL'), ('algorithm', 'algorithm'), ('agent', 'agent'), (';', ';'), ('environment', 'environment'), (';', ';'), ('actions', 'action'), ('.', '.')]



============================ Sentence 310 =============================

The actions   are taken by the algorithm based on the environment, and depending on the feedback from the   environment, it determines whether the action is positive, thus using it again in future, or negative,   thus discarding it. 


>> Tokens are: 
 ['The', 'actions', 'taken', 'algorithm', 'based', 'environment', ',', 'depending', 'feedback', 'environment', ',', 'determines', 'whether', 'action', 'positive', ',', 'thus', 'using', 'future', ',', 'negative', ',', 'thus', 'discarding', '.']

>> Bigrams are: 
 [('The', 'actions'), ('actions', 'taken'), ('taken', 'algorithm'), ('algorithm', 'based'), ('based', 'environment'), ('environment', ','), (',', 'depending'), ('depending', 'feedback'), ('feedback', 'environment'), ('environment', ','), (',', 'determines'), ('determines', 'whether'), ('whether', 'action'), ('action', 'positive'), ('positive', ','), (',', 'thus'), ('thus', 'using'), ('using', 'future'), ('future', ','), (',', 'negative'), ('negative', ','), (',', 'thus'), ('thus', 'discarding'), ('discarding', '.')]

>> Trigrams are: 
 [('The', 'actions', 'taken'), ('actions', 'taken', 'algorithm'), ('taken', 'algorithm', 'based'), ('algorithm', 'based', 'environment'), ('based', 'environment', ','), ('environment', ',', 'depending'), (',', 'depending', 'feedback'), ('depending', 'feedback', 'environment'), ('feedback', 'environment', ','), ('environment', ',', 'determines'), (',', 'determines', 'whether'), ('determines', 'whether', 'action'), ('whether', 'action', 'positive'), ('action', 'positive', ','), ('positive', ',', 'thus'), (',', 'thus', 'using'), ('thus', 'using', 'future'), ('using', 'future', ','), ('future', ',', 'negative'), (',', 'negative', ','), ('negative', ',', 'thus'), (',', 'thus', 'discarding'), ('thus', 'discarding', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('actions', 'NNS'), ('taken', 'VBN'), ('algorithm', 'RB'), ('based', 'VBN'), ('environment', 'NN'), (',', ','), ('depending', 'VBG'), ('feedback', 'NN'), ('environment', 'NN'), (',', ','), ('determines', 'VBZ'), ('whether', 'IN'), ('action', 'NN'), ('positive', 'JJ'), (',', ','), ('thus', 'RB'), ('using', 'VBG'), ('future', 'JJ'), (',', ','), ('negative', 'JJ'), (',', ','), ('thus', 'RB'), ('discarding', 'VBG'), ('.', '.')]

 (S
  (NP The/DT actions/NNS)
  taken/VBN
  algorithm/RB
  based/VBN
  (NP environment/NN)
  ,/,
  depending/VBG
  (NP feedback/NN environment/NN)
  ,/,
  determines/VBZ
  whether/IN
  (NP action/NN)
  positive/JJ
  ,/,
  thus/RB
  using/VBG
  future/JJ
  ,/,
  negative/JJ
  ,/,
  thus/RB
  discarding/VBG
  ./.) 


>> Noun Phrases are: 
 ['The actions', 'environment', 'feedback environment', 'action']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('actions', 'action'), ('taken', 'taken'), ('algorithm', 'algorithm'), ('based', 'base'), ('environment', 'environ'), (',', ','), ('depending', 'depend'), ('feedback', 'feedback'), ('environment', 'environ'), (',', ','), ('determines', 'determin'), ('whether', 'whether'), ('action', 'action'), ('positive', 'posit'), (',', ','), ('thus', 'thu'), ('using', 'use'), ('future', 'futur'), (',', ','), ('negative', 'neg'), (',', ','), ('thus', 'thu'), ('discarding', 'discard'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('actions', 'action'), ('taken', 'taken'), ('algorithm', 'algorithm'), ('based', 'base'), ('environment', 'environ'), (',', ','), ('depending', 'depend'), ('feedback', 'feedback'), ('environment', 'environ'), (',', ','), ('determines', 'determin'), ('whether', 'whether'), ('action', 'action'), ('positive', 'posit'), (',', ','), ('thus', 'thus'), ('using', 'use'), ('future', 'futur'), (',', ','), ('negative', 'negat'), (',', ','), ('thus', 'thus'), ('discarding', 'discard'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('actions', 'action'), ('taken', 'taken'), ('algorithm', 'algorithm'), ('based', 'based'), ('environment', 'environment'), (',', ','), ('depending', 'depending'), ('feedback', 'feedback'), ('environment', 'environment'), (',', ','), ('determines', 'determines'), ('whether', 'whether'), ('action', 'action'), ('positive', 'positive'), (',', ','), ('thus', 'thus'), ('using', 'using'), ('future', 'future'), (',', ','), ('negative', 'negative'), (',', ','), ('thus', 'thus'), ('discarding', 'discarding'), ('.', '.')]



============================ Sentence 311 =============================

An example of reinforcement learning is Markov Chains (Markov Decision   Process) (Müller et al., 2016). 


>> Tokens are: 
 ['An', 'example', 'reinforcement', 'learning', 'Markov', 'Chains', '(', 'Markov', 'Decision', 'Process', ')', '(', 'Müller', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('An', 'example'), ('example', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'Markov'), ('Markov', 'Chains'), ('Chains', '('), ('(', 'Markov'), ('Markov', 'Decision'), ('Decision', 'Process'), ('Process', ')'), (')', '('), ('(', 'Müller'), ('Müller', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('An', 'example', 'reinforcement'), ('example', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'Markov'), ('learning', 'Markov', 'Chains'), ('Markov', 'Chains', '('), ('Chains', '(', 'Markov'), ('(', 'Markov', 'Decision'), ('Markov', 'Decision', 'Process'), ('Decision', 'Process', ')'), ('Process', ')', '('), (')', '(', 'Müller'), ('(', 'Müller', 'et'), ('Müller', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('Markov', 'NNP'), ('Chains', 'NNP'), ('(', '('), ('Markov', 'NNP'), ('Decision', 'NNP'), ('Process', 'NNP'), (')', ')'), ('(', '('), ('Müller', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP An/DT example/NN reinforcement/NN)
  learning/VBG
  (NP Markov/NNP Chains/NNP)
  (/(
  (NP Markov/NNP Decision/NNP Process/NNP)
  )/)
  (/(
  (NP Müller/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['An example reinforcement', 'Markov Chains', 'Markov Decision Process', 'Müller']

>> Named Entities are: 
 [('PERSON', 'Markov Chains'), ('PERSON', 'Markov Decision'), ('PERSON', 'Müller')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('Markov', 'markov'), ('Chains', 'chain'), ('(', '('), ('Markov', 'markov'), ('Decision', 'decis'), ('Process', 'process'), (')', ')'), ('(', '('), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('Markov', 'markov'), ('Chains', 'chain'), ('(', '('), ('Markov', 'markov'), ('Decision', 'decis'), ('Process', 'process'), (')', ')'), ('(', '('), ('Müller', 'müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('Markov', 'Markov'), ('Chains', 'Chains'), ('(', '('), ('Markov', 'Markov'), ('Decision', 'Decision'), ('Process', 'Process'), (')', ')'), ('(', '('), ('Müller', 'Müller'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 312 =============================

The difference between RL and supervised or unsupervised learning   is that RL works based on the feedback which is either good or not depending on the situation and   is hence dynamic, while supervised and unsupervised learning give static solutions (Cui, et al.,   2019). 


>> Tokens are: 
 ['The', 'difference', 'RL', 'supervised', 'unsupervised', 'learning', 'RL', 'works', 'based', 'feedback', 'either', 'good', 'depending', 'situation', 'hence', 'dynamic', ',', 'supervised', 'unsupervised', 'learning', 'give', 'static', 'solutions', '(', 'Cui', ',', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('The', 'difference'), ('difference', 'RL'), ('RL', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'RL'), ('RL', 'works'), ('works', 'based'), ('based', 'feedback'), ('feedback', 'either'), ('either', 'good'), ('good', 'depending'), ('depending', 'situation'), ('situation', 'hence'), ('hence', 'dynamic'), ('dynamic', ','), (',', 'supervised'), ('supervised', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'give'), ('give', 'static'), ('static', 'solutions'), ('solutions', '('), ('(', 'Cui'), ('Cui', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'difference', 'RL'), ('difference', 'RL', 'supervised'), ('RL', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'RL'), ('learning', 'RL', 'works'), ('RL', 'works', 'based'), ('works', 'based', 'feedback'), ('based', 'feedback', 'either'), ('feedback', 'either', 'good'), ('either', 'good', 'depending'), ('good', 'depending', 'situation'), ('depending', 'situation', 'hence'), ('situation', 'hence', 'dynamic'), ('hence', 'dynamic', ','), ('dynamic', ',', 'supervised'), (',', 'supervised', 'unsupervised'), ('supervised', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'give'), ('learning', 'give', 'static'), ('give', 'static', 'solutions'), ('static', 'solutions', '('), ('solutions', '(', 'Cui'), ('(', 'Cui', ','), ('Cui', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('difference', 'NN'), ('RL', 'NNP'), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'NN'), ('RL', 'NNP'), ('works', 'VBZ'), ('based', 'VBN'), ('feedback', 'NN'), ('either', 'RB'), ('good', 'JJ'), ('depending', 'VBG'), ('situation', 'NN'), ('hence', 'NN'), ('dynamic', 'JJ'), (',', ','), ('supervised', 'VBD'), ('unsupervised', 'JJ'), ('learning', 'VBG'), ('give', 'JJ'), ('static', 'JJ'), ('solutions', 'NNS'), ('(', '('), ('Cui', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT difference/NN RL/NNP)
  supervised/VBD
  (NP unsupervised/JJ learning/NN RL/NNP)
  works/VBZ
  based/VBN
  (NP feedback/NN)
  either/RB
  good/JJ
  depending/VBG
  (NP situation/NN hence/NN)
  dynamic/JJ
  ,/,
  supervised/VBD
  unsupervised/JJ
  learning/VBG
  (NP give/JJ static/JJ solutions/NNS)
  (/(
  (NP Cui/NNP)
  ,/,
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The difference RL', 'unsupervised learning RL', 'feedback', 'situation hence', 'give static solutions', 'Cui', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Cui')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('difference', 'differ'), ('RL', 'rl'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('RL', 'rl'), ('works', 'work'), ('based', 'base'), ('feedback', 'feedback'), ('either', 'either'), ('good', 'good'), ('depending', 'depend'), ('situation', 'situat'), ('hence', 'henc'), ('dynamic', 'dynam'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('give', 'give'), ('static', 'static'), ('solutions', 'solut'), ('(', '('), ('Cui', 'cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('difference', 'differ'), ('RL', 'rl'), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('RL', 'rl'), ('works', 'work'), ('based', 'base'), ('feedback', 'feedback'), ('either', 'either'), ('good', 'good'), ('depending', 'depend'), ('situation', 'situat'), ('hence', 'henc'), ('dynamic', 'dynam'), (',', ','), ('supervised', 'supervis'), ('unsupervised', 'unsupervis'), ('learning', 'learn'), ('give', 'give'), ('static', 'static'), ('solutions', 'solut'), ('(', '('), ('Cui', 'cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('difference', 'difference'), ('RL', 'RL'), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('RL', 'RL'), ('works', 'work'), ('based', 'based'), ('feedback', 'feedback'), ('either', 'either'), ('good', 'good'), ('depending', 'depending'), ('situation', 'situation'), ('hence', 'hence'), ('dynamic', 'dynamic'), (',', ','), ('supervised', 'supervised'), ('unsupervised', 'unsupervised'), ('learning', 'learning'), ('give', 'give'), ('static', 'static'), ('solutions', 'solution'), ('(', '('), ('Cui', 'Cui'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 313 =============================

The RL process includes an actor which acts in the environment with its own copy of the data; the   data can thus be stored in a separate replay memory and sampled by the learner to be computed   within the policy parameters. 


>> Tokens are: 
 ['The', 'RL', 'process', 'includes', 'actor', 'acts', 'environment', 'copy', 'data', ';', 'data', 'thus', 'stored', 'separate', 'replay', 'memory', 'sampled', 'learner', 'computed', 'within', 'policy', 'parameters', '.']

>> Bigrams are: 
 [('The', 'RL'), ('RL', 'process'), ('process', 'includes'), ('includes', 'actor'), ('actor', 'acts'), ('acts', 'environment'), ('environment', 'copy'), ('copy', 'data'), ('data', ';'), (';', 'data'), ('data', 'thus'), ('thus', 'stored'), ('stored', 'separate'), ('separate', 'replay'), ('replay', 'memory'), ('memory', 'sampled'), ('sampled', 'learner'), ('learner', 'computed'), ('computed', 'within'), ('within', 'policy'), ('policy', 'parameters'), ('parameters', '.')]

>> Trigrams are: 
 [('The', 'RL', 'process'), ('RL', 'process', 'includes'), ('process', 'includes', 'actor'), ('includes', 'actor', 'acts'), ('actor', 'acts', 'environment'), ('acts', 'environment', 'copy'), ('environment', 'copy', 'data'), ('copy', 'data', ';'), ('data', ';', 'data'), (';', 'data', 'thus'), ('data', 'thus', 'stored'), ('thus', 'stored', 'separate'), ('stored', 'separate', 'replay'), ('separate', 'replay', 'memory'), ('replay', 'memory', 'sampled'), ('memory', 'sampled', 'learner'), ('sampled', 'learner', 'computed'), ('learner', 'computed', 'within'), ('computed', 'within', 'policy'), ('within', 'policy', 'parameters'), ('policy', 'parameters', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('RL', 'NNP'), ('process', 'NN'), ('includes', 'VBZ'), ('actor', 'NN'), ('acts', 'NNS'), ('environment', 'NN'), ('copy', 'NN'), ('data', 'NNS'), (';', ':'), ('data', 'NNS'), ('thus', 'RB'), ('stored', 'VBN'), ('separate', 'JJ'), ('replay', 'NN'), ('memory', 'NN'), ('sampled', 'VBD'), ('learner', 'RB'), ('computed', 'VBN'), ('within', 'IN'), ('policy', 'NN'), ('parameters', 'NNS'), ('.', '.')]

 (S
  (NP The/DT RL/NNP process/NN)
  includes/VBZ
  (NP actor/NN acts/NNS environment/NN copy/NN data/NNS)
  ;/:
  (NP data/NNS)
  thus/RB
  stored/VBN
  (NP separate/JJ replay/NN memory/NN)
  sampled/VBD
  learner/RB
  computed/VBN
  within/IN
  (NP policy/NN parameters/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The RL process', 'actor acts environment copy data', 'data', 'separate replay memory', 'policy parameters']

>> Named Entities are: 
 [('ORGANIZATION', 'RL')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('RL', 'rl'), ('process', 'process'), ('includes', 'includ'), ('actor', 'actor'), ('acts', 'act'), ('environment', 'environ'), ('copy', 'copi'), ('data', 'data'), (';', ';'), ('data', 'data'), ('thus', 'thu'), ('stored', 'store'), ('separate', 'separ'), ('replay', 'replay'), ('memory', 'memori'), ('sampled', 'sampl'), ('learner', 'learner'), ('computed', 'comput'), ('within', 'within'), ('policy', 'polici'), ('parameters', 'paramet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('RL', 'rl'), ('process', 'process'), ('includes', 'includ'), ('actor', 'actor'), ('acts', 'act'), ('environment', 'environ'), ('copy', 'copi'), ('data', 'data'), (';', ';'), ('data', 'data'), ('thus', 'thus'), ('stored', 'store'), ('separate', 'separ'), ('replay', 'replay'), ('memory', 'memori'), ('sampled', 'sampl'), ('learner', 'learner'), ('computed', 'comput'), ('within', 'within'), ('policy', 'polici'), ('parameters', 'paramet'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('RL', 'RL'), ('process', 'process'), ('includes', 'includes'), ('actor', 'actor'), ('acts', 'act'), ('environment', 'environment'), ('copy', 'copy'), ('data', 'data'), (';', ';'), ('data', 'data'), ('thus', 'thus'), ('stored', 'stored'), ('separate', 'separate'), ('replay', 'replay'), ('memory', 'memory'), ('sampled', 'sampled'), ('learner', 'learner'), ('computed', 'computed'), ('within', 'within'), ('policy', 'policy'), ('parameters', 'parameter'), ('.', '.')]



============================ Sentence 314 =============================

The actor learners then receive the updated policy parameters (Mnih   et al., 2015; Mnih et al., 2016). 


>> Tokens are: 
 ['The', 'actor', 'learners', 'receive', 'updated', 'policy', 'parameters', '(', 'Mnih', 'et', 'al.', ',', '2015', ';', 'Mnih', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('The', 'actor'), ('actor', 'learners'), ('learners', 'receive'), ('receive', 'updated'), ('updated', 'policy'), ('policy', 'parameters'), ('parameters', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'actor', 'learners'), ('actor', 'learners', 'receive'), ('learners', 'receive', 'updated'), ('receive', 'updated', 'policy'), ('updated', 'policy', 'parameters'), ('policy', 'parameters', '('), ('parameters', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('actor', 'NN'), ('learners', 'NNS'), ('receive', 'VBP'), ('updated', 'JJ'), ('policy', 'NN'), ('parameters', 'NNS'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT actor/NN learners/NNS)
  receive/VBP
  (NP updated/JJ policy/NN parameters/NNS)
  (/(
  (NP Mnih/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  ;/:
  (NP Mnih/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The actor learners', 'updated policy parameters', 'Mnih', 'Mnih', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('actor', 'actor'), ('learners', 'learner'), ('receive', 'receiv'), ('updated', 'updat'), ('policy', 'polici'), ('parameters', 'paramet'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('actor', 'actor'), ('learners', 'learner'), ('receive', 'receiv'), ('updated', 'updat'), ('policy', 'polici'), ('parameters', 'paramet'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('actor', 'actor'), ('learners', 'learner'), ('receive', 'receive'), ('updated', 'updated'), ('policy', 'policy'), ('parameters', 'parameter'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 315 =============================

The Map-Reduce framework was utilized by Li and Schuurmans (2011) for parallelising batch   reinforcement learning methods with linear function approximation (Mnih et al., 2016). 


>> Tokens are: 
 ['The', 'Map-Reduce', 'framework', 'utilized', 'Li', 'Schuurmans', '(', '2011', ')', 'parallelising', 'batch', 'reinforcement', 'learning', 'methods', 'linear', 'function', 'approximation', '(', 'Mnih', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('The', 'Map-Reduce'), ('Map-Reduce', 'framework'), ('framework', 'utilized'), ('utilized', 'Li'), ('Li', 'Schuurmans'), ('Schuurmans', '('), ('(', '2011'), ('2011', ')'), (')', 'parallelising'), ('parallelising', 'batch'), ('batch', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'methods'), ('methods', 'linear'), ('linear', 'function'), ('function', 'approximation'), ('approximation', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'Map-Reduce', 'framework'), ('Map-Reduce', 'framework', 'utilized'), ('framework', 'utilized', 'Li'), ('utilized', 'Li', 'Schuurmans'), ('Li', 'Schuurmans', '('), ('Schuurmans', '(', '2011'), ('(', '2011', ')'), ('2011', ')', 'parallelising'), (')', 'parallelising', 'batch'), ('parallelising', 'batch', 'reinforcement'), ('batch', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'methods'), ('learning', 'methods', 'linear'), ('methods', 'linear', 'function'), ('linear', 'function', 'approximation'), ('function', 'approximation', '('), ('approximation', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('Map-Reduce', 'NNP'), ('framework', 'NN'), ('utilized', 'JJ'), ('Li', 'NNP'), ('Schuurmans', 'NNP'), ('(', '('), ('2011', 'CD'), (')', ')'), ('parallelising', 'VBG'), ('batch', 'NN'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('linear', 'JJ'), ('function', 'NN'), ('approximation', 'NN'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT Map-Reduce/NNP framework/NN)
  (NP utilized/JJ Li/NNP Schuurmans/NNP)
  (/(
  2011/CD
  )/)
  parallelising/VBG
  (NP batch/NN reinforcement/NN)
  learning/VBG
  (NP methods/NNS)
  (NP linear/JJ function/NN approximation/NN)
  (/(
  (NP Mnih/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The Map-Reduce framework', 'utilized Li Schuurmans', 'batch reinforcement', 'methods', 'linear function approximation', 'Mnih']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Map-Reduce', 'map-reduc'), ('framework', 'framework'), ('utilized', 'util'), ('Li', 'li'), ('Schuurmans', 'schuurman'), ('(', '('), ('2011', '2011'), (')', ')'), ('parallelising', 'parallelis'), ('batch', 'batch'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('methods', 'method'), ('linear', 'linear'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Map-Reduce', 'map-reduc'), ('framework', 'framework'), ('utilized', 'util'), ('Li', 'li'), ('Schuurmans', 'schuurman'), ('(', '('), ('2011', '2011'), (')', ')'), ('parallelising', 'parallelis'), ('batch', 'batch'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('methods', 'method'), ('linear', 'linear'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('Map-Reduce', 'Map-Reduce'), ('framework', 'framework'), ('utilized', 'utilized'), ('Li', 'Li'), ('Schuurmans', 'Schuurmans'), ('(', '('), ('2011', '2011'), (')', ')'), ('parallelising', 'parallelising'), ('batch', 'batch'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('methods', 'method'), ('linear', 'linear'), ('function', 'function'), ('approximation', 'approximation'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 316 =============================

Applying   parallelism helped speed up large matrix operations but did not assist the collection of experience   or stabilise learning. 


>> Tokens are: 
 ['Applying', 'parallelism', 'helped', 'speed', 'large', 'matrix', 'operations', 'assist', 'collection', 'experience', 'stabilise', 'learning', '.']

>> Bigrams are: 
 [('Applying', 'parallelism'), ('parallelism', 'helped'), ('helped', 'speed'), ('speed', 'large'), ('large', 'matrix'), ('matrix', 'operations'), ('operations', 'assist'), ('assist', 'collection'), ('collection', 'experience'), ('experience', 'stabilise'), ('stabilise', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Applying', 'parallelism', 'helped'), ('parallelism', 'helped', 'speed'), ('helped', 'speed', 'large'), ('speed', 'large', 'matrix'), ('large', 'matrix', 'operations'), ('matrix', 'operations', 'assist'), ('operations', 'assist', 'collection'), ('assist', 'collection', 'experience'), ('collection', 'experience', 'stabilise'), ('experience', 'stabilise', 'learning'), ('stabilise', 'learning', '.')]

>> POS Tags are: 
 [('Applying', 'VBG'), ('parallelism', 'NN'), ('helped', 'VBD'), ('speed', 'VB'), ('large', 'JJ'), ('matrix', 'NN'), ('operations', 'NNS'), ('assist', 'VBP'), ('collection', 'NN'), ('experience', 'NN'), ('stabilise', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  Applying/VBG
  (NP parallelism/NN)
  helped/VBD
  speed/VB
  (NP large/JJ matrix/NN operations/NNS)
  assist/VBP
  (NP collection/NN experience/NN stabilise/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['parallelism', 'large matrix operations', 'collection experience stabilise learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli'), ('parallelism', 'parallel'), ('helped', 'help'), ('speed', 'speed'), ('large', 'larg'), ('matrix', 'matrix'), ('operations', 'oper'), ('assist', 'assist'), ('collection', 'collect'), ('experience', 'experi'), ('stabilise', 'stabilis'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli'), ('parallelism', 'parallel'), ('helped', 'help'), ('speed', 'speed'), ('large', 'larg'), ('matrix', 'matrix'), ('operations', 'oper'), ('assist', 'assist'), ('collection', 'collect'), ('experience', 'experi'), ('stabilise', 'stabilis'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Applying', 'Applying'), ('parallelism', 'parallelism'), ('helped', 'helped'), ('speed', 'speed'), ('large', 'large'), ('matrix', 'matrix'), ('operations', 'operation'), ('assist', 'assist'), ('collection', 'collection'), ('experience', 'experience'), ('stabilise', 'stabilise'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 317 =============================

The reinforcement learning goal is to develop policies that help in decision making. 


>> Tokens are: 
 ['The', 'reinforcement', 'learning', 'goal', 'develop', 'policies', 'help', 'decision', 'making', '.']

>> Bigrams are: 
 [('The', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'goal'), ('goal', 'develop'), ('develop', 'policies'), ('policies', 'help'), ('help', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('The', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'goal'), ('learning', 'goal', 'develop'), ('goal', 'develop', 'policies'), ('develop', 'policies', 'help'), ('policies', 'help', 'decision'), ('help', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('goal', 'NN'), ('develop', 'VB'), ('policies', 'NNS'), ('help', 'VBP'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

 (S
  (NP The/DT reinforcement/NN)
  learning/VBG
  (NP goal/NN)
  develop/VB
  (NP policies/NNS)
  help/VBP
  (NP decision/NN making/NN)
  ./.) 


>> Noun Phrases are: 
 ['The reinforcement', 'goal', 'policies', 'decision making']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('goal', 'goal'), ('develop', 'develop'), ('policies', 'polici'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('goal', 'goal'), ('develop', 'develop'), ('policies', 'polici'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('goal', 'goal'), ('develop', 'develop'), ('policies', 'policy'), ('help', 'help'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



============================ Sentence 318 =============================

An example,   is Q-learning, where the algorithm has no knowledge of the data but has the ability to find out   about the data in an automated way (Wu et al., 2018; Cui et al., 2019). 


>> Tokens are: 
 ['An', 'example', ',', 'Q-learning', ',', 'algorithm', 'knowledge', 'data', 'ability', 'find', 'data', 'automated', 'way', '(', 'Wu', 'et', 'al.', ',', '2018', ';', 'Cui', 'et', 'al.', ',', '2019', ')', '.']

>> Bigrams are: 
 [('An', 'example'), ('example', ','), (',', 'Q-learning'), ('Q-learning', ','), (',', 'algorithm'), ('algorithm', 'knowledge'), ('knowledge', 'data'), ('data', 'ability'), ('ability', 'find'), ('find', 'data'), ('data', 'automated'), ('automated', 'way'), ('way', '('), ('(', 'Wu'), ('Wu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ';'), (';', 'Cui'), ('Cui', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('An', 'example', ','), ('example', ',', 'Q-learning'), (',', 'Q-learning', ','), ('Q-learning', ',', 'algorithm'), (',', 'algorithm', 'knowledge'), ('algorithm', 'knowledge', 'data'), ('knowledge', 'data', 'ability'), ('data', 'ability', 'find'), ('ability', 'find', 'data'), ('find', 'data', 'automated'), ('data', 'automated', 'way'), ('automated', 'way', '('), ('way', '(', 'Wu'), ('(', 'Wu', 'et'), ('Wu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ';'), ('2018', ';', 'Cui'), (';', 'Cui', 'et'), ('Cui', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('example', 'NN'), (',', ','), ('Q-learning', 'NNP'), (',', ','), ('algorithm', 'NN'), ('knowledge', 'NN'), ('data', 'NNS'), ('ability', 'NN'), ('find', 'VBP'), ('data', 'NNS'), ('automated', 'VBN'), ('way', 'NN'), ('(', '('), ('Wu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (';', ':'), ('Cui', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP An/DT example/NN)
  ,/,
  (NP Q-learning/NNP)
  ,/,
  (NP algorithm/NN knowledge/NN data/NNS ability/NN)
  find/VBP
  (NP data/NNS)
  automated/VBN
  (NP way/NN)
  (/(
  (NP Wu/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  ;/:
  (NP Cui/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['An example', 'Q-learning', 'algorithm knowledge data ability', 'data', 'way', 'Wu', 'Cui', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('example', 'exampl'), (',', ','), ('Q-learning', 'q-learn'), (',', ','), ('algorithm', 'algorithm'), ('knowledge', 'knowledg'), ('data', 'data'), ('ability', 'abil'), ('find', 'find'), ('data', 'data'), ('automated', 'autom'), ('way', 'way'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('example', 'exampl'), (',', ','), ('Q-learning', 'q-learn'), (',', ','), ('algorithm', 'algorithm'), ('knowledge', 'knowledg'), ('data', 'data'), ('ability', 'abil'), ('find', 'find'), ('data', 'data'), ('automated', 'autom'), ('way', 'way'), ('(', '('), ('Wu', 'wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('example', 'example'), (',', ','), ('Q-learning', 'Q-learning'), (',', ','), ('algorithm', 'algorithm'), ('knowledge', 'knowledge'), ('data', 'data'), ('ability', 'ability'), ('find', 'find'), ('data', 'data'), ('automated', 'automated'), ('way', 'way'), ('(', '('), ('Wu', 'Wu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (';', ';'), ('Cui', 'Cui'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 319 =============================

Q-learning is one of the   most popular reinforcement learning algorithms, though it learns unrealistically high action values   as it includes ”a maximization step of overestimated action values, which tends to prefer   overestimated to underestimated values” (Hester et al., 2018). 


>> Tokens are: 
 ['Q-learning', 'one', 'popular', 'reinforcement', 'learning', 'algorithms', ',', 'though', 'learns', 'unrealistically', 'high', 'action', 'values', 'includes', '”', 'maximization', 'step', 'overestimated', 'action', 'values', ',', 'tends', 'prefer', 'overestimated', 'underestimated', 'values', '”', '(', 'Hester', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Q-learning', 'one'), ('one', 'popular'), ('popular', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'algorithms'), ('algorithms', ','), (',', 'though'), ('though', 'learns'), ('learns', 'unrealistically'), ('unrealistically', 'high'), ('high', 'action'), ('action', 'values'), ('values', 'includes'), ('includes', '”'), ('”', 'maximization'), ('maximization', 'step'), ('step', 'overestimated'), ('overestimated', 'action'), ('action', 'values'), ('values', ','), (',', 'tends'), ('tends', 'prefer'), ('prefer', 'overestimated'), ('overestimated', 'underestimated'), ('underestimated', 'values'), ('values', '”'), ('”', '('), ('(', 'Hester'), ('Hester', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Q-learning', 'one', 'popular'), ('one', 'popular', 'reinforcement'), ('popular', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'algorithms'), ('learning', 'algorithms', ','), ('algorithms', ',', 'though'), (',', 'though', 'learns'), ('though', 'learns', 'unrealistically'), ('learns', 'unrealistically', 'high'), ('unrealistically', 'high', 'action'), ('high', 'action', 'values'), ('action', 'values', 'includes'), ('values', 'includes', '”'), ('includes', '”', 'maximization'), ('”', 'maximization', 'step'), ('maximization', 'step', 'overestimated'), ('step', 'overestimated', 'action'), ('overestimated', 'action', 'values'), ('action', 'values', ','), ('values', ',', 'tends'), (',', 'tends', 'prefer'), ('tends', 'prefer', 'overestimated'), ('prefer', 'overestimated', 'underestimated'), ('overestimated', 'underestimated', 'values'), ('underestimated', 'values', '”'), ('values', '”', '('), ('”', '(', 'Hester'), ('(', 'Hester', 'et'), ('Hester', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Q-learning', 'VBG'), ('one', 'CD'), ('popular', 'JJ'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('algorithms', 'NN'), (',', ','), ('though', 'IN'), ('learns', 'NNS'), ('unrealistically', 'RB'), ('high', 'JJ'), ('action', 'NN'), ('values', 'NNS'), ('includes', 'VBZ'), ('”', 'JJ'), ('maximization', 'NN'), ('step', 'NN'), ('overestimated', 'VBN'), ('action', 'NN'), ('values', 'NNS'), (',', ','), ('tends', 'VBZ'), ('prefer', 'VBP'), ('overestimated', 'VBN'), ('underestimated', 'JJ'), ('values', 'NNS'), ('”', 'VBP'), ('(', '('), ('Hester', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  Q-learning/VBG
  one/CD
  (NP popular/JJ reinforcement/NN)
  learning/VBG
  (NP algorithms/NN)
  ,/,
  though/IN
  (NP learns/NNS)
  unrealistically/RB
  (NP high/JJ action/NN values/NNS)
  includes/VBZ
  (NP ”/JJ maximization/NN step/NN)
  overestimated/VBN
  (NP action/NN values/NNS)
  ,/,
  tends/VBZ
  prefer/VBP
  overestimated/VBN
  (NP underestimated/JJ values/NNS)
  ”/VBP
  (/(
  (NP Hester/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['popular reinforcement', 'algorithms', 'learns', 'high action values', '” maximization step', 'action values', 'underestimated values', 'Hester']

>> Named Entities are: 
 [('PERSON', 'Hester')] 

>> Stemming using Porter Stemmer: 
 [('Q-learning', 'q-learn'), ('one', 'one'), ('popular', 'popular'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('though', 'though'), ('learns', 'learn'), ('unrealistically', 'unrealist'), ('high', 'high'), ('action', 'action'), ('values', 'valu'), ('includes', 'includ'), ('”', '”'), ('maximization', 'maxim'), ('step', 'step'), ('overestimated', 'overestim'), ('action', 'action'), ('values', 'valu'), (',', ','), ('tends', 'tend'), ('prefer', 'prefer'), ('overestimated', 'overestim'), ('underestimated', 'underestim'), ('values', 'valu'), ('”', '”'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Q-learning', 'q-learn'), ('one', 'one'), ('popular', 'popular'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('algorithms', 'algorithm'), (',', ','), ('though', 'though'), ('learns', 'learn'), ('unrealistically', 'unrealist'), ('high', 'high'), ('action', 'action'), ('values', 'valu'), ('includes', 'includ'), ('”', '”'), ('maximization', 'maxim'), ('step', 'step'), ('overestimated', 'overestim'), ('action', 'action'), ('values', 'valu'), (',', ','), ('tends', 'tend'), ('prefer', 'prefer'), ('overestimated', 'overestim'), ('underestimated', 'underestim'), ('values', 'valu'), ('”', '”'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Q-learning', 'Q-learning'), ('one', 'one'), ('popular', 'popular'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('algorithms', 'algorithm'), (',', ','), ('though', 'though'), ('learns', 'learns'), ('unrealistically', 'unrealistically'), ('high', 'high'), ('action', 'action'), ('values', 'value'), ('includes', 'includes'), ('”', '”'), ('maximization', 'maximization'), ('step', 'step'), ('overestimated', 'overestimated'), ('action', 'action'), ('values', 'value'), (',', ','), ('tends', 'tends'), ('prefer', 'prefer'), ('overestimated', 'overestimated'), ('underestimated', 'underestimated'), ('values', 'value'), ('”', '”'), ('(', '('), ('Hester', 'Hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 320 =============================

The Q-learning algorithm is thus   best used for overestimating action values in specific conditions. 


>> Tokens are: 
 ['The', 'Q-learning', 'algorithm', 'thus', 'best', 'used', 'overestimating', 'action', 'values', 'specific', 'conditions', '.']

>> Bigrams are: 
 [('The', 'Q-learning'), ('Q-learning', 'algorithm'), ('algorithm', 'thus'), ('thus', 'best'), ('best', 'used'), ('used', 'overestimating'), ('overestimating', 'action'), ('action', 'values'), ('values', 'specific'), ('specific', 'conditions'), ('conditions', '.')]

>> Trigrams are: 
 [('The', 'Q-learning', 'algorithm'), ('Q-learning', 'algorithm', 'thus'), ('algorithm', 'thus', 'best'), ('thus', 'best', 'used'), ('best', 'used', 'overestimating'), ('used', 'overestimating', 'action'), ('overestimating', 'action', 'values'), ('action', 'values', 'specific'), ('values', 'specific', 'conditions'), ('specific', 'conditions', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('Q-learning', 'JJ'), ('algorithm', 'NN'), ('thus', 'RB'), ('best', 'RB'), ('used', 'VBN'), ('overestimating', 'VBG'), ('action', 'NN'), ('values', 'NNS'), ('specific', 'JJ'), ('conditions', 'NNS'), ('.', '.')]

 (S
  (NP The/DT Q-learning/JJ algorithm/NN)
  thus/RB
  best/RB
  used/VBN
  overestimating/VBG
  (NP action/NN values/NNS)
  (NP specific/JJ conditions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The Q-learning algorithm', 'action values', 'specific conditions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('thus', 'thu'), ('best', 'best'), ('used', 'use'), ('overestimating', 'overestim'), ('action', 'action'), ('values', 'valu'), ('specific', 'specif'), ('conditions', 'condit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('thus', 'thus'), ('best', 'best'), ('used', 'use'), ('overestimating', 'overestim'), ('action', 'action'), ('values', 'valu'), ('specific', 'specif'), ('conditions', 'condit'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('Q-learning', 'Q-learning'), ('algorithm', 'algorithm'), ('thus', 'thus'), ('best', 'best'), ('used', 'used'), ('overestimating', 'overestimating'), ('action', 'action'), ('values', 'value'), ('specific', 'specific'), ('conditions', 'condition'), ('.', '.')]



============================ Sentence 321 =============================

Recently, Q-learning has been combined with deep neural networks to produce Double Q-learning   (DQN); that combination also suffers from overestimations (Mnih et al.,2015). 


>> Tokens are: 
 ['Recently', ',', 'Q-learning', 'combined', 'deep', 'neural', 'networks', 'produce', 'Double', 'Q-learning', '(', 'DQN', ')', ';', 'combination', 'also', 'suffers', 'overestimations', '(', 'Mnih', 'et', 'al.,2015', ')', '.']

>> Bigrams are: 
 [('Recently', ','), (',', 'Q-learning'), ('Q-learning', 'combined'), ('combined', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'produce'), ('produce', 'Double'), ('Double', 'Q-learning'), ('Q-learning', '('), ('(', 'DQN'), ('DQN', ')'), (')', ';'), (';', 'combination'), ('combination', 'also'), ('also', 'suffers'), ('suffers', 'overestimations'), ('overestimations', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.,2015'), ('al.,2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Recently', ',', 'Q-learning'), (',', 'Q-learning', 'combined'), ('Q-learning', 'combined', 'deep'), ('combined', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'produce'), ('networks', 'produce', 'Double'), ('produce', 'Double', 'Q-learning'), ('Double', 'Q-learning', '('), ('Q-learning', '(', 'DQN'), ('(', 'DQN', ')'), ('DQN', ')', ';'), (')', ';', 'combination'), (';', 'combination', 'also'), ('combination', 'also', 'suffers'), ('also', 'suffers', 'overestimations'), ('suffers', 'overestimations', '('), ('overestimations', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.,2015'), ('et', 'al.,2015', ')'), ('al.,2015', ')', '.')]

>> POS Tags are: 
 [('Recently', 'RB'), (',', ','), ('Q-learning', 'NNP'), ('combined', 'VBD'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('produce', 'VBP'), ('Double', 'JJ'), ('Q-learning', 'NNP'), ('(', '('), ('DQN', 'NNP'), (')', ')'), (';', ':'), ('combination', 'NN'), ('also', 'RB'), ('suffers', 'VBZ'), ('overestimations', 'NNS'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.,2015', 'RB'), (')', ')'), ('.', '.')]

 (S
  Recently/RB
  ,/,
  (NP Q-learning/NNP)
  combined/VBD
  (NP deep/JJ neural/JJ networks/NNS)
  produce/VBP
  (NP Double/JJ Q-learning/NNP)
  (/(
  (NP DQN/NNP)
  )/)
  ;/:
  (NP combination/NN)
  also/RB
  suffers/VBZ
  (NP overestimations/NNS)
  (/(
  (NP Mnih/NNP)
  et/RB
  al.,2015/RB
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Q-learning', 'deep neural networks', 'Double Q-learning', 'DQN', 'combination', 'overestimations', 'Mnih']

>> Named Entities are: 
 [('PERSON', 'Double'), ('ORGANIZATION', 'DQN'), ('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('Recently', 'recent'), (',', ','), ('Q-learning', 'q-learn'), ('combined', 'combin'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('produce', 'produc'), ('Double', 'doubl'), ('Q-learning', 'q-learn'), ('(', '('), ('DQN', 'dqn'), (')', ')'), (';', ';'), ('combination', 'combin'), ('also', 'also'), ('suffers', 'suffer'), ('overestimations', 'overestim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.,2015', 'al.,2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Recently', 'recent'), (',', ','), ('Q-learning', 'q-learn'), ('combined', 'combin'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('produce', 'produc'), ('Double', 'doubl'), ('Q-learning', 'q-learn'), ('(', '('), ('DQN', 'dqn'), (')', ')'), (';', ';'), ('combination', 'combin'), ('also', 'also'), ('suffers', 'suffer'), ('overestimations', 'overestim'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.,2015', 'al.,2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Recently', 'Recently'), (',', ','), ('Q-learning', 'Q-learning'), ('combined', 'combined'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('produce', 'produce'), ('Double', 'Double'), ('Q-learning', 'Q-learning'), ('(', '('), ('DQN', 'DQN'), (')', ')'), (';', ';'), ('combination', 'combination'), ('also', 'also'), ('suffers', 'suffers'), ('overestimations', 'overestimation'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.,2015', 'al.,2015'), (')', ')'), ('.', '.')]



============================ Sentence 322 =============================

Deep neural   networks are artificial neural networks with multiple layers between the input and output layer,   which help RL algorithms to provide effective performance. 


>> Tokens are: 
 ['Deep', 'neural', 'networks', 'artificial', 'neural', 'networks', 'multiple', 'layers', 'input', 'output', 'layer', ',', 'help', 'RL', 'algorithms', 'provide', 'effective', 'performance', '.']

>> Bigrams are: 
 [('Deep', 'neural'), ('neural', 'networks'), ('networks', 'artificial'), ('artificial', 'neural'), ('neural', 'networks'), ('networks', 'multiple'), ('multiple', 'layers'), ('layers', 'input'), ('input', 'output'), ('output', 'layer'), ('layer', ','), (',', 'help'), ('help', 'RL'), ('RL', 'algorithms'), ('algorithms', 'provide'), ('provide', 'effective'), ('effective', 'performance'), ('performance', '.')]

>> Trigrams are: 
 [('Deep', 'neural', 'networks'), ('neural', 'networks', 'artificial'), ('networks', 'artificial', 'neural'), ('artificial', 'neural', 'networks'), ('neural', 'networks', 'multiple'), ('networks', 'multiple', 'layers'), ('multiple', 'layers', 'input'), ('layers', 'input', 'output'), ('input', 'output', 'layer'), ('output', 'layer', ','), ('layer', ',', 'help'), (',', 'help', 'RL'), ('help', 'RL', 'algorithms'), ('RL', 'algorithms', 'provide'), ('algorithms', 'provide', 'effective'), ('provide', 'effective', 'performance'), ('effective', 'performance', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('multiple', 'JJ'), ('layers', 'NNS'), ('input', 'VBP'), ('output', 'NN'), ('layer', 'NN'), (',', ','), ('help', 'NN'), ('RL', 'NNP'), ('algorithms', 'VBZ'), ('provide', 'RB'), ('effective', 'JJ'), ('performance', 'NN'), ('.', '.')]

 (S
  (NP Deep/JJ neural/JJ networks/NNS)
  (NP artificial/JJ neural/JJ networks/NNS)
  (NP multiple/JJ layers/NNS)
  input/VBP
  (NP output/NN layer/NN)
  ,/,
  (NP help/NN RL/NNP)
  algorithms/VBZ
  provide/RB
  (NP effective/JJ performance/NN)
  ./.) 


>> Noun Phrases are: 
 ['Deep neural networks', 'artificial neural networks', 'multiple layers', 'output layer', 'help RL', 'effective performance']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('multiple', 'multipl'), ('layers', 'layer'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('help', 'help'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('effective', 'effect'), ('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('artificial', 'artifici'), ('neural', 'neural'), ('networks', 'network'), ('multiple', 'multipl'), ('layers', 'layer'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('help', 'help'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('provide', 'provid'), ('effective', 'effect'), ('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('neural', 'neural'), ('networks', 'network'), ('artificial', 'artificial'), ('neural', 'neural'), ('networks', 'network'), ('multiple', 'multiple'), ('layers', 'layer'), ('input', 'input'), ('output', 'output'), ('layer', 'layer'), (',', ','), ('help', 'help'), ('RL', 'RL'), ('algorithms', 'algorithm'), ('provide', 'provide'), ('effective', 'effective'), ('performance', 'performance'), ('.', '.')]



============================ Sentence 323 =============================

However, it was previously thought   was that combining simple online RL algorithms with deep neural networks was unstable (Mnih   et al., 2013; Mnih et al., 2015; Schulman et al., 2015; Mnih et al., 2016; Van Hasselt et al., 2016). 


>> Tokens are: 
 ['However', ',', 'previously', 'thought', 'combining', 'simple', 'online', 'RL', 'algorithms', 'deep', 'neural', 'networks', 'unstable', '(', 'Mnih', 'et', 'al.', ',', '2013', ';', 'Mnih', 'et', 'al.', ',', '2015', ';', 'Schulman', 'et', 'al.', ',', '2015', ';', 'Mnih', 'et', 'al.', ',', '2016', ';', 'Van', 'Hasselt', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('However', ','), (',', 'previously'), ('previously', 'thought'), ('thought', 'combining'), ('combining', 'simple'), ('simple', 'online'), ('online', 'RL'), ('RL', 'algorithms'), ('algorithms', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'unstable'), ('unstable', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Schulman'), ('Schulman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Van'), ('Van', 'Hasselt'), ('Hasselt', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('However', ',', 'previously'), (',', 'previously', 'thought'), ('previously', 'thought', 'combining'), ('thought', 'combining', 'simple'), ('combining', 'simple', 'online'), ('simple', 'online', 'RL'), ('online', 'RL', 'algorithms'), ('RL', 'algorithms', 'deep'), ('algorithms', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'unstable'), ('networks', 'unstable', '('), ('unstable', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Schulman'), (';', 'Schulman', 'et'), ('Schulman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Van'), (';', 'Van', 'Hasselt'), ('Van', 'Hasselt', 'et'), ('Hasselt', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('previously', 'RB'), ('thought', 'VBN'), ('combining', 'VBG'), ('simple', 'JJ'), ('online', 'JJ'), ('RL', 'NNP'), ('algorithms', 'NN'), ('deep', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('unstable', 'JJ'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (';', ':'), ('Schulman', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (';', ':'), ('Van', 'NNP'), ('Hasselt', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  However/RB
  ,/,
  previously/RB
  thought/VBN
  combining/VBG
  (NP simple/JJ online/JJ RL/NNP algorithms/NN)
  (NP deep/JJ neural/JJ networks/NNS)
  unstable/JJ
  (/(
  (NP Mnih/NNP)
  et/RB
  al./RB
  ,/,
  2013/CD
  ;/:
  (NP Mnih/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2015/CD
  ;/:
  (NP Schulman/NNP)
  et/VBZ
  al./RB
  ,/,
  2015/CD
  ;/:
  (NP Mnih/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  ;/:
  (NP Van/NNP Hasselt/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['simple online RL algorithms', 'deep neural networks', 'Mnih', 'Mnih', 'al.', 'Schulman', 'Mnih', 'al.', 'Van Hasselt', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Mnih'), ('PERSON', 'Schulman'), ('PERSON', 'Van Hasselt')] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('previously', 'previous'), ('thought', 'thought'), ('combining', 'combin'), ('simple', 'simpl'), ('online', 'onlin'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('unstable', 'unstabl'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('previously', 'previous'), ('thought', 'thought'), ('combining', 'combin'), ('simple', 'simpl'), ('online', 'onlin'), ('RL', 'rl'), ('algorithms', 'algorithm'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('unstable', 'unstabl'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('previously', 'previously'), ('thought', 'thought'), ('combining', 'combining'), ('simple', 'simple'), ('online', 'online'), ('RL', 'RL'), ('algorithms', 'algorithm'), ('deep', 'deep'), ('neural', 'neural'), ('networks', 'network'), ('unstable', 'unstable'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Schulman', 'Schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Van', 'Van'), ('Hasselt', 'Hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 324 =============================

The common idea arising from early studies was that the data sequences observed by online RL   agents were not stable, and had no strong correlations to RL updates. 


>> Tokens are: 
 ['The', 'common', 'idea', 'arising', 'early', 'studies', 'data', 'sequences', 'observed', 'online', 'RL', 'agents', 'stable', ',', 'strong', 'correlations', 'RL', 'updates', '.']

>> Bigrams are: 
 [('The', 'common'), ('common', 'idea'), ('idea', 'arising'), ('arising', 'early'), ('early', 'studies'), ('studies', 'data'), ('data', 'sequences'), ('sequences', 'observed'), ('observed', 'online'), ('online', 'RL'), ('RL', 'agents'), ('agents', 'stable'), ('stable', ','), (',', 'strong'), ('strong', 'correlations'), ('correlations', 'RL'), ('RL', 'updates'), ('updates', '.')]

>> Trigrams are: 
 [('The', 'common', 'idea'), ('common', 'idea', 'arising'), ('idea', 'arising', 'early'), ('arising', 'early', 'studies'), ('early', 'studies', 'data'), ('studies', 'data', 'sequences'), ('data', 'sequences', 'observed'), ('sequences', 'observed', 'online'), ('observed', 'online', 'RL'), ('online', 'RL', 'agents'), ('RL', 'agents', 'stable'), ('agents', 'stable', ','), ('stable', ',', 'strong'), (',', 'strong', 'correlations'), ('strong', 'correlations', 'RL'), ('correlations', 'RL', 'updates'), ('RL', 'updates', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('common', 'JJ'), ('idea', 'NN'), ('arising', 'VBG'), ('early', 'JJ'), ('studies', 'NNS'), ('data', 'NNS'), ('sequences', 'NNS'), ('observed', 'VBD'), ('online', 'JJ'), ('RL', 'NNP'), ('agents', 'NNS'), ('stable', 'JJ'), (',', ','), ('strong', 'JJ'), ('correlations', 'NNS'), ('RL', 'NNP'), ('updates', 'NNS'), ('.', '.')]

 (S
  (NP The/DT common/JJ idea/NN)
  arising/VBG
  (NP early/JJ studies/NNS data/NNS sequences/NNS)
  observed/VBD
  (NP online/JJ RL/NNP agents/NNS)
  stable/JJ
  ,/,
  (NP strong/JJ correlations/NNS RL/NNP updates/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The common idea', 'early studies data sequences', 'online RL agents', 'strong correlations RL updates']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('common', 'common'), ('idea', 'idea'), ('arising', 'aris'), ('early', 'earli'), ('studies', 'studi'), ('data', 'data'), ('sequences', 'sequenc'), ('observed', 'observ'), ('online', 'onlin'), ('RL', 'rl'), ('agents', 'agent'), ('stable', 'stabl'), (',', ','), ('strong', 'strong'), ('correlations', 'correl'), ('RL', 'rl'), ('updates', 'updat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('common', 'common'), ('idea', 'idea'), ('arising', 'aris'), ('early', 'earli'), ('studies', 'studi'), ('data', 'data'), ('sequences', 'sequenc'), ('observed', 'observ'), ('online', 'onlin'), ('RL', 'rl'), ('agents', 'agent'), ('stable', 'stabl'), (',', ','), ('strong', 'strong'), ('correlations', 'correl'), ('RL', 'rl'), ('updates', 'updat'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('common', 'common'), ('idea', 'idea'), ('arising', 'arising'), ('early', 'early'), ('studies', 'study'), ('data', 'data'), ('sequences', 'sequence'), ('observed', 'observed'), ('online', 'online'), ('RL', 'RL'), ('agents', 'agent'), ('stable', 'stable'), (',', ','), ('strong', 'strong'), ('correlations', 'correlation'), ('RL', 'RL'), ('updates', 'update'), ('.', '.')]



============================ Sentence 325 =============================

However, data can be batched   if the agent's data are stored in an experience replay memory (Schulman et al., 2015) or sampled   from different time steps randomly (Mnih et al., 2013; Mnih et al. 


>> Tokens are: 
 ['However', ',', 'data', 'batched', 'agent', "'s", 'data', 'stored', 'experience', 'replay', 'memory', '(', 'Schulman', 'et', 'al.', ',', '2015', ')', 'sampled', 'different', 'time', 'steps', 'randomly', '(', 'Mnih', 'et', 'al.', ',', '2013', ';', 'Mnih', 'et', 'al', '.']

>> Bigrams are: 
 [('However', ','), (',', 'data'), ('data', 'batched'), ('batched', 'agent'), ('agent', "'s"), ("'s", 'data'), ('data', 'stored'), ('stored', 'experience'), ('experience', 'replay'), ('replay', 'memory'), ('memory', '('), ('(', 'Schulman'), ('Schulman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', 'sampled'), ('sampled', 'different'), ('different', 'time'), ('time', 'steps'), ('steps', 'randomly'), ('randomly', '('), ('(', 'Mnih'), ('Mnih', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ';'), (';', 'Mnih'), ('Mnih', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('However', ',', 'data'), (',', 'data', 'batched'), ('data', 'batched', 'agent'), ('batched', 'agent', "'s"), ('agent', "'s", 'data'), ("'s", 'data', 'stored'), ('data', 'stored', 'experience'), ('stored', 'experience', 'replay'), ('experience', 'replay', 'memory'), ('replay', 'memory', '('), ('memory', '(', 'Schulman'), ('(', 'Schulman', 'et'), ('Schulman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', 'sampled'), (')', 'sampled', 'different'), ('sampled', 'different', 'time'), ('different', 'time', 'steps'), ('time', 'steps', 'randomly'), ('steps', 'randomly', '('), ('randomly', '(', 'Mnih'), ('(', 'Mnih', 'et'), ('Mnih', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Mnih'), (';', 'Mnih', 'et'), ('Mnih', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('data', 'NNS'), ('batched', 'VBD'), ('agent', 'NN'), ("'s", 'POS'), ('data', 'NNS'), ('stored', 'VBD'), ('experience', 'NN'), ('replay', 'NN'), ('memory', 'NN'), ('(', '('), ('Schulman', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('sampled', 'VBN'), ('different', 'JJ'), ('time', 'NN'), ('steps', 'NNS'), ('randomly', 'RB'), ('(', '('), ('Mnih', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (';', ':'), ('Mnih', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  (NP data/NNS)
  batched/VBD
  (NP agent/NN)
  's/POS
  (NP data/NNS)
  stored/VBD
  (NP experience/NN replay/NN memory/NN)
  (/(
  (NP Schulman/NNP)
  et/VBZ
  al./RB
  ,/,
  2015/CD
  )/)
  sampled/VBN
  (NP different/JJ time/NN steps/NNS)
  randomly/RB
  (/(
  (NP Mnih/NNP)
  et/RB
  al./RB
  ,/,
  2013/CD
  ;/:
  (NP Mnih/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['data', 'agent', 'data', 'experience replay memory', 'Schulman', 'different time steps', 'Mnih', 'Mnih', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'Schulman'), ('ORGANIZATION', 'Mnih')] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('data', 'data'), ('batched', 'batch'), ('agent', 'agent'), ("'s", "'s"), ('data', 'data'), ('stored', 'store'), ('experience', 'experi'), ('replay', 'replay'), ('memory', 'memori'), ('(', '('), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('sampled', 'sampl'), ('different', 'differ'), ('time', 'time'), ('steps', 'step'), ('randomly', 'randomli'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('data', 'data'), ('batched', 'batch'), ('agent', 'agent'), ("'s", "'s"), ('data', 'data'), ('stored', 'store'), ('experience', 'experi'), ('replay', 'replay'), ('memory', 'memori'), ('(', '('), ('Schulman', 'schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('sampled', 'sampl'), ('different', 'differ'), ('time', 'time'), ('steps', 'step'), ('randomly', 'random'), ('(', '('), ('Mnih', 'mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'mnih'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('data', 'data'), ('batched', 'batched'), ('agent', 'agent'), ("'s", "'s"), ('data', 'data'), ('stored', 'stored'), ('experience', 'experience'), ('replay', 'replay'), ('memory', 'memory'), ('(', '('), ('Schulman', 'Schulman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('sampled', 'sampled'), ('different', 'different'), ('time', 'time'), ('steps', 'step'), ('randomly', 'randomly'), ('(', '('), ('Mnih', 'Mnih'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Mnih', 'Mnih'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 326 =============================

, 2016; Van Hasselt et al., 2016),   and the Double Q-learning algorithm can work with large-scale function approximation (Hasselt,     Sarah Al-Shiakhli   26      H.V., 2010). 


>> Tokens are: 
 [',', '2016', ';', 'Van', 'Hasselt', 'et', 'al.', ',', '2016', ')', ',', 'Double', 'Q-learning', 'algorithm', 'work', 'large-scale', 'function', 'approximation', '(', 'Hasselt', ',', 'Sarah', 'Al-Shiakhli', '26', 'H.V.', ',', '2010', ')', '.']

>> Bigrams are: 
 [(',', '2016'), ('2016', ';'), (';', 'Van'), ('Van', 'Hasselt'), ('Hasselt', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', ','), (',', 'Double'), ('Double', 'Q-learning'), ('Q-learning', 'algorithm'), ('algorithm', 'work'), ('work', 'large-scale'), ('large-scale', 'function'), ('function', 'approximation'), ('approximation', '('), ('(', 'Hasselt'), ('Hasselt', ','), (',', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '26'), ('26', 'H.V.'), ('H.V.', ','), (',', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [(',', '2016', ';'), ('2016', ';', 'Van'), (';', 'Van', 'Hasselt'), ('Van', 'Hasselt', 'et'), ('Hasselt', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', ','), (')', ',', 'Double'), (',', 'Double', 'Q-learning'), ('Double', 'Q-learning', 'algorithm'), ('Q-learning', 'algorithm', 'work'), ('algorithm', 'work', 'large-scale'), ('work', 'large-scale', 'function'), ('large-scale', 'function', 'approximation'), ('function', 'approximation', '('), ('approximation', '(', 'Hasselt'), ('(', 'Hasselt', ','), ('Hasselt', ',', 'Sarah'), (',', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '26'), ('Al-Shiakhli', '26', 'H.V.'), ('26', 'H.V.', ','), ('H.V.', ',', '2010'), (',', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [(',', ','), ('2016', 'CD'), (';', ':'), ('Van', 'NNP'), ('Hasselt', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), (',', ','), ('Double', 'JJ'), ('Q-learning', 'JJ'), ('algorithm', 'NN'), ('work', 'NN'), ('large-scale', 'JJ'), ('function', 'NN'), ('approximation', 'NN'), ('(', '('), ('Hasselt', 'NNP'), (',', ','), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('26', 'CD'), ('H.V.', 'NNP'), (',', ','), ('2010', 'CD'), (')', ')'), ('.', '.')]

 (S
  ,/,
  2016/CD
  ;/:
  (NP Van/NNP Hasselt/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  )/)
  ,/,
  (NP Double/JJ Q-learning/JJ algorithm/NN work/NN)
  (NP large-scale/JJ function/NN approximation/NN)
  (/(
  (NP Hasselt/NNP)
  ,/,
  (NP Sarah/NNP Al-Shiakhli/NNP)
  26/CD
  (NP H.V./NNP)
  ,/,
  2010/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Van Hasselt', 'al.', 'Double Q-learning algorithm work', 'large-scale function approximation', 'Hasselt', 'Sarah Al-Shiakhli', 'H.V.']

>> Named Entities are: 
 [('PERSON', 'Van Hasselt'), ('ORGANIZATION', 'Double'), ('ORGANIZATION', 'Hasselt'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [(',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('Double', 'doubl'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('work', 'work'), ('large-scale', 'large-scal'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Hasselt', 'hasselt'), (',', ','), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('26', '26'), ('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(',', ','), ('2016', '2016'), (';', ';'), ('Van', 'van'), ('Hasselt', 'hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('Double', 'doubl'), ('Q-learning', 'q-learn'), ('algorithm', 'algorithm'), ('work', 'work'), ('large-scale', 'large-scal'), ('function', 'function'), ('approximation', 'approxim'), ('(', '('), ('Hasselt', 'hasselt'), (',', ','), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('26', '26'), ('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [(',', ','), ('2016', '2016'), (';', ';'), ('Van', 'Van'), ('Hasselt', 'Hasselt'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), (',', ','), ('Double', 'Double'), ('Q-learning', 'Q-learning'), ('algorithm', 'algorithm'), ('work', 'work'), ('large-scale', 'large-scale'), ('function', 'function'), ('approximation', 'approximation'), ('(', '('), ('Hasselt', 'Hasselt'), (',', ','), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('26', '26'), ('H.V.', 'H.V.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]



============================ Sentence 327 =============================

Thus, a new algorithm known as Double DQN (a combination of Double Q-learning   with neural networks) has been constructed which offers higher scores on several games; however,   this algorithm has not displayed more accurate value estimation (Hester et al., 2018). 


>> Tokens are: 
 ['Thus', ',', 'new', 'algorithm', 'known', 'Double', 'DQN', '(', 'combination', 'Double', 'Q-learning', 'neural', 'networks', ')', 'constructed', 'offers', 'higher', 'scores', 'several', 'games', ';', 'however', ',', 'algorithm', 'displayed', 'accurate', 'value', 'estimation', '(', 'Hester', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Thus', ','), (',', 'new'), ('new', 'algorithm'), ('algorithm', 'known'), ('known', 'Double'), ('Double', 'DQN'), ('DQN', '('), ('(', 'combination'), ('combination', 'Double'), ('Double', 'Q-learning'), ('Q-learning', 'neural'), ('neural', 'networks'), ('networks', ')'), (')', 'constructed'), ('constructed', 'offers'), ('offers', 'higher'), ('higher', 'scores'), ('scores', 'several'), ('several', 'games'), ('games', ';'), (';', 'however'), ('however', ','), (',', 'algorithm'), ('algorithm', 'displayed'), ('displayed', 'accurate'), ('accurate', 'value'), ('value', 'estimation'), ('estimation', '('), ('(', 'Hester'), ('Hester', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Thus', ',', 'new'), (',', 'new', 'algorithm'), ('new', 'algorithm', 'known'), ('algorithm', 'known', 'Double'), ('known', 'Double', 'DQN'), ('Double', 'DQN', '('), ('DQN', '(', 'combination'), ('(', 'combination', 'Double'), ('combination', 'Double', 'Q-learning'), ('Double', 'Q-learning', 'neural'), ('Q-learning', 'neural', 'networks'), ('neural', 'networks', ')'), ('networks', ')', 'constructed'), (')', 'constructed', 'offers'), ('constructed', 'offers', 'higher'), ('offers', 'higher', 'scores'), ('higher', 'scores', 'several'), ('scores', 'several', 'games'), ('several', 'games', ';'), ('games', ';', 'however'), (';', 'however', ','), ('however', ',', 'algorithm'), (',', 'algorithm', 'displayed'), ('algorithm', 'displayed', 'accurate'), ('displayed', 'accurate', 'value'), ('accurate', 'value', 'estimation'), ('value', 'estimation', '('), ('estimation', '(', 'Hester'), ('(', 'Hester', 'et'), ('Hester', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Thus', 'RB'), (',', ','), ('new', 'JJ'), ('algorithm', 'NN'), ('known', 'VBN'), ('Double', 'NNP'), ('DQN', 'NNP'), ('(', '('), ('combination', 'NN'), ('Double', 'NNP'), ('Q-learning', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), (')', ')'), ('constructed', 'VBD'), ('offers', 'NNS'), ('higher', 'RBR'), ('scores', 'NNS'), ('several', 'JJ'), ('games', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('algorithm', 'JJ'), ('displayed', 'VBN'), ('accurate', 'JJ'), ('value', 'NN'), ('estimation', 'NN'), ('(', '('), ('Hester', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  Thus/RB
  ,/,
  (NP new/JJ algorithm/NN)
  known/VBN
  (NP Double/NNP DQN/NNP)
  (/(
  (NP combination/NN Double/NNP)
  (NP Q-learning/JJ neural/JJ networks/NNS)
  )/)
  constructed/VBD
  (NP offers/NNS)
  higher/RBR
  (NP scores/NNS)
  (NP several/JJ games/NNS)
  ;/:
  however/RB
  ,/,
  algorithm/JJ
  displayed/VBN
  (NP accurate/JJ value/NN estimation/NN)
  (/(
  (NP Hester/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['new algorithm', 'Double DQN', 'combination Double', 'Q-learning neural networks', 'offers', 'scores', 'several games', 'accurate value estimation', 'Hester']

>> Named Entities are: 
 [('PERSON', 'Double DQN'), ('PERSON', 'Double'), ('PERSON', 'Hester')] 

>> Stemming using Porter Stemmer: 
 [('Thus', 'thu'), (',', ','), ('new', 'new'), ('algorithm', 'algorithm'), ('known', 'known'), ('Double', 'doubl'), ('DQN', 'dqn'), ('(', '('), ('combination', 'combin'), ('Double', 'doubl'), ('Q-learning', 'q-learn'), ('neural', 'neural'), ('networks', 'network'), (')', ')'), ('constructed', 'construct'), ('offers', 'offer'), ('higher', 'higher'), ('scores', 'score'), ('several', 'sever'), ('games', 'game'), (';', ';'), ('however', 'howev'), (',', ','), ('algorithm', 'algorithm'), ('displayed', 'display'), ('accurate', 'accur'), ('value', 'valu'), ('estimation', 'estim'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Thus', 'thus'), (',', ','), ('new', 'new'), ('algorithm', 'algorithm'), ('known', 'known'), ('Double', 'doubl'), ('DQN', 'dqn'), ('(', '('), ('combination', 'combin'), ('Double', 'doubl'), ('Q-learning', 'q-learn'), ('neural', 'neural'), ('networks', 'network'), (')', ')'), ('constructed', 'construct'), ('offers', 'offer'), ('higher', 'higher'), ('scores', 'score'), ('several', 'sever'), ('games', 'game'), (';', ';'), ('however', 'howev'), (',', ','), ('algorithm', 'algorithm'), ('displayed', 'display'), ('accurate', 'accur'), ('value', 'valu'), ('estimation', 'estim'), ('(', '('), ('Hester', 'hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Thus', 'Thus'), (',', ','), ('new', 'new'), ('algorithm', 'algorithm'), ('known', 'known'), ('Double', 'Double'), ('DQN', 'DQN'), ('(', '('), ('combination', 'combination'), ('Double', 'Double'), ('Q-learning', 'Q-learning'), ('neural', 'neural'), ('networks', 'network'), (')', ')'), ('constructed', 'constructed'), ('offers', 'offer'), ('higher', 'higher'), ('scores', 'score'), ('several', 'several'), ('games', 'game'), (';', ';'), ('however', 'however'), (',', ','), ('algorithm', 'algorithm'), ('displayed', 'displayed'), ('accurate', 'accurate'), ('value', 'value'), ('estimation', 'estimation'), ('(', '('), ('Hester', 'Hester'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 328 =============================

7.4. 


>> Tokens are: 
 ['7.4', '.']

>> Bigrams are: 
 [('7.4', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7.4', 'CD'), ('.', '.')]

 (S 7.4/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7.4', '7.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7.4', '7.4'), ('.', '.')]

>> Lemmatization: 
 [('7.4', '7.4'), ('.', '.')]



============================ Sentence 329 =============================

Analytics techniques       Correlation Analysis: this is an analytical method used to determine the relationships such as   “correlation, correlative dependence, and mutual restriction, among observed phenomena and   accordingly conducting forecast and control” (Chen, M., Mao, S. and Liu, Y., 2014), as shown in   Figure 15. 


>> Tokens are: 
 ['Analytics', 'techniques', 'Correlation', 'Analysis', ':', 'analytical', 'method', 'used', 'determine', 'relationships', '“', 'correlation', ',', 'correlative', 'dependence', ',', 'mutual', 'restriction', ',', 'among', 'observed', 'phenomena', 'accordingly', 'conducting', 'forecast', 'control', '”', '(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', ',', 'shown', 'Figure', '15', '.']

>> Bigrams are: 
 [('Analytics', 'techniques'), ('techniques', 'Correlation'), ('Correlation', 'Analysis'), ('Analysis', ':'), (':', 'analytical'), ('analytical', 'method'), ('method', 'used'), ('used', 'determine'), ('determine', 'relationships'), ('relationships', '“'), ('“', 'correlation'), ('correlation', ','), (',', 'correlative'), ('correlative', 'dependence'), ('dependence', ','), (',', 'mutual'), ('mutual', 'restriction'), ('restriction', ','), (',', 'among'), ('among', 'observed'), ('observed', 'phenomena'), ('phenomena', 'accordingly'), ('accordingly', 'conducting'), ('conducting', 'forecast'), ('forecast', 'control'), ('control', '”'), ('”', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '15'), ('15', '.')]

>> Trigrams are: 
 [('Analytics', 'techniques', 'Correlation'), ('techniques', 'Correlation', 'Analysis'), ('Correlation', 'Analysis', ':'), ('Analysis', ':', 'analytical'), (':', 'analytical', 'method'), ('analytical', 'method', 'used'), ('method', 'used', 'determine'), ('used', 'determine', 'relationships'), ('determine', 'relationships', '“'), ('relationships', '“', 'correlation'), ('“', 'correlation', ','), ('correlation', ',', 'correlative'), (',', 'correlative', 'dependence'), ('correlative', 'dependence', ','), ('dependence', ',', 'mutual'), (',', 'mutual', 'restriction'), ('mutual', 'restriction', ','), ('restriction', ',', 'among'), (',', 'among', 'observed'), ('among', 'observed', 'phenomena'), ('observed', 'phenomena', 'accordingly'), ('phenomena', 'accordingly', 'conducting'), ('accordingly', 'conducting', 'forecast'), ('conducting', 'forecast', 'control'), ('forecast', 'control', '”'), ('control', '”', '('), ('”', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '15'), ('Figure', '15', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('techniques', 'NNS'), ('Correlation', 'NNP'), ('Analysis', 'NN'), (':', ':'), ('analytical', 'JJ'), ('method', 'NN'), ('used', 'VBN'), ('determine', 'JJ'), ('relationships', 'NNS'), ('“', 'POS'), ('correlation', 'NN'), (',', ','), ('correlative', 'JJ'), ('dependence', 'NN'), (',', ','), ('mutual', 'JJ'), ('restriction', 'NN'), (',', ','), ('among', 'IN'), ('observed', 'JJ'), ('phenomena', 'NNS'), ('accordingly', 'RB'), ('conducting', 'VBG'), ('forecast', 'VBN'), ('control', 'NN'), ('”', 'NNP'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('15', 'CD'), ('.', '.')]

 (S
  (NP Analytics/NNS techniques/NNS Correlation/NNP Analysis/NN)
  :/:
  (NP analytical/JJ method/NN)
  used/VBN
  (NP determine/JJ relationships/NNS)
  “/POS
  (NP correlation/NN)
  ,/,
  (NP correlative/JJ dependence/NN)
  ,/,
  (NP mutual/JJ restriction/NN)
  ,/,
  among/IN
  (NP observed/JJ phenomena/NNS)
  accordingly/RB
  conducting/VBG
  forecast/VBN
  (NP control/NN ”/NNP)
  (/(
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Mao/NNP)
  ,/,
  (NP S./NNP Liu/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2014/CD
  )/)
  ,/,
  shown/VBN
  (NP Figure/NN)
  15/CD
  ./.) 


>> Noun Phrases are: 
 ['Analytics techniques Correlation Analysis', 'analytical method', 'determine relationships', 'correlation', 'correlative dependence', 'mutual restriction', 'observed phenomena', 'control ”', 'Chen', 'M.', 'Mao', 'S. Liu', 'Y.', 'Figure']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu'), ('Correlation', 'correl'), ('Analysis', 'analysi'), (':', ':'), ('analytical', 'analyt'), ('method', 'method'), ('used', 'use'), ('determine', 'determin'), ('relationships', 'relationship'), ('“', '“'), ('correlation', 'correl'), (',', ','), ('correlative', 'correl'), ('dependence', 'depend'), (',', ','), ('mutual', 'mutual'), ('restriction', 'restrict'), (',', ','), ('among', 'among'), ('observed', 'observ'), ('phenomena', 'phenomena'), ('accordingly', 'accordingli'), ('conducting', 'conduct'), ('forecast', 'forecast'), ('control', 'control'), ('”', '”'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('15', '15'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('techniques', 'techniqu'), ('Correlation', 'correl'), ('Analysis', 'analysi'), (':', ':'), ('analytical', 'analyt'), ('method', 'method'), ('used', 'use'), ('determine', 'determin'), ('relationships', 'relationship'), ('“', '“'), ('correlation', 'correl'), (',', ','), ('correlative', 'correl'), ('dependence', 'depend'), (',', ','), ('mutual', 'mutual'), ('restriction', 'restrict'), (',', ','), ('among', 'among'), ('observed', 'observ'), ('phenomena', 'phenomena'), ('accordingly', 'accord'), ('conducting', 'conduct'), ('forecast', 'forecast'), ('control', 'control'), ('”', '”'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('15', '15'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('techniques', 'technique'), ('Correlation', 'Correlation'), ('Analysis', 'Analysis'), (':', ':'), ('analytical', 'analytical'), ('method', 'method'), ('used', 'used'), ('determine', 'determine'), ('relationships', 'relationship'), ('“', '“'), ('correlation', 'correlation'), (',', ','), ('correlative', 'correlative'), ('dependence', 'dependence'), (',', ','), ('mutual', 'mutual'), ('restriction', 'restriction'), (',', ','), ('among', 'among'), ('observed', 'observed'), ('phenomena', 'phenomenon'), ('accordingly', 'accordingly'), ('conducting', 'conducting'), ('forecast', 'forecast'), ('control', 'control'), ('”', '”'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('15', '15'), ('.', '.')]



============================ Sentence 330 =============================

Positive correlation, on the left means while one variable increases so does the other. 


>> Tokens are: 
 ['Positive', 'correlation', ',', 'left', 'means', 'one', 'variable', 'increases', '.']

>> Bigrams are: 
 [('Positive', 'correlation'), ('correlation', ','), (',', 'left'), ('left', 'means'), ('means', 'one'), ('one', 'variable'), ('variable', 'increases'), ('increases', '.')]

>> Trigrams are: 
 [('Positive', 'correlation', ','), ('correlation', ',', 'left'), (',', 'left', 'means'), ('left', 'means', 'one'), ('means', 'one', 'variable'), ('one', 'variable', 'increases'), ('variable', 'increases', '.')]

>> POS Tags are: 
 [('Positive', 'JJ'), ('correlation', 'NN'), (',', ','), ('left', 'VBD'), ('means', 'VBZ'), ('one', 'CD'), ('variable', 'NN'), ('increases', 'NNS'), ('.', '.')]

 (S
  (NP Positive/JJ correlation/NN)
  ,/,
  left/VBD
  means/VBZ
  one/CD
  (NP variable/NN increases/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Positive correlation', 'variable increases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Positive', 'posit'), ('correlation', 'correl'), (',', ','), ('left', 'left'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Positive', 'posit'), ('correlation', 'correl'), (',', ','), ('left', 'left'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), ('.', '.')]

>> Lemmatization: 
 [('Positive', 'Positive'), ('correlation', 'correlation'), (',', ','), ('left', 'left'), ('means', 'mean'), ('one', 'one'), ('variable', 'variable'), ('increases', 'increase'), ('.', '.')]



============================ Sentence 331 =============================

No linear correlation on the middle means there is no visible relationship between the variables. 


>> Tokens are: 
 ['No', 'linear', 'correlation', 'middle', 'means', 'visible', 'relationship', 'variables', '.']

>> Bigrams are: 
 [('No', 'linear'), ('linear', 'correlation'), ('correlation', 'middle'), ('middle', 'means'), ('means', 'visible'), ('visible', 'relationship'), ('relationship', 'variables'), ('variables', '.')]

>> Trigrams are: 
 [('No', 'linear', 'correlation'), ('linear', 'correlation', 'middle'), ('correlation', 'middle', 'means'), ('middle', 'means', 'visible'), ('means', 'visible', 'relationship'), ('visible', 'relationship', 'variables'), ('relationship', 'variables', '.')]

>> POS Tags are: 
 [('No', 'DT'), ('linear', 'JJ'), ('correlation', 'NN'), ('middle', 'NN'), ('means', 'VBZ'), ('visible', 'JJ'), ('relationship', 'NN'), ('variables', 'NNS'), ('.', '.')]

 (S
  (NP No/DT linear/JJ correlation/NN middle/NN)
  means/VBZ
  (NP visible/JJ relationship/NN variables/NNS)
  ./.) 


>> Noun Phrases are: 
 ['No linear correlation middle', 'visible relationship variables']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('No', 'no'), ('linear', 'linear'), ('correlation', 'correl'), ('middle', 'middl'), ('means', 'mean'), ('visible', 'visibl'), ('relationship', 'relationship'), ('variables', 'variabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('No', 'no'), ('linear', 'linear'), ('correlation', 'correl'), ('middle', 'middl'), ('means', 'mean'), ('visible', 'visibl'), ('relationship', 'relationship'), ('variables', 'variabl'), ('.', '.')]

>> Lemmatization: 
 [('No', 'No'), ('linear', 'linear'), ('correlation', 'correlation'), ('middle', 'middle'), ('means', 'mean'), ('visible', 'visible'), ('relationship', 'relationship'), ('variables', 'variable'), ('.', '.')]



============================ Sentence 332 =============================

Negative correlation on the right means as one variable increases, the other decreases (Chen, M.,   Mao, S. and Liu, Y., 2014). 


>> Tokens are: 
 ['Negative', 'correlation', 'right', 'means', 'one', 'variable', 'increases', ',', 'decreases', '(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Negative', 'correlation'), ('correlation', 'right'), ('right', 'means'), ('means', 'one'), ('one', 'variable'), ('variable', 'increases'), ('increases', ','), (',', 'decreases'), ('decreases', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Negative', 'correlation', 'right'), ('correlation', 'right', 'means'), ('right', 'means', 'one'), ('means', 'one', 'variable'), ('one', 'variable', 'increases'), ('variable', 'increases', ','), ('increases', ',', 'decreases'), (',', 'decreases', '('), ('decreases', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Negative', 'JJ'), ('correlation', 'NN'), ('right', 'RB'), ('means', 'VBZ'), ('one', 'CD'), ('variable', 'NN'), ('increases', 'NNS'), (',', ','), ('decreases', 'NNS'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Negative/JJ correlation/NN)
  right/RB
  means/VBZ
  one/CD
  (NP variable/NN increases/NNS)
  ,/,
  (NP decreases/NNS)
  (/(
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Mao/NNP)
  ,/,
  (NP S./NNP Liu/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Negative correlation', 'variable increases', 'decreases', 'Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Negative'), ('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('Negative', 'neg'), ('correlation', 'correl'), ('right', 'right'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), (',', ','), ('decreases', 'decreas'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Negative', 'negat'), ('correlation', 'correl'), ('right', 'right'), ('means', 'mean'), ('one', 'one'), ('variable', 'variabl'), ('increases', 'increas'), (',', ','), ('decreases', 'decreas'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Negative', 'Negative'), ('correlation', 'correlation'), ('right', 'right'), ('means', 'mean'), ('one', 'one'), ('variable', 'variable'), ('increases', 'increase'), (',', ','), ('decreases', 'decrease'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 333 =============================

Figure 15: Correlation Analysis. 


>> Tokens are: 
 ['Figure', '15', ':', 'Correlation', 'Analysis', '.']

>> Bigrams are: 
 [('Figure', '15'), ('15', ':'), (':', 'Correlation'), ('Correlation', 'Analysis'), ('Analysis', '.')]

>> Trigrams are: 
 [('Figure', '15', ':'), ('15', ':', 'Correlation'), (':', 'Correlation', 'Analysis'), ('Correlation', 'Analysis', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('15', 'CD'), (':', ':'), ('Correlation', 'NN'), ('Analysis', 'NN'), ('.', '.')]

 (S (NP Figure/NN) 15/CD :/: (NP Correlation/NN Analysis/NN) ./.) 


>> Noun Phrases are: 
 ['Figure', 'Correlation Analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('15', '15'), (':', ':'), ('Correlation', 'correl'), ('Analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('15', '15'), (':', ':'), ('Correlation', 'correl'), ('Analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('15', '15'), (':', ':'), ('Correlation', 'Correlation'), ('Analysis', 'Analysis'), ('.', '.')]



============================ Sentence 334 =============================

Text Mining: This converts the content from unstructured text to structured text in order to help   uncover the meaning and the information contained. 


>> Tokens are: 
 ['Text', 'Mining', ':', 'This', 'converts', 'content', 'unstructured', 'text', 'structured', 'text', 'order', 'help', 'uncover', 'meaning', 'information', 'contained', '.']

>> Bigrams are: 
 [('Text', 'Mining'), ('Mining', ':'), (':', 'This'), ('This', 'converts'), ('converts', 'content'), ('content', 'unstructured'), ('unstructured', 'text'), ('text', 'structured'), ('structured', 'text'), ('text', 'order'), ('order', 'help'), ('help', 'uncover'), ('uncover', 'meaning'), ('meaning', 'information'), ('information', 'contained'), ('contained', '.')]

>> Trigrams are: 
 [('Text', 'Mining', ':'), ('Mining', ':', 'This'), (':', 'This', 'converts'), ('This', 'converts', 'content'), ('converts', 'content', 'unstructured'), ('content', 'unstructured', 'text'), ('unstructured', 'text', 'structured'), ('text', 'structured', 'text'), ('structured', 'text', 'order'), ('text', 'order', 'help'), ('order', 'help', 'uncover'), ('help', 'uncover', 'meaning'), ('uncover', 'meaning', 'information'), ('meaning', 'information', 'contained'), ('information', 'contained', '.')]

>> POS Tags are: 
 [('Text', 'NN'), ('Mining', 'NN'), (':', ':'), ('This', 'DT'), ('converts', 'VBZ'), ('content', 'NN'), ('unstructured', 'JJ'), ('text', 'NN'), ('structured', 'VBD'), ('text', 'JJ'), ('order', 'NN'), ('help', 'NN'), ('uncover', 'VB'), ('meaning', 'VBG'), ('information', 'NN'), ('contained', 'VBN'), ('.', '.')]

 (S
  (NP Text/NN Mining/NN)
  :/:
  This/DT
  converts/VBZ
  (NP content/NN)
  (NP unstructured/JJ text/NN)
  structured/VBD
  (NP text/JJ order/NN help/NN)
  uncover/VB
  meaning/VBG
  (NP information/NN)
  contained/VBN
  ./.) 


>> Noun Phrases are: 
 ['Text Mining', 'content', 'unstructured text', 'text order help', 'information']

>> Named Entities are: 
 [('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('Mining', 'mine'), (':', ':'), ('This', 'thi'), ('converts', 'convert'), ('content', 'content'), ('unstructured', 'unstructur'), ('text', 'text'), ('structured', 'structur'), ('text', 'text'), ('order', 'order'), ('help', 'help'), ('uncover', 'uncov'), ('meaning', 'mean'), ('information', 'inform'), ('contained', 'contain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('Mining', 'mine'), (':', ':'), ('This', 'this'), ('converts', 'convert'), ('content', 'content'), ('unstructured', 'unstructur'), ('text', 'text'), ('structured', 'structur'), ('text', 'text'), ('order', 'order'), ('help', 'help'), ('uncover', 'uncov'), ('meaning', 'mean'), ('information', 'inform'), ('contained', 'contain'), ('.', '.')]

>> Lemmatization: 
 [('Text', 'Text'), ('Mining', 'Mining'), (':', ':'), ('This', 'This'), ('converts', 'convert'), ('content', 'content'), ('unstructured', 'unstructured'), ('text', 'text'), ('structured', 'structured'), ('text', 'text'), ('order', 'order'), ('help', 'help'), ('uncover', 'uncover'), ('meaning', 'meaning'), ('information', 'information'), ('contained', 'contained'), ('.', '.')]



============================ Sentence 335 =============================

Factor Analysis: This groups several related variables into a single factor, which means that fewer   factors are used in analysis, which is thus simpler. 


>> Tokens are: 
 ['Factor', 'Analysis', ':', 'This', 'groups', 'several', 'related', 'variables', 'single', 'factor', ',', 'means', 'fewer', 'factors', 'used', 'analysis', ',', 'thus', 'simpler', '.']

>> Bigrams are: 
 [('Factor', 'Analysis'), ('Analysis', ':'), (':', 'This'), ('This', 'groups'), ('groups', 'several'), ('several', 'related'), ('related', 'variables'), ('variables', 'single'), ('single', 'factor'), ('factor', ','), (',', 'means'), ('means', 'fewer'), ('fewer', 'factors'), ('factors', 'used'), ('used', 'analysis'), ('analysis', ','), (',', 'thus'), ('thus', 'simpler'), ('simpler', '.')]

>> Trigrams are: 
 [('Factor', 'Analysis', ':'), ('Analysis', ':', 'This'), (':', 'This', 'groups'), ('This', 'groups', 'several'), ('groups', 'several', 'related'), ('several', 'related', 'variables'), ('related', 'variables', 'single'), ('variables', 'single', 'factor'), ('single', 'factor', ','), ('factor', ',', 'means'), (',', 'means', 'fewer'), ('means', 'fewer', 'factors'), ('fewer', 'factors', 'used'), ('factors', 'used', 'analysis'), ('used', 'analysis', ','), ('analysis', ',', 'thus'), (',', 'thus', 'simpler'), ('thus', 'simpler', '.')]

>> POS Tags are: 
 [('Factor', 'NN'), ('Analysis', 'NN'), (':', ':'), ('This', 'DT'), ('groups', 'NNS'), ('several', 'JJ'), ('related', 'JJ'), ('variables', 'NNS'), ('single', 'JJ'), ('factor', 'NN'), (',', ','), ('means', 'VBZ'), ('fewer', 'JJR'), ('factors', 'NNS'), ('used', 'VBD'), ('analysis', 'NN'), (',', ','), ('thus', 'RB'), ('simpler', 'NN'), ('.', '.')]

 (S
  (NP Factor/NN Analysis/NN)
  :/:
  (NP This/DT groups/NNS)
  (NP several/JJ related/JJ variables/NNS)
  (NP single/JJ factor/NN)
  ,/,
  means/VBZ
  fewer/JJR
  (NP factors/NNS)
  used/VBD
  (NP analysis/NN)
  ,/,
  thus/RB
  (NP simpler/NN)
  ./.) 


>> Noun Phrases are: 
 ['Factor Analysis', 'This groups', 'several related variables', 'single factor', 'factors', 'analysis', 'simpler']

>> Named Entities are: 
 [('GPE', 'Factor'), ('PERSON', 'Analysis')] 

>> Stemming using Porter Stemmer: 
 [('Factor', 'factor'), ('Analysis', 'analysi'), (':', ':'), ('This', 'thi'), ('groups', 'group'), ('several', 'sever'), ('related', 'relat'), ('variables', 'variabl'), ('single', 'singl'), ('factor', 'factor'), (',', ','), ('means', 'mean'), ('fewer', 'fewer'), ('factors', 'factor'), ('used', 'use'), ('analysis', 'analysi'), (',', ','), ('thus', 'thu'), ('simpler', 'simpler'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Factor', 'factor'), ('Analysis', 'analysi'), (':', ':'), ('This', 'this'), ('groups', 'group'), ('several', 'sever'), ('related', 'relat'), ('variables', 'variabl'), ('single', 'singl'), ('factor', 'factor'), (',', ','), ('means', 'mean'), ('fewer', 'fewer'), ('factors', 'factor'), ('used', 'use'), ('analysis', 'analysi'), (',', ','), ('thus', 'thus'), ('simpler', 'simpler'), ('.', '.')]

>> Lemmatization: 
 [('Factor', 'Factor'), ('Analysis', 'Analysis'), (':', ':'), ('This', 'This'), ('groups', 'group'), ('several', 'several'), ('related', 'related'), ('variables', 'variable'), ('single', 'single'), ('factor', 'factor'), (',', ','), ('means', 'mean'), ('fewer', 'fewer'), ('factors', 'factor'), ('used', 'used'), ('analysis', 'analysis'), (',', ','), ('thus', 'thus'), ('simpler', 'simpler'), ('.', '.')]



============================ Sentence 336 =============================

The research presented in Schelén et al. 


>> Tokens are: 
 ['The', 'research', 'presented', 'Schelén', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'research'), ('research', 'presented'), ('presented', 'Schelén'), ('Schelén', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'research', 'presented'), ('research', 'presented', 'Schelén'), ('presented', 'Schelén', 'et'), ('Schelén', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('research', 'NN'), ('presented', 'VBD'), ('Schelén', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S
  (NP The/DT research/NN)
  presented/VBD
  (NP Schelén/NNP)
  et/CC
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['The research', 'Schelén', 'al']

>> Named Entities are: 
 [('PERSON', 'Schelén')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('research', 'research'), ('presented', 'present'), ('Schelén', 'schelén'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('research', 'research'), ('presented', 'present'), ('Schelén', 'schelén'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('research', 'research'), ('presented', 'presented'), ('Schelén', 'Schelén'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 337 =============================

(2015) examines the state-of-the-art in big data at that time   and discusses research agendas. 


>> Tokens are: 
 ['(', '2015', ')', 'examines', 'state-of-the-art', 'big', 'data', 'time', 'discusses', 'research', 'agendas', '.']

>> Bigrams are: 
 [('(', '2015'), ('2015', ')'), (')', 'examines'), ('examines', 'state-of-the-art'), ('state-of-the-art', 'big'), ('big', 'data'), ('data', 'time'), ('time', 'discusses'), ('discusses', 'research'), ('research', 'agendas'), ('agendas', '.')]

>> Trigrams are: 
 [('(', '2015', ')'), ('2015', ')', 'examines'), (')', 'examines', 'state-of-the-art'), ('examines', 'state-of-the-art', 'big'), ('state-of-the-art', 'big', 'data'), ('big', 'data', 'time'), ('data', 'time', 'discusses'), ('time', 'discusses', 'research'), ('discusses', 'research', 'agendas'), ('research', 'agendas', '.')]

>> POS Tags are: 
 [('(', '('), ('2015', 'CD'), (')', ')'), ('examines', 'VBZ'), ('state-of-the-art', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('time', 'NN'), ('discusses', 'VBZ'), ('research', 'NN'), ('agendas', 'NN'), ('.', '.')]

 (S
  (/(
  2015/CD
  )/)
  examines/VBZ
  (NP state-of-the-art/JJ big/JJ data/NNS time/NN)
  discusses/VBZ
  (NP research/NN agendas/NN)
  ./.) 


>> Noun Phrases are: 
 ['state-of-the-art big data time', 'research agendas']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('examines', 'examin'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('time', 'time'), ('discusses', 'discuss'), ('research', 'research'), ('agendas', 'agenda'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('examines', 'examin'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('time', 'time'), ('discusses', 'discuss'), ('research', 'research'), ('agendas', 'agenda'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2015', '2015'), (')', ')'), ('examines', 'examines'), ('state-of-the-art', 'state-of-the-art'), ('big', 'big'), ('data', 'data'), ('time', 'time'), ('discusses', 'discus'), ('research', 'research'), ('agendas', 'agenda'), ('.', '.')]



============================ Sentence 338 =============================

In addition, it defines the basic technology and toolsets used. 


>> Tokens are: 
 ['In', 'addition', ',', 'defines', 'basic', 'technology', 'toolsets', 'used', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'defines'), ('defines', 'basic'), ('basic', 'technology'), ('technology', 'toolsets'), ('toolsets', 'used'), ('used', '.')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'defines'), (',', 'defines', 'basic'), ('defines', 'basic', 'technology'), ('basic', 'technology', 'toolsets'), ('technology', 'toolsets', 'used'), ('toolsets', 'used', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('defines', 'NNS'), ('basic', 'JJ'), ('technology', 'NN'), ('toolsets', 'NNS'), ('used', 'VBN'), ('.', '.')]

 (S
  In/IN
  (NP addition/NN)
  ,/,
  (NP defines/NNS)
  (NP basic/JJ technology/NN toolsets/NNS)
  used/VBN
  ./.) 


>> Noun Phrases are: 
 ['addition', 'defines', 'basic technology toolsets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('defines', 'defin'), ('basic', 'basic'), ('technology', 'technolog'), ('toolsets', 'toolset'), ('used', 'use'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('defines', 'defin'), ('basic', 'basic'), ('technology', 'technolog'), ('toolsets', 'toolset'), ('used', 'use'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('defines', 'defines'), ('basic', 'basic'), ('technology', 'technology'), ('toolsets', 'toolsets'), ('used', 'used'), ('.', '.')]



============================ Sentence 339 =============================

It is   not easy to analyse datasets with traditional data management techniques (Constantiou and   Kallinikos, 2015); therefore, new methods and tools have been developed for big data analytics,   as well as for storing and managing such data. 


>> Tokens are: 
 ['It', 'easy', 'analyse', 'datasets', 'traditional', 'data', 'management', 'techniques', '(', 'Constantiou', 'Kallinikos', ',', '2015', ')', ';', 'therefore', ',', 'new', 'methods', 'tools', 'developed', 'big', 'data', 'analytics', ',', 'well', 'storing', 'managing', 'data', '.']

>> Bigrams are: 
 [('It', 'easy'), ('easy', 'analyse'), ('analyse', 'datasets'), ('datasets', 'traditional'), ('traditional', 'data'), ('data', 'management'), ('management', 'techniques'), ('techniques', '('), ('(', 'Constantiou'), ('Constantiou', 'Kallinikos'), ('Kallinikos', ','), (',', '2015'), ('2015', ')'), (')', ';'), (';', 'therefore'), ('therefore', ','), (',', 'new'), ('new', 'methods'), ('methods', 'tools'), ('tools', 'developed'), ('developed', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'well'), ('well', 'storing'), ('storing', 'managing'), ('managing', 'data'), ('data', '.')]

>> Trigrams are: 
 [('It', 'easy', 'analyse'), ('easy', 'analyse', 'datasets'), ('analyse', 'datasets', 'traditional'), ('datasets', 'traditional', 'data'), ('traditional', 'data', 'management'), ('data', 'management', 'techniques'), ('management', 'techniques', '('), ('techniques', '(', 'Constantiou'), ('(', 'Constantiou', 'Kallinikos'), ('Constantiou', 'Kallinikos', ','), ('Kallinikos', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';'), (')', ';', 'therefore'), (';', 'therefore', ','), ('therefore', ',', 'new'), (',', 'new', 'methods'), ('new', 'methods', 'tools'), ('methods', 'tools', 'developed'), ('tools', 'developed', 'big'), ('developed', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'well'), (',', 'well', 'storing'), ('well', 'storing', 'managing'), ('storing', 'managing', 'data'), ('managing', 'data', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('easy', 'JJ'), ('analyse', 'JJ'), ('datasets', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('management', 'NN'), ('techniques', 'NNS'), ('(', '('), ('Constantiou', 'NNP'), ('Kallinikos', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':'), ('therefore', 'RB'), (',', ','), ('new', 'JJ'), ('methods', 'NNS'), ('tools', 'NNS'), ('developed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('well', 'RB'), ('storing', 'VBG'), ('managing', 'VBG'), ('data', 'NNS'), ('.', '.')]

 (S
  It/PRP
  (NP easy/JJ analyse/JJ datasets/NNS)
  (NP traditional/JJ data/NNS management/NN techniques/NNS)
  (/(
  (NP Constantiou/NNP Kallinikos/NNP)
  ,/,
  2015/CD
  )/)
  ;/:
  therefore/RB
  ,/,
  (NP new/JJ methods/NNS tools/NNS)
  developed/VBD
  (NP big/JJ data/NNS analytics/NNS)
  ,/,
  well/RB
  storing/VBG
  managing/VBG
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['easy analyse datasets', 'traditional data management techniques', 'Constantiou Kallinikos', 'new methods tools', 'big data analytics', 'data']

>> Named Entities are: 
 [('ORGANIZATION', 'Constantiou Kallinikos')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('techniques', 'techniqu'), ('(', '('), ('Constantiou', 'constanti'), ('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('new', 'new'), ('methods', 'method'), ('tools', 'tool'), ('developed', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('well', 'well'), ('storing', 'store'), ('managing', 'manag'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('easy', 'easi'), ('analyse', 'analys'), ('datasets', 'dataset'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), ('techniques', 'techniqu'), ('(', '('), ('Constantiou', 'constantiou'), ('Kallinikos', 'kalliniko'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('therefore', 'therefor'), (',', ','), ('new', 'new'), ('methods', 'method'), ('tools', 'tool'), ('developed', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('well', 'well'), ('storing', 'store'), ('managing', 'manag'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('easy', 'easy'), ('analyse', 'analyse'), ('datasets', 'datasets'), ('traditional', 'traditional'), ('data', 'data'), ('management', 'management'), ('techniques', 'technique'), ('(', '('), ('Constantiou', 'Constantiou'), ('Kallinikos', 'Kallinikos'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('therefore', 'therefore'), (',', ','), ('new', 'new'), ('methods', 'method'), ('tools', 'tool'), ('developed', 'developed'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('well', 'well'), ('storing', 'storing'), ('managing', 'managing'), ('data', 'data'), ('.', '.')]



============================ Sentence 340 =============================

These solutions thus need to be studied in terms of   handling datasets and extracting knowledge and value. 


>> Tokens are: 
 ['These', 'solutions', 'thus', 'need', 'studied', 'terms', 'handling', 'datasets', 'extracting', 'knowledge', 'value', '.']

>> Bigrams are: 
 [('These', 'solutions'), ('solutions', 'thus'), ('thus', 'need'), ('need', 'studied'), ('studied', 'terms'), ('terms', 'handling'), ('handling', 'datasets'), ('datasets', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'value'), ('value', '.')]

>> Trigrams are: 
 [('These', 'solutions', 'thus'), ('solutions', 'thus', 'need'), ('thus', 'need', 'studied'), ('need', 'studied', 'terms'), ('studied', 'terms', 'handling'), ('terms', 'handling', 'datasets'), ('handling', 'datasets', 'extracting'), ('datasets', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'value'), ('knowledge', 'value', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('solutions', 'NNS'), ('thus', 'RB'), ('need', 'VBP'), ('studied', 'JJ'), ('terms', 'NNS'), ('handling', 'VBG'), ('datasets', 'NNS'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('value', 'NN'), ('.', '.')]

 (S
  (NP These/DT solutions/NNS)
  thus/RB
  need/VBP
  (NP studied/JJ terms/NNS)
  handling/VBG
  (NP datasets/NNS)
  extracting/VBG
  (NP knowledge/NN value/NN)
  ./.) 


>> Noun Phrases are: 
 ['These solutions', 'studied terms', 'datasets', 'knowledge value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('solutions', 'solut'), ('thus', 'thu'), ('need', 'need'), ('studied', 'studi'), ('terms', 'term'), ('handling', 'handl'), ('datasets', 'dataset'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('solutions', 'solut'), ('thus', 'thus'), ('need', 'need'), ('studied', 'studi'), ('terms', 'term'), ('handling', 'handl'), ('datasets', 'dataset'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('solutions', 'solution'), ('thus', 'thus'), ('need', 'need'), ('studied', 'studied'), ('terms', 'term'), ('handling', 'handling'), ('datasets', 'datasets'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('value', 'value'), ('.', '.')]



============================ Sentence 341 =============================

In addition, the rapid changes in data   volume, variety, velocity, and value require decision makers to know how to obtain valuable   insights. 


>> Tokens are: 
 ['In', 'addition', ',', 'rapid', 'changes', 'data', 'volume', ',', 'variety', ',', 'velocity', ',', 'value', 'require', 'decision', 'makers', 'know', 'obtain', 'valuable', 'insights', '.']

>> Bigrams are: 
 [('In', 'addition'), ('addition', ','), (',', 'rapid'), ('rapid', 'changes'), ('changes', 'data'), ('data', 'volume'), ('volume', ','), (',', 'variety'), ('variety', ','), (',', 'velocity'), ('velocity', ','), (',', 'value'), ('value', 'require'), ('require', 'decision'), ('decision', 'makers'), ('makers', 'know'), ('know', 'obtain'), ('obtain', 'valuable'), ('valuable', 'insights'), ('insights', '.')]

>> Trigrams are: 
 [('In', 'addition', ','), ('addition', ',', 'rapid'), (',', 'rapid', 'changes'), ('rapid', 'changes', 'data'), ('changes', 'data', 'volume'), ('data', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'value'), (',', 'value', 'require'), ('value', 'require', 'decision'), ('require', 'decision', 'makers'), ('decision', 'makers', 'know'), ('makers', 'know', 'obtain'), ('know', 'obtain', 'valuable'), ('obtain', 'valuable', 'insights'), ('valuable', 'insights', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('addition', 'NN'), (',', ','), ('rapid', 'JJ'), ('changes', 'NNS'), ('data', 'NNS'), ('volume', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('value', 'NN'), ('require', 'VB'), ('decision', 'NN'), ('makers', 'NNS'), ('know', 'VBP'), ('obtain', 'VB'), ('valuable', 'JJ'), ('insights', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP addition/NN)
  ,/,
  (NP rapid/JJ changes/NNS data/NNS volume/NN)
  ,/,
  (NP variety/NN)
  ,/,
  (NP velocity/NN)
  ,/,
  (NP value/NN)
  require/VB
  (NP decision/NN makers/NNS)
  know/VBP
  obtain/VB
  (NP valuable/JJ insights/NNS)
  ./.) 


>> Noun Phrases are: 
 ['addition', 'rapid changes data volume', 'variety', 'velocity', 'value', 'decision makers', 'valuable insights']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('rapid', 'rapid'), ('changes', 'chang'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ','), ('value', 'valu'), ('require', 'requir'), ('decision', 'decis'), ('makers', 'maker'), ('know', 'know'), ('obtain', 'obtain'), ('valuable', 'valuabl'), ('insights', 'insight'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('addition', 'addit'), (',', ','), ('rapid', 'rapid'), ('changes', 'chang'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), (',', ','), ('velocity', 'veloc'), (',', ','), ('value', 'valu'), ('require', 'requir'), ('decision', 'decis'), ('makers', 'maker'), ('know', 'know'), ('obtain', 'obtain'), ('valuable', 'valuabl'), ('insights', 'insight'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('addition', 'addition'), (',', ','), ('rapid', 'rapid'), ('changes', 'change'), ('data', 'data'), ('volume', 'volume'), (',', ','), ('variety', 'variety'), (',', ','), ('velocity', 'velocity'), (',', ','), ('value', 'value'), ('require', 'require'), ('decision', 'decision'), ('makers', 'maker'), ('know', 'know'), ('obtain', 'obtain'), ('valuable', 'valuable'), ('insights', 'insight'), ('.', '.')]



============================ Sentence 342 =============================

Sarah Al-Shiakhli   27      Traditional data analysis uses formal statistical methods to analyse data, constructing, extracting,   and refining useful data, and identifying subject matter relationships in order to maximise the value   of data. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '27', 'Traditional', 'data', 'analysis', 'uses', 'formal', 'statistical', 'methods', 'analyse', 'data', ',', 'constructing', ',', 'extracting', ',', 'refining', 'useful', 'data', ',', 'identifying', 'subject', 'matter', 'relationships', 'order', 'maximise', 'value', 'data', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '27'), ('27', 'Traditional'), ('Traditional', 'data'), ('data', 'analysis'), ('analysis', 'uses'), ('uses', 'formal'), ('formal', 'statistical'), ('statistical', 'methods'), ('methods', 'analyse'), ('analyse', 'data'), ('data', ','), (',', 'constructing'), ('constructing', ','), (',', 'extracting'), ('extracting', ','), (',', 'refining'), ('refining', 'useful'), ('useful', 'data'), ('data', ','), (',', 'identifying'), ('identifying', 'subject'), ('subject', 'matter'), ('matter', 'relationships'), ('relationships', 'order'), ('order', 'maximise'), ('maximise', 'value'), ('value', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '27'), ('Al-Shiakhli', '27', 'Traditional'), ('27', 'Traditional', 'data'), ('Traditional', 'data', 'analysis'), ('data', 'analysis', 'uses'), ('analysis', 'uses', 'formal'), ('uses', 'formal', 'statistical'), ('formal', 'statistical', 'methods'), ('statistical', 'methods', 'analyse'), ('methods', 'analyse', 'data'), ('analyse', 'data', ','), ('data', ',', 'constructing'), (',', 'constructing', ','), ('constructing', ',', 'extracting'), (',', 'extracting', ','), ('extracting', ',', 'refining'), (',', 'refining', 'useful'), ('refining', 'useful', 'data'), ('useful', 'data', ','), ('data', ',', 'identifying'), (',', 'identifying', 'subject'), ('identifying', 'subject', 'matter'), ('subject', 'matter', 'relationships'), ('matter', 'relationships', 'order'), ('relationships', 'order', 'maximise'), ('order', 'maximise', 'value'), ('maximise', 'value', 'data'), ('value', 'data', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('27', 'CD'), ('Traditional', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('uses', 'VBZ'), ('formal', 'JJ'), ('statistical', 'JJ'), ('methods', 'NNS'), ('analyse', 'RB'), ('data', 'NNS'), (',', ','), ('constructing', 'NN'), (',', ','), ('extracting', 'VBG'), (',', ','), ('refining', 'VBG'), ('useful', 'JJ'), ('data', 'NNS'), (',', ','), ('identifying', 'VBG'), ('subject', 'JJ'), ('matter', 'NN'), ('relationships', 'NNS'), ('order', 'NN'), ('maximise', 'NN'), ('value', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  27/CD
  (NP Traditional/NNP data/NNS analysis/NN)
  uses/VBZ
  (NP formal/JJ statistical/JJ methods/NNS)
  analyse/RB
  (NP data/NNS)
  ,/,
  (NP constructing/NN)
  ,/,
  extracting/VBG
  ,/,
  refining/VBG
  (NP useful/JJ data/NNS)
  ,/,
  identifying/VBG
  (NP
    subject/JJ
    matter/NN
    relationships/NNS
    order/NN
    maximise/NN
    value/NN
    data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Traditional data analysis', 'formal statistical methods', 'data', 'constructing', 'useful data', 'subject matter relationships order maximise value data']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('27', '27'), ('Traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('uses', 'use'), ('formal', 'formal'), ('statistical', 'statist'), ('methods', 'method'), ('analyse', 'analys'), ('data', 'data'), (',', ','), ('constructing', 'construct'), (',', ','), ('extracting', 'extract'), (',', ','), ('refining', 'refin'), ('useful', 'use'), ('data', 'data'), (',', ','), ('identifying', 'identifi'), ('subject', 'subject'), ('matter', 'matter'), ('relationships', 'relationship'), ('order', 'order'), ('maximise', 'maximis'), ('value', 'valu'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('27', '27'), ('Traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('uses', 'use'), ('formal', 'formal'), ('statistical', 'statist'), ('methods', 'method'), ('analyse', 'analys'), ('data', 'data'), (',', ','), ('constructing', 'construct'), (',', ','), ('extracting', 'extract'), (',', ','), ('refining', 'refin'), ('useful', 'use'), ('data', 'data'), (',', ','), ('identifying', 'identifi'), ('subject', 'subject'), ('matter', 'matter'), ('relationships', 'relationship'), ('order', 'order'), ('maximise', 'maximis'), ('value', 'valu'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('27', '27'), ('Traditional', 'Traditional'), ('data', 'data'), ('analysis', 'analysis'), ('uses', 'us'), ('formal', 'formal'), ('statistical', 'statistical'), ('methods', 'method'), ('analyse', 'analyse'), ('data', 'data'), (',', ','), ('constructing', 'constructing'), (',', ','), ('extracting', 'extracting'), (',', ','), ('refining', 'refining'), ('useful', 'useful'), ('data', 'data'), (',', ','), ('identifying', 'identifying'), ('subject', 'subject'), ('matter', 'matter'), ('relationships', 'relationship'), ('order', 'order'), ('maximise', 'maximise'), ('value', 'value'), ('data', 'data'), ('.', '.')]



============================ Sentence 343 =============================

It can now be regarded as an analysis technique to be used for special kinds of data, though   many traditional data analysis methods are still be used for big data analysis where analysts have   backgrounds in statistics and computer science. 


>> Tokens are: 
 ['It', 'regarded', 'analysis', 'technique', 'used', 'special', 'kinds', 'data', ',', 'though', 'many', 'traditional', 'data', 'analysis', 'methods', 'still', 'used', 'big', 'data', 'analysis', 'analysts', 'backgrounds', 'statistics', 'computer', 'science', '.']

>> Bigrams are: 
 [('It', 'regarded'), ('regarded', 'analysis'), ('analysis', 'technique'), ('technique', 'used'), ('used', 'special'), ('special', 'kinds'), ('kinds', 'data'), ('data', ','), (',', 'though'), ('though', 'many'), ('many', 'traditional'), ('traditional', 'data'), ('data', 'analysis'), ('analysis', 'methods'), ('methods', 'still'), ('still', 'used'), ('used', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'analysts'), ('analysts', 'backgrounds'), ('backgrounds', 'statistics'), ('statistics', 'computer'), ('computer', 'science'), ('science', '.')]

>> Trigrams are: 
 [('It', 'regarded', 'analysis'), ('regarded', 'analysis', 'technique'), ('analysis', 'technique', 'used'), ('technique', 'used', 'special'), ('used', 'special', 'kinds'), ('special', 'kinds', 'data'), ('kinds', 'data', ','), ('data', ',', 'though'), (',', 'though', 'many'), ('though', 'many', 'traditional'), ('many', 'traditional', 'data'), ('traditional', 'data', 'analysis'), ('data', 'analysis', 'methods'), ('analysis', 'methods', 'still'), ('methods', 'still', 'used'), ('still', 'used', 'big'), ('used', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'analysts'), ('analysis', 'analysts', 'backgrounds'), ('analysts', 'backgrounds', 'statistics'), ('backgrounds', 'statistics', 'computer'), ('statistics', 'computer', 'science'), ('computer', 'science', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('regarded', 'VBD'), ('analysis', 'NN'), ('technique', 'NN'), ('used', 'VBN'), ('special', 'JJ'), ('kinds', 'NNS'), ('data', 'NNS'), (',', ','), ('though', 'IN'), ('many', 'JJ'), ('traditional', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('methods', 'NNS'), ('still', 'RB'), ('used', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('analysts', 'NNS'), ('backgrounds', 'VBP'), ('statistics', 'NNS'), ('computer', 'NN'), ('science', 'NN'), ('.', '.')]

 (S
  It/PRP
  regarded/VBD
  (NP analysis/NN technique/NN)
  used/VBN
  (NP special/JJ kinds/NNS data/NNS)
  ,/,
  though/IN
  (NP many/JJ traditional/JJ data/NNS analysis/NN methods/NNS)
  still/RB
  used/VBD
  (NP big/JJ data/NNS analysis/NN analysts/NNS)
  backgrounds/VBP
  (NP statistics/NNS computer/NN science/NN)
  ./.) 


>> Noun Phrases are: 
 ['analysis technique', 'special kinds data', 'many traditional data analysis methods', 'big data analysis analysts', 'statistics computer science']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('regarded', 'regard'), ('analysis', 'analysi'), ('technique', 'techniqu'), ('used', 'use'), ('special', 'special'), ('kinds', 'kind'), ('data', 'data'), (',', ','), ('though', 'though'), ('many', 'mani'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('still', 'still'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('analysts', 'analyst'), ('backgrounds', 'background'), ('statistics', 'statist'), ('computer', 'comput'), ('science', 'scienc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('regarded', 'regard'), ('analysis', 'analysi'), ('technique', 'techniqu'), ('used', 'use'), ('special', 'special'), ('kinds', 'kind'), ('data', 'data'), (',', ','), ('though', 'though'), ('many', 'mani'), ('traditional', 'tradit'), ('data', 'data'), ('analysis', 'analysi'), ('methods', 'method'), ('still', 'still'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('analysts', 'analyst'), ('backgrounds', 'background'), ('statistics', 'statist'), ('computer', 'comput'), ('science', 'scienc'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('regarded', 'regarded'), ('analysis', 'analysis'), ('technique', 'technique'), ('used', 'used'), ('special', 'special'), ('kinds', 'kind'), ('data', 'data'), (',', ','), ('though', 'though'), ('many', 'many'), ('traditional', 'traditional'), ('data', 'data'), ('analysis', 'analysis'), ('methods', 'method'), ('still', 'still'), ('used', 'used'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('analysts', 'analyst'), ('backgrounds', 'background'), ('statistics', 'statistic'), ('computer', 'computer'), ('science', 'science'), ('.', '.')]



============================ Sentence 344 =============================

Association rules, clustering, classification, decision trees, and regression are the most common   data analytics methods; however, some additional analyses have become common in terms of big   data, especially in terms of social media, which relies on social networking and content sharing. 


>> Tokens are: 
 ['Association', 'rules', ',', 'clustering', ',', 'classification', ',', 'decision', 'trees', ',', 'regression', 'common', 'data', 'analytics', 'methods', ';', 'however', ',', 'additional', 'analyses', 'become', 'common', 'terms', 'big', 'data', ',', 'especially', 'terms', 'social', 'media', ',', 'relies', 'social', 'networking', 'content', 'sharing', '.']

>> Bigrams are: 
 [('Association', 'rules'), ('rules', ','), (',', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', ','), (',', 'decision'), ('decision', 'trees'), ('trees', ','), (',', 'regression'), ('regression', 'common'), ('common', 'data'), ('data', 'analytics'), ('analytics', 'methods'), ('methods', ';'), (';', 'however'), ('however', ','), (',', 'additional'), ('additional', 'analyses'), ('analyses', 'become'), ('become', 'common'), ('common', 'terms'), ('terms', 'big'), ('big', 'data'), ('data', ','), (',', 'especially'), ('especially', 'terms'), ('terms', 'social'), ('social', 'media'), ('media', ','), (',', 'relies'), ('relies', 'social'), ('social', 'networking'), ('networking', 'content'), ('content', 'sharing'), ('sharing', '.')]

>> Trigrams are: 
 [('Association', 'rules', ','), ('rules', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'decision'), (',', 'decision', 'trees'), ('decision', 'trees', ','), ('trees', ',', 'regression'), (',', 'regression', 'common'), ('regression', 'common', 'data'), ('common', 'data', 'analytics'), ('data', 'analytics', 'methods'), ('analytics', 'methods', ';'), ('methods', ';', 'however'), (';', 'however', ','), ('however', ',', 'additional'), (',', 'additional', 'analyses'), ('additional', 'analyses', 'become'), ('analyses', 'become', 'common'), ('become', 'common', 'terms'), ('common', 'terms', 'big'), ('terms', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'especially'), (',', 'especially', 'terms'), ('especially', 'terms', 'social'), ('terms', 'social', 'media'), ('social', 'media', ','), ('media', ',', 'relies'), (',', 'relies', 'social'), ('relies', 'social', 'networking'), ('social', 'networking', 'content'), ('networking', 'content', 'sharing'), ('content', 'sharing', '.')]

>> POS Tags are: 
 [('Association', 'NNP'), ('rules', 'NNS'), (',', ','), ('clustering', 'VBG'), (',', ','), ('classification', 'NN'), (',', ','), ('decision', 'NN'), ('trees', 'NNS'), (',', ','), ('regression', 'NN'), ('common', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('methods', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('additional', 'JJ'), ('analyses', 'VBZ'), ('become', 'JJ'), ('common', 'JJ'), ('terms', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('especially', 'RB'), ('terms', 'NNS'), ('social', 'JJ'), ('media', 'NNS'), (',', ','), ('relies', 'NNS'), ('social', 'JJ'), ('networking', 'JJ'), ('content', 'NN'), ('sharing', 'NN'), ('.', '.')]

 (S
  (NP Association/NNP rules/NNS)
  ,/,
  clustering/VBG
  ,/,
  (NP classification/NN)
  ,/,
  (NP decision/NN trees/NNS)
  ,/,
  (NP regression/NN)
  (NP common/JJ data/NN analytics/NNS methods/NNS)
  ;/:
  however/RB
  ,/,
  additional/JJ
  analyses/VBZ
  (NP become/JJ common/JJ terms/NNS)
  (NP big/JJ data/NNS)
  ,/,
  especially/RB
  (NP terms/NNS)
  (NP social/JJ media/NNS)
  ,/,
  (NP relies/NNS)
  (NP social/JJ networking/JJ content/NN sharing/NN)
  ./.) 


>> Noun Phrases are: 
 ['Association rules', 'classification', 'decision trees', 'regression', 'common data analytics methods', 'become common terms', 'big data', 'terms', 'social media', 'relies', 'social networking content sharing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Association', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), ('common', 'common'), ('data', 'data'), ('analytics', 'analyt'), ('methods', 'method'), (';', ';'), ('however', 'howev'), (',', ','), ('additional', 'addit'), ('analyses', 'analys'), ('become', 'becom'), ('common', 'common'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), (',', ','), ('especially', 'especi'), ('terms', 'term'), ('social', 'social'), ('media', 'media'), (',', ','), ('relies', 'reli'), ('social', 'social'), ('networking', 'network'), ('content', 'content'), ('sharing', 'share'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Association', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), ('common', 'common'), ('data', 'data'), ('analytics', 'analyt'), ('methods', 'method'), (';', ';'), ('however', 'howev'), (',', ','), ('additional', 'addit'), ('analyses', 'analys'), ('become', 'becom'), ('common', 'common'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), (',', ','), ('especially', 'especi'), ('terms', 'term'), ('social', 'social'), ('media', 'media'), (',', ','), ('relies', 'reli'), ('social', 'social'), ('networking', 'network'), ('content', 'content'), ('sharing', 'share'), ('.', '.')]

>> Lemmatization: 
 [('Association', 'Association'), ('rules', 'rule'), (',', ','), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('decision', 'decision'), ('trees', 'tree'), (',', ','), ('regression', 'regression'), ('common', 'common'), ('data', 'data'), ('analytics', 'analytics'), ('methods', 'method'), (';', ';'), ('however', 'however'), (',', ','), ('additional', 'additional'), ('analyses', 'analysis'), ('become', 'become'), ('common', 'common'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), (',', ','), ('especially', 'especially'), ('terms', 'term'), ('social', 'social'), ('media', 'medium'), (',', ','), ('relies', 'relies'), ('social', 'social'), ('networking', 'networking'), ('content', 'content'), ('sharing', 'sharing'), ('.', '.')]



============================ Sentence 345 =============================

Social network analysis is thus dependent on the relationships between social entities. 


>> Tokens are: 
 ['Social', 'network', 'analysis', 'thus', 'dependent', 'relationships', 'social', 'entities', '.']

>> Bigrams are: 
 [('Social', 'network'), ('network', 'analysis'), ('analysis', 'thus'), ('thus', 'dependent'), ('dependent', 'relationships'), ('relationships', 'social'), ('social', 'entities'), ('entities', '.')]

>> Trigrams are: 
 [('Social', 'network', 'analysis'), ('network', 'analysis', 'thus'), ('analysis', 'thus', 'dependent'), ('thus', 'dependent', 'relationships'), ('dependent', 'relationships', 'social'), ('relationships', 'social', 'entities'), ('social', 'entities', '.')]

>> POS Tags are: 
 [('Social', 'NNP'), ('network', 'NN'), ('analysis', 'NN'), ('thus', 'RB'), ('dependent', 'JJ'), ('relationships', 'NNS'), ('social', 'JJ'), ('entities', 'NNS'), ('.', '.')]

 (S
  (NP Social/NNP network/NN analysis/NN)
  thus/RB
  (NP dependent/JJ relationships/NNS)
  (NP social/JJ entities/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Social network analysis', 'dependent relationships', 'social entities']

>> Named Entities are: 
 [('GPE', 'Social')] 

>> Stemming using Porter Stemmer: 
 [('Social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('thus', 'thu'), ('dependent', 'depend'), ('relationships', 'relationship'), ('social', 'social'), ('entities', 'entiti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('thus', 'thus'), ('dependent', 'depend'), ('relationships', 'relationship'), ('social', 'social'), ('entities', 'entiti'), ('.', '.')]

>> Lemmatization: 
 [('Social', 'Social'), ('network', 'network'), ('analysis', 'analysis'), ('thus', 'thus'), ('dependent', 'dependent'), ('relationships', 'relationship'), ('social', 'social'), ('entities', 'entity'), ('.', '.')]



============================ Sentence 346 =============================

Text mining   used to analyse the contents of documents and to develop an understanding of the information   therein. 


>> Tokens are: 
 ['Text', 'mining', 'used', 'analyse', 'contents', 'documents', 'develop', 'understanding', 'information', 'therein', '.']

>> Bigrams are: 
 [('Text', 'mining'), ('mining', 'used'), ('used', 'analyse'), ('analyse', 'contents'), ('contents', 'documents'), ('documents', 'develop'), ('develop', 'understanding'), ('understanding', 'information'), ('information', 'therein'), ('therein', '.')]

>> Trigrams are: 
 [('Text', 'mining', 'used'), ('mining', 'used', 'analyse'), ('used', 'analyse', 'contents'), ('analyse', 'contents', 'documents'), ('contents', 'documents', 'develop'), ('documents', 'develop', 'understanding'), ('develop', 'understanding', 'information'), ('understanding', 'information', 'therein'), ('information', 'therein', '.')]

>> POS Tags are: 
 [('Text', 'NN'), ('mining', 'NN'), ('used', 'VBN'), ('analyse', 'JJ'), ('contents', 'NNS'), ('documents', 'NNS'), ('develop', 'VB'), ('understanding', 'JJ'), ('information', 'NN'), ('therein', 'NN'), ('.', '.')]

 (S
  (NP Text/NN mining/NN)
  used/VBN
  (NP analyse/JJ contents/NNS documents/NNS)
  develop/VB
  (NP understanding/JJ information/NN therein/NN)
  ./.) 


>> Noun Phrases are: 
 ['Text mining', 'analyse contents documents', 'understanding information therein']

>> Named Entities are: 
 [('GPE', 'Text')] 

>> Stemming using Porter Stemmer: 
 [('Text', 'text'), ('mining', 'mine'), ('used', 'use'), ('analyse', 'analys'), ('contents', 'content'), ('documents', 'document'), ('develop', 'develop'), ('understanding', 'understand'), ('information', 'inform'), ('therein', 'therein'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Text', 'text'), ('mining', 'mine'), ('used', 'use'), ('analyse', 'analys'), ('contents', 'content'), ('documents', 'document'), ('develop', 'develop'), ('understanding', 'understand'), ('information', 'inform'), ('therein', 'therein'), ('.', '.')]

>> Lemmatization: 
 [('Text', 'Text'), ('mining', 'mining'), ('used', 'used'), ('analyse', 'analyse'), ('contents', 'content'), ('documents', 'document'), ('develop', 'develop'), ('understanding', 'understanding'), ('information', 'information'), ('therein', 'therein'), ('.', '.')]



============================ Sentence 347 =============================

Sentiment analysis is then used to analyse the emotions underlying that content, and this   more important form of analysis uses language processing to identify such information. 


>> Tokens are: 
 ['Sentiment', 'analysis', 'used', 'analyse', 'emotions', 'underlying', 'content', ',', 'important', 'form', 'analysis', 'uses', 'language', 'processing', 'identify', 'information', '.']

>> Bigrams are: 
 [('Sentiment', 'analysis'), ('analysis', 'used'), ('used', 'analyse'), ('analyse', 'emotions'), ('emotions', 'underlying'), ('underlying', 'content'), ('content', ','), (',', 'important'), ('important', 'form'), ('form', 'analysis'), ('analysis', 'uses'), ('uses', 'language'), ('language', 'processing'), ('processing', 'identify'), ('identify', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Sentiment', 'analysis', 'used'), ('analysis', 'used', 'analyse'), ('used', 'analyse', 'emotions'), ('analyse', 'emotions', 'underlying'), ('emotions', 'underlying', 'content'), ('underlying', 'content', ','), ('content', ',', 'important'), (',', 'important', 'form'), ('important', 'form', 'analysis'), ('form', 'analysis', 'uses'), ('analysis', 'uses', 'language'), ('uses', 'language', 'processing'), ('language', 'processing', 'identify'), ('processing', 'identify', 'information'), ('identify', 'information', '.')]

>> POS Tags are: 
 [('Sentiment', 'NN'), ('analysis', 'NN'), ('used', 'VBN'), ('analyse', 'JJ'), ('emotions', 'NNS'), ('underlying', 'VBG'), ('content', 'NN'), (',', ','), ('important', 'JJ'), ('form', 'NN'), ('analysis', 'NN'), ('uses', 'VBZ'), ('language', 'NN'), ('processing', 'VBG'), ('identify', 'JJ'), ('information', 'NN'), ('.', '.')]

 (S
  (NP Sentiment/NN analysis/NN)
  used/VBN
  (NP analyse/JJ emotions/NNS)
  underlying/VBG
  (NP content/NN)
  ,/,
  (NP important/JJ form/NN analysis/NN)
  uses/VBZ
  (NP language/NN)
  processing/VBG
  (NP identify/JJ information/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sentiment analysis', 'analyse emotions', 'content', 'important form analysis', 'language', 'identify information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('used', 'use'), ('analyse', 'analys'), ('emotions', 'emot'), ('underlying', 'underli'), ('content', 'content'), (',', ','), ('important', 'import'), ('form', 'form'), ('analysis', 'analysi'), ('uses', 'use'), ('language', 'languag'), ('processing', 'process'), ('identify', 'identifi'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('used', 'use'), ('analyse', 'analys'), ('emotions', 'emot'), ('underlying', 'under'), ('content', 'content'), (',', ','), ('important', 'import'), ('form', 'form'), ('analysis', 'analysi'), ('uses', 'use'), ('language', 'languag'), ('processing', 'process'), ('identify', 'identifi'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('analysis', 'analysis'), ('used', 'used'), ('analyse', 'analyse'), ('emotions', 'emotion'), ('underlying', 'underlying'), ('content', 'content'), (',', ','), ('important', 'important'), ('form', 'form'), ('analysis', 'analysis'), ('uses', 'us'), ('language', 'language'), ('processing', 'processing'), ('identify', 'identify'), ('information', 'information'), ('.', '.')]



============================ Sentence 348 =============================

Finally, advanced data visualisation is becoming an important analysis tool, as this enables faster   and better decision making (Russom, 2011; Elgendy and Elragal, 2016). 


>> Tokens are: 
 ['Finally', ',', 'advanced', 'data', 'visualisation', 'becoming', 'important', 'analysis', 'tool', ',', 'enables', 'faster', 'better', 'decision', 'making', '(', 'Russom', ',', '2011', ';', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'advanced'), ('advanced', 'data'), ('data', 'visualisation'), ('visualisation', 'becoming'), ('becoming', 'important'), ('important', 'analysis'), ('analysis', 'tool'), ('tool', ','), (',', 'enables'), ('enables', 'faster'), ('faster', 'better'), ('better', 'decision'), ('decision', 'making'), ('making', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Finally', ',', 'advanced'), (',', 'advanced', 'data'), ('advanced', 'data', 'visualisation'), ('data', 'visualisation', 'becoming'), ('visualisation', 'becoming', 'important'), ('becoming', 'important', 'analysis'), ('important', 'analysis', 'tool'), ('analysis', 'tool', ','), ('tool', ',', 'enables'), (',', 'enables', 'faster'), ('enables', 'faster', 'better'), ('faster', 'better', 'decision'), ('better', 'decision', 'making'), ('decision', 'making', '('), ('making', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('advanced', 'VBD'), ('data', 'NNS'), ('visualisation', 'NN'), ('becoming', 'VBG'), ('important', 'JJ'), ('analysis', 'NN'), ('tool', 'NN'), (',', ','), ('enables', 'VBZ'), ('faster', 'RBR'), ('better', 'JJR'), ('decision', 'NN'), ('making', 'NN'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  advanced/VBD
  (NP data/NNS visualisation/NN)
  becoming/VBG
  (NP important/JJ analysis/NN tool/NN)
  ,/,
  enables/VBZ
  faster/RBR
  better/JJR
  (NP decision/NN making/NN)
  (/(
  (NP Russom/NNP)
  ,/,
  2011/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['data visualisation', 'important analysis tool', 'decision making', 'Russom', 'Elgendy Elragal']

>> Named Entities are: 
 [('GPE', 'Russom'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('advanced', 'advanc'), ('data', 'data'), ('visualisation', 'visualis'), ('becoming', 'becom'), ('important', 'import'), ('analysis', 'analysi'), ('tool', 'tool'), (',', ','), ('enables', 'enabl'), ('faster', 'faster'), ('better', 'better'), ('decision', 'decis'), ('making', 'make'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('advanced', 'advanc'), ('data', 'data'), ('visualisation', 'visualis'), ('becoming', 'becom'), ('important', 'import'), ('analysis', 'analysi'), ('tool', 'tool'), (',', ','), ('enables', 'enabl'), ('faster', 'faster'), ('better', 'better'), ('decision', 'decis'), ('making', 'make'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('advanced', 'advanced'), ('data', 'data'), ('visualisation', 'visualisation'), ('becoming', 'becoming'), ('important', 'important'), ('analysis', 'analysis'), ('tool', 'tool'), (',', ','), ('enables', 'enables'), ('faster', 'faster'), ('better', 'better'), ('decision', 'decision'), ('making', 'making'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 349 =============================

Some of the more   common models and analyses are explained further below, and shown in Figure 16:      • Text analytics:  ➢ Sentiment Analysis: This is based on understanding the subjects’ emotions from   their text patterns to help in organising viewpoints into good or bad, positive or   negative (Mouthami et al., 2013). 


>> Tokens are: 
 ['Some', 'common', 'models', 'analyses', 'explained', ',', 'shown', 'Figure', '16', ':', '•', 'Text', 'analytics', ':', '➢', 'Sentiment', 'Analysis', ':', 'This', 'based', 'understanding', 'subjects', '’', 'emotions', 'text', 'patterns', 'help', 'organising', 'viewpoints', 'good', 'bad', ',', 'positive', 'negative', '(', 'Mouthami', 'et', 'al.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('Some', 'common'), ('common', 'models'), ('models', 'analyses'), ('analyses', 'explained'), ('explained', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '16'), ('16', ':'), (':', '•'), ('•', 'Text'), ('Text', 'analytics'), ('analytics', ':'), (':', '➢'), ('➢', 'Sentiment'), ('Sentiment', 'Analysis'), ('Analysis', ':'), (':', 'This'), ('This', 'based'), ('based', 'understanding'), ('understanding', 'subjects'), ('subjects', '’'), ('’', 'emotions'), ('emotions', 'text'), ('text', 'patterns'), ('patterns', 'help'), ('help', 'organising'), ('organising', 'viewpoints'), ('viewpoints', 'good'), ('good', 'bad'), ('bad', ','), (',', 'positive'), ('positive', 'negative'), ('negative', '('), ('(', 'Mouthami'), ('Mouthami', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Some', 'common', 'models'), ('common', 'models', 'analyses'), ('models', 'analyses', 'explained'), ('analyses', 'explained', ','), ('explained', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '16'), ('Figure', '16', ':'), ('16', ':', '•'), (':', '•', 'Text'), ('•', 'Text', 'analytics'), ('Text', 'analytics', ':'), ('analytics', ':', '➢'), (':', '➢', 'Sentiment'), ('➢', 'Sentiment', 'Analysis'), ('Sentiment', 'Analysis', ':'), ('Analysis', ':', 'This'), (':', 'This', 'based'), ('This', 'based', 'understanding'), ('based', 'understanding', 'subjects'), ('understanding', 'subjects', '’'), ('subjects', '’', 'emotions'), ('’', 'emotions', 'text'), ('emotions', 'text', 'patterns'), ('text', 'patterns', 'help'), ('patterns', 'help', 'organising'), ('help', 'organising', 'viewpoints'), ('organising', 'viewpoints', 'good'), ('viewpoints', 'good', 'bad'), ('good', 'bad', ','), ('bad', ',', 'positive'), (',', 'positive', 'negative'), ('positive', 'negative', '('), ('negative', '(', 'Mouthami'), ('(', 'Mouthami', 'et'), ('Mouthami', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('common', 'JJ'), ('models', 'NNS'), ('analyses', 'NNS'), ('explained', 'VBD'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('16', 'CD'), (':', ':'), ('•', 'NN'), ('Text', 'IN'), ('analytics', 'NNS'), (':', ':'), ('➢', 'JJ'), ('Sentiment', 'NN'), ('Analysis', 'NN'), (':', ':'), ('This', 'DT'), ('based', 'VBN'), ('understanding', 'JJ'), ('subjects', 'NNS'), ('’', 'JJ'), ('emotions', 'NNS'), ('text', 'NN'), ('patterns', 'NNS'), ('help', 'VBP'), ('organising', 'VBG'), ('viewpoints', 'NNS'), ('good', 'JJ'), ('bad', 'JJ'), (',', ','), ('positive', 'JJ'), ('negative', 'JJ'), ('(', '('), ('Mouthami', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Some/DT common/JJ models/NNS analyses/NNS)
  explained/VBD
  ,/,
  shown/VBN
  (NP Figure/NN)
  16/CD
  :/:
  (NP •/NN)
  Text/IN
  (NP analytics/NNS)
  :/:
  (NP ➢/JJ Sentiment/NN Analysis/NN)
  :/:
  This/DT
  based/VBN
  (NP understanding/JJ subjects/NNS)
  (NP ’/JJ emotions/NNS text/NN patterns/NNS)
  help/VBP
  organising/VBG
  (NP viewpoints/NNS)
  good/JJ
  bad/JJ
  ,/,
  positive/JJ
  negative/JJ
  (/(
  (NP Mouthami/NNP)
  et/RB
  al./RB
  ,/,
  2013/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Some common models analyses', 'Figure', '•', 'analytics', '➢ Sentiment Analysis', 'understanding subjects', '’ emotions text patterns', 'viewpoints', 'Mouthami']

>> Named Entities are: 
 [('ORGANIZATION', 'Mouthami')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('common', 'common'), ('models', 'model'), ('analyses', 'analys'), ('explained', 'explain'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('16', '16'), (':', ':'), ('•', '•'), ('Text', 'text'), ('analytics', 'analyt'), (':', ':'), ('➢', '➢'), ('Sentiment', 'sentiment'), ('Analysis', 'analysi'), (':', ':'), ('This', 'thi'), ('based', 'base'), ('understanding', 'understand'), ('subjects', 'subject'), ('’', '’'), ('emotions', 'emot'), ('text', 'text'), ('patterns', 'pattern'), ('help', 'help'), ('organising', 'organis'), ('viewpoints', 'viewpoint'), ('good', 'good'), ('bad', 'bad'), (',', ','), ('positive', 'posit'), ('negative', 'neg'), ('(', '('), ('Mouthami', 'mouthami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('common', 'common'), ('models', 'model'), ('analyses', 'analys'), ('explained', 'explain'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('16', '16'), (':', ':'), ('•', '•'), ('Text', 'text'), ('analytics', 'analyt'), (':', ':'), ('➢', '➢'), ('Sentiment', 'sentiment'), ('Analysis', 'analysi'), (':', ':'), ('This', 'this'), ('based', 'base'), ('understanding', 'understand'), ('subjects', 'subject'), ('’', '’'), ('emotions', 'emot'), ('text', 'text'), ('patterns', 'pattern'), ('help', 'help'), ('organising', 'organis'), ('viewpoints', 'viewpoint'), ('good', 'good'), ('bad', 'bad'), (',', ','), ('positive', 'posit'), ('negative', 'negat'), ('(', '('), ('Mouthami', 'mouthami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('common', 'common'), ('models', 'model'), ('analyses', 'analysis'), ('explained', 'explained'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('16', '16'), (':', ':'), ('•', '•'), ('Text', 'Text'), ('analytics', 'analytics'), (':', ':'), ('➢', '➢'), ('Sentiment', 'Sentiment'), ('Analysis', 'Analysis'), (':', ':'), ('This', 'This'), ('based', 'based'), ('understanding', 'understanding'), ('subjects', 'subject'), ('’', '’'), ('emotions', 'emotion'), ('text', 'text'), ('patterns', 'pattern'), ('help', 'help'), ('organising', 'organising'), ('viewpoints', 'viewpoint'), ('good', 'good'), ('bad', 'bad'), (',', ','), ('positive', 'positive'), ('negative', 'negative'), ('(', '('), ('Mouthami', 'Mouthami'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



============================ Sentence 350 =============================

This analysis helps firms by alerting them where   customers are dissatisfied or seeking to shift to other products, allowing   preventative actions to be taken (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 ['This', 'analysis', 'helps', 'firms', 'alerting', 'customers', 'dissatisfied', 'seeking', 'shift', 'products', ',', 'allowing', 'preventative', 'actions', 'taken', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('This', 'analysis'), ('analysis', 'helps'), ('helps', 'firms'), ('firms', 'alerting'), ('alerting', 'customers'), ('customers', 'dissatisfied'), ('dissatisfied', 'seeking'), ('seeking', 'shift'), ('shift', 'products'), ('products', ','), (',', 'allowing'), ('allowing', 'preventative'), ('preventative', 'actions'), ('actions', 'taken'), ('taken', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'analysis', 'helps'), ('analysis', 'helps', 'firms'), ('helps', 'firms', 'alerting'), ('firms', 'alerting', 'customers'), ('alerting', 'customers', 'dissatisfied'), ('customers', 'dissatisfied', 'seeking'), ('dissatisfied', 'seeking', 'shift'), ('seeking', 'shift', 'products'), ('shift', 'products', ','), ('products', ',', 'allowing'), (',', 'allowing', 'preventative'), ('allowing', 'preventative', 'actions'), ('preventative', 'actions', 'taken'), ('actions', 'taken', '('), ('taken', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('analysis', 'NN'), ('helps', 'VBZ'), ('firms', 'NNS'), ('alerting', 'VBG'), ('customers', 'NNS'), ('dissatisfied', 'VBD'), ('seeking', 'VBG'), ('shift', 'NN'), ('products', 'NNS'), (',', ','), ('allowing', 'VBG'), ('preventative', 'JJ'), ('actions', 'NNS'), ('taken', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT analysis/NN)
  helps/VBZ
  (NP firms/NNS)
  alerting/VBG
  (NP customers/NNS)
  dissatisfied/VBD
  seeking/VBG
  (NP shift/NN products/NNS)
  ,/,
  allowing/VBG
  (NP preventative/JJ actions/NNS)
  taken/VBN
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This analysis', 'firms', 'customers', 'shift products', 'preventative actions', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('analysis', 'analysi'), ('helps', 'help'), ('firms', 'firm'), ('alerting', 'alert'), ('customers', 'custom'), ('dissatisfied', 'dissatisfi'), ('seeking', 'seek'), ('shift', 'shift'), ('products', 'product'), (',', ','), ('allowing', 'allow'), ('preventative', 'prevent'), ('actions', 'action'), ('taken', 'taken'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('analysis', 'analysi'), ('helps', 'help'), ('firms', 'firm'), ('alerting', 'alert'), ('customers', 'custom'), ('dissatisfied', 'dissatisfi'), ('seeking', 'seek'), ('shift', 'shift'), ('products', 'product'), (',', ','), ('allowing', 'allow'), ('preventative', 'prevent'), ('actions', 'action'), ('taken', 'taken'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('analysis', 'analysis'), ('helps', 'help'), ('firms', 'firm'), ('alerting', 'alerting'), ('customers', 'customer'), ('dissatisfied', 'dissatisfied'), ('seeking', 'seeking'), ('shift', 'shift'), ('products', 'product'), (',', ','), ('allowing', 'allowing'), ('preventative', 'preventative'), ('actions', 'action'), ('taken', 'taken'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 351 =============================

• Audio analytics or speech analytics using technical approaches:  ➢ LVCSR: large-vocabulary continuous speech recognition, indexing and searching. 


>> Tokens are: 
 ['•', 'Audio', 'analytics', 'speech', 'analytics', 'using', 'technical', 'approaches', ':', '➢', 'LVCSR', ':', 'large-vocabulary', 'continuous', 'speech', 'recognition', ',', 'indexing', 'searching', '.']

>> Bigrams are: 
 [('•', 'Audio'), ('Audio', 'analytics'), ('analytics', 'speech'), ('speech', 'analytics'), ('analytics', 'using'), ('using', 'technical'), ('technical', 'approaches'), ('approaches', ':'), (':', '➢'), ('➢', 'LVCSR'), ('LVCSR', ':'), (':', 'large-vocabulary'), ('large-vocabulary', 'continuous'), ('continuous', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'indexing'), ('indexing', 'searching'), ('searching', '.')]

>> Trigrams are: 
 [('•', 'Audio', 'analytics'), ('Audio', 'analytics', 'speech'), ('analytics', 'speech', 'analytics'), ('speech', 'analytics', 'using'), ('analytics', 'using', 'technical'), ('using', 'technical', 'approaches'), ('technical', 'approaches', ':'), ('approaches', ':', '➢'), (':', '➢', 'LVCSR'), ('➢', 'LVCSR', ':'), ('LVCSR', ':', 'large-vocabulary'), (':', 'large-vocabulary', 'continuous'), ('large-vocabulary', 'continuous', 'speech'), ('continuous', 'speech', 'recognition'), ('speech', 'recognition', ','), ('recognition', ',', 'indexing'), (',', 'indexing', 'searching'), ('indexing', 'searching', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Audio', 'NNP'), ('analytics', 'NNS'), ('speech', 'VBP'), ('analytics', 'NNS'), ('using', 'VBG'), ('technical', 'JJ'), ('approaches', 'NNS'), (':', ':'), ('➢', 'JJ'), ('LVCSR', 'NNP'), (':', ':'), ('large-vocabulary', 'JJ'), ('continuous', 'JJ'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('indexing', 'VBG'), ('searching', 'NN'), ('.', '.')]

 (S
  (NP •/JJ Audio/NNP analytics/NNS)
  speech/VBP
  (NP analytics/NNS)
  using/VBG
  (NP technical/JJ approaches/NNS)
  :/:
  (NP ➢/JJ LVCSR/NNP)
  :/:
  (NP large-vocabulary/JJ continuous/JJ speech/NN recognition/NN)
  ,/,
  indexing/VBG
  (NP searching/NN)
  ./.) 


>> Noun Phrases are: 
 ['• Audio analytics', 'analytics', 'technical approaches', '➢ LVCSR', 'large-vocabulary continuous speech recognition', 'searching']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Audio', 'audio'), ('analytics', 'analyt'), ('speech', 'speech'), ('analytics', 'analyt'), ('using', 'use'), ('technical', 'technic'), ('approaches', 'approach'), (':', ':'), ('➢', '➢'), ('LVCSR', 'lvcsr'), (':', ':'), ('large-vocabulary', 'large-vocabulari'), ('continuous', 'continu'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('indexing', 'index'), ('searching', 'search'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Audio', 'audio'), ('analytics', 'analyt'), ('speech', 'speech'), ('analytics', 'analyt'), ('using', 'use'), ('technical', 'technic'), ('approaches', 'approach'), (':', ':'), ('➢', '➢'), ('LVCSR', 'lvcsr'), (':', ':'), ('large-vocabulary', 'large-vocabulari'), ('continuous', 'continu'), ('speech', 'speech'), ('recognition', 'recognit'), (',', ','), ('indexing', 'index'), ('searching', 'search'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Audio', 'Audio'), ('analytics', 'analytics'), ('speech', 'speech'), ('analytics', 'analytics'), ('using', 'using'), ('technical', 'technical'), ('approaches', 'approach'), (':', ':'), ('➢', '➢'), ('LVCSR', 'LVCSR'), (':', ':'), ('large-vocabulary', 'large-vocabulary'), ('continuous', 'continuous'), ('speech', 'speech'), ('recognition', 'recognition'), (',', ','), ('indexing', 'indexing'), ('searching', 'searching'), ('.', '.')]



============================ Sentence 352 =============================

➢ Phonetic-based systems: work with sounds or phonemes (Gandomi and Haider,   2015). 


>> Tokens are: 
 ['➢', 'Phonetic-based', 'systems', ':', 'work', 'sounds', 'phonemes', '(', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('➢', 'Phonetic-based'), ('Phonetic-based', 'systems'), ('systems', ':'), (':', 'work'), ('work', 'sounds'), ('sounds', 'phonemes'), ('phonemes', '('), ('(', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('➢', 'Phonetic-based', 'systems'), ('Phonetic-based', 'systems', ':'), ('systems', ':', 'work'), (':', 'work', 'sounds'), ('work', 'sounds', 'phonemes'), ('sounds', 'phonemes', '('), ('phonemes', '(', 'Gandomi'), ('(', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('➢', 'JJ'), ('Phonetic-based', 'JJ'), ('systems', 'NNS'), (':', ':'), ('work', 'NN'), ('sounds', 'VBZ'), ('phonemes', 'NNS'), ('(', '('), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP ➢/JJ Phonetic-based/JJ systems/NNS)
  :/:
  (NP work/NN)
  sounds/VBZ
  (NP phonemes/NNS)
  (/(
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['➢ Phonetic-based systems', 'work', 'phonemes', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('➢', '➢'), ('Phonetic-based', 'phonetic-bas'), ('systems', 'system'), (':', ':'), ('work', 'work'), ('sounds', 'sound'), ('phonemes', 'phonem'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('➢', '➢'), ('Phonetic-based', 'phonetic-bas'), ('systems', 'system'), (':', ':'), ('work', 'work'), ('sounds', 'sound'), ('phonemes', 'phonem'), ('(', '('), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('➢', '➢'), ('Phonetic-based', 'Phonetic-based'), ('systems', 'system'), (':', ':'), ('work', 'work'), ('sounds', 'sound'), ('phonemes', 'phoneme'), ('(', '('), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 353 =============================

• Social media and social network analysis (SNA): Social media depends on multiple tools  and frameworks for collecting, monitoring, summarising, analysing, and visualising social   media data, and SNA depends on social entities’ relationships with each other to measure   the knowledge linking parties, including who shares information, what information, and   with whom. 


>> Tokens are: 
 ['•', 'Social', 'media', 'social', 'network', 'analysis', '(', 'SNA', ')', ':', 'Social', 'media', 'depends', 'multiple', 'tools', 'frameworks', 'collecting', ',', 'monitoring', ',', 'summarising', ',', 'analysing', ',', 'visualising', 'social', 'media', 'data', ',', 'SNA', 'depends', 'social', 'entities', '’', 'relationships', 'measure', 'knowledge', 'linking', 'parties', ',', 'including', 'shares', 'information', ',', 'information', ',', '.']

>> Bigrams are: 
 [('•', 'Social'), ('Social', 'media'), ('media', 'social'), ('social', 'network'), ('network', 'analysis'), ('analysis', '('), ('(', 'SNA'), ('SNA', ')'), (')', ':'), (':', 'Social'), ('Social', 'media'), ('media', 'depends'), ('depends', 'multiple'), ('multiple', 'tools'), ('tools', 'frameworks'), ('frameworks', 'collecting'), ('collecting', ','), (',', 'monitoring'), ('monitoring', ','), (',', 'summarising'), ('summarising', ','), (',', 'analysing'), ('analysing', ','), (',', 'visualising'), ('visualising', 'social'), ('social', 'media'), ('media', 'data'), ('data', ','), (',', 'SNA'), ('SNA', 'depends'), ('depends', 'social'), ('social', 'entities'), ('entities', '’'), ('’', 'relationships'), ('relationships', 'measure'), ('measure', 'knowledge'), ('knowledge', 'linking'), ('linking', 'parties'), ('parties', ','), (',', 'including'), ('including', 'shares'), ('shares', 'information'), ('information', ','), (',', 'information'), ('information', ','), (',', '.')]

>> Trigrams are: 
 [('•', 'Social', 'media'), ('Social', 'media', 'social'), ('media', 'social', 'network'), ('social', 'network', 'analysis'), ('network', 'analysis', '('), ('analysis', '(', 'SNA'), ('(', 'SNA', ')'), ('SNA', ')', ':'), (')', ':', 'Social'), (':', 'Social', 'media'), ('Social', 'media', 'depends'), ('media', 'depends', 'multiple'), ('depends', 'multiple', 'tools'), ('multiple', 'tools', 'frameworks'), ('tools', 'frameworks', 'collecting'), ('frameworks', 'collecting', ','), ('collecting', ',', 'monitoring'), (',', 'monitoring', ','), ('monitoring', ',', 'summarising'), (',', 'summarising', ','), ('summarising', ',', 'analysing'), (',', 'analysing', ','), ('analysing', ',', 'visualising'), (',', 'visualising', 'social'), ('visualising', 'social', 'media'), ('social', 'media', 'data'), ('media', 'data', ','), ('data', ',', 'SNA'), (',', 'SNA', 'depends'), ('SNA', 'depends', 'social'), ('depends', 'social', 'entities'), ('social', 'entities', '’'), ('entities', '’', 'relationships'), ('’', 'relationships', 'measure'), ('relationships', 'measure', 'knowledge'), ('measure', 'knowledge', 'linking'), ('knowledge', 'linking', 'parties'), ('linking', 'parties', ','), ('parties', ',', 'including'), (',', 'including', 'shares'), ('including', 'shares', 'information'), ('shares', 'information', ','), ('information', ',', 'information'), (',', 'information', ','), ('information', ',', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Social', 'NNP'), ('media', 'NNS'), ('social', 'JJ'), ('network', 'NN'), ('analysis', 'NN'), ('(', '('), ('SNA', 'NNP'), (')', ')'), (':', ':'), ('Social', 'JJ'), ('media', 'NNS'), ('depends', 'VBZ'), ('multiple', 'JJ'), ('tools', 'NNS'), ('frameworks', 'NNS'), ('collecting', 'VBG'), (',', ','), ('monitoring', 'NN'), (',', ','), ('summarising', 'VBG'), (',', ','), ('analysing', 'VBG'), (',', ','), ('visualising', 'VBG'), ('social', 'JJ'), ('media', 'NNS'), ('data', 'NNS'), (',', ','), ('SNA', 'NNP'), ('depends', 'VBZ'), ('social', 'JJ'), ('entities', 'NNS'), ('’', 'VBP'), ('relationships', 'NNS'), ('measure', 'NN'), ('knowledge', 'NN'), ('linking', 'VBG'), ('parties', 'NNS'), (',', ','), ('including', 'VBG'), ('shares', 'NNS'), ('information', 'NN'), (',', ','), ('information', 'NN'), (',', ','), ('.', '.')]

 (S
  (NP •/JJ Social/NNP media/NNS)
  (NP social/JJ network/NN analysis/NN)
  (/(
  (NP SNA/NNP)
  )/)
  :/:
  (NP Social/JJ media/NNS)
  depends/VBZ
  (NP multiple/JJ tools/NNS frameworks/NNS)
  collecting/VBG
  ,/,
  (NP monitoring/NN)
  ,/,
  summarising/VBG
  ,/,
  analysing/VBG
  ,/,
  visualising/VBG
  (NP social/JJ media/NNS data/NNS)
  ,/,
  (NP SNA/NNP)
  depends/VBZ
  (NP social/JJ entities/NNS)
  ’/VBP
  (NP relationships/NNS measure/NN knowledge/NN)
  linking/VBG
  (NP parties/NNS)
  ,/,
  including/VBG
  (NP shares/NNS information/NN)
  ,/,
  (NP information/NN)
  ,/,
  ./.) 


>> Noun Phrases are: 
 ['• Social media', 'social network analysis', 'SNA', 'Social media', 'multiple tools frameworks', 'monitoring', 'social media data', 'SNA', 'social entities', 'relationships measure knowledge', 'parties', 'shares information', 'information']

>> Named Entities are: 
 [('ORGANIZATION', 'Social'), ('ORGANIZATION', 'SNA'), ('ORGANIZATION', 'SNA')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Social', 'social'), ('media', 'media'), ('social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('(', '('), ('SNA', 'sna'), (')', ')'), (':', ':'), ('Social', 'social'), ('media', 'media'), ('depends', 'depend'), ('multiple', 'multipl'), ('tools', 'tool'), ('frameworks', 'framework'), ('collecting', 'collect'), (',', ','), ('monitoring', 'monitor'), (',', ','), ('summarising', 'summaris'), (',', ','), ('analysing', 'analys'), (',', ','), ('visualising', 'visualis'), ('social', 'social'), ('media', 'media'), ('data', 'data'), (',', ','), ('SNA', 'sna'), ('depends', 'depend'), ('social', 'social'), ('entities', 'entiti'), ('’', '’'), ('relationships', 'relationship'), ('measure', 'measur'), ('knowledge', 'knowledg'), ('linking', 'link'), ('parties', 'parti'), (',', ','), ('including', 'includ'), ('shares', 'share'), ('information', 'inform'), (',', ','), ('information', 'inform'), (',', ','), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Social', 'social'), ('media', 'media'), ('social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('(', '('), ('SNA', 'sna'), (')', ')'), (':', ':'), ('Social', 'social'), ('media', 'media'), ('depends', 'depend'), ('multiple', 'multipl'), ('tools', 'tool'), ('frameworks', 'framework'), ('collecting', 'collect'), (',', ','), ('monitoring', 'monitor'), (',', ','), ('summarising', 'summaris'), (',', ','), ('analysing', 'analys'), (',', ','), ('visualising', 'visualis'), ('social', 'social'), ('media', 'media'), ('data', 'data'), (',', ','), ('SNA', 'sna'), ('depends', 'depend'), ('social', 'social'), ('entities', 'entiti'), ('’', '’'), ('relationships', 'relationship'), ('measure', 'measur'), ('knowledge', 'knowledg'), ('linking', 'link'), ('parties', 'parti'), (',', ','), ('including', 'includ'), ('shares', 'share'), ('information', 'inform'), (',', ','), ('information', 'inform'), (',', ','), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Social', 'Social'), ('media', 'medium'), ('social', 'social'), ('network', 'network'), ('analysis', 'analysis'), ('(', '('), ('SNA', 'SNA'), (')', ')'), (':', ':'), ('Social', 'Social'), ('media', 'medium'), ('depends', 'depends'), ('multiple', 'multiple'), ('tools', 'tool'), ('frameworks', 'framework'), ('collecting', 'collecting'), (',', ','), ('monitoring', 'monitoring'), (',', ','), ('summarising', 'summarising'), (',', ','), ('analysing', 'analysing'), (',', ','), ('visualising', 'visualising'), ('social', 'social'), ('media', 'medium'), ('data', 'data'), (',', ','), ('SNA', 'SNA'), ('depends', 'depends'), ('social', 'social'), ('entities', 'entity'), ('’', '’'), ('relationships', 'relationship'), ('measure', 'measure'), ('knowledge', 'knowledge'), ('linking', 'linking'), ('parties', 'party'), (',', ','), ('including', 'including'), ('shares', 'share'), ('information', 'information'), (',', ','), ('information', 'information'), (',', ','), ('.', '.')]



============================ Sentence 354 =============================

SNA tries to get develop network patterns, while social media tries to uncover   useful patterns and user information using text mining or sentiment analysis (Elgendy and   Elragal, 2014; Gandomi and Haider, 2015). 


>> Tokens are: 
 ['SNA', 'tries', 'get', 'develop', 'network', 'patterns', ',', 'social', 'media', 'tries', 'uncover', 'useful', 'patterns', 'user', 'information', 'using', 'text', 'mining', 'sentiment', 'analysis', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Gandomi', 'Haider', ',', '2015', ')', '.']

>> Bigrams are: 
 [('SNA', 'tries'), ('tries', 'get'), ('get', 'develop'), ('develop', 'network'), ('network', 'patterns'), ('patterns', ','), (',', 'social'), ('social', 'media'), ('media', 'tries'), ('tries', 'uncover'), ('uncover', 'useful'), ('useful', 'patterns'), ('patterns', 'user'), ('user', 'information'), ('information', 'using'), ('using', 'text'), ('text', 'mining'), ('mining', 'sentiment'), ('sentiment', 'analysis'), ('analysis', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Gandomi'), ('Gandomi', 'Haider'), ('Haider', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('SNA', 'tries', 'get'), ('tries', 'get', 'develop'), ('get', 'develop', 'network'), ('develop', 'network', 'patterns'), ('network', 'patterns', ','), ('patterns', ',', 'social'), (',', 'social', 'media'), ('social', 'media', 'tries'), ('media', 'tries', 'uncover'), ('tries', 'uncover', 'useful'), ('uncover', 'useful', 'patterns'), ('useful', 'patterns', 'user'), ('patterns', 'user', 'information'), ('user', 'information', 'using'), ('information', 'using', 'text'), ('using', 'text', 'mining'), ('text', 'mining', 'sentiment'), ('mining', 'sentiment', 'analysis'), ('sentiment', 'analysis', '('), ('analysis', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Gandomi'), (';', 'Gandomi', 'Haider'), ('Gandomi', 'Haider', ','), ('Haider', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('SNA', 'NNP'), ('tries', 'VBZ'), ('get', 'VBP'), ('develop', 'VB'), ('network', 'NN'), ('patterns', 'NNS'), (',', ','), ('social', 'JJ'), ('media', 'NNS'), ('tries', 'NNS'), ('uncover', 'RB'), ('useful', 'JJ'), ('patterns', 'NNS'), ('user', 'JJ'), ('information', 'NN'), ('using', 'VBG'), ('text', 'NN'), ('mining', 'NN'), ('sentiment', 'NN'), ('analysis', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Gandomi', 'NNP'), ('Haider', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP SNA/NNP)
  tries/VBZ
  get/VBP
  develop/VB
  (NP network/NN patterns/NNS)
  ,/,
  (NP social/JJ media/NNS tries/NNS)
  uncover/RB
  (NP useful/JJ patterns/NNS)
  (NP user/JJ information/NN)
  using/VBG
  (NP text/NN mining/NN sentiment/NN analysis/NN)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Gandomi/NNP Haider/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['SNA', 'network patterns', 'social media tries', 'useful patterns', 'user information', 'text mining sentiment analysis', 'Elgendy Elragal', 'Gandomi Haider']

>> Named Entities are: 
 [('ORGANIZATION', 'SNA'), ('PERSON', 'Elgendy Elragal'), ('PERSON', 'Gandomi Haider')] 

>> Stemming using Porter Stemmer: 
 [('SNA', 'sna'), ('tries', 'tri'), ('get', 'get'), ('develop', 'develop'), ('network', 'network'), ('patterns', 'pattern'), (',', ','), ('social', 'social'), ('media', 'media'), ('tries', 'tri'), ('uncover', 'uncov'), ('useful', 'use'), ('patterns', 'pattern'), ('user', 'user'), ('information', 'inform'), ('using', 'use'), ('text', 'text'), ('mining', 'mine'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('SNA', 'sna'), ('tries', 'tri'), ('get', 'get'), ('develop', 'develop'), ('network', 'network'), ('patterns', 'pattern'), (',', ','), ('social', 'social'), ('media', 'media'), ('tries', 'tri'), ('uncover', 'uncov'), ('useful', 'use'), ('patterns', 'pattern'), ('user', 'user'), ('information', 'inform'), ('using', 'use'), ('text', 'text'), ('mining', 'mine'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Gandomi', 'gandomi'), ('Haider', 'haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('SNA', 'SNA'), ('tries', 'try'), ('get', 'get'), ('develop', 'develop'), ('network', 'network'), ('patterns', 'pattern'), (',', ','), ('social', 'social'), ('media', 'medium'), ('tries', 'try'), ('uncover', 'uncover'), ('useful', 'useful'), ('patterns', 'pattern'), ('user', 'user'), ('information', 'information'), ('using', 'using'), ('text', 'text'), ('mining', 'mining'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Gandomi', 'Gandomi'), ('Haider', 'Haider'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 355 =============================

• Data Visualisation: This can be used even by decision makers with little knowledge about  the data, as it presents the information visually prior to deep analysis. 


>> Tokens are: 
 ['•', 'Data', 'Visualisation', ':', 'This', 'used', 'even', 'decision', 'makers', 'little', 'knowledge', 'data', ',', 'presents', 'information', 'visually', 'prior', 'deep', 'analysis', '.']

>> Bigrams are: 
 [('•', 'Data'), ('Data', 'Visualisation'), ('Visualisation', ':'), (':', 'This'), ('This', 'used'), ('used', 'even'), ('even', 'decision'), ('decision', 'makers'), ('makers', 'little'), ('little', 'knowledge'), ('knowledge', 'data'), ('data', ','), (',', 'presents'), ('presents', 'information'), ('information', 'visually'), ('visually', 'prior'), ('prior', 'deep'), ('deep', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('•', 'Data', 'Visualisation'), ('Data', 'Visualisation', ':'), ('Visualisation', ':', 'This'), (':', 'This', 'used'), ('This', 'used', 'even'), ('used', 'even', 'decision'), ('even', 'decision', 'makers'), ('decision', 'makers', 'little'), ('makers', 'little', 'knowledge'), ('little', 'knowledge', 'data'), ('knowledge', 'data', ','), ('data', ',', 'presents'), (',', 'presents', 'information'), ('presents', 'information', 'visually'), ('information', 'visually', 'prior'), ('visually', 'prior', 'deep'), ('prior', 'deep', 'analysis'), ('deep', 'analysis', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('Data', 'NNP'), ('Visualisation', 'NN'), (':', ':'), ('This', 'DT'), ('used', 'VBD'), ('even', 'RB'), ('decision', 'NN'), ('makers', 'NNS'), ('little', 'JJ'), ('knowledge', 'NN'), ('data', 'NNS'), (',', ','), ('presents', 'NNS'), ('information', 'NN'), ('visually', 'RB'), ('prior', 'RB'), ('deep', 'JJ'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP •/NN Data/NNP Visualisation/NN)
  :/:
  This/DT
  used/VBD
  even/RB
  (NP decision/NN makers/NNS)
  (NP little/JJ knowledge/NN data/NNS)
  ,/,
  (NP presents/NNS information/NN)
  visually/RB
  prior/RB
  (NP deep/JJ analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['• Data Visualisation', 'decision makers', 'little knowledge data', 'presents information', 'deep analysis']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Data', 'data'), ('Visualisation', 'visualis'), (':', ':'), ('This', 'thi'), ('used', 'use'), ('even', 'even'), ('decision', 'decis'), ('makers', 'maker'), ('little', 'littl'), ('knowledge', 'knowledg'), ('data', 'data'), (',', ','), ('presents', 'present'), ('information', 'inform'), ('visually', 'visual'), ('prior', 'prior'), ('deep', 'deep'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Data', 'data'), ('Visualisation', 'visualis'), (':', ':'), ('This', 'this'), ('used', 'use'), ('even', 'even'), ('decision', 'decis'), ('makers', 'maker'), ('little', 'littl'), ('knowledge', 'knowledg'), ('data', 'data'), (',', ','), ('presents', 'present'), ('information', 'inform'), ('visually', 'visual'), ('prior', 'prior'), ('deep', 'deep'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Data', 'Data'), ('Visualisation', 'Visualisation'), (':', ':'), ('This', 'This'), ('used', 'used'), ('even', 'even'), ('decision', 'decision'), ('makers', 'maker'), ('little', 'little'), ('knowledge', 'knowledge'), ('data', 'data'), (',', ','), ('presents', 'present'), ('information', 'information'), ('visually', 'visually'), ('prior', 'prior'), ('deep', 'deep'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 356 =============================

Advanced Data   visualisation (ADV) offers strong potential growth to big data analytics as it allows analysis   of data at several levels by taking advantage of human perceptual and reasoning abilities   (Manyika et al., 2011; Russom, 2011; Elragal, and Klischewski, 2017). 


>> Tokens are: 
 ['Advanced', 'Data', 'visualisation', '(', 'ADV', ')', 'offers', 'strong', 'potential', 'growth', 'big', 'data', 'analytics', 'allows', 'analysis', 'data', 'several', 'levels', 'taking', 'advantage', 'human', 'perceptual', 'reasoning', 'abilities', '(', 'Manyika', 'et', 'al.', ',', '2011', ';', 'Russom', ',', '2011', ';', 'Elragal', ',', 'Klischewski', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Advanced', 'Data'), ('Data', 'visualisation'), ('visualisation', '('), ('(', 'ADV'), ('ADV', ')'), (')', 'offers'), ('offers', 'strong'), ('strong', 'potential'), ('potential', 'growth'), ('growth', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'allows'), ('allows', 'analysis'), ('analysis', 'data'), ('data', 'several'), ('several', 'levels'), ('levels', 'taking'), ('taking', 'advantage'), ('advantage', 'human'), ('human', 'perceptual'), ('perceptual', 'reasoning'), ('reasoning', 'abilities'), ('abilities', '('), ('(', 'Manyika'), ('Manyika', 'et'), ('et', 'al.'), ('al.', ','), (',', '2011'), ('2011', ';'), (';', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elragal'), ('Elragal', ','), (',', 'Klischewski'), ('Klischewski', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Advanced', 'Data', 'visualisation'), ('Data', 'visualisation', '('), ('visualisation', '(', 'ADV'), ('(', 'ADV', ')'), ('ADV', ')', 'offers'), (')', 'offers', 'strong'), ('offers', 'strong', 'potential'), ('strong', 'potential', 'growth'), ('potential', 'growth', 'big'), ('growth', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'allows'), ('analytics', 'allows', 'analysis'), ('allows', 'analysis', 'data'), ('analysis', 'data', 'several'), ('data', 'several', 'levels'), ('several', 'levels', 'taking'), ('levels', 'taking', 'advantage'), ('taking', 'advantage', 'human'), ('advantage', 'human', 'perceptual'), ('human', 'perceptual', 'reasoning'), ('perceptual', 'reasoning', 'abilities'), ('reasoning', 'abilities', '('), ('abilities', '(', 'Manyika'), ('(', 'Manyika', 'et'), ('Manyika', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Russom'), (';', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elragal'), (';', 'Elragal', ','), ('Elragal', ',', 'Klischewski'), (',', 'Klischewski', ','), ('Klischewski', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Advanced', 'NNP'), ('Data', 'NNP'), ('visualisation', 'NN'), ('(', '('), ('ADV', 'NNP'), (')', ')'), ('offers', 'VBZ'), ('strong', 'JJ'), ('potential', 'JJ'), ('growth', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('allows', 'VBP'), ('analysis', 'NN'), ('data', 'NNS'), ('several', 'JJ'), ('levels', 'NNS'), ('taking', 'VBG'), ('advantage', 'NN'), ('human', 'JJ'), ('perceptual', 'JJ'), ('reasoning', 'NN'), ('abilities', 'NNS'), ('(', '('), ('Manyika', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2011', 'CD'), (';', ':'), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elragal', 'NNP'), (',', ','), ('Klischewski', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Advanced/NNP Data/NNP visualisation/NN)
  (/(
  (NP ADV/NNP)
  )/)
  offers/VBZ
  (NP strong/JJ potential/JJ growth/NN)
  (NP big/JJ data/NNS analytics/NNS)
  allows/VBP
  (NP analysis/NN data/NNS)
  (NP several/JJ levels/NNS)
  taking/VBG
  (NP advantage/NN)
  (NP human/JJ perceptual/JJ reasoning/NN abilities/NNS)
  (/(
  (NP Manyika/NNP)
  et/RB
  al./RB
  ,/,
  2011/CD
  ;/:
  (NP Russom/NNP)
  ,/,
  2011/CD
  ;/:
  (NP Elragal/NNP)
  ,/,
  (NP Klischewski/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Advanced Data visualisation', 'ADV', 'strong potential growth', 'big data analytics', 'analysis data', 'several levels', 'advantage', 'human perceptual reasoning abilities', 'Manyika', 'Russom', 'Elragal', 'Klischewski']

>> Named Entities are: 
 [('PERSON', 'Advanced'), ('ORGANIZATION', 'Data'), ('ORGANIZATION', 'ADV'), ('PERSON', 'Manyika'), ('GPE', 'Russom'), ('GPE', 'Elragal'), ('GPE', 'Klischewski')] 

>> Stemming using Porter Stemmer: 
 [('Advanced', 'advanc'), ('Data', 'data'), ('visualisation', 'visualis'), ('(', '('), ('ADV', 'adv'), (')', ')'), ('offers', 'offer'), ('strong', 'strong'), ('potential', 'potenti'), ('growth', 'growth'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('allows', 'allow'), ('analysis', 'analysi'), ('data', 'data'), ('several', 'sever'), ('levels', 'level'), ('taking', 'take'), ('advantage', 'advantag'), ('human', 'human'), ('perceptual', 'perceptu'), ('reasoning', 'reason'), ('abilities', 'abil'), ('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Advanced', 'advanc'), ('Data', 'data'), ('visualisation', 'visualis'), ('(', '('), ('ADV', 'adv'), (')', ')'), ('offers', 'offer'), ('strong', 'strong'), ('potential', 'potenti'), ('growth', 'growth'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('allows', 'allow'), ('analysis', 'analysi'), ('data', 'data'), ('several', 'sever'), ('levels', 'level'), ('taking', 'take'), ('advantage', 'advantag'), ('human', 'human'), ('perceptual', 'perceptu'), ('reasoning', 'reason'), ('abilities', 'abil'), ('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'elrag'), (',', ','), ('Klischewski', 'klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Advanced', 'Advanced'), ('Data', 'Data'), ('visualisation', 'visualisation'), ('(', '('), ('ADV', 'ADV'), (')', ')'), ('offers', 'offer'), ('strong', 'strong'), ('potential', 'potential'), ('growth', 'growth'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('allows', 'allows'), ('analysis', 'analysis'), ('data', 'data'), ('several', 'several'), ('levels', 'level'), ('taking', 'taking'), ('advantage', 'advantage'), ('human', 'human'), ('perceptual', 'perceptual'), ('reasoning', 'reasoning'), ('abilities', 'ability'), ('(', '('), ('Manyika', 'Manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elragal', 'Elragal'), (',', ','), ('Klischewski', 'Klischewski'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 357 =============================

Sarah Al-Shiakhli   28      • Predictive analytics: This is based on statistical methods such as associative rules,  clustering, classification and decision trees, regression, and factor analysis (Fan et al.,   2014; Bradlow et al., 2017; Breed and Verster, 2019). 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '28', '•', 'Predictive', 'analytics', ':', 'This', 'based', 'statistical', 'methods', 'associative', 'rules', ',', 'clustering', ',', 'classification', 'decision', 'trees', ',', 'regression', ',', 'factor', 'analysis', '(', 'Fan', 'et', 'al.', ',', '2014', ';', 'Bradlow', 'et', 'al.', ',', '2017', ';', 'Breed', 'Verster', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '28'), ('28', '•'), ('•', 'Predictive'), ('Predictive', 'analytics'), ('analytics', ':'), (':', 'This'), ('This', 'based'), ('based', 'statistical'), ('statistical', 'methods'), ('methods', 'associative'), ('associative', 'rules'), ('rules', ','), (',', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', 'decision'), ('decision', 'trees'), ('trees', ','), (',', 'regression'), ('regression', ','), (',', 'factor'), ('factor', 'analysis'), ('analysis', '('), ('(', 'Fan'), ('Fan', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Bradlow'), ('Bradlow', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '28'), ('Al-Shiakhli', '28', '•'), ('28', '•', 'Predictive'), ('•', 'Predictive', 'analytics'), ('Predictive', 'analytics', ':'), ('analytics', ':', 'This'), (':', 'This', 'based'), ('This', 'based', 'statistical'), ('based', 'statistical', 'methods'), ('statistical', 'methods', 'associative'), ('methods', 'associative', 'rules'), ('associative', 'rules', ','), ('rules', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', 'decision'), ('classification', 'decision', 'trees'), ('decision', 'trees', ','), ('trees', ',', 'regression'), (',', 'regression', ','), ('regression', ',', 'factor'), (',', 'factor', 'analysis'), ('factor', 'analysis', '('), ('analysis', '(', 'Fan'), ('(', 'Fan', 'et'), ('Fan', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Bradlow'), (';', 'Bradlow', 'et'), ('Bradlow', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('28', 'CD'), ('•', 'NNP'), ('Predictive', 'NNP'), ('analytics', 'NNS'), (':', ':'), ('This', 'DT'), ('based', 'VBN'), ('statistical', 'JJ'), ('methods', 'NNS'), ('associative', 'JJ'), ('rules', 'NNS'), (',', ','), ('clustering', 'VBG'), (',', ','), ('classification', 'NN'), ('decision', 'NN'), ('trees', 'NNS'), (',', ','), ('regression', 'NN'), (',', ','), ('factor', 'NN'), ('analysis', 'NN'), ('(', '('), ('Fan', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (';', ':'), ('Bradlow', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  28/CD
  (NP •/NNP Predictive/NNP analytics/NNS)
  :/:
  This/DT
  based/VBN
  (NP statistical/JJ methods/NNS)
  (NP associative/JJ rules/NNS)
  ,/,
  clustering/VBG
  ,/,
  (NP classification/NN decision/NN trees/NNS)
  ,/,
  (NP regression/NN)
  ,/,
  (NP factor/NN analysis/NN)
  (/(
  (NP Fan/NNP)
  et/RB
  al./RB
  ,/,
  2014/CD
  ;/:
  (NP Bradlow/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2017/CD
  ;/:
  (NP Breed/NNP Verster/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', '• Predictive analytics', 'statistical methods', 'associative rules', 'classification decision trees', 'regression', 'factor analysis', 'Fan', 'Bradlow', 'al.', 'Breed Verster']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'Fan'), ('PERSON', 'Bradlow'), ('PERSON', 'Breed Verster')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('28', '28'), ('•', '•'), ('Predictive', 'predict'), ('analytics', 'analyt'), (':', ':'), ('This', 'thi'), ('based', 'base'), ('statistical', 'statist'), ('methods', 'method'), ('associative', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analysis', 'analysi'), ('(', '('), ('Fan', 'fan'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Bradlow', 'bradlow'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('28', '28'), ('•', '•'), ('Predictive', 'predict'), ('analytics', 'analyt'), (':', ':'), ('This', 'this'), ('based', 'base'), ('statistical', 'statist'), ('methods', 'method'), ('associative', 'associ'), ('rules', 'rule'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), ('decision', 'decis'), ('trees', 'tree'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analysis', 'analysi'), ('(', '('), ('Fan', 'fan'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Bradlow', 'bradlow'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('28', '28'), ('•', '•'), ('Predictive', 'Predictive'), ('analytics', 'analytics'), (':', ':'), ('This', 'This'), ('based', 'based'), ('statistical', 'statistical'), ('methods', 'method'), ('associative', 'associative'), ('rules', 'rule'), (',', ','), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), ('decision', 'decision'), ('trees', 'tree'), (',', ','), ('regression', 'regression'), (',', ','), ('factor', 'factor'), ('analysis', 'analysis'), ('(', '('), ('Fan', 'Fan'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Bradlow', 'Bradlow'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 358 =============================

Figure 16: Common big data analytic methods. 


>> Tokens are: 
 ['Figure', '16', ':', 'Common', 'big', 'data', 'analytic', 'methods', '.']

>> Bigrams are: 
 [('Figure', '16'), ('16', ':'), (':', 'Common'), ('Common', 'big'), ('big', 'data'), ('data', 'analytic'), ('analytic', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('Figure', '16', ':'), ('16', ':', 'Common'), (':', 'Common', 'big'), ('Common', 'big', 'data'), ('big', 'data', 'analytic'), ('data', 'analytic', 'methods'), ('analytic', 'methods', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('16', 'CD'), (':', ':'), ('Common', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytic', 'JJ'), ('methods', 'NNS'), ('.', '.')]

 (S
  (NP Figure/NN)
  16/CD
  :/:
  (NP Common/JJ big/JJ data/NNS)
  (NP analytic/JJ methods/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Common big data', 'analytic methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('16', '16'), (':', ':'), ('Common', 'common'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('16', '16'), (':', ':'), ('Common', 'common'), ('big', 'big'), ('data', 'data'), ('analytic', 'analyt'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('16', '16'), (':', ':'), ('Common', 'Common'), ('big', 'big'), ('data', 'data'), ('analytic', 'analytic'), ('methods', 'method'), ('.', '.')]



============================ Sentence 359 =============================

The other types of big data analytics used for systematic review are presented by Grover and Kar   (2017), and these include descriptive analytics, diagnostic analytics, predictive analytics, and   prescriptive analytics, as shown in Figure 17. 


>> Tokens are: 
 ['The', 'types', 'big', 'data', 'analytics', 'used', 'systematic', 'review', 'presented', 'Grover', 'Kar', '(', '2017', ')', ',', 'include', 'descriptive', 'analytics', ',', 'diagnostic', 'analytics', ',', 'predictive', 'analytics', ',', 'prescriptive', 'analytics', ',', 'shown', 'Figure', '17', '.']

>> Bigrams are: 
 [('The', 'types'), ('types', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'used'), ('used', 'systematic'), ('systematic', 'review'), ('review', 'presented'), ('presented', 'Grover'), ('Grover', 'Kar'), ('Kar', '('), ('(', '2017'), ('2017', ')'), (')', ','), (',', 'include'), ('include', 'descriptive'), ('descriptive', 'analytics'), ('analytics', ','), (',', 'diagnostic'), ('diagnostic', 'analytics'), ('analytics', ','), (',', 'predictive'), ('predictive', 'analytics'), ('analytics', ','), (',', 'prescriptive'), ('prescriptive', 'analytics'), ('analytics', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '17'), ('17', '.')]

>> Trigrams are: 
 [('The', 'types', 'big'), ('types', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'used'), ('analytics', 'used', 'systematic'), ('used', 'systematic', 'review'), ('systematic', 'review', 'presented'), ('review', 'presented', 'Grover'), ('presented', 'Grover', 'Kar'), ('Grover', 'Kar', '('), ('Kar', '(', '2017'), ('(', '2017', ')'), ('2017', ')', ','), (')', ',', 'include'), (',', 'include', 'descriptive'), ('include', 'descriptive', 'analytics'), ('descriptive', 'analytics', ','), ('analytics', ',', 'diagnostic'), (',', 'diagnostic', 'analytics'), ('diagnostic', 'analytics', ','), ('analytics', ',', 'predictive'), (',', 'predictive', 'analytics'), ('predictive', 'analytics', ','), ('analytics', ',', 'prescriptive'), (',', 'prescriptive', 'analytics'), ('prescriptive', 'analytics', ','), ('analytics', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '17'), ('Figure', '17', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('types', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('used', 'VBD'), ('systematic', 'JJ'), ('review', 'NN'), ('presented', 'VBD'), ('Grover', 'NNP'), ('Kar', 'NNP'), ('(', '('), ('2017', 'CD'), (')', ')'), (',', ','), ('include', 'VBP'), ('descriptive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('diagnostic', 'JJ'), ('analytics', 'NNS'), (',', ','), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('prescriptive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('17', 'CD'), ('.', '.')]

 (S
  (NP The/DT types/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  used/VBD
  (NP systematic/JJ review/NN)
  presented/VBD
  (NP Grover/NNP Kar/NNP)
  (/(
  2017/CD
  )/)
  ,/,
  include/VBP
  (NP descriptive/JJ analytics/NNS)
  ,/,
  (NP diagnostic/JJ analytics/NNS)
  ,/,
  (NP predictive/JJ analytics/NNS)
  ,/,
  (NP prescriptive/JJ analytics/NNS)
  ,/,
  shown/VBN
  (NP Figure/NN)
  17/CD
  ./.) 


>> Noun Phrases are: 
 ['The types', 'big data analytics', 'systematic review', 'Grover Kar', 'descriptive analytics', 'diagnostic analytics', 'predictive analytics', 'prescriptive analytics', 'Figure']

>> Named Entities are: 
 [('PERSON', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('systematic', 'systemat'), ('review', 'review'), ('presented', 'present'), ('Grover', 'grover'), ('Kar', 'kar'), ('(', '('), ('2017', '2017'), (')', ')'), (',', ','), ('include', 'includ'), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('prescriptive', 'prescript'), ('analytics', 'analyt'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('17', '17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('systematic', 'systemat'), ('review', 'review'), ('presented', 'present'), ('Grover', 'grover'), ('Kar', 'kar'), ('(', '('), ('2017', '2017'), (')', ')'), (',', ','), ('include', 'includ'), ('descriptive', 'descript'), ('analytics', 'analyt'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('prescriptive', 'prescript'), ('analytics', 'analyt'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('17', '17'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('used', 'used'), ('systematic', 'systematic'), ('review', 'review'), ('presented', 'presented'), ('Grover', 'Grover'), ('Kar', 'Kar'), ('(', '('), ('2017', '2017'), (')', ')'), (',', ','), ('include', 'include'), ('descriptive', 'descriptive'), ('analytics', 'analytics'), (',', ','), ('diagnostic', 'diagnostic'), ('analytics', 'analytics'), (',', ','), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ','), ('prescriptive', 'prescriptive'), ('analytics', 'analytics'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('17', '17'), ('.', '.')]



============================ Sentence 360 =============================

Organisations and individual rend to use statistical models for predictive purposes, as most   predictive models are built with statistical criteria. 


>> Tokens are: 
 ['Organisations', 'individual', 'rend', 'use', 'statistical', 'models', 'predictive', 'purposes', ',', 'predictive', 'models', 'built', 'statistical', 'criteria', '.']

>> Bigrams are: 
 [('Organisations', 'individual'), ('individual', 'rend'), ('rend', 'use'), ('use', 'statistical'), ('statistical', 'models'), ('models', 'predictive'), ('predictive', 'purposes'), ('purposes', ','), (',', 'predictive'), ('predictive', 'models'), ('models', 'built'), ('built', 'statistical'), ('statistical', 'criteria'), ('criteria', '.')]

>> Trigrams are: 
 [('Organisations', 'individual', 'rend'), ('individual', 'rend', 'use'), ('rend', 'use', 'statistical'), ('use', 'statistical', 'models'), ('statistical', 'models', 'predictive'), ('models', 'predictive', 'purposes'), ('predictive', 'purposes', ','), ('purposes', ',', 'predictive'), (',', 'predictive', 'models'), ('predictive', 'models', 'built'), ('models', 'built', 'statistical'), ('built', 'statistical', 'criteria'), ('statistical', 'criteria', '.')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('individual', 'JJ'), ('rend', 'VBP'), ('use', 'JJ'), ('statistical', 'JJ'), ('models', 'NNS'), ('predictive', 'JJ'), ('purposes', 'NNS'), (',', ','), ('predictive', 'JJ'), ('models', 'NNS'), ('built', 'VBN'), ('statistical', 'JJ'), ('criteria', 'NNS'), ('.', '.')]

 (S
  (NP Organisations/NNS)
  individual/JJ
  rend/VBP
  (NP use/JJ statistical/JJ models/NNS)
  (NP predictive/JJ purposes/NNS)
  ,/,
  (NP predictive/JJ models/NNS)
  built/VBN
  (NP statistical/JJ criteria/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Organisations', 'use statistical models', 'predictive purposes', 'predictive models', 'statistical criteria']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('rend', 'rend'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model'), ('predictive', 'predict'), ('purposes', 'purpos'), (',', ','), ('predictive', 'predict'), ('models', 'model'), ('built', 'built'), ('statistical', 'statist'), ('criteria', 'criteria'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('individual', 'individu'), ('rend', 'rend'), ('use', 'use'), ('statistical', 'statist'), ('models', 'model'), ('predictive', 'predict'), ('purposes', 'purpos'), (',', ','), ('predictive', 'predict'), ('models', 'model'), ('built', 'built'), ('statistical', 'statist'), ('criteria', 'criteria'), ('.', '.')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('individual', 'individual'), ('rend', 'rend'), ('use', 'use'), ('statistical', 'statistical'), ('models', 'model'), ('predictive', 'predictive'), ('purposes', 'purpose'), (',', ','), ('predictive', 'predictive'), ('models', 'model'), ('built', 'built'), ('statistical', 'statistical'), ('criteria', 'criterion'), ('.', '.')]



============================ Sentence 361 =============================

Artificial intelligence modelling is also     Sarah Al-Shiakhli   29      becoming more popular. 


>> Tokens are: 
 ['Artificial', 'intelligence', 'modelling', 'also', 'Sarah', 'Al-Shiakhli', '29', 'becoming', 'popular', '.']

>> Bigrams are: 
 [('Artificial', 'intelligence'), ('intelligence', 'modelling'), ('modelling', 'also'), ('also', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '29'), ('29', 'becoming'), ('becoming', 'popular'), ('popular', '.')]

>> Trigrams are: 
 [('Artificial', 'intelligence', 'modelling'), ('intelligence', 'modelling', 'also'), ('modelling', 'also', 'Sarah'), ('also', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '29'), ('Al-Shiakhli', '29', 'becoming'), ('29', 'becoming', 'popular'), ('becoming', 'popular', '.')]

>> POS Tags are: 
 [('Artificial', 'JJ'), ('intelligence', 'NN'), ('modelling', 'NN'), ('also', 'RB'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('29', 'CD'), ('becoming', 'VBG'), ('popular', 'JJ'), ('.', '.')]

 (S
  (NP Artificial/JJ intelligence/NN modelling/NN)
  also/RB
  (NP Sarah/NNP Al-Shiakhli/NNP)
  29/CD
  becoming/VBG
  popular/JJ
  ./.) 


>> Noun Phrases are: 
 ['Artificial intelligence modelling', 'Sarah Al-Shiakhli']

>> Named Entities are: 
 [('GPE', 'Artificial'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('also', 'also'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('29', '29'), ('becoming', 'becom'), ('popular', 'popular'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Artificial', 'artifici'), ('intelligence', 'intellig'), ('modelling', 'model'), ('also', 'also'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('29', '29'), ('becoming', 'becom'), ('popular', 'popular'), ('.', '.')]

>> Lemmatization: 
 [('Artificial', 'Artificial'), ('intelligence', 'intelligence'), ('modelling', 'modelling'), ('also', 'also'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('29', '29'), ('becoming', 'becoming'), ('popular', 'popular'), ('.', '.')]



============================ Sentence 362 =============================

Machine learning algorithms can combine statistical and artificial   intelligence methods in order to analyse large amounts of data with high-performance (Watson,   2019). 


>> Tokens are: 
 ['Machine', 'learning', 'algorithms', 'combine', 'statistical', 'artificial', 'intelligence', 'methods', 'order', 'analyse', 'large', 'amounts', 'data', 'high-performance', '(', 'Watson', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'combine'), ('combine', 'statistical'), ('statistical', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'methods'), ('methods', 'order'), ('order', 'analyse'), ('analyse', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', 'high-performance'), ('high-performance', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'combine'), ('algorithms', 'combine', 'statistical'), ('combine', 'statistical', 'artificial'), ('statistical', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'methods'), ('intelligence', 'methods', 'order'), ('methods', 'order', 'analyse'), ('order', 'analyse', 'large'), ('analyse', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', 'high-performance'), ('data', 'high-performance', '('), ('high-performance', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('algorithms', 'JJ'), ('combine', 'JJ'), ('statistical', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('methods', 'NNS'), ('order', 'NN'), ('analyse', 'VBP'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('high-performance', 'NN'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP
    algorithms/JJ
    combine/JJ
    statistical/JJ
    artificial/JJ
    intelligence/NN
    methods/NNS
    order/NN)
  analyse/VBP
  (NP large/JJ amounts/NNS data/NNS high-performance/NN)
  (/(
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'algorithms combine statistical artificial intelligence methods order', 'large amounts data high-performance', 'Watson']

>> Named Entities are: 
 [('GPE', 'Machine'), ('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('combine', 'combin'), ('statistical', 'statist'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('methods', 'method'), ('order', 'order'), ('analyse', 'analys'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('algorithms', 'algorithm'), ('combine', 'combin'), ('statistical', 'statist'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('methods', 'method'), ('order', 'order'), ('analyse', 'analys'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-perform'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('algorithms', 'algorithm'), ('combine', 'combine'), ('statistical', 'statistical'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('methods', 'method'), ('order', 'order'), ('analyse', 'analyse'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('high-performance', 'high-performance'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 363 =============================

Figure 17: Other types of big data analytics2   Descriptive analytics describes either what has happened or what is going to happen, while   diagnostic analytics estimates the reason for something having happened, which requires   techniques for discovering a problem’s root causes. 


>> Tokens are: 
 ['Figure', '17', ':', 'Other', 'types', 'big', 'data', 'analytics2', 'Descriptive', 'analytics', 'describes', 'either', 'happened', 'going', 'happen', ',', 'diagnostic', 'analytics', 'estimates', 'reason', 'something', 'happened', ',', 'requires', 'techniques', 'discovering', 'problem', '’', 'root', 'causes', '.']

>> Bigrams are: 
 [('Figure', '17'), ('17', ':'), (':', 'Other'), ('Other', 'types'), ('types', 'big'), ('big', 'data'), ('data', 'analytics2'), ('analytics2', 'Descriptive'), ('Descriptive', 'analytics'), ('analytics', 'describes'), ('describes', 'either'), ('either', 'happened'), ('happened', 'going'), ('going', 'happen'), ('happen', ','), (',', 'diagnostic'), ('diagnostic', 'analytics'), ('analytics', 'estimates'), ('estimates', 'reason'), ('reason', 'something'), ('something', 'happened'), ('happened', ','), (',', 'requires'), ('requires', 'techniques'), ('techniques', 'discovering'), ('discovering', 'problem'), ('problem', '’'), ('’', 'root'), ('root', 'causes'), ('causes', '.')]

>> Trigrams are: 
 [('Figure', '17', ':'), ('17', ':', 'Other'), (':', 'Other', 'types'), ('Other', 'types', 'big'), ('types', 'big', 'data'), ('big', 'data', 'analytics2'), ('data', 'analytics2', 'Descriptive'), ('analytics2', 'Descriptive', 'analytics'), ('Descriptive', 'analytics', 'describes'), ('analytics', 'describes', 'either'), ('describes', 'either', 'happened'), ('either', 'happened', 'going'), ('happened', 'going', 'happen'), ('going', 'happen', ','), ('happen', ',', 'diagnostic'), (',', 'diagnostic', 'analytics'), ('diagnostic', 'analytics', 'estimates'), ('analytics', 'estimates', 'reason'), ('estimates', 'reason', 'something'), ('reason', 'something', 'happened'), ('something', 'happened', ','), ('happened', ',', 'requires'), (',', 'requires', 'techniques'), ('requires', 'techniques', 'discovering'), ('techniques', 'discovering', 'problem'), ('discovering', 'problem', '’'), ('problem', '’', 'root'), ('’', 'root', 'causes'), ('root', 'causes', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('17', 'CD'), (':', ':'), ('Other', 'JJ'), ('types', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics2', 'RB'), ('Descriptive', 'NNP'), ('analytics', 'NNS'), ('describes', 'VBP'), ('either', 'DT'), ('happened', 'VBD'), ('going', 'VBG'), ('happen', 'NN'), (',', ','), ('diagnostic', 'JJ'), ('analytics', 'NNS'), ('estimates', 'NNS'), ('reason', 'NN'), ('something', 'NN'), ('happened', 'VBD'), (',', ','), ('requires', 'VBZ'), ('techniques', 'NNS'), ('discovering', 'VBG'), ('problem', 'NN'), ('’', 'NN'), ('root', 'NN'), ('causes', 'NNS'), ('.', '.')]

 (S
  (NP Figure/NN)
  17/CD
  :/:
  (NP Other/JJ types/NNS)
  (NP big/JJ data/NNS)
  analytics2/RB
  (NP Descriptive/NNP analytics/NNS)
  describes/VBP
  either/DT
  happened/VBD
  going/VBG
  (NP happen/NN)
  ,/,
  (NP
    diagnostic/JJ
    analytics/NNS
    estimates/NNS
    reason/NN
    something/NN)
  happened/VBD
  ,/,
  requires/VBZ
  (NP techniques/NNS)
  discovering/VBG
  (NP problem/NN ’/NN root/NN causes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Other types', 'big data', 'Descriptive analytics', 'happen', 'diagnostic analytics estimates reason something', 'techniques', 'problem ’ root causes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('17', '17'), (':', ':'), ('Other', 'other'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics2', 'analytics2'), ('Descriptive', 'descript'), ('analytics', 'analyt'), ('describes', 'describ'), ('either', 'either'), ('happened', 'happen'), ('going', 'go'), ('happen', 'happen'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('estimates', 'estim'), ('reason', 'reason'), ('something', 'someth'), ('happened', 'happen'), (',', ','), ('requires', 'requir'), ('techniques', 'techniqu'), ('discovering', 'discov'), ('problem', 'problem'), ('’', '’'), ('root', 'root'), ('causes', 'caus'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('17', '17'), (':', ':'), ('Other', 'other'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics2', 'analytics2'), ('Descriptive', 'descript'), ('analytics', 'analyt'), ('describes', 'describ'), ('either', 'either'), ('happened', 'happen'), ('going', 'go'), ('happen', 'happen'), (',', ','), ('diagnostic', 'diagnost'), ('analytics', 'analyt'), ('estimates', 'estim'), ('reason', 'reason'), ('something', 'someth'), ('happened', 'happen'), (',', ','), ('requires', 'requir'), ('techniques', 'techniqu'), ('discovering', 'discov'), ('problem', 'problem'), ('’', '’'), ('root', 'root'), ('causes', 'caus'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('17', '17'), (':', ':'), ('Other', 'Other'), ('types', 'type'), ('big', 'big'), ('data', 'data'), ('analytics2', 'analytics2'), ('Descriptive', 'Descriptive'), ('analytics', 'analytics'), ('describes', 'describes'), ('either', 'either'), ('happened', 'happened'), ('going', 'going'), ('happen', 'happen'), (',', ','), ('diagnostic', 'diagnostic'), ('analytics', 'analytics'), ('estimates', 'estimate'), ('reason', 'reason'), ('something', 'something'), ('happened', 'happened'), (',', ','), ('requires', 'requires'), ('techniques', 'technique'), ('discovering', 'discovering'), ('problem', 'problem'), ('’', '’'), ('root', 'root'), ('causes', 'cause'), ('.', '.')]



============================ Sentence 364 =============================

Predictive analytics attempts to determine the   most likely future outcomes by applying statistical models (Waller and Fawcett, 2013), while   prescriptive analytics explains and predicts the future and describes outcomes using tools such as    optimisation, simulation, business rules, algorithms, and machine learning (Banerjee et al., 2013;   Grover and Kar, 2017). 


>> Tokens are: 
 ['Predictive', 'analytics', 'attempts', 'determine', 'likely', 'future', 'outcomes', 'applying', 'statistical', 'models', '(', 'Waller', 'Fawcett', ',', '2013', ')', ',', 'prescriptive', 'analytics', 'explains', 'predicts', 'future', 'describes', 'outcomes', 'using', 'tools', 'optimisation', ',', 'simulation', ',', 'business', 'rules', ',', 'algorithms', ',', 'machine', 'learning', '(', 'Banerjee', 'et', 'al.', ',', '2013', ';', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Predictive', 'analytics'), ('analytics', 'attempts'), ('attempts', 'determine'), ('determine', 'likely'), ('likely', 'future'), ('future', 'outcomes'), ('outcomes', 'applying'), ('applying', 'statistical'), ('statistical', 'models'), ('models', '('), ('(', 'Waller'), ('Waller', 'Fawcett'), ('Fawcett', ','), (',', '2013'), ('2013', ')'), (')', ','), (',', 'prescriptive'), ('prescriptive', 'analytics'), ('analytics', 'explains'), ('explains', 'predicts'), ('predicts', 'future'), ('future', 'describes'), ('describes', 'outcomes'), ('outcomes', 'using'), ('using', 'tools'), ('tools', 'optimisation'), ('optimisation', ','), (',', 'simulation'), ('simulation', ','), (',', 'business'), ('business', 'rules'), ('rules', ','), (',', 'algorithms'), ('algorithms', ','), (',', 'machine'), ('machine', 'learning'), ('learning', '('), ('(', 'Banerjee'), ('Banerjee', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ';'), (';', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Predictive', 'analytics', 'attempts'), ('analytics', 'attempts', 'determine'), ('attempts', 'determine', 'likely'), ('determine', 'likely', 'future'), ('likely', 'future', 'outcomes'), ('future', 'outcomes', 'applying'), ('outcomes', 'applying', 'statistical'), ('applying', 'statistical', 'models'), ('statistical', 'models', '('), ('models', '(', 'Waller'), ('(', 'Waller', 'Fawcett'), ('Waller', 'Fawcett', ','), ('Fawcett', ',', '2013'), (',', '2013', ')'), ('2013', ')', ','), (')', ',', 'prescriptive'), (',', 'prescriptive', 'analytics'), ('prescriptive', 'analytics', 'explains'), ('analytics', 'explains', 'predicts'), ('explains', 'predicts', 'future'), ('predicts', 'future', 'describes'), ('future', 'describes', 'outcomes'), ('describes', 'outcomes', 'using'), ('outcomes', 'using', 'tools'), ('using', 'tools', 'optimisation'), ('tools', 'optimisation', ','), ('optimisation', ',', 'simulation'), (',', 'simulation', ','), ('simulation', ',', 'business'), (',', 'business', 'rules'), ('business', 'rules', ','), ('rules', ',', 'algorithms'), (',', 'algorithms', ','), ('algorithms', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', '('), ('learning', '(', 'Banerjee'), ('(', 'Banerjee', 'et'), ('Banerjee', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ';'), ('2013', ';', 'Grover'), (';', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Predictive', 'JJ'), ('analytics', 'NNS'), ('attempts', 'NNS'), ('determine', 'VBP'), ('likely', 'JJ'), ('future', 'JJ'), ('outcomes', 'NNS'), ('applying', 'VBG'), ('statistical', 'JJ'), ('models', 'NNS'), ('(', '('), ('Waller', 'NNP'), ('Fawcett', 'NNP'), (',', ','), ('2013', 'CD'), (')', ')'), (',', ','), ('prescriptive', 'JJ'), ('analytics', 'NNS'), ('explains', 'VBZ'), ('predicts', 'NNS'), ('future', 'JJ'), ('describes', 'NNS'), ('outcomes', 'NNS'), ('using', 'VBG'), ('tools', 'JJ'), ('optimisation', 'NN'), (',', ','), ('simulation', 'NN'), (',', ','), ('business', 'NN'), ('rules', 'NNS'), (',', ','), ('algorithms', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), ('(', '('), ('Banerjee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (';', ':'), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Predictive/JJ analytics/NNS attempts/NNS)
  determine/VBP
  (NP likely/JJ future/JJ outcomes/NNS)
  applying/VBG
  (NP statistical/JJ models/NNS)
  (/(
  (NP Waller/NNP Fawcett/NNP)
  ,/,
  2013/CD
  )/)
  ,/,
  (NP prescriptive/JJ analytics/NNS)
  explains/VBZ
  (NP predicts/NNS)
  (NP future/JJ describes/NNS outcomes/NNS)
  using/VBG
  (NP tools/JJ optimisation/NN)
  ,/,
  (NP simulation/NN)
  ,/,
  (NP business/NN rules/NNS)
  ,/,
  (NP algorithms/NN)
  ,/,
  (NP machine/NN learning/NN)
  (/(
  (NP Banerjee/NNP)
  et/RB
  al./RB
  ,/,
  2013/CD
  ;/:
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Predictive analytics attempts', 'likely future outcomes', 'statistical models', 'Waller Fawcett', 'prescriptive analytics', 'predicts', 'future describes outcomes', 'tools optimisation', 'simulation', 'business rules', 'algorithms', 'machine learning', 'Banerjee', 'Grover Kar']

>> Named Entities are: 
 [('PERSON', 'Waller Fawcett'), ('ORGANIZATION', 'Banerjee'), ('PERSON', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('attempts', 'attempt'), ('determine', 'determin'), ('likely', 'like'), ('future', 'futur'), ('outcomes', 'outcom'), ('applying', 'appli'), ('statistical', 'statist'), ('models', 'model'), ('(', '('), ('Waller', 'waller'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (')', ')'), (',', ','), ('prescriptive', 'prescript'), ('analytics', 'analyt'), ('explains', 'explain'), ('predicts', 'predict'), ('future', 'futur'), ('describes', 'describ'), ('outcomes', 'outcom'), ('using', 'use'), ('tools', 'tool'), ('optimisation', 'optimis'), (',', ','), ('simulation', 'simul'), (',', ','), ('business', 'busi'), ('rules', 'rule'), (',', ','), ('algorithms', 'algorithm'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('attempts', 'attempt'), ('determine', 'determin'), ('likely', 'like'), ('future', 'futur'), ('outcomes', 'outcom'), ('applying', 'appli'), ('statistical', 'statist'), ('models', 'model'), ('(', '('), ('Waller', 'waller'), ('Fawcett', 'fawcett'), (',', ','), ('2013', '2013'), (')', ')'), (',', ','), ('prescriptive', 'prescript'), ('analytics', 'analyt'), ('explains', 'explain'), ('predicts', 'predict'), ('future', 'futur'), ('describes', 'describ'), ('outcomes', 'outcom'), ('using', 'use'), ('tools', 'tool'), ('optimisation', 'optimis'), (',', ','), ('simulation', 'simul'), (',', ','), ('business', 'busi'), ('rules', 'rule'), (',', ','), ('algorithms', 'algorithm'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Predictive', 'Predictive'), ('analytics', 'analytics'), ('attempts', 'attempt'), ('determine', 'determine'), ('likely', 'likely'), ('future', 'future'), ('outcomes', 'outcome'), ('applying', 'applying'), ('statistical', 'statistical'), ('models', 'model'), ('(', '('), ('Waller', 'Waller'), ('Fawcett', 'Fawcett'), (',', ','), ('2013', '2013'), (')', ')'), (',', ','), ('prescriptive', 'prescriptive'), ('analytics', 'analytics'), ('explains', 'explains'), ('predicts', 'predicts'), ('future', 'future'), ('describes', 'describes'), ('outcomes', 'outcome'), ('using', 'using'), ('tools', 'tool'), ('optimisation', 'optimisation'), (',', ','), ('simulation', 'simulation'), (',', ','), ('business', 'business'), ('rules', 'rule'), (',', ','), ('algorithms', 'algorithm'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('(', '('), ('Banerjee', 'Banerjee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (';', ';'), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 365 =============================

2 Based on (Grover and Kar, 2017)     Sarah Al-Shiakhli   30      The distribution of the research studies selected for systematic review across industry domains and   analytic types in terms of big data analytics is shown in Figure 18. 


>> Tokens are: 
 ['2', 'Based', '(', 'Grover', 'Kar', ',', '2017', ')', 'Sarah', 'Al-Shiakhli', '30', 'The', 'distribution', 'research', 'studies', 'selected', 'systematic', 'review', 'across', 'industry', 'domains', 'analytic', 'types', 'terms', 'big', 'data', 'analytics', 'shown', 'Figure', '18', '.']

>> Bigrams are: 
 [('2', 'Based'), ('Based', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '30'), ('30', 'The'), ('The', 'distribution'), ('distribution', 'research'), ('research', 'studies'), ('studies', 'selected'), ('selected', 'systematic'), ('systematic', 'review'), ('review', 'across'), ('across', 'industry'), ('industry', 'domains'), ('domains', 'analytic'), ('analytic', 'types'), ('types', 'terms'), ('terms', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'shown'), ('shown', 'Figure'), ('Figure', '18'), ('18', '.')]

>> Trigrams are: 
 [('2', 'Based', '('), ('Based', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', 'Sarah'), (')', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '30'), ('Al-Shiakhli', '30', 'The'), ('30', 'The', 'distribution'), ('The', 'distribution', 'research'), ('distribution', 'research', 'studies'), ('research', 'studies', 'selected'), ('studies', 'selected', 'systematic'), ('selected', 'systematic', 'review'), ('systematic', 'review', 'across'), ('review', 'across', 'industry'), ('across', 'industry', 'domains'), ('industry', 'domains', 'analytic'), ('domains', 'analytic', 'types'), ('analytic', 'types', 'terms'), ('types', 'terms', 'big'), ('terms', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'shown'), ('analytics', 'shown', 'Figure'), ('shown', 'Figure', '18'), ('Figure', '18', '.')]

>> POS Tags are: 
 [('2', 'CD'), ('Based', 'VBN'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('30', 'CD'), ('The', 'DT'), ('distribution', 'NN'), ('research', 'NN'), ('studies', 'NNS'), ('selected', 'VBN'), ('systematic', 'JJ'), ('review', 'NN'), ('across', 'IN'), ('industry', 'NN'), ('domains', 'VBZ'), ('analytic', 'JJ'), ('types', 'NNS'), ('terms', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('shown', 'VBN'), ('Figure', 'NNP'), ('18', 'CD'), ('.', '.')]

 (S
  2/CD
  Based/VBN
  (/(
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  )/)
  (NP Sarah/NNP Al-Shiakhli/NNP)
  30/CD
  (NP The/DT distribution/NN research/NN studies/NNS)
  selected/VBN
  (NP systematic/JJ review/NN)
  across/IN
  (NP industry/NN)
  domains/VBZ
  (NP analytic/JJ types/NNS terms/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  shown/VBN
  (NP Figure/NNP)
  18/CD
  ./.) 


>> Noun Phrases are: 
 ['Grover Kar', 'Sarah Al-Shiakhli', 'The distribution research studies', 'systematic review', 'industry', 'analytic types terms', 'big data analytics', 'Figure']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('2', '2'), ('Based', 'base'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('30', '30'), ('The', 'the'), ('distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri'), ('domains', 'domain'), ('analytic', 'analyt'), ('types', 'type'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shown', 'shown'), ('Figure', 'figur'), ('18', '18'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2', '2'), ('Based', 'base'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('30', '30'), ('The', 'the'), ('distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri'), ('domains', 'domain'), ('analytic', 'analyt'), ('types', 'type'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('shown', 'shown'), ('Figure', 'figur'), ('18', '18'), ('.', '.')]

>> Lemmatization: 
 [('2', '2'), ('Based', 'Based'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('30', '30'), ('The', 'The'), ('distribution', 'distribution'), ('research', 'research'), ('studies', 'study'), ('selected', 'selected'), ('systematic', 'systematic'), ('review', 'review'), ('across', 'across'), ('industry', 'industry'), ('domains', 'domain'), ('analytic', 'analytic'), ('types', 'type'), ('terms', 'term'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('shown', 'shown'), ('Figure', 'Figure'), ('18', '18'), ('.', '.')]



============================ Sentence 366 =============================

Figure 18: Distribution of research studies selected for systematic review across industry   domains and analytics types, adopted from (Grover and Kar, 2017)   7.5. 


>> Tokens are: 
 ['Figure', '18', ':', 'Distribution', 'research', 'studies', 'selected', 'systematic', 'review', 'across', 'industry', 'domains', 'analytics', 'types', ',', 'adopted', '(', 'Grover', 'Kar', ',', '2017', ')', '7.5', '.']

>> Bigrams are: 
 [('Figure', '18'), ('18', ':'), (':', 'Distribution'), ('Distribution', 'research'), ('research', 'studies'), ('studies', 'selected'), ('selected', 'systematic'), ('systematic', 'review'), ('review', 'across'), ('across', 'industry'), ('industry', 'domains'), ('domains', 'analytics'), ('analytics', 'types'), ('types', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '7.5'), ('7.5', '.')]

>> Trigrams are: 
 [('Figure', '18', ':'), ('18', ':', 'Distribution'), (':', 'Distribution', 'research'), ('Distribution', 'research', 'studies'), ('research', 'studies', 'selected'), ('studies', 'selected', 'systematic'), ('selected', 'systematic', 'review'), ('systematic', 'review', 'across'), ('review', 'across', 'industry'), ('across', 'industry', 'domains'), ('industry', 'domains', 'analytics'), ('domains', 'analytics', 'types'), ('analytics', 'types', ','), ('types', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Grover'), ('(', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '7.5'), (')', '7.5', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('18', 'CD'), (':', ':'), ('Distribution', 'NN'), ('research', 'NN'), ('studies', 'NNS'), ('selected', 'VBN'), ('systematic', 'JJ'), ('review', 'NN'), ('across', 'IN'), ('industry', 'NN'), ('domains', 'VBZ'), ('analytics', 'NNS'), ('types', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('7.5', 'CD'), ('.', '.')]

 (S
  (NP Figure/NN)
  18/CD
  :/:
  (NP Distribution/NN research/NN studies/NNS)
  selected/VBN
  (NP systematic/JJ review/NN)
  across/IN
  (NP industry/NN)
  domains/VBZ
  (NP analytics/NNS types/NNS)
  ,/,
  adopted/VBN
  (/(
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  )/)
  7.5/CD
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Distribution research studies', 'systematic review', 'industry', 'analytics types', 'Grover Kar']

>> Named Entities are: 
 [('ORGANIZATION', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('18', '18'), (':', ':'), ('Distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri'), ('domains', 'domain'), ('analytics', 'analyt'), ('types', 'type'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('7.5', '7.5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('18', '18'), (':', ':'), ('Distribution', 'distribut'), ('research', 'research'), ('studies', 'studi'), ('selected', 'select'), ('systematic', 'systemat'), ('review', 'review'), ('across', 'across'), ('industry', 'industri'), ('domains', 'domain'), ('analytics', 'analyt'), ('types', 'type'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('7.5', '7.5'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('18', '18'), (':', ':'), ('Distribution', 'Distribution'), ('research', 'research'), ('studies', 'study'), ('selected', 'selected'), ('systematic', 'systematic'), ('review', 'review'), ('across', 'across'), ('industry', 'industry'), ('domains', 'domain'), ('analytics', 'analytics'), ('types', 'type'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('7.5', '7.5'), ('.', '.')]



============================ Sentence 367 =============================

Big data platforms and tools   There are now multiple big data analytics tools and the study done by Oussous et al. 


>> Tokens are: 
 ['Big', 'data', 'platforms', 'tools', 'There', 'multiple', 'big', 'data', 'analytics', 'tools', 'study', 'done', 'Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', 'There'), ('There', 'multiple'), ('multiple', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', 'study'), ('study', 'done'), ('done', 'Oussous'), ('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', 'There'), ('tools', 'There', 'multiple'), ('There', 'multiple', 'big'), ('multiple', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', 'study'), ('tools', 'study', 'done'), ('study', 'done', 'Oussous'), ('done', 'Oussous', 'et'), ('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'NNS'), ('There', 'EX'), ('multiple', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), ('study', 'VBP'), ('done', 'VBN'), ('Oussous', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS platforms/NNS tools/NNS)
  There/EX
  (NP multiple/JJ big/JJ data/NNS analytics/NNS tools/NNS)
  study/VBP
  done/VBN
  (NP Oussous/NNP)
  et/CC
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data platforms tools', 'multiple big data analytics tools', 'Oussous', 'al']

>> Named Entities are: 
 [('PERSON', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('There', 'there'), ('multiple', 'multipl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('study', 'studi'), ('done', 'done'), ('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('There', 'there'), ('multiple', 'multipl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('study', 'studi'), ('done', 'done'), ('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('There', 'There'), ('multiple', 'multiple'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), ('study', 'study'), ('done', 'done'), ('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 368 =============================

(2018) showed   the importance of carefully choosing the right tool for the circumstances. 


>> Tokens are: 
 ['(', '2018', ')', 'showed', 'importance', 'carefully', 'choosing', 'right', 'tool', 'circumstances', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'showed'), ('showed', 'importance'), ('importance', 'carefully'), ('carefully', 'choosing'), ('choosing', 'right'), ('right', 'tool'), ('tool', 'circumstances'), ('circumstances', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'showed'), (')', 'showed', 'importance'), ('showed', 'importance', 'carefully'), ('importance', 'carefully', 'choosing'), ('carefully', 'choosing', 'right'), ('choosing', 'right', 'tool'), ('right', 'tool', 'circumstances'), ('tool', 'circumstances', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('showed', 'VBD'), ('importance', 'NN'), ('carefully', 'RB'), ('choosing', 'VBG'), ('right', 'JJ'), ('tool', 'NN'), ('circumstances', 'NNS'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  showed/VBD
  (NP importance/NN)
  carefully/RB
  choosing/VBG
  (NP right/JJ tool/NN circumstances/NNS)
  ./.) 


>> Noun Phrases are: 
 ['importance', 'right tool circumstances']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('showed', 'show'), ('importance', 'import'), ('carefully', 'care'), ('choosing', 'choos'), ('right', 'right'), ('tool', 'tool'), ('circumstances', 'circumst'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('showed', 'show'), ('importance', 'import'), ('carefully', 'care'), ('choosing', 'choos'), ('right', 'right'), ('tool', 'tool'), ('circumstances', 'circumst'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('showed', 'showed'), ('importance', 'importance'), ('carefully', 'carefully'), ('choosing', 'choosing'), ('right', 'right'), ('tool', 'tool'), ('circumstances', 'circumstance'), ('.', '.')]



============================ Sentence 369 =============================

The choice is dependent   on the “nature of datasets (i.e.-, volumes, streams, distribution), the complexity of analytical   problems, algorithms and analytical solutions used, systems capabilities, security and privacy   issues, the required performance and scalability in addition to the available budget” (ibid). 


>> Tokens are: 
 ['The', 'choice', 'dependent', '“', 'nature', 'datasets', '(', 'i.e.-', ',', 'volumes', ',', 'streams', ',', 'distribution', ')', ',', 'complexity', 'analytical', 'problems', ',', 'algorithms', 'analytical', 'solutions', 'used', ',', 'systems', 'capabilities', ',', 'security', 'privacy', 'issues', ',', 'required', 'performance', 'scalability', 'addition', 'available', 'budget', '”', '(', 'ibid', ')', '.']

>> Bigrams are: 
 [('The', 'choice'), ('choice', 'dependent'), ('dependent', '“'), ('“', 'nature'), ('nature', 'datasets'), ('datasets', '('), ('(', 'i.e.-'), ('i.e.-', ','), (',', 'volumes'), ('volumes', ','), (',', 'streams'), ('streams', ','), (',', 'distribution'), ('distribution', ')'), (')', ','), (',', 'complexity'), ('complexity', 'analytical'), ('analytical', 'problems'), ('problems', ','), (',', 'algorithms'), ('algorithms', 'analytical'), ('analytical', 'solutions'), ('solutions', 'used'), ('used', ','), (',', 'systems'), ('systems', 'capabilities'), ('capabilities', ','), (',', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', ','), (',', 'required'), ('required', 'performance'), ('performance', 'scalability'), ('scalability', 'addition'), ('addition', 'available'), ('available', 'budget'), ('budget', '”'), ('”', '('), ('(', 'ibid'), ('ibid', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'choice', 'dependent'), ('choice', 'dependent', '“'), ('dependent', '“', 'nature'), ('“', 'nature', 'datasets'), ('nature', 'datasets', '('), ('datasets', '(', 'i.e.-'), ('(', 'i.e.-', ','), ('i.e.-', ',', 'volumes'), (',', 'volumes', ','), ('volumes', ',', 'streams'), (',', 'streams', ','), ('streams', ',', 'distribution'), (',', 'distribution', ')'), ('distribution', ')', ','), (')', ',', 'complexity'), (',', 'complexity', 'analytical'), ('complexity', 'analytical', 'problems'), ('analytical', 'problems', ','), ('problems', ',', 'algorithms'), (',', 'algorithms', 'analytical'), ('algorithms', 'analytical', 'solutions'), ('analytical', 'solutions', 'used'), ('solutions', 'used', ','), ('used', ',', 'systems'), (',', 'systems', 'capabilities'), ('systems', 'capabilities', ','), ('capabilities', ',', 'security'), (',', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', ','), ('issues', ',', 'required'), (',', 'required', 'performance'), ('required', 'performance', 'scalability'), ('performance', 'scalability', 'addition'), ('scalability', 'addition', 'available'), ('addition', 'available', 'budget'), ('available', 'budget', '”'), ('budget', '”', '('), ('”', '(', 'ibid'), ('(', 'ibid', ')'), ('ibid', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('choice', 'NN'), ('dependent', 'JJ'), ('“', 'JJ'), ('nature', 'NN'), ('datasets', 'NNS'), ('(', '('), ('i.e.-', 'JJ'), (',', ','), ('volumes', 'NNS'), (',', ','), ('streams', 'NNS'), (',', ','), ('distribution', 'NN'), (')', ')'), (',', ','), ('complexity', 'JJ'), ('analytical', 'JJ'), ('problems', 'NNS'), (',', ','), ('algorithms', 'RB'), ('analytical', 'JJ'), ('solutions', 'NNS'), ('used', 'VBN'), (',', ','), ('systems', 'NNS'), ('capabilities', 'NNS'), (',', ','), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), (',', ','), ('required', 'VBN'), ('performance', 'NN'), ('scalability', 'NN'), ('addition', 'NN'), ('available', 'JJ'), ('budget', 'NN'), ('”', 'NN'), ('(', '('), ('ibid', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT choice/NN)
  (NP dependent/JJ “/JJ nature/NN datasets/NNS)
  (/(
  i.e.-/JJ
  ,/,
  (NP volumes/NNS)
  ,/,
  (NP streams/NNS)
  ,/,
  (NP distribution/NN)
  )/)
  ,/,
  (NP complexity/JJ analytical/JJ problems/NNS)
  ,/,
  algorithms/RB
  (NP analytical/JJ solutions/NNS)
  used/VBN
  ,/,
  (NP systems/NNS capabilities/NNS)
  ,/,
  (NP security/NN privacy/NN issues/NNS)
  ,/,
  required/VBN
  (NP performance/NN scalability/NN addition/NN)
  (NP available/JJ budget/NN ”/NN)
  (/(
  (NP ibid/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The choice', 'dependent “ nature datasets', 'volumes', 'streams', 'distribution', 'complexity analytical problems', 'analytical solutions', 'systems capabilities', 'security privacy issues', 'performance scalability addition', 'available budget ”', 'ibid']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('choice', 'choic'), ('dependent', 'depend'), ('“', '“'), ('nature', 'natur'), ('datasets', 'dataset'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('volumes', 'volum'), (',', ','), ('streams', 'stream'), (',', ','), ('distribution', 'distribut'), (')', ')'), (',', ','), ('complexity', 'complex'), ('analytical', 'analyt'), ('problems', 'problem'), (',', ','), ('algorithms', 'algorithm'), ('analytical', 'analyt'), ('solutions', 'solut'), ('used', 'use'), (',', ','), ('systems', 'system'), ('capabilities', 'capabl'), (',', ','), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('required', 'requir'), ('performance', 'perform'), ('scalability', 'scalabl'), ('addition', 'addit'), ('available', 'avail'), ('budget', 'budget'), ('”', '”'), ('(', '('), ('ibid', 'ibid'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('choice', 'choic'), ('dependent', 'depend'), ('“', '“'), ('nature', 'natur'), ('datasets', 'dataset'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('volumes', 'volum'), (',', ','), ('streams', 'stream'), (',', ','), ('distribution', 'distribut'), (')', ')'), (',', ','), ('complexity', 'complex'), ('analytical', 'analyt'), ('problems', 'problem'), (',', ','), ('algorithms', 'algorithm'), ('analytical', 'analyt'), ('solutions', 'solut'), ('used', 'use'), (',', ','), ('systems', 'system'), ('capabilities', 'capabl'), (',', ','), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('required', 'requir'), ('performance', 'perform'), ('scalability', 'scalabl'), ('addition', 'addit'), ('available', 'avail'), ('budget', 'budget'), ('”', '”'), ('(', '('), ('ibid', 'ibid'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('choice', 'choice'), ('dependent', 'dependent'), ('“', '“'), ('nature', 'nature'), ('datasets', 'datasets'), ('(', '('), ('i.e.-', 'i.e.-'), (',', ','), ('volumes', 'volume'), (',', ','), ('streams', 'stream'), (',', ','), ('distribution', 'distribution'), (')', ')'), (',', ','), ('complexity', 'complexity'), ('analytical', 'analytical'), ('problems', 'problem'), (',', ','), ('algorithms', 'algorithm'), ('analytical', 'analytical'), ('solutions', 'solution'), ('used', 'used'), (',', ','), ('systems', 'system'), ('capabilities', 'capability'), (',', ','), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), (',', ','), ('required', 'required'), ('performance', 'performance'), ('scalability', 'scalability'), ('addition', 'addition'), ('available', 'available'), ('budget', 'budget'), ('”', '”'), ('(', '('), ('ibid', 'ibid'), (')', ')'), ('.', '.')]



============================ Sentence 370 =============================

Some   of big data platforms and tools are shown in Figure 20. 


>> Tokens are: 
 ['Some', 'big', 'data', 'platforms', 'tools', 'shown', 'Figure', '20', '.']

>> Bigrams are: 
 [('Some', 'big'), ('big', 'data'), ('data', 'platforms'), ('platforms', 'tools'), ('tools', 'shown'), ('shown', 'Figure'), ('Figure', '20'), ('20', '.')]

>> Trigrams are: 
 [('Some', 'big', 'data'), ('big', 'data', 'platforms'), ('data', 'platforms', 'tools'), ('platforms', 'tools', 'shown'), ('tools', 'shown', 'Figure'), ('shown', 'Figure', '20'), ('Figure', '20', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('tools', 'VBP'), ('shown', 'VBN'), ('Figure', 'NNP'), ('20', 'CD'), ('.', '.')]

 (S
  (NP Some/DT big/JJ data/NNS platforms/NNS)
  tools/VBP
  shown/VBN
  (NP Figure/NNP)
  20/CD
  ./.) 


>> Noun Phrases are: 
 ['Some big data platforms', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('shown', 'shown'), ('Figure', 'figur'), ('20', '20'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('shown', 'shown'), ('Figure', 'figur'), ('20', '20'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('tools', 'tool'), ('shown', 'shown'), ('Figure', 'Figure'), ('20', '20'), ('.', '.')]



============================ Sentence 371 =============================

• Apache Mahout:  This is an open source machine learning software library that can be  used for executing algorithms via MapReduce, a framework for processing large datasets   (Eldawy and Mokbel, 2015). 


>> Tokens are: 
 ['•', 'Apache', 'Mahout', ':', 'This', 'open', 'source', 'machine', 'learning', 'software', 'library', 'used', 'executing', 'algorithms', 'via', 'MapReduce', ',', 'framework', 'processing', 'large', 'datasets', '(', 'Eldawy', 'Mokbel', ',', '2015', ')', '.']

>> Bigrams are: 
 [('•', 'Apache'), ('Apache', 'Mahout'), ('Mahout', ':'), (':', 'This'), ('This', 'open'), ('open', 'source'), ('source', 'machine'), ('machine', 'learning'), ('learning', 'software'), ('software', 'library'), ('library', 'used'), ('used', 'executing'), ('executing', 'algorithms'), ('algorithms', 'via'), ('via', 'MapReduce'), ('MapReduce', ','), (',', 'framework'), ('framework', 'processing'), ('processing', 'large'), ('large', 'datasets'), ('datasets', '('), ('(', 'Eldawy'), ('Eldawy', 'Mokbel'), ('Mokbel', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'Apache', 'Mahout'), ('Apache', 'Mahout', ':'), ('Mahout', ':', 'This'), (':', 'This', 'open'), ('This', 'open', 'source'), ('open', 'source', 'machine'), ('source', 'machine', 'learning'), ('machine', 'learning', 'software'), ('learning', 'software', 'library'), ('software', 'library', 'used'), ('library', 'used', 'executing'), ('used', 'executing', 'algorithms'), ('executing', 'algorithms', 'via'), ('algorithms', 'via', 'MapReduce'), ('via', 'MapReduce', ','), ('MapReduce', ',', 'framework'), (',', 'framework', 'processing'), ('framework', 'processing', 'large'), ('processing', 'large', 'datasets'), ('large', 'datasets', '('), ('datasets', '(', 'Eldawy'), ('(', 'Eldawy', 'Mokbel'), ('Eldawy', 'Mokbel', ','), ('Mokbel', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Apache', 'NNP'), ('Mahout', 'NN'), (':', ':'), ('This', 'DT'), ('open', 'JJ'), ('source', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('software', 'NN'), ('library', 'NN'), ('used', 'VBD'), ('executing', 'VBG'), ('algorithms', 'JJ'), ('via', 'IN'), ('MapReduce', 'NNP'), (',', ','), ('framework', 'NN'), ('processing', 'VBG'), ('large', 'JJ'), ('datasets', 'NNS'), ('(', '('), ('Eldawy', 'NNP'), ('Mokbel', 'NNP'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP •/JJ Apache/NNP Mahout/NN)
  :/:
  (NP This/DT open/JJ source/NN machine/NN)
  learning/VBG
  (NP software/NN library/NN)
  used/VBD
  executing/VBG
  algorithms/JJ
  via/IN
  (NP MapReduce/NNP)
  ,/,
  (NP framework/NN)
  processing/VBG
  (NP large/JJ datasets/NNS)
  (/(
  (NP Eldawy/NNP Mokbel/NNP)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['• Apache Mahout', 'This open source machine', 'software library', 'MapReduce', 'framework', 'large datasets', 'Eldawy Mokbel']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce'), ('ORGANIZATION', 'Eldawy Mokbel')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Apache', 'apach'), ('Mahout', 'mahout'), (':', ':'), ('This', 'thi'), ('open', 'open'), ('source', 'sourc'), ('machine', 'machin'), ('learning', 'learn'), ('software', 'softwar'), ('library', 'librari'), ('used', 'use'), ('executing', 'execut'), ('algorithms', 'algorithm'), ('via', 'via'), ('MapReduce', 'mapreduc'), (',', ','), ('framework', 'framework'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset'), ('(', '('), ('Eldawy', 'eldawi'), ('Mokbel', 'mokbel'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Apache', 'apach'), ('Mahout', 'mahout'), (':', ':'), ('This', 'this'), ('open', 'open'), ('source', 'sourc'), ('machine', 'machin'), ('learning', 'learn'), ('software', 'softwar'), ('library', 'librari'), ('used', 'use'), ('executing', 'execut'), ('algorithms', 'algorithm'), ('via', 'via'), ('MapReduce', 'mapreduc'), (',', ','), ('framework', 'framework'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset'), ('(', '('), ('Eldawy', 'eldawi'), ('Mokbel', 'mokbel'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Apache', 'Apache'), ('Mahout', 'Mahout'), (':', ':'), ('This', 'This'), ('open', 'open'), ('source', 'source'), ('machine', 'machine'), ('learning', 'learning'), ('software', 'software'), ('library', 'library'), ('used', 'used'), ('executing', 'executing'), ('algorithms', 'algorithm'), ('via', 'via'), ('MapReduce', 'MapReduce'), (',', ','), ('framework', 'framework'), ('processing', 'processing'), ('large', 'large'), ('datasets', 'datasets'), ('(', '('), ('Eldawy', 'Eldawy'), ('Mokbel', 'Mokbel'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 372 =============================

Mahout encompasses several Java libraries, ensuring   efficiency of processing large datasets by allowing application of large-scale machine   learning applications and algorithms. 


>> Tokens are: 
 ['Mahout', 'encompasses', 'several', 'Java', 'libraries', ',', 'ensuring', 'efficiency', 'processing', 'large', 'datasets', 'allowing', 'application', 'large-scale', 'machine', 'learning', 'applications', 'algorithms', '.']

>> Bigrams are: 
 [('Mahout', 'encompasses'), ('encompasses', 'several'), ('several', 'Java'), ('Java', 'libraries'), ('libraries', ','), (',', 'ensuring'), ('ensuring', 'efficiency'), ('efficiency', 'processing'), ('processing', 'large'), ('large', 'datasets'), ('datasets', 'allowing'), ('allowing', 'application'), ('application', 'large-scale'), ('large-scale', 'machine'), ('machine', 'learning'), ('learning', 'applications'), ('applications', 'algorithms'), ('algorithms', '.')]

>> Trigrams are: 
 [('Mahout', 'encompasses', 'several'), ('encompasses', 'several', 'Java'), ('several', 'Java', 'libraries'), ('Java', 'libraries', ','), ('libraries', ',', 'ensuring'), (',', 'ensuring', 'efficiency'), ('ensuring', 'efficiency', 'processing'), ('efficiency', 'processing', 'large'), ('processing', 'large', 'datasets'), ('large', 'datasets', 'allowing'), ('datasets', 'allowing', 'application'), ('allowing', 'application', 'large-scale'), ('application', 'large-scale', 'machine'), ('large-scale', 'machine', 'learning'), ('machine', 'learning', 'applications'), ('learning', 'applications', 'algorithms'), ('applications', 'algorithms', '.')]

>> POS Tags are: 
 [('Mahout', 'NNP'), ('encompasses', 'VBZ'), ('several', 'JJ'), ('Java', 'NNP'), ('libraries', 'NNS'), (',', ','), ('ensuring', 'VBG'), ('efficiency', 'NN'), ('processing', 'VBG'), ('large', 'JJ'), ('datasets', 'NNS'), ('allowing', 'VBG'), ('application', 'NN'), ('large-scale', 'JJ'), ('machine', 'NN'), ('learning', 'NN'), ('applications', 'NNS'), ('algorithms', 'VBP'), ('.', '.')]

 (S
  (NP Mahout/NNP)
  encompasses/VBZ
  (NP several/JJ Java/NNP libraries/NNS)
  ,/,
  ensuring/VBG
  (NP efficiency/NN)
  processing/VBG
  (NP large/JJ datasets/NNS)
  allowing/VBG
  (NP application/NN)
  (NP large-scale/JJ machine/NN learning/NN applications/NNS)
  algorithms/VBP
  ./.) 


>> Noun Phrases are: 
 ['Mahout', 'several Java libraries', 'efficiency', 'large datasets', 'application', 'large-scale machine learning applications']

>> Named Entities are: 
 [('GPE', 'Mahout')] 

>> Stemming using Porter Stemmer: 
 [('Mahout', 'mahout'), ('encompasses', 'encompass'), ('several', 'sever'), ('Java', 'java'), ('libraries', 'librari'), (',', ','), ('ensuring', 'ensur'), ('efficiency', 'effici'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset'), ('allowing', 'allow'), ('application', 'applic'), ('large-scale', 'large-scal'), ('machine', 'machin'), ('learning', 'learn'), ('applications', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mahout', 'mahout'), ('encompasses', 'encompass'), ('several', 'sever'), ('Java', 'java'), ('libraries', 'librari'), (',', ','), ('ensuring', 'ensur'), ('efficiency', 'effici'), ('processing', 'process'), ('large', 'larg'), ('datasets', 'dataset'), ('allowing', 'allow'), ('application', 'applic'), ('large-scale', 'large-scal'), ('machine', 'machin'), ('learning', 'learn'), ('applications', 'applic'), ('algorithms', 'algorithm'), ('.', '.')]

>> Lemmatization: 
 [('Mahout', 'Mahout'), ('encompasses', 'encompasses'), ('several', 'several'), ('Java', 'Java'), ('libraries', 'library'), (',', ','), ('ensuring', 'ensuring'), ('efficiency', 'efficiency'), ('processing', 'processing'), ('large', 'large'), ('datasets', 'datasets'), ('allowing', 'allowing'), ('application', 'application'), ('large-scale', 'large-scale'), ('machine', 'machine'), ('learning', 'learning'), ('applications', 'application'), ('algorithms', 'algorithm'), ('.', '.')]



============================ Sentence 373 =============================

It provides an optimised algorithm in which Mahout   converts machine learning tasks presented in Java into MapReduce jobs (Acharjya et al.,   2016). 


>> Tokens are: 
 ['It', 'provides', 'optimised', 'algorithm', 'Mahout', 'converts', 'machine', 'learning', 'tasks', 'presented', 'Java', 'MapReduce', 'jobs', '(', 'Acharjya', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('It', 'provides'), ('provides', 'optimised'), ('optimised', 'algorithm'), ('algorithm', 'Mahout'), ('Mahout', 'converts'), ('converts', 'machine'), ('machine', 'learning'), ('learning', 'tasks'), ('tasks', 'presented'), ('presented', 'Java'), ('Java', 'MapReduce'), ('MapReduce', 'jobs'), ('jobs', '('), ('(', 'Acharjya'), ('Acharjya', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'provides', 'optimised'), ('provides', 'optimised', 'algorithm'), ('optimised', 'algorithm', 'Mahout'), ('algorithm', 'Mahout', 'converts'), ('Mahout', 'converts', 'machine'), ('converts', 'machine', 'learning'), ('machine', 'learning', 'tasks'), ('learning', 'tasks', 'presented'), ('tasks', 'presented', 'Java'), ('presented', 'Java', 'MapReduce'), ('Java', 'MapReduce', 'jobs'), ('MapReduce', 'jobs', '('), ('jobs', '(', 'Acharjya'), ('(', 'Acharjya', 'et'), ('Acharjya', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('provides', 'VBZ'), ('optimised', 'JJ'), ('algorithm', 'NN'), ('Mahout', 'NNP'), ('converts', 'VBZ'), ('machine', 'NN'), ('learning', 'VBG'), ('tasks', 'NNS'), ('presented', 'VBN'), ('Java', 'NNP'), ('MapReduce', 'NNP'), ('jobs', 'NNS'), ('(', '('), ('Acharjya', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  provides/VBZ
  (NP optimised/JJ algorithm/NN Mahout/NNP)
  converts/VBZ
  (NP machine/NN)
  learning/VBG
  (NP tasks/NNS)
  presented/VBN
  (NP Java/NNP MapReduce/NNP jobs/NNS)
  (/(
  (NP Acharjya/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['optimised algorithm Mahout', 'machine', 'tasks', 'Java MapReduce jobs', 'Acharjya']

>> Named Entities are: 
 [('PERSON', 'Mahout'), ('PERSON', 'Java MapReduce'), ('ORGANIZATION', 'Acharjya')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('optimised', 'optimis'), ('algorithm', 'algorithm'), ('Mahout', 'mahout'), ('converts', 'convert'), ('machine', 'machin'), ('learning', 'learn'), ('tasks', 'task'), ('presented', 'present'), ('Java', 'java'), ('MapReduce', 'mapreduc'), ('jobs', 'job'), ('(', '('), ('Acharjya', 'acharjya'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('optimised', 'optimis'), ('algorithm', 'algorithm'), ('Mahout', 'mahout'), ('converts', 'convert'), ('machine', 'machin'), ('learning', 'learn'), ('tasks', 'task'), ('presented', 'present'), ('Java', 'java'), ('MapReduce', 'mapreduc'), ('jobs', 'job'), ('(', '('), ('Acharjya', 'acharjya'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('provides', 'provides'), ('optimised', 'optimised'), ('algorithm', 'algorithm'), ('Mahout', 'Mahout'), ('converts', 'convert'), ('machine', 'machine'), ('learning', 'learning'), ('tasks', 'task'), ('presented', 'presented'), ('Java', 'Java'), ('MapReduce', 'MapReduce'), ('jobs', 'job'), ('(', '('), ('Acharjya', 'Acharjya'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 374 =============================

• R: This is a programming language often used for big data analysis, which offers relatively  easy solutions to performing advanced analysis on large data sets via Hadoop. 


>> Tokens are: 
 ['•', 'R', ':', 'This', 'programming', 'language', 'often', 'used', 'big', 'data', 'analysis', ',', 'offers', 'relatively', 'easy', 'solutions', 'performing', 'advanced', 'analysis', 'large', 'data', 'sets', 'via', 'Hadoop', '.']

>> Bigrams are: 
 [('•', 'R'), ('R', ':'), (':', 'This'), ('This', 'programming'), ('programming', 'language'), ('language', 'often'), ('often', 'used'), ('used', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'offers'), ('offers', 'relatively'), ('relatively', 'easy'), ('easy', 'solutions'), ('solutions', 'performing'), ('performing', 'advanced'), ('advanced', 'analysis'), ('analysis', 'large'), ('large', 'data'), ('data', 'sets'), ('sets', 'via'), ('via', 'Hadoop'), ('Hadoop', '.')]

>> Trigrams are: 
 [('•', 'R', ':'), ('R', ':', 'This'), (':', 'This', 'programming'), ('This', 'programming', 'language'), ('programming', 'language', 'often'), ('language', 'often', 'used'), ('often', 'used', 'big'), ('used', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'offers'), (',', 'offers', 'relatively'), ('offers', 'relatively', 'easy'), ('relatively', 'easy', 'solutions'), ('easy', 'solutions', 'performing'), ('solutions', 'performing', 'advanced'), ('performing', 'advanced', 'analysis'), ('advanced', 'analysis', 'large'), ('analysis', 'large', 'data'), ('large', 'data', 'sets'), ('data', 'sets', 'via'), ('sets', 'via', 'Hadoop'), ('via', 'Hadoop', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('R', 'NN'), (':', ':'), ('This', 'DT'), ('programming', 'NN'), ('language', 'NN'), ('often', 'RB'), ('used', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('offers', 'VBZ'), ('relatively', 'RB'), ('easy', 'JJ'), ('solutions', 'NNS'), ('performing', 'VBG'), ('advanced', 'JJ'), ('analysis', 'NN'), ('large', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('via', 'IN'), ('Hadoop', 'NNP'), ('.', '.')]

 (S
  (NP •/JJ R/NN)
  :/:
  (NP This/DT programming/NN language/NN)
  often/RB
  used/VBD
  (NP big/JJ data/NNS analysis/NN)
  ,/,
  offers/VBZ
  relatively/RB
  (NP easy/JJ solutions/NNS)
  performing/VBG
  (NP advanced/JJ analysis/NN)
  (NP large/JJ data/NNS sets/NNS)
  via/IN
  (NP Hadoop/NNP)
  ./.) 


>> Noun Phrases are: 
 ['• R', 'This programming language', 'big data analysis', 'easy solutions', 'advanced analysis', 'large data sets', 'Hadoop']

>> Named Entities are: 
 [('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('R', 'r'), (':', ':'), ('This', 'thi'), ('programming', 'program'), ('language', 'languag'), ('often', 'often'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('offers', 'offer'), ('relatively', 'rel'), ('easy', 'easi'), ('solutions', 'solut'), ('performing', 'perform'), ('advanced', 'advanc'), ('analysis', 'analysi'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('via', 'via'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('R', 'r'), (':', ':'), ('This', 'this'), ('programming', 'program'), ('language', 'languag'), ('often', 'often'), ('used', 'use'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('offers', 'offer'), ('relatively', 'relat'), ('easy', 'easi'), ('solutions', 'solut'), ('performing', 'perform'), ('advanced', 'advanc'), ('analysis', 'analysi'), ('large', 'larg'), ('data', 'data'), ('sets', 'set'), ('via', 'via'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('R', 'R'), (':', ':'), ('This', 'This'), ('programming', 'programming'), ('language', 'language'), ('often', 'often'), ('used', 'used'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('offers', 'offer'), ('relatively', 'relatively'), ('easy', 'easy'), ('solutions', 'solution'), ('performing', 'performing'), ('advanced', 'advanced'), ('analysis', 'analysis'), ('large', 'large'), ('data', 'data'), ('sets', 'set'), ('via', 'via'), ('Hadoop', 'Hadoop'), ('.', '.')]



============================ Sentence 375 =============================

As compared   to Mahout, in term of types and algorithms, R provides a more complete set of classification   models; however, it is limited by its nature as an object-oriented programming language,   which can cause problems with memory management compared to other solutions. 


>> Tokens are: 
 ['As', 'compared', 'Mahout', ',', 'term', 'types', 'algorithms', ',', 'R', 'provides', 'complete', 'set', 'classification', 'models', ';', 'however', ',', 'limited', 'nature', 'object-oriented', 'programming', 'language', ',', 'cause', 'problems', 'memory', 'management', 'compared', 'solutions', '.']

>> Bigrams are: 
 [('As', 'compared'), ('compared', 'Mahout'), ('Mahout', ','), (',', 'term'), ('term', 'types'), ('types', 'algorithms'), ('algorithms', ','), (',', 'R'), ('R', 'provides'), ('provides', 'complete'), ('complete', 'set'), ('set', 'classification'), ('classification', 'models'), ('models', ';'), (';', 'however'), ('however', ','), (',', 'limited'), ('limited', 'nature'), ('nature', 'object-oriented'), ('object-oriented', 'programming'), ('programming', 'language'), ('language', ','), (',', 'cause'), ('cause', 'problems'), ('problems', 'memory'), ('memory', 'management'), ('management', 'compared'), ('compared', 'solutions'), ('solutions', '.')]

>> Trigrams are: 
 [('As', 'compared', 'Mahout'), ('compared', 'Mahout', ','), ('Mahout', ',', 'term'), (',', 'term', 'types'), ('term', 'types', 'algorithms'), ('types', 'algorithms', ','), ('algorithms', ',', 'R'), (',', 'R', 'provides'), ('R', 'provides', 'complete'), ('provides', 'complete', 'set'), ('complete', 'set', 'classification'), ('set', 'classification', 'models'), ('classification', 'models', ';'), ('models', ';', 'however'), (';', 'however', ','), ('however', ',', 'limited'), (',', 'limited', 'nature'), ('limited', 'nature', 'object-oriented'), ('nature', 'object-oriented', 'programming'), ('object-oriented', 'programming', 'language'), ('programming', 'language', ','), ('language', ',', 'cause'), (',', 'cause', 'problems'), ('cause', 'problems', 'memory'), ('problems', 'memory', 'management'), ('memory', 'management', 'compared'), ('management', 'compared', 'solutions'), ('compared', 'solutions', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('compared', 'VBN'), ('Mahout', 'NNP'), (',', ','), ('term', 'NN'), ('types', 'NNS'), ('algorithms', 'VBP'), (',', ','), ('R', 'NNP'), ('provides', 'VBZ'), ('complete', 'JJ'), ('set', 'VBN'), ('classification', 'NN'), ('models', 'NNS'), (';', ':'), ('however', 'RB'), (',', ','), ('limited', 'JJ'), ('nature', 'NN'), ('object-oriented', 'JJ'), ('programming', 'NN'), ('language', 'NN'), (',', ','), ('cause', 'NN'), ('problems', 'NNS'), ('memory', 'JJ'), ('management', 'NN'), ('compared', 'VBN'), ('solutions', 'NNS'), ('.', '.')]

 (S
  As/IN
  compared/VBN
  (NP Mahout/NNP)
  ,/,
  (NP term/NN types/NNS)
  algorithms/VBP
  ,/,
  (NP R/NNP)
  provides/VBZ
  complete/JJ
  set/VBN
  (NP classification/NN models/NNS)
  ;/:
  however/RB
  ,/,
  (NP limited/JJ nature/NN)
  (NP object-oriented/JJ programming/NN language/NN)
  ,/,
  (NP cause/NN problems/NNS)
  (NP memory/JJ management/NN)
  compared/VBN
  (NP solutions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Mahout', 'term types', 'R', 'classification models', 'limited nature', 'object-oriented programming language', 'cause problems', 'memory management', 'solutions']

>> Named Entities are: 
 [('PERSON', 'Mahout'), ('ORGANIZATION', 'R')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('compared', 'compar'), ('Mahout', 'mahout'), (',', ','), ('term', 'term'), ('types', 'type'), ('algorithms', 'algorithm'), (',', ','), ('R', 'r'), ('provides', 'provid'), ('complete', 'complet'), ('set', 'set'), ('classification', 'classif'), ('models', 'model'), (';', ';'), ('however', 'howev'), (',', ','), ('limited', 'limit'), ('nature', 'natur'), ('object-oriented', 'object-ori'), ('programming', 'program'), ('language', 'languag'), (',', ','), ('cause', 'caus'), ('problems', 'problem'), ('memory', 'memori'), ('management', 'manag'), ('compared', 'compar'), ('solutions', 'solut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('compared', 'compar'), ('Mahout', 'mahout'), (',', ','), ('term', 'term'), ('types', 'type'), ('algorithms', 'algorithm'), (',', ','), ('R', 'r'), ('provides', 'provid'), ('complete', 'complet'), ('set', 'set'), ('classification', 'classif'), ('models', 'model'), (';', ';'), ('however', 'howev'), (',', ','), ('limited', 'limit'), ('nature', 'natur'), ('object-oriented', 'object-ori'), ('programming', 'program'), ('language', 'languag'), (',', ','), ('cause', 'caus'), ('problems', 'problem'), ('memory', 'memori'), ('management', 'manag'), ('compared', 'compar'), ('solutions', 'solut'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('compared', 'compared'), ('Mahout', 'Mahout'), (',', ','), ('term', 'term'), ('types', 'type'), ('algorithms', 'algorithm'), (',', ','), ('R', 'R'), ('provides', 'provides'), ('complete', 'complete'), ('set', 'set'), ('classification', 'classification'), ('models', 'model'), (';', ';'), ('however', 'however'), (',', ','), ('limited', 'limited'), ('nature', 'nature'), ('object-oriented', 'object-oriented'), ('programming', 'programming'), ('language', 'language'), (',', ','), ('cause', 'cause'), ('problems', 'problem'), ('memory', 'memory'), ('management', 'management'), ('compared', 'compared'), ('solutions', 'solution'), ('.', '.')]



============================ Sentence 376 =============================

In many     Sarah Al-Shiakhli   31      cases, use in combination with Mahout is thus recommended (Team, R.C., 2000), as R can   be used to execute small data exploration while Hadoop/Jaql executes the larger operations. 


>> Tokens are: 
 ['In', 'many', 'Sarah', 'Al-Shiakhli', '31', 'cases', ',', 'use', 'combination', 'Mahout', 'thus', 'recommended', '(', 'Team', ',', 'R.C.', ',', '2000', ')', ',', 'R', 'used', 'execute', 'small', 'data', 'exploration', 'Hadoop/Jaql', 'executes', 'larger', 'operations', '.']

>> Bigrams are: 
 [('In', 'many'), ('many', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '31'), ('31', 'cases'), ('cases', ','), (',', 'use'), ('use', 'combination'), ('combination', 'Mahout'), ('Mahout', 'thus'), ('thus', 'recommended'), ('recommended', '('), ('(', 'Team'), ('Team', ','), (',', 'R.C.'), ('R.C.', ','), (',', '2000'), ('2000', ')'), (')', ','), (',', 'R'), ('R', 'used'), ('used', 'execute'), ('execute', 'small'), ('small', 'data'), ('data', 'exploration'), ('exploration', 'Hadoop/Jaql'), ('Hadoop/Jaql', 'executes'), ('executes', 'larger'), ('larger', 'operations'), ('operations', '.')]

>> Trigrams are: 
 [('In', 'many', 'Sarah'), ('many', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '31'), ('Al-Shiakhli', '31', 'cases'), ('31', 'cases', ','), ('cases', ',', 'use'), (',', 'use', 'combination'), ('use', 'combination', 'Mahout'), ('combination', 'Mahout', 'thus'), ('Mahout', 'thus', 'recommended'), ('thus', 'recommended', '('), ('recommended', '(', 'Team'), ('(', 'Team', ','), ('Team', ',', 'R.C.'), (',', 'R.C.', ','), ('R.C.', ',', '2000'), (',', '2000', ')'), ('2000', ')', ','), (')', ',', 'R'), (',', 'R', 'used'), ('R', 'used', 'execute'), ('used', 'execute', 'small'), ('execute', 'small', 'data'), ('small', 'data', 'exploration'), ('data', 'exploration', 'Hadoop/Jaql'), ('exploration', 'Hadoop/Jaql', 'executes'), ('Hadoop/Jaql', 'executes', 'larger'), ('executes', 'larger', 'operations'), ('larger', 'operations', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('many', 'JJ'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('31', 'CD'), ('cases', 'NNS'), (',', ','), ('use', 'NN'), ('combination', 'NN'), ('Mahout', 'NNP'), ('thus', 'RB'), ('recommended', 'VBD'), ('(', '('), ('Team', 'NNP'), (',', ','), ('R.C.', 'NNP'), (',', ','), ('2000', 'CD'), (')', ')'), (',', ','), ('R', 'NNP'), ('used', 'VBD'), ('execute', 'VB'), ('small', 'JJ'), ('data', 'NNS'), ('exploration', 'NN'), ('Hadoop/Jaql', 'NNP'), ('executes', 'VBZ'), ('larger', 'JJR'), ('operations', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP many/JJ Sarah/NNP Al-Shiakhli/NNP)
  31/CD
  (NP cases/NNS)
  ,/,
  (NP use/NN combination/NN Mahout/NNP)
  thus/RB
  recommended/VBD
  (/(
  (NP Team/NNP)
  ,/,
  (NP R.C./NNP)
  ,/,
  2000/CD
  )/)
  ,/,
  (NP R/NNP)
  used/VBD
  execute/VB
  (NP small/JJ data/NNS exploration/NN Hadoop/Jaql/NNP)
  executes/VBZ
  larger/JJR
  (NP operations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['many Sarah Al-Shiakhli', 'cases', 'use combination Mahout', 'Team', 'R.C.', 'R', 'small data exploration Hadoop/Jaql', 'operations']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Mahout'), ('ORGANIZATION', 'Team'), ('PERSON', 'R')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('many', 'mani'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('31', '31'), ('cases', 'case'), (',', ','), ('use', 'use'), ('combination', 'combin'), ('Mahout', 'mahout'), ('thus', 'thu'), ('recommended', 'recommend'), ('(', '('), ('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), (')', ')'), (',', ','), ('R', 'r'), ('used', 'use'), ('execute', 'execut'), ('small', 'small'), ('data', 'data'), ('exploration', 'explor'), ('Hadoop/Jaql', 'hadoop/jaql'), ('executes', 'execut'), ('larger', 'larger'), ('operations', 'oper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('many', 'mani'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('31', '31'), ('cases', 'case'), (',', ','), ('use', 'use'), ('combination', 'combin'), ('Mahout', 'mahout'), ('thus', 'thus'), ('recommended', 'recommend'), ('(', '('), ('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), (')', ')'), (',', ','), ('R', 'r'), ('used', 'use'), ('execute', 'execut'), ('small', 'small'), ('data', 'data'), ('exploration', 'explor'), ('Hadoop/Jaql', 'hadoop/jaql'), ('executes', 'execut'), ('larger', 'larger'), ('operations', 'oper'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('many', 'many'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('31', '31'), ('cases', 'case'), (',', ','), ('use', 'use'), ('combination', 'combination'), ('Mahout', 'Mahout'), ('thus', 'thus'), ('recommended', 'recommended'), ('(', '('), ('Team', 'Team'), (',', ','), ('R.C.', 'R.C.'), (',', ','), ('2000', '2000'), (')', ')'), (',', ','), ('R', 'R'), ('used', 'used'), ('execute', 'execute'), ('small', 'small'), ('data', 'data'), ('exploration', 'exploration'), ('Hadoop/Jaql', 'Hadoop/Jaql'), ('executes', 'executes'), ('larger', 'larger'), ('operations', 'operation'), ('.', '.')]



============================ Sentence 377 =============================

• Alteryx: This tool offers data blending and an advanced analytics platform where analysts  can merge internal business processes, third-party tools, and cloud data centres. 


>> Tokens are: 
 ['•', 'Alteryx', ':', 'This', 'tool', 'offers', 'data', 'blending', 'advanced', 'analytics', 'platform', 'analysts', 'merge', 'internal', 'business', 'processes', ',', 'third-party', 'tools', ',', 'cloud', 'data', 'centres', '.']

>> Bigrams are: 
 [('•', 'Alteryx'), ('Alteryx', ':'), (':', 'This'), ('This', 'tool'), ('tool', 'offers'), ('offers', 'data'), ('data', 'blending'), ('blending', 'advanced'), ('advanced', 'analytics'), ('analytics', 'platform'), ('platform', 'analysts'), ('analysts', 'merge'), ('merge', 'internal'), ('internal', 'business'), ('business', 'processes'), ('processes', ','), (',', 'third-party'), ('third-party', 'tools'), ('tools', ','), (',', 'cloud'), ('cloud', 'data'), ('data', 'centres'), ('centres', '.')]

>> Trigrams are: 
 [('•', 'Alteryx', ':'), ('Alteryx', ':', 'This'), (':', 'This', 'tool'), ('This', 'tool', 'offers'), ('tool', 'offers', 'data'), ('offers', 'data', 'blending'), ('data', 'blending', 'advanced'), ('blending', 'advanced', 'analytics'), ('advanced', 'analytics', 'platform'), ('analytics', 'platform', 'analysts'), ('platform', 'analysts', 'merge'), ('analysts', 'merge', 'internal'), ('merge', 'internal', 'business'), ('internal', 'business', 'processes'), ('business', 'processes', ','), ('processes', ',', 'third-party'), (',', 'third-party', 'tools'), ('third-party', 'tools', ','), ('tools', ',', 'cloud'), (',', 'cloud', 'data'), ('cloud', 'data', 'centres'), ('data', 'centres', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Alteryx', 'NNP'), (':', ':'), ('This', 'DT'), ('tool', 'NN'), ('offers', 'VBZ'), ('data', 'NNS'), ('blending', 'NN'), ('advanced', 'VBD'), ('analytics', 'NNS'), ('platform', 'NN'), ('analysts', 'NNS'), ('merge', 'VBP'), ('internal', 'JJ'), ('business', 'NN'), ('processes', 'NNS'), (',', ','), ('third-party', 'JJ'), ('tools', 'NNS'), (',', ','), ('cloud', 'NN'), ('data', 'NNS'), ('centres', 'NNS'), ('.', '.')]

 (S
  (NP •/JJ Alteryx/NNP)
  :/:
  (NP This/DT tool/NN)
  offers/VBZ
  (NP data/NNS blending/NN)
  advanced/VBD
  (NP analytics/NNS platform/NN analysts/NNS)
  merge/VBP
  (NP internal/JJ business/NN processes/NNS)
  ,/,
  (NP third-party/JJ tools/NNS)
  ,/,
  (NP cloud/NN data/NNS centres/NNS)
  ./.) 


>> Noun Phrases are: 
 ['• Alteryx', 'This tool', 'data blending', 'analytics platform analysts', 'internal business processes', 'third-party tools', 'cloud data centres']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Alteryx', 'alteryx'), (':', ':'), ('This', 'thi'), ('tool', 'tool'), ('offers', 'offer'), ('data', 'data'), ('blending', 'blend'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('platform', 'platform'), ('analysts', 'analyst'), ('merge', 'merg'), ('internal', 'intern'), ('business', 'busi'), ('processes', 'process'), (',', ','), ('third-party', 'third-parti'), ('tools', 'tool'), (',', ','), ('cloud', 'cloud'), ('data', 'data'), ('centres', 'centr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Alteryx', 'alteryx'), (':', ':'), ('This', 'this'), ('tool', 'tool'), ('offers', 'offer'), ('data', 'data'), ('blending', 'blend'), ('advanced', 'advanc'), ('analytics', 'analyt'), ('platform', 'platform'), ('analysts', 'analyst'), ('merge', 'merg'), ('internal', 'intern'), ('business', 'busi'), ('processes', 'process'), (',', ','), ('third-party', 'third-parti'), ('tools', 'tool'), (',', ','), ('cloud', 'cloud'), ('data', 'data'), ('centres', 'centr'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Alteryx', 'Alteryx'), (':', ':'), ('This', 'This'), ('tool', 'tool'), ('offers', 'offer'), ('data', 'data'), ('blending', 'blending'), ('advanced', 'advanced'), ('analytics', 'analytics'), ('platform', 'platform'), ('analysts', 'analyst'), ('merge', 'merge'), ('internal', 'internal'), ('business', 'business'), ('processes', 'process'), (',', ','), ('third-party', 'third-party'), ('tools', 'tool'), (',', ','), ('cloud', 'cloud'), ('data', 'data'), ('centres', 'centre'), ('.', '.')]



============================ Sentence 378 =============================

Also, it   allows data analytics utilizing some tools in a single workflow (ur Rehman et al., 2016). 


>> Tokens are: 
 ['Also', ',', 'allows', 'data', 'analytics', 'utilizing', 'tools', 'single', 'workflow', '(', 'ur', 'Rehman', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Also', ','), (',', 'allows'), ('allows', 'data'), ('data', 'analytics'), ('analytics', 'utilizing'), ('utilizing', 'tools'), ('tools', 'single'), ('single', 'workflow'), ('workflow', '('), ('(', 'ur'), ('ur', 'Rehman'), ('Rehman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Also', ',', 'allows'), (',', 'allows', 'data'), ('allows', 'data', 'analytics'), ('data', 'analytics', 'utilizing'), ('analytics', 'utilizing', 'tools'), ('utilizing', 'tools', 'single'), ('tools', 'single', 'workflow'), ('single', 'workflow', '('), ('workflow', '(', 'ur'), ('(', 'ur', 'Rehman'), ('ur', 'Rehman', 'et'), ('Rehman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('allows', 'VBZ'), ('data', 'NNS'), ('analytics', 'NNS'), ('utilizing', 'JJ'), ('tools', 'NNS'), ('single', 'JJ'), ('workflow', 'NN'), ('(', '('), ('ur', 'JJ'), ('Rehman', 'NNP'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  Also/RB
  ,/,
  allows/VBZ
  (NP data/NNS analytics/NNS)
  (NP utilizing/JJ tools/NNS)
  (NP single/JJ workflow/NN)
  (/(
  (NP ur/JJ Rehman/NNP et/NN al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['data analytics', 'utilizing tools', 'single workflow', 'ur Rehman et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('allows', 'allow'), ('data', 'data'), ('analytics', 'analyt'), ('utilizing', 'util'), ('tools', 'tool'), ('single', 'singl'), ('workflow', 'workflow'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('allows', 'allow'), ('data', 'data'), ('analytics', 'analyt'), ('utilizing', 'util'), ('tools', 'tool'), ('single', 'singl'), ('workflow', 'workflow'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('allows', 'allows'), ('data', 'data'), ('analytics', 'analytics'), ('utilizing', 'utilizing'), ('tools', 'tool'), ('single', 'single'), ('workflow', 'workflow'), ('(', '('), ('ur', 'ur'), ('Rehman', 'Rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 379 =============================

• Google Cloud Platform (GCP) is one of the leaders among cloud Application  Programming Interfaces (APIs). 


>> Tokens are: 
 ['•', 'Google', 'Cloud', 'Platform', '(', 'GCP', ')', 'one', 'leaders', 'among', 'cloud', 'Application', 'Programming', 'Interfaces', '(', 'APIs', ')', '.']

>> Bigrams are: 
 [('•', 'Google'), ('Google', 'Cloud'), ('Cloud', 'Platform'), ('Platform', '('), ('(', 'GCP'), ('GCP', ')'), (')', 'one'), ('one', 'leaders'), ('leaders', 'among'), ('among', 'cloud'), ('cloud', 'Application'), ('Application', 'Programming'), ('Programming', 'Interfaces'), ('Interfaces', '('), ('(', 'APIs'), ('APIs', ')'), (')', '.')]

>> Trigrams are: 
 [('•', 'Google', 'Cloud'), ('Google', 'Cloud', 'Platform'), ('Cloud', 'Platform', '('), ('Platform', '(', 'GCP'), ('(', 'GCP', ')'), ('GCP', ')', 'one'), (')', 'one', 'leaders'), ('one', 'leaders', 'among'), ('leaders', 'among', 'cloud'), ('among', 'cloud', 'Application'), ('cloud', 'Application', 'Programming'), ('Application', 'Programming', 'Interfaces'), ('Programming', 'Interfaces', '('), ('Interfaces', '(', 'APIs'), ('(', 'APIs', ')'), ('APIs', ')', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Google', 'NNP'), ('Cloud', 'NNP'), ('Platform', 'NNP'), ('(', '('), ('GCP', 'NNP'), (')', ')'), ('one', 'CD'), ('leaders', 'NNS'), ('among', 'IN'), ('cloud', 'JJ'), ('Application', 'NNP'), ('Programming', 'NNP'), ('Interfaces', 'NNP'), ('(', '('), ('APIs', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP •/JJ Google/NNP Cloud/NNP Platform/NNP)
  (/(
  (NP GCP/NNP)
  )/)
  one/CD
  (NP leaders/NNS)
  among/IN
  (NP cloud/JJ Application/NNP Programming/NNP Interfaces/NNP)
  (/(
  (NP APIs/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['• Google Cloud Platform', 'GCP', 'leaders', 'cloud Application Programming Interfaces', 'APIs']

>> Named Entities are: 
 [('PERSON', 'Google Cloud Platform'), ('ORGANIZATION', 'GCP'), ('ORGANIZATION', 'APIs')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Google', 'googl'), ('Cloud', 'cloud'), ('Platform', 'platform'), ('(', '('), ('GCP', 'gcp'), (')', ')'), ('one', 'one'), ('leaders', 'leader'), ('among', 'among'), ('cloud', 'cloud'), ('Application', 'applic'), ('Programming', 'program'), ('Interfaces', 'interfac'), ('(', '('), ('APIs', 'api'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Google', 'googl'), ('Cloud', 'cloud'), ('Platform', 'platform'), ('(', '('), ('GCP', 'gcp'), (')', ')'), ('one', 'one'), ('leaders', 'leader'), ('among', 'among'), ('cloud', 'cloud'), ('Application', 'applic'), ('Programming', 'program'), ('Interfaces', 'interfac'), ('(', '('), ('APIs', 'api'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Google', 'Google'), ('Cloud', 'Cloud'), ('Platform', 'Platform'), ('(', '('), ('GCP', 'GCP'), (')', ')'), ('one', 'one'), ('leaders', 'leader'), ('among', 'among'), ('cloud', 'cloud'), ('Application', 'Application'), ('Programming', 'Programming'), ('Interfaces', 'Interfaces'), ('(', '('), ('APIs', 'APIs'), (')', ')'), ('.', '.')]



============================ Sentence 380 =============================

Despite the fact that it was established a few years ago,   GCP has realized a significant growth since it suits the public cloud services that are based   on massive, solid infrastructures. 


>> Tokens are: 
 ['Despite', 'fact', 'established', 'years', 'ago', ',', 'GCP', 'realized', 'significant', 'growth', 'since', 'suits', 'public', 'cloud', 'services', 'based', 'massive', ',', 'solid', 'infrastructures', '.']

>> Bigrams are: 
 [('Despite', 'fact'), ('fact', 'established'), ('established', 'years'), ('years', 'ago'), ('ago', ','), (',', 'GCP'), ('GCP', 'realized'), ('realized', 'significant'), ('significant', 'growth'), ('growth', 'since'), ('since', 'suits'), ('suits', 'public'), ('public', 'cloud'), ('cloud', 'services'), ('services', 'based'), ('based', 'massive'), ('massive', ','), (',', 'solid'), ('solid', 'infrastructures'), ('infrastructures', '.')]

>> Trigrams are: 
 [('Despite', 'fact', 'established'), ('fact', 'established', 'years'), ('established', 'years', 'ago'), ('years', 'ago', ','), ('ago', ',', 'GCP'), (',', 'GCP', 'realized'), ('GCP', 'realized', 'significant'), ('realized', 'significant', 'growth'), ('significant', 'growth', 'since'), ('growth', 'since', 'suits'), ('since', 'suits', 'public'), ('suits', 'public', 'cloud'), ('public', 'cloud', 'services'), ('cloud', 'services', 'based'), ('services', 'based', 'massive'), ('based', 'massive', ','), ('massive', ',', 'solid'), (',', 'solid', 'infrastructures'), ('solid', 'infrastructures', '.')]

>> POS Tags are: 
 [('Despite', 'IN'), ('fact', 'NN'), ('established', 'VBN'), ('years', 'NNS'), ('ago', 'RB'), (',', ','), ('GCP', 'NNP'), ('realized', 'VBD'), ('significant', 'JJ'), ('growth', 'NN'), ('since', 'IN'), ('suits', 'NNS'), ('public', 'JJ'), ('cloud', 'NN'), ('services', 'NNS'), ('based', 'VBN'), ('massive', 'JJ'), (',', ','), ('solid', 'JJ'), ('infrastructures', 'NNS'), ('.', '.')]

 (S
  Despite/IN
  (NP fact/NN)
  established/VBN
  (NP years/NNS)
  ago/RB
  ,/,
  (NP GCP/NNP)
  realized/VBD
  (NP significant/JJ growth/NN)
  since/IN
  (NP suits/NNS)
  (NP public/JJ cloud/NN services/NNS)
  based/VBN
  massive/JJ
  ,/,
  (NP solid/JJ infrastructures/NNS)
  ./.) 


>> Noun Phrases are: 
 ['fact', 'years', 'GCP', 'significant growth', 'suits', 'public cloud services', 'solid infrastructures']

>> Named Entities are: 
 [('ORGANIZATION', 'GCP')] 

>> Stemming using Porter Stemmer: 
 [('Despite', 'despit'), ('fact', 'fact'), ('established', 'establish'), ('years', 'year'), ('ago', 'ago'), (',', ','), ('GCP', 'gcp'), ('realized', 'realiz'), ('significant', 'signific'), ('growth', 'growth'), ('since', 'sinc'), ('suits', 'suit'), ('public', 'public'), ('cloud', 'cloud'), ('services', 'servic'), ('based', 'base'), ('massive', 'massiv'), (',', ','), ('solid', 'solid'), ('infrastructures', 'infrastructur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Despite', 'despit'), ('fact', 'fact'), ('established', 'establish'), ('years', 'year'), ('ago', 'ago'), (',', ','), ('GCP', 'gcp'), ('realized', 'realiz'), ('significant', 'signific'), ('growth', 'growth'), ('since', 'sinc'), ('suits', 'suit'), ('public', 'public'), ('cloud', 'cloud'), ('services', 'servic'), ('based', 'base'), ('massive', 'massiv'), (',', ','), ('solid', 'solid'), ('infrastructures', 'infrastructur'), ('.', '.')]

>> Lemmatization: 
 [('Despite', 'Despite'), ('fact', 'fact'), ('established', 'established'), ('years', 'year'), ('ago', 'ago'), (',', ','), ('GCP', 'GCP'), ('realized', 'realized'), ('significant', 'significant'), ('growth', 'growth'), ('since', 'since'), ('suits', 'suit'), ('public', 'public'), ('cloud', 'cloud'), ('services', 'service'), ('based', 'based'), ('massive', 'massive'), (',', ','), ('solid', 'solid'), ('infrastructures', 'infrastructure'), ('.', '.')]



============================ Sentence 381 =============================

It gives the developer the ability to build a range of   programs starting from simple websites to complex world-wide distributed applications. 


>> Tokens are: 
 ['It', 'gives', 'developer', 'ability', 'build', 'range', 'programs', 'starting', 'simple', 'websites', 'complex', 'world-wide', 'distributed', 'applications', '.']

>> Bigrams are: 
 [('It', 'gives'), ('gives', 'developer'), ('developer', 'ability'), ('ability', 'build'), ('build', 'range'), ('range', 'programs'), ('programs', 'starting'), ('starting', 'simple'), ('simple', 'websites'), ('websites', 'complex'), ('complex', 'world-wide'), ('world-wide', 'distributed'), ('distributed', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('It', 'gives', 'developer'), ('gives', 'developer', 'ability'), ('developer', 'ability', 'build'), ('ability', 'build', 'range'), ('build', 'range', 'programs'), ('range', 'programs', 'starting'), ('programs', 'starting', 'simple'), ('starting', 'simple', 'websites'), ('simple', 'websites', 'complex'), ('websites', 'complex', 'world-wide'), ('complex', 'world-wide', 'distributed'), ('world-wide', 'distributed', 'applications'), ('distributed', 'applications', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('gives', 'VBZ'), ('developer', 'JJ'), ('ability', 'NN'), ('build', 'VBP'), ('range', 'NN'), ('programs', 'NNS'), ('starting', 'VBG'), ('simple', 'JJ'), ('websites', 'NNS'), ('complex', 'JJ'), ('world-wide', 'JJ'), ('distributed', 'VBN'), ('applications', 'NNS'), ('.', '.')]

 (S
  It/PRP
  gives/VBZ
  (NP developer/JJ ability/NN)
  build/VBP
  (NP range/NN programs/NNS)
  starting/VBG
  (NP simple/JJ websites/NNS)
  complex/JJ
  world-wide/JJ
  distributed/VBN
  (NP applications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['developer ability', 'range programs', 'simple websites', 'applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('gives', 'give'), ('developer', 'develop'), ('ability', 'abil'), ('build', 'build'), ('range', 'rang'), ('programs', 'program'), ('starting', 'start'), ('simple', 'simpl'), ('websites', 'websit'), ('complex', 'complex'), ('world-wide', 'world-wid'), ('distributed', 'distribut'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('gives', 'give'), ('developer', 'develop'), ('ability', 'abil'), ('build', 'build'), ('range', 'rang'), ('programs', 'program'), ('starting', 'start'), ('simple', 'simpl'), ('websites', 'websit'), ('complex', 'complex'), ('world-wide', 'world-wid'), ('distributed', 'distribut'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('gives', 'give'), ('developer', 'developer'), ('ability', 'ability'), ('build', 'build'), ('range', 'range'), ('programs', 'program'), ('starting', 'starting'), ('simple', 'simple'), ('websites', 'website'), ('complex', 'complex'), ('world-wide', 'world-wide'), ('distributed', 'distributed'), ('applications', 'application'), ('.', '.')]



============================ Sentence 382 =============================

GCP platform contains a set of physical assets (e.g.-.-, computers and hard disk drives) and   virtual resources (e.g.-.-, virtual machines, a.k.a. 


>> Tokens are: 
 ['GCP', 'platform', 'contains', 'set', 'physical', 'assets', '(', 'e.g.-.-', ',', 'computers', 'hard', 'disk', 'drives', ')', 'virtual', 'resources', '(', 'e.g.-.-', ',', 'virtual', 'machines', ',', 'a.k.a', '.']

>> Bigrams are: 
 [('GCP', 'platform'), ('platform', 'contains'), ('contains', 'set'), ('set', 'physical'), ('physical', 'assets'), ('assets', '('), ('(', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'computers'), ('computers', 'hard'), ('hard', 'disk'), ('disk', 'drives'), ('drives', ')'), (')', 'virtual'), ('virtual', 'resources'), ('resources', '('), ('(', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'virtual'), ('virtual', 'machines'), ('machines', ','), (',', 'a.k.a'), ('a.k.a', '.')]

>> Trigrams are: 
 [('GCP', 'platform', 'contains'), ('platform', 'contains', 'set'), ('contains', 'set', 'physical'), ('set', 'physical', 'assets'), ('physical', 'assets', '('), ('assets', '(', 'e.g.-.-'), ('(', 'e.g.-.-', ','), ('e.g.-.-', ',', 'computers'), (',', 'computers', 'hard'), ('computers', 'hard', 'disk'), ('hard', 'disk', 'drives'), ('disk', 'drives', ')'), ('drives', ')', 'virtual'), (')', 'virtual', 'resources'), ('virtual', 'resources', '('), ('resources', '(', 'e.g.-.-'), ('(', 'e.g.-.-', ','), ('e.g.-.-', ',', 'virtual'), (',', 'virtual', 'machines'), ('virtual', 'machines', ','), ('machines', ',', 'a.k.a'), (',', 'a.k.a', '.')]

>> POS Tags are: 
 [('GCP', 'NNP'), ('platform', 'NN'), ('contains', 'VBZ'), ('set', 'VBN'), ('physical', 'JJ'), ('assets', 'NNS'), ('(', '('), ('e.g.-.-', 'JJ'), (',', ','), ('computers', 'NNS'), ('hard', 'JJ'), ('disk', 'NN'), ('drives', 'NNS'), (')', ')'), ('virtual', 'JJ'), ('resources', 'NNS'), ('(', '('), ('e.g.-.-', 'JJ'), (',', ','), ('virtual', 'JJ'), ('machines', 'NNS'), (',', ','), ('a.k.a', 'NN'), ('.', '.')]

 (S
  (NP GCP/NNP platform/NN)
  contains/VBZ
  set/VBN
  (NP physical/JJ assets/NNS)
  (/(
  e.g.-.-/JJ
  ,/,
  (NP computers/NNS)
  (NP hard/JJ disk/NN drives/NNS)
  )/)
  (NP virtual/JJ resources/NNS)
  (/(
  e.g.-.-/JJ
  ,/,
  (NP virtual/JJ machines/NNS)
  ,/,
  (NP a.k.a/NN)
  ./.) 


>> Noun Phrases are: 
 ['GCP platform', 'physical assets', 'computers', 'hard disk drives', 'virtual resources', 'virtual machines', 'a.k.a']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('GCP', 'gcp'), ('platform', 'platform'), ('contains', 'contain'), ('set', 'set'), ('physical', 'physic'), ('assets', 'asset'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('computers', 'comput'), ('hard', 'hard'), ('disk', 'disk'), ('drives', 'drive'), (')', ')'), ('virtual', 'virtual'), ('resources', 'resourc'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('virtual', 'virtual'), ('machines', 'machin'), (',', ','), ('a.k.a', 'a.k.a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('GCP', 'gcp'), ('platform', 'platform'), ('contains', 'contain'), ('set', 'set'), ('physical', 'physic'), ('assets', 'asset'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('computers', 'comput'), ('hard', 'hard'), ('disk', 'disk'), ('drives', 'drive'), (')', ')'), ('virtual', 'virtual'), ('resources', 'resourc'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('virtual', 'virtual'), ('machines', 'machin'), (',', ','), ('a.k.a', 'a.k.a'), ('.', '.')]

>> Lemmatization: 
 [('GCP', 'GCP'), ('platform', 'platform'), ('contains', 'contains'), ('set', 'set'), ('physical', 'physical'), ('assets', 'asset'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('computers', 'computer'), ('hard', 'hard'), ('disk', 'disk'), ('drives', 'drive'), (')', ')'), ('virtual', 'virtual'), ('resources', 'resource'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('virtual', 'virtual'), ('machines', 'machine'), (',', ','), ('a.k.a', 'a.k.a'), ('.', '.')]



============================ Sentence 383 =============================

VMs) hosted in Google’s data centres   around the globe (Challita et al.,  2018 ). 


>> Tokens are: 
 ['VMs', ')', 'hosted', 'Google', '’', 'data', 'centres', 'around', 'globe', '(', 'Challita', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('VMs', ')'), (')', 'hosted'), ('hosted', 'Google'), ('Google', '’'), ('’', 'data'), ('data', 'centres'), ('centres', 'around'), ('around', 'globe'), ('globe', '('), ('(', 'Challita'), ('Challita', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('VMs', ')', 'hosted'), (')', 'hosted', 'Google'), ('hosted', 'Google', '’'), ('Google', '’', 'data'), ('’', 'data', 'centres'), ('data', 'centres', 'around'), ('centres', 'around', 'globe'), ('around', 'globe', '('), ('globe', '(', 'Challita'), ('(', 'Challita', 'et'), ('Challita', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('VMs', 'NNP'), (')', ')'), ('hosted', 'VBD'), ('Google', 'NNP'), ('’', 'NNP'), ('data', 'NN'), ('centres', 'NNS'), ('around', 'IN'), ('globe', 'NN'), ('(', '('), ('Challita', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP VMs/NNP)
  )/)
  hosted/VBD
  (NP Google/NNP ’/NNP data/NN centres/NNS)
  around/IN
  (NP globe/NN)
  (/(
  (NP Challita/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['VMs', 'Google ’ data centres', 'globe', 'Challita']

>> Named Entities are: 
 [('PERSON', 'Google')] 

>> Stemming using Porter Stemmer: 
 [('VMs', 'vm'), (')', ')'), ('hosted', 'host'), ('Google', 'googl'), ('’', '’'), ('data', 'data'), ('centres', 'centr'), ('around', 'around'), ('globe', 'globe'), ('(', '('), ('Challita', 'challita'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('VMs', 'vms'), (')', ')'), ('hosted', 'host'), ('Google', 'googl'), ('’', '’'), ('data', 'data'), ('centres', 'centr'), ('around', 'around'), ('globe', 'globe'), ('(', '('), ('Challita', 'challita'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('VMs', 'VMs'), (')', ')'), ('hosted', 'hosted'), ('Google', 'Google'), ('’', '’'), ('data', 'data'), ('centres', 'centre'), ('around', 'around'), ('globe', 'globe'), ('(', '('), ('Challita', 'Challita'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 384 =============================

• H2O is an open source framework offering parallel processing, analytics, math, and  machine learning libraries beside data pre-processing and assessment tools. 


>> Tokens are: 
 ['•', 'H2O', 'open', 'source', 'framework', 'offering', 'parallel', 'processing', ',', 'analytics', ',', 'math', ',', 'machine', 'learning', 'libraries', 'beside', 'data', 'pre-processing', 'assessment', 'tools', '.']

>> Bigrams are: 
 [('•', 'H2O'), ('H2O', 'open'), ('open', 'source'), ('source', 'framework'), ('framework', 'offering'), ('offering', 'parallel'), ('parallel', 'processing'), ('processing', ','), (',', 'analytics'), ('analytics', ','), (',', 'math'), ('math', ','), (',', 'machine'), ('machine', 'learning'), ('learning', 'libraries'), ('libraries', 'beside'), ('beside', 'data'), ('data', 'pre-processing'), ('pre-processing', 'assessment'), ('assessment', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('•', 'H2O', 'open'), ('H2O', 'open', 'source'), ('open', 'source', 'framework'), ('source', 'framework', 'offering'), ('framework', 'offering', 'parallel'), ('offering', 'parallel', 'processing'), ('parallel', 'processing', ','), ('processing', ',', 'analytics'), (',', 'analytics', ','), ('analytics', ',', 'math'), (',', 'math', ','), ('math', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', 'libraries'), ('learning', 'libraries', 'beside'), ('libraries', 'beside', 'data'), ('beside', 'data', 'pre-processing'), ('data', 'pre-processing', 'assessment'), ('pre-processing', 'assessment', 'tools'), ('assessment', 'tools', '.')]

>> POS Tags are: 
 [('•', 'NN'), ('H2O', 'NNP'), ('open', 'JJ'), ('source', 'NN'), ('framework', 'NN'), ('offering', 'VBG'), ('parallel', 'JJ'), ('processing', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('math', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'VBG'), ('libraries', 'NNS'), ('beside', 'IN'), ('data', 'NNS'), ('pre-processing', 'JJ'), ('assessment', 'NN'), ('tools', 'NNS'), ('.', '.')]

 (S
  (NP •/NN H2O/NNP)
  (NP open/JJ source/NN framework/NN)
  offering/VBG
  (NP parallel/JJ processing/NN)
  ,/,
  (NP analytics/NNS)
  ,/,
  (NP math/NN)
  ,/,
  (NP machine/NN)
  learning/VBG
  (NP libraries/NNS)
  beside/IN
  (NP data/NNS)
  (NP pre-processing/JJ assessment/NN tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['• H2O', 'open source framework', 'parallel processing', 'analytics', 'math', 'machine', 'libraries', 'data', 'pre-processing assessment tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('H2O', 'h2o'), ('open', 'open'), ('source', 'sourc'), ('framework', 'framework'), ('offering', 'offer'), ('parallel', 'parallel'), ('processing', 'process'), (',', ','), ('analytics', 'analyt'), (',', ','), ('math', 'math'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('libraries', 'librari'), ('beside', 'besid'), ('data', 'data'), ('pre-processing', 'pre-process'), ('assessment', 'assess'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('H2O', 'h2o'), ('open', 'open'), ('source', 'sourc'), ('framework', 'framework'), ('offering', 'offer'), ('parallel', 'parallel'), ('processing', 'process'), (',', ','), ('analytics', 'analyt'), (',', ','), ('math', 'math'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), ('libraries', 'librari'), ('beside', 'besid'), ('data', 'data'), ('pre-processing', 'pre-process'), ('assessment', 'assess'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('H2O', 'H2O'), ('open', 'open'), ('source', 'source'), ('framework', 'framework'), ('offering', 'offering'), ('parallel', 'parallel'), ('processing', 'processing'), (',', ','), ('analytics', 'analytics'), (',', ','), ('math', 'math'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), ('libraries', 'library'), ('beside', 'beside'), ('data', 'data'), ('pre-processing', 'pre-processing'), ('assessment', 'assessment'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 385 =============================

Furthermore,   it offers a web-based user interface that eases its use by analysts and statisticians who have   limited programming backgrounds. 


>> Tokens are: 
 ['Furthermore', ',', 'offers', 'web-based', 'user', 'interface', 'eases', 'use', 'analysts', 'statisticians', 'limited', 'programming', 'backgrounds', '.']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'offers'), ('offers', 'web-based'), ('web-based', 'user'), ('user', 'interface'), ('interface', 'eases'), ('eases', 'use'), ('use', 'analysts'), ('analysts', 'statisticians'), ('statisticians', 'limited'), ('limited', 'programming'), ('programming', 'backgrounds'), ('backgrounds', '.')]

>> Trigrams are: 
 [('Furthermore', ',', 'offers'), (',', 'offers', 'web-based'), ('offers', 'web-based', 'user'), ('web-based', 'user', 'interface'), ('user', 'interface', 'eases'), ('interface', 'eases', 'use'), ('eases', 'use', 'analysts'), ('use', 'analysts', 'statisticians'), ('analysts', 'statisticians', 'limited'), ('statisticians', 'limited', 'programming'), ('limited', 'programming', 'backgrounds'), ('programming', 'backgrounds', '.')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('offers', 'VBZ'), ('web-based', 'JJ'), ('user', 'NN'), ('interface', 'NN'), ('eases', 'VBZ'), ('use', 'VBP'), ('analysts', 'NNS'), ('statisticians', 'NNS'), ('limited', 'JJ'), ('programming', 'VBG'), ('backgrounds', 'NNS'), ('.', '.')]

 (S
  Furthermore/RB
  ,/,
  offers/VBZ
  (NP web-based/JJ user/NN interface/NN)
  eases/VBZ
  use/VBP
  (NP analysts/NNS statisticians/NNS)
  limited/JJ
  programming/VBG
  (NP backgrounds/NNS)
  ./.) 


>> Noun Phrases are: 
 ['web-based user interface', 'analysts statisticians', 'backgrounds']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('offers', 'offer'), ('web-based', 'web-bas'), ('user', 'user'), ('interface', 'interfac'), ('eases', 'eas'), ('use', 'use'), ('analysts', 'analyst'), ('statisticians', 'statistician'), ('limited', 'limit'), ('programming', 'program'), ('backgrounds', 'background'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('offers', 'offer'), ('web-based', 'web-bas'), ('user', 'user'), ('interface', 'interfac'), ('eases', 'eas'), ('use', 'use'), ('analysts', 'analyst'), ('statisticians', 'statistician'), ('limited', 'limit'), ('programming', 'program'), ('backgrounds', 'background'), ('.', '.')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('offers', 'offer'), ('web-based', 'web-based'), ('user', 'user'), ('interface', 'interface'), ('eases', 'eas'), ('use', 'use'), ('analysts', 'analyst'), ('statisticians', 'statistician'), ('limited', 'limited'), ('programming', 'programming'), ('backgrounds', 'background'), ('.', '.')]



============================ Sentence 386 =============================

It also provides support for Java, R, Python, and Scala   (Landset et al., 2015). 


>> Tokens are: 
 ['It', 'also', 'provides', 'support', 'Java', ',', 'R', ',', 'Python', ',', 'Scala', '(', 'Landset', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'provides'), ('provides', 'support'), ('support', 'Java'), ('Java', ','), (',', 'R'), ('R', ','), (',', 'Python'), ('Python', ','), (',', 'Scala'), ('Scala', '('), ('(', 'Landset'), ('Landset', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'also', 'provides'), ('also', 'provides', 'support'), ('provides', 'support', 'Java'), ('support', 'Java', ','), ('Java', ',', 'R'), (',', 'R', ','), ('R', ',', 'Python'), (',', 'Python', ','), ('Python', ',', 'Scala'), (',', 'Scala', '('), ('Scala', '(', 'Landset'), ('(', 'Landset', 'et'), ('Landset', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('provides', 'VBZ'), ('support', 'NN'), ('Java', 'NNP'), (',', ','), ('R', 'NNP'), (',', ','), ('Python', 'NNP'), (',', ','), ('Scala', 'NNP'), ('(', '('), ('Landset', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  also/RB
  provides/VBZ
  (NP support/NN Java/NNP)
  ,/,
  (NP R/NNP)
  ,/,
  (NP Python/NNP)
  ,/,
  (NP Scala/NNP)
  (/(
  (NP Landset/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['support Java', 'R', 'Python', 'Scala', 'Landset']

>> Named Entities are: 
 [('PERSON', 'Java'), ('GPE', 'R'), ('PERSON', 'Python'), ('GPE', 'Scala'), ('PERSON', 'Landset')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('provides', 'provid'), ('support', 'support'), ('Java', 'java'), (',', ','), ('R', 'r'), (',', ','), ('Python', 'python'), (',', ','), ('Scala', 'scala'), ('(', '('), ('Landset', 'landset'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('provides', 'provid'), ('support', 'support'), ('Java', 'java'), (',', ','), ('R', 'r'), (',', ','), ('Python', 'python'), (',', ','), ('Scala', 'scala'), ('(', '('), ('Landset', 'landset'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('provides', 'provides'), ('support', 'support'), ('Java', 'Java'), (',', ','), ('R', 'R'), (',', ','), ('Python', 'Python'), (',', ','), ('Scala', 'Scala'), ('(', '('), ('Landset', 'Landset'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 387 =============================

• MicroStrategy provides an integrated big data analytics platform where the data is stored  in Hadoop clusters and the users are given permission to access the desktop computer and   mobile devices. 


>> Tokens are: 
 ['•', 'MicroStrategy', 'provides', 'integrated', 'big', 'data', 'analytics', 'platform', 'data', 'stored', 'Hadoop', 'clusters', 'users', 'given', 'permission', 'access', 'desktop', 'computer', 'mobile', 'devices', '.']

>> Bigrams are: 
 [('•', 'MicroStrategy'), ('MicroStrategy', 'provides'), ('provides', 'integrated'), ('integrated', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'platform'), ('platform', 'data'), ('data', 'stored'), ('stored', 'Hadoop'), ('Hadoop', 'clusters'), ('clusters', 'users'), ('users', 'given'), ('given', 'permission'), ('permission', 'access'), ('access', 'desktop'), ('desktop', 'computer'), ('computer', 'mobile'), ('mobile', 'devices'), ('devices', '.')]

>> Trigrams are: 
 [('•', 'MicroStrategy', 'provides'), ('MicroStrategy', 'provides', 'integrated'), ('provides', 'integrated', 'big'), ('integrated', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'platform'), ('analytics', 'platform', 'data'), ('platform', 'data', 'stored'), ('data', 'stored', 'Hadoop'), ('stored', 'Hadoop', 'clusters'), ('Hadoop', 'clusters', 'users'), ('clusters', 'users', 'given'), ('users', 'given', 'permission'), ('given', 'permission', 'access'), ('permission', 'access', 'desktop'), ('access', 'desktop', 'computer'), ('desktop', 'computer', 'mobile'), ('computer', 'mobile', 'devices'), ('mobile', 'devices', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('MicroStrategy', 'NNP'), ('provides', 'VBZ'), ('integrated', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('platform', 'NN'), ('data', 'NNS'), ('stored', 'VBD'), ('Hadoop', 'NNP'), ('clusters', 'NNS'), ('users', 'NNS'), ('given', 'VBN'), ('permission', 'NN'), ('access', 'NN'), ('desktop', 'NN'), ('computer', 'NN'), ('mobile', 'JJ'), ('devices', 'NNS'), ('.', '.')]

 (S
  (NP •/JJ MicroStrategy/NNP)
  provides/VBZ
  (NP
    integrated/JJ
    big/JJ
    data/NNS
    analytics/NNS
    platform/NN
    data/NNS)
  stored/VBD
  (NP Hadoop/NNP clusters/NNS users/NNS)
  given/VBN
  (NP permission/NN access/NN desktop/NN computer/NN)
  (NP mobile/JJ devices/NNS)
  ./.) 


>> Noun Phrases are: 
 ['• MicroStrategy', 'integrated big data analytics platform data', 'Hadoop clusters users', 'permission access desktop computer', 'mobile devices']

>> Named Entities are: 
 [('ORGANIZATION', 'MicroStrategy'), ('GPE', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('MicroStrategy', 'microstrategi'), ('provides', 'provid'), ('integrated', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('data', 'data'), ('stored', 'store'), ('Hadoop', 'hadoop'), ('clusters', 'cluster'), ('users', 'user'), ('given', 'given'), ('permission', 'permiss'), ('access', 'access'), ('desktop', 'desktop'), ('computer', 'comput'), ('mobile', 'mobil'), ('devices', 'devic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('MicroStrategy', 'microstrategi'), ('provides', 'provid'), ('integrated', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platform', 'platform'), ('data', 'data'), ('stored', 'store'), ('Hadoop', 'hadoop'), ('clusters', 'cluster'), ('users', 'user'), ('given', 'given'), ('permission', 'permiss'), ('access', 'access'), ('desktop', 'desktop'), ('computer', 'comput'), ('mobile', 'mobil'), ('devices', 'devic'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('MicroStrategy', 'MicroStrategy'), ('provides', 'provides'), ('integrated', 'integrated'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('platform', 'platform'), ('data', 'data'), ('stored', 'stored'), ('Hadoop', 'Hadoop'), ('clusters', 'cluster'), ('users', 'user'), ('given', 'given'), ('permission', 'permission'), ('access', 'access'), ('desktop', 'desktop'), ('computer', 'computer'), ('mobile', 'mobile'), ('devices', 'device'), ('.', '.')]



============================ Sentence 388 =============================

This tool offers real-time visualization and interactions to implement fast   decisions (ur Rehman et al., 2016). 


>> Tokens are: 
 ['This', 'tool', 'offers', 'real-time', 'visualization', 'interactions', 'implement', 'fast', 'decisions', '(', 'ur', 'Rehman', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('This', 'tool'), ('tool', 'offers'), ('offers', 'real-time'), ('real-time', 'visualization'), ('visualization', 'interactions'), ('interactions', 'implement'), ('implement', 'fast'), ('fast', 'decisions'), ('decisions', '('), ('(', 'ur'), ('ur', 'Rehman'), ('Rehman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'tool', 'offers'), ('tool', 'offers', 'real-time'), ('offers', 'real-time', 'visualization'), ('real-time', 'visualization', 'interactions'), ('visualization', 'interactions', 'implement'), ('interactions', 'implement', 'fast'), ('implement', 'fast', 'decisions'), ('fast', 'decisions', '('), ('decisions', '(', 'ur'), ('(', 'ur', 'Rehman'), ('ur', 'Rehman', 'et'), ('Rehman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('tool', 'NN'), ('offers', 'VBZ'), ('real-time', 'JJ'), ('visualization', 'NN'), ('interactions', 'NNS'), ('implement', 'VBP'), ('fast', 'JJ'), ('decisions', 'NNS'), ('(', '('), ('ur', 'JJ'), ('Rehman', 'NNP'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT tool/NN)
  offers/VBZ
  (NP real-time/JJ visualization/NN interactions/NNS)
  implement/VBP
  (NP fast/JJ decisions/NNS)
  (/(
  (NP ur/JJ Rehman/NNP et/NN al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This tool', 'real-time visualization interactions', 'fast decisions', 'ur Rehman et al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('tool', 'tool'), ('offers', 'offer'), ('real-time', 'real-tim'), ('visualization', 'visual'), ('interactions', 'interact'), ('implement', 'implement'), ('fast', 'fast'), ('decisions', 'decis'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('tool', 'tool'), ('offers', 'offer'), ('real-time', 'real-tim'), ('visualization', 'visual'), ('interactions', 'interact'), ('implement', 'implement'), ('fast', 'fast'), ('decisions', 'decis'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('tool', 'tool'), ('offers', 'offer'), ('real-time', 'real-time'), ('visualization', 'visualization'), ('interactions', 'interaction'), ('implement', 'implement'), ('fast', 'fast'), ('decisions', 'decision'), ('(', '('), ('ur', 'ur'), ('Rehman', 'Rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 389 =============================

• RapidMiner: is a programming-free data analysis platform. 


>> Tokens are: 
 ['•', 'RapidMiner', ':', 'programming-free', 'data', 'analysis', 'platform', '.']

>> Bigrams are: 
 [('•', 'RapidMiner'), ('RapidMiner', ':'), (':', 'programming-free'), ('programming-free', 'data'), ('data', 'analysis'), ('analysis', 'platform'), ('platform', '.')]

>> Trigrams are: 
 [('•', 'RapidMiner', ':'), ('RapidMiner', ':', 'programming-free'), (':', 'programming-free', 'data'), ('programming-free', 'data', 'analysis'), ('data', 'analysis', 'platform'), ('analysis', 'platform', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('RapidMiner', 'NNP'), (':', ':'), ('programming-free', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('platform', 'NN'), ('.', '.')]

 (S
  (NP •/JJ RapidMiner/NNP)
  :/:
  (NP programming-free/JJ data/NNS analysis/NN platform/NN)
  ./.) 


>> Noun Phrases are: 
 ['• RapidMiner', 'programming-free data analysis platform']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('RapidMiner', 'rapidmin'), (':', ':'), ('programming-free', 'programming-fre'), ('data', 'data'), ('analysis', 'analysi'), ('platform', 'platform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('RapidMiner', 'rapidmin'), (':', ':'), ('programming-free', 'programming-fre'), ('data', 'data'), ('analysis', 'analysi'), ('platform', 'platform'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('RapidMiner', 'RapidMiner'), (':', ':'), ('programming-free', 'programming-free'), ('data', 'data'), ('analysis', 'analysis'), ('platform', 'platform'), ('.', '.')]



============================ Sentence 390 =============================

It provides the user with the  ability to "design data analysis processes in a plug-and-play fashion by wiring operators". 


>> Tokens are: 
 ['It', 'provides', 'user', 'ability', '``', 'design', 'data', 'analysis', 'processes', 'plug-and-play', 'fashion', 'wiring', 'operators', "''", '.']

>> Bigrams are: 
 [('It', 'provides'), ('provides', 'user'), ('user', 'ability'), ('ability', '``'), ('``', 'design'), ('design', 'data'), ('data', 'analysis'), ('analysis', 'processes'), ('processes', 'plug-and-play'), ('plug-and-play', 'fashion'), ('fashion', 'wiring'), ('wiring', 'operators'), ('operators', "''"), ("''", '.')]

>> Trigrams are: 
 [('It', 'provides', 'user'), ('provides', 'user', 'ability'), ('user', 'ability', '``'), ('ability', '``', 'design'), ('``', 'design', 'data'), ('design', 'data', 'analysis'), ('data', 'analysis', 'processes'), ('analysis', 'processes', 'plug-and-play'), ('processes', 'plug-and-play', 'fashion'), ('plug-and-play', 'fashion', 'wiring'), ('fashion', 'wiring', 'operators'), ('wiring', 'operators', "''"), ('operators', "''", '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('provides', 'VBZ'), ('user', 'JJ'), ('ability', 'NN'), ('``', '``'), ('design', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('processes', 'VBZ'), ('plug-and-play', 'JJ'), ('fashion', 'NN'), ('wiring', 'NN'), ('operators', 'NNS'), ("''", "''"), ('.', '.')]

 (S
  It/PRP
  provides/VBZ
  (NP user/JJ ability/NN)
  ``/``
  (NP design/NN data/NNS analysis/NN)
  processes/VBZ
  (NP plug-and-play/JJ fashion/NN wiring/NN operators/NNS)
  ''/''
  ./.) 


>> Noun Phrases are: 
 ['user ability', 'design data analysis', 'plug-and-play fashion wiring operators']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('user', 'user'), ('ability', 'abil'), ('``', '``'), ('design', 'design'), ('data', 'data'), ('analysis', 'analysi'), ('processes', 'process'), ('plug-and-play', 'plug-and-play'), ('fashion', 'fashion'), ('wiring', 'wire'), ('operators', 'oper'), ("''", "''"), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('provides', 'provid'), ('user', 'user'), ('ability', 'abil'), ('``', '``'), ('design', 'design'), ('data', 'data'), ('analysis', 'analysi'), ('processes', 'process'), ('plug-and-play', 'plug-and-play'), ('fashion', 'fashion'), ('wiring', 'wire'), ('operators', 'oper'), ("''", "''"), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('provides', 'provides'), ('user', 'user'), ('ability', 'ability'), ('``', '``'), ('design', 'design'), ('data', 'data'), ('analysis', 'analysis'), ('processes', 'process'), ('plug-and-play', 'plug-and-play'), ('fashion', 'fashion'), ('wiring', 'wiring'), ('operators', 'operator'), ("''", "''"), ('.', '.')]



============================ Sentence 391 =============================

It allows importing operators for various data formats (e.g.-.-, Excel, CSV, XML). 


>> Tokens are: 
 ['It', 'allows', 'importing', 'operators', 'various', 'data', 'formats', '(', 'e.g.-.-', ',', 'Excel', ',', 'CSV', ',', 'XML', ')', '.']

>> Bigrams are: 
 [('It', 'allows'), ('allows', 'importing'), ('importing', 'operators'), ('operators', 'various'), ('various', 'data'), ('data', 'formats'), ('formats', '('), ('(', 'e.g.-.-'), ('e.g.-.-', ','), (',', 'Excel'), ('Excel', ','), (',', 'CSV'), ('CSV', ','), (',', 'XML'), ('XML', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'allows', 'importing'), ('allows', 'importing', 'operators'), ('importing', 'operators', 'various'), ('operators', 'various', 'data'), ('various', 'data', 'formats'), ('data', 'formats', '('), ('formats', '(', 'e.g.-.-'), ('(', 'e.g.-.-', ','), ('e.g.-.-', ',', 'Excel'), (',', 'Excel', ','), ('Excel', ',', 'CSV'), (',', 'CSV', ','), ('CSV', ',', 'XML'), (',', 'XML', ')'), ('XML', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('allows', 'VBZ'), ('importing', 'VBG'), ('operators', 'NNS'), ('various', 'JJ'), ('data', 'NNS'), ('formats', 'NNS'), ('(', '('), ('e.g.-.-', 'JJ'), (',', ','), ('Excel', 'NNP'), (',', ','), ('CSV', 'NNP'), (',', ','), ('XML', 'NNP'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  allows/VBZ
  importing/VBG
  (NP operators/NNS)
  (NP various/JJ data/NNS formats/NNS)
  (/(
  e.g.-.-/JJ
  ,/,
  (NP Excel/NNP)
  ,/,
  (NP CSV/NNP)
  ,/,
  (NP XML/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['operators', 'various data formats', 'Excel', 'CSV', 'XML']

>> Named Entities are: 
 [('PERSON', 'Excel'), ('ORGANIZATION', 'CSV'), ('ORGANIZATION', 'XML')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('allows', 'allow'), ('importing', 'import'), ('operators', 'oper'), ('various', 'variou'), ('data', 'data'), ('formats', 'format'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('Excel', 'excel'), (',', ','), ('CSV', 'csv'), (',', ','), ('XML', 'xml'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('allows', 'allow'), ('importing', 'import'), ('operators', 'oper'), ('various', 'various'), ('data', 'data'), ('formats', 'format'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('Excel', 'excel'), (',', ','), ('CSV', 'csv'), (',', ','), ('XML', 'xml'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('allows', 'allows'), ('importing', 'importing'), ('operators', 'operator'), ('various', 'various'), ('data', 'data'), ('formats', 'format'), ('(', '('), ('e.g.-.-', 'e.g.-.-'), (',', ','), ('Excel', 'Excel'), (',', ','), ('CSV', 'CSV'), (',', ','), ('XML', 'XML'), (')', ')'), ('.', '.')]



============================ Sentence 392 =============================

It prepares   a set of operators for massive datasets with further attributes from open data sources which   give an advantage of a better predictive and descriptive models (Ristoski et al., 2015). 


>> Tokens are: 
 ['It', 'prepares', 'set', 'operators', 'massive', 'datasets', 'attributes', 'open', 'data', 'sources', 'give', 'advantage', 'better', 'predictive', 'descriptive', 'models', '(', 'Ristoski', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('It', 'prepares'), ('prepares', 'set'), ('set', 'operators'), ('operators', 'massive'), ('massive', 'datasets'), ('datasets', 'attributes'), ('attributes', 'open'), ('open', 'data'), ('data', 'sources'), ('sources', 'give'), ('give', 'advantage'), ('advantage', 'better'), ('better', 'predictive'), ('predictive', 'descriptive'), ('descriptive', 'models'), ('models', '('), ('(', 'Ristoski'), ('Ristoski', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('It', 'prepares', 'set'), ('prepares', 'set', 'operators'), ('set', 'operators', 'massive'), ('operators', 'massive', 'datasets'), ('massive', 'datasets', 'attributes'), ('datasets', 'attributes', 'open'), ('attributes', 'open', 'data'), ('open', 'data', 'sources'), ('data', 'sources', 'give'), ('sources', 'give', 'advantage'), ('give', 'advantage', 'better'), ('advantage', 'better', 'predictive'), ('better', 'predictive', 'descriptive'), ('predictive', 'descriptive', 'models'), ('descriptive', 'models', '('), ('models', '(', 'Ristoski'), ('(', 'Ristoski', 'et'), ('Ristoski', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('prepares', 'VBZ'), ('set', 'VBN'), ('operators', 'NNS'), ('massive', 'JJ'), ('datasets', 'NNS'), ('attributes', 'VBZ'), ('open', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('give', 'VBP'), ('advantage', 'NN'), ('better', 'RBR'), ('predictive', 'JJ'), ('descriptive', 'JJ'), ('models', 'NNS'), ('(', '('), ('Ristoski', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  It/PRP
  prepares/VBZ
  set/VBN
  (NP operators/NNS)
  (NP massive/JJ datasets/NNS)
  attributes/VBZ
  (NP open/JJ data/NNS sources/NNS)
  give/VBP
  (NP advantage/NN)
  better/RBR
  (NP predictive/JJ descriptive/JJ models/NNS)
  (/(
  (NP Ristoski/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['operators', 'massive datasets', 'open data sources', 'advantage', 'predictive descriptive models', 'Ristoski']

>> Named Entities are: 
 [('PERSON', 'Ristoski')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('prepares', 'prepar'), ('set', 'set'), ('operators', 'oper'), ('massive', 'massiv'), ('datasets', 'dataset'), ('attributes', 'attribut'), ('open', 'open'), ('data', 'data'), ('sources', 'sourc'), ('give', 'give'), ('advantage', 'advantag'), ('better', 'better'), ('predictive', 'predict'), ('descriptive', 'descript'), ('models', 'model'), ('(', '('), ('Ristoski', 'ristoski'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('prepares', 'prepar'), ('set', 'set'), ('operators', 'oper'), ('massive', 'massiv'), ('datasets', 'dataset'), ('attributes', 'attribut'), ('open', 'open'), ('data', 'data'), ('sources', 'sourc'), ('give', 'give'), ('advantage', 'advantag'), ('better', 'better'), ('predictive', 'predict'), ('descriptive', 'descript'), ('models', 'model'), ('(', '('), ('Ristoski', 'ristoski'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('prepares', 'prepares'), ('set', 'set'), ('operators', 'operator'), ('massive', 'massive'), ('datasets', 'datasets'), ('attributes', 'attribute'), ('open', 'open'), ('data', 'data'), ('sources', 'source'), ('give', 'give'), ('advantage', 'advantage'), ('better', 'better'), ('predictive', 'predictive'), ('descriptive', 'descriptive'), ('models', 'model'), ('(', '('), ('Ristoski', 'Ristoski'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 393 =============================

• Datameer: Datameer Analytics Solution (DAS) is a business integration platform for  Hadoop. 


>> Tokens are: 
 ['•', 'Datameer', ':', 'Datameer', 'Analytics', 'Solution', '(', 'DAS', ')', 'business', 'integration', 'platform', 'Hadoop', '.']

>> Bigrams are: 
 [('•', 'Datameer'), ('Datameer', ':'), (':', 'Datameer'), ('Datameer', 'Analytics'), ('Analytics', 'Solution'), ('Solution', '('), ('(', 'DAS'), ('DAS', ')'), (')', 'business'), ('business', 'integration'), ('integration', 'platform'), ('platform', 'Hadoop'), ('Hadoop', '.')]

>> Trigrams are: 
 [('•', 'Datameer', ':'), ('Datameer', ':', 'Datameer'), (':', 'Datameer', 'Analytics'), ('Datameer', 'Analytics', 'Solution'), ('Analytics', 'Solution', '('), ('Solution', '(', 'DAS'), ('(', 'DAS', ')'), ('DAS', ')', 'business'), (')', 'business', 'integration'), ('business', 'integration', 'platform'), ('integration', 'platform', 'Hadoop'), ('platform', 'Hadoop', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Datameer', 'NNP'), (':', ':'), ('Datameer', 'NNP'), ('Analytics', 'NNPS'), ('Solution', 'NNP'), ('(', '('), ('DAS', 'NNP'), (')', ')'), ('business', 'NN'), ('integration', 'NN'), ('platform', 'NN'), ('Hadoop', 'NNP'), ('.', '.')]

 (S
  (NP •/JJ Datameer/NNP)
  :/:
  (NP Datameer/NNP)
  Analytics/NNPS
  (NP Solution/NNP)
  (/(
  (NP DAS/NNP)
  )/)
  (NP business/NN integration/NN platform/NN Hadoop/NNP)
  ./.) 


>> Noun Phrases are: 
 ['• Datameer', 'Datameer', 'Solution', 'DAS', 'business integration platform Hadoop']

>> Named Entities are: 
 [('ORGANIZATION', 'Datameer Analytics Solution'), ('ORGANIZATION', 'DAS'), ('PERSON', 'Hadoop')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Datameer', 'datam'), (':', ':'), ('Datameer', 'datam'), ('Analytics', 'analyt'), ('Solution', 'solut'), ('(', '('), ('DAS', 'da'), (')', ')'), ('business', 'busi'), ('integration', 'integr'), ('platform', 'platform'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Datameer', 'datam'), (':', ':'), ('Datameer', 'datam'), ('Analytics', 'analyt'), ('Solution', 'solut'), ('(', '('), ('DAS', 'das'), (')', ')'), ('business', 'busi'), ('integration', 'integr'), ('platform', 'platform'), ('Hadoop', 'hadoop'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Datameer', 'Datameer'), (':', ':'), ('Datameer', 'Datameer'), ('Analytics', 'Analytics'), ('Solution', 'Solution'), ('(', '('), ('DAS', 'DAS'), (')', ')'), ('business', 'business'), ('integration', 'integration'), ('platform', 'platform'), ('Hadoop', 'Hadoop'), ('.', '.')]



============================ Sentence 394 =============================

It contains data source integration, “an analytics mechanism with a spreadsheet   interface”, designed with analytic functions and visualization to help business users in   reports, charts and dashboards. 


>> Tokens are: 
 ['It', 'contains', 'data', 'source', 'integration', ',', '“', 'analytics', 'mechanism', 'spreadsheet', 'interface', '”', ',', 'designed', 'analytic', 'functions', 'visualization', 'help', 'business', 'users', 'reports', ',', 'charts', 'dashboards', '.']

>> Bigrams are: 
 [('It', 'contains'), ('contains', 'data'), ('data', 'source'), ('source', 'integration'), ('integration', ','), (',', '“'), ('“', 'analytics'), ('analytics', 'mechanism'), ('mechanism', 'spreadsheet'), ('spreadsheet', 'interface'), ('interface', '”'), ('”', ','), (',', 'designed'), ('designed', 'analytic'), ('analytic', 'functions'), ('functions', 'visualization'), ('visualization', 'help'), ('help', 'business'), ('business', 'users'), ('users', 'reports'), ('reports', ','), (',', 'charts'), ('charts', 'dashboards'), ('dashboards', '.')]

>> Trigrams are: 
 [('It', 'contains', 'data'), ('contains', 'data', 'source'), ('data', 'source', 'integration'), ('source', 'integration', ','), ('integration', ',', '“'), (',', '“', 'analytics'), ('“', 'analytics', 'mechanism'), ('analytics', 'mechanism', 'spreadsheet'), ('mechanism', 'spreadsheet', 'interface'), ('spreadsheet', 'interface', '”'), ('interface', '”', ','), ('”', ',', 'designed'), (',', 'designed', 'analytic'), ('designed', 'analytic', 'functions'), ('analytic', 'functions', 'visualization'), ('functions', 'visualization', 'help'), ('visualization', 'help', 'business'), ('help', 'business', 'users'), ('business', 'users', 'reports'), ('users', 'reports', ','), ('reports', ',', 'charts'), (',', 'charts', 'dashboards'), ('charts', 'dashboards', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('contains', 'VBZ'), ('data', 'NNS'), ('source', 'NN'), ('integration', 'NN'), (',', ','), ('“', 'NNP'), ('analytics', 'NNS'), ('mechanism', 'NN'), ('spreadsheet', 'NN'), ('interface', 'NN'), ('”', 'NNP'), (',', ','), ('designed', 'VBN'), ('analytic', 'JJ'), ('functions', 'NNS'), ('visualization', 'NN'), ('help', 'NN'), ('business', 'NN'), ('users', 'NNS'), ('reports', 'NNS'), (',', ','), ('charts', 'NNS'), ('dashboards', 'NNS'), ('.', '.')]

 (S
  It/PRP
  contains/VBZ
  (NP data/NNS source/NN integration/NN)
  ,/,
  (NP
    “/NNP
    analytics/NNS
    mechanism/NN
    spreadsheet/NN
    interface/NN
    ”/NNP)
  ,/,
  designed/VBN
  (NP
    analytic/JJ
    functions/NNS
    visualization/NN
    help/NN
    business/NN
    users/NNS
    reports/NNS)
  ,/,
  (NP charts/NNS dashboards/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data source integration', '“ analytics mechanism spreadsheet interface ”', 'analytic functions visualization help business users reports', 'charts dashboards']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('contains', 'contain'), ('data', 'data'), ('source', 'sourc'), ('integration', 'integr'), (',', ','), ('“', '“'), ('analytics', 'analyt'), ('mechanism', 'mechan'), ('spreadsheet', 'spreadsheet'), ('interface', 'interfac'), ('”', '”'), (',', ','), ('designed', 'design'), ('analytic', 'analyt'), ('functions', 'function'), ('visualization', 'visual'), ('help', 'help'), ('business', 'busi'), ('users', 'user'), ('reports', 'report'), (',', ','), ('charts', 'chart'), ('dashboards', 'dashboard'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('contains', 'contain'), ('data', 'data'), ('source', 'sourc'), ('integration', 'integr'), (',', ','), ('“', '“'), ('analytics', 'analyt'), ('mechanism', 'mechan'), ('spreadsheet', 'spreadsheet'), ('interface', 'interfac'), ('”', '”'), (',', ','), ('designed', 'design'), ('analytic', 'analyt'), ('functions', 'function'), ('visualization', 'visual'), ('help', 'help'), ('business', 'busi'), ('users', 'user'), ('reports', 'report'), (',', ','), ('charts', 'chart'), ('dashboards', 'dashboard'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('contains', 'contains'), ('data', 'data'), ('source', 'source'), ('integration', 'integration'), (',', ','), ('“', '“'), ('analytics', 'analytics'), ('mechanism', 'mechanism'), ('spreadsheet', 'spreadsheet'), ('interface', 'interface'), ('”', '”'), (',', ','), ('designed', 'designed'), ('analytic', 'analytic'), ('functions', 'function'), ('visualization', 'visualization'), ('help', 'help'), ('business', 'business'), ('users', 'user'), ('reports', 'report'), (',', ','), ('charts', 'chart'), ('dashboards', 'dashboard'), ('.', '.')]



============================ Sentence 395 =============================

Datameer can bring data from both structured such as   Oracle, IBM DB2, and unstructured sources such as Twitter, Facebook, LinkedIn or e-  mails (Di Martino et al., 2014). 


>> Tokens are: 
 ['Datameer', 'bring', 'data', 'structured', 'Oracle', ',', 'IBM', 'DB2', ',', 'unstructured', 'sources', 'Twitter', ',', 'Facebook', ',', 'LinkedIn', 'e-', 'mails', '(', 'Di', 'Martino', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Datameer', 'bring'), ('bring', 'data'), ('data', 'structured'), ('structured', 'Oracle'), ('Oracle', ','), (',', 'IBM'), ('IBM', 'DB2'), ('DB2', ','), (',', 'unstructured'), ('unstructured', 'sources'), ('sources', 'Twitter'), ('Twitter', ','), (',', 'Facebook'), ('Facebook', ','), (',', 'LinkedIn'), ('LinkedIn', 'e-'), ('e-', 'mails'), ('mails', '('), ('(', 'Di'), ('Di', 'Martino'), ('Martino', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Datameer', 'bring', 'data'), ('bring', 'data', 'structured'), ('data', 'structured', 'Oracle'), ('structured', 'Oracle', ','), ('Oracle', ',', 'IBM'), (',', 'IBM', 'DB2'), ('IBM', 'DB2', ','), ('DB2', ',', 'unstructured'), (',', 'unstructured', 'sources'), ('unstructured', 'sources', 'Twitter'), ('sources', 'Twitter', ','), ('Twitter', ',', 'Facebook'), (',', 'Facebook', ','), ('Facebook', ',', 'LinkedIn'), (',', 'LinkedIn', 'e-'), ('LinkedIn', 'e-', 'mails'), ('e-', 'mails', '('), ('mails', '(', 'Di'), ('(', 'Di', 'Martino'), ('Di', 'Martino', 'et'), ('Martino', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Datameer', 'NNP'), ('bring', 'NN'), ('data', 'NNS'), ('structured', 'VBD'), ('Oracle', 'NNP'), (',', ','), ('IBM', 'NNP'), ('DB2', 'NNP'), (',', ','), ('unstructured', 'JJ'), ('sources', 'NNS'), ('Twitter', 'NNP'), (',', ','), ('Facebook', 'NNP'), (',', ','), ('LinkedIn', 'NNP'), ('e-', 'NN'), ('mails', 'NNS'), ('(', '('), ('Di', 'NNP'), ('Martino', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Datameer/NNP bring/NN data/NNS)
  structured/VBD
  (NP Oracle/NNP)
  ,/,
  (NP IBM/NNP DB2/NNP)
  ,/,
  (NP unstructured/JJ sources/NNS Twitter/NNP)
  ,/,
  (NP Facebook/NNP)
  ,/,
  (NP LinkedIn/NNP e-/NN mails/NNS)
  (/(
  (NP Di/NNP Martino/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Datameer bring data', 'Oracle', 'IBM DB2', 'unstructured sources Twitter', 'Facebook', 'LinkedIn e- mails', 'Di Martino', 'al.']

>> Named Entities are: 
 [('GPE', 'Datameer'), ('PERSON', 'Oracle'), ('ORGANIZATION', 'IBM'), ('PERSON', 'Twitter'), ('GPE', 'Facebook'), ('ORGANIZATION', 'LinkedIn')] 

>> Stemming using Porter Stemmer: 
 [('Datameer', 'datam'), ('bring', 'bring'), ('data', 'data'), ('structured', 'structur'), ('Oracle', 'oracl'), (',', ','), ('IBM', 'ibm'), ('DB2', 'db2'), (',', ','), ('unstructured', 'unstructur'), ('sources', 'sourc'), ('Twitter', 'twitter'), (',', ','), ('Facebook', 'facebook'), (',', ','), ('LinkedIn', 'linkedin'), ('e-', 'e-'), ('mails', 'mail'), ('(', '('), ('Di', 'di'), ('Martino', 'martino'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Datameer', 'datam'), ('bring', 'bring'), ('data', 'data'), ('structured', 'structur'), ('Oracle', 'oracl'), (',', ','), ('IBM', 'ibm'), ('DB2', 'db2'), (',', ','), ('unstructured', 'unstructur'), ('sources', 'sourc'), ('Twitter', 'twitter'), (',', ','), ('Facebook', 'facebook'), (',', ','), ('LinkedIn', 'linkedin'), ('e-', 'e-'), ('mails', 'mail'), ('(', '('), ('Di', 'di'), ('Martino', 'martino'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Datameer', 'Datameer'), ('bring', 'bring'), ('data', 'data'), ('structured', 'structured'), ('Oracle', 'Oracle'), (',', ','), ('IBM', 'IBM'), ('DB2', 'DB2'), (',', ','), ('unstructured', 'unstructured'), ('sources', 'source'), ('Twitter', 'Twitter'), (',', ','), ('Facebook', 'Facebook'), (',', ','), ('LinkedIn', 'LinkedIn'), ('e-', 'e-'), ('mails', 'mail'), ('(', '('), ('Di', 'Di'), ('Martino', 'Martino'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 396 =============================

• Microsoft: Microsoft platform provides predictive analytics capability called SSAS and  integrated in the SQL Server. 


>> Tokens are: 
 ['•', 'Microsoft', ':', 'Microsoft', 'platform', 'provides', 'predictive', 'analytics', 'capability', 'called', 'SSAS', 'integrated', 'SQL', 'Server', '.']

>> Bigrams are: 
 [('•', 'Microsoft'), ('Microsoft', ':'), (':', 'Microsoft'), ('Microsoft', 'platform'), ('platform', 'provides'), ('provides', 'predictive'), ('predictive', 'analytics'), ('analytics', 'capability'), ('capability', 'called'), ('called', 'SSAS'), ('SSAS', 'integrated'), ('integrated', 'SQL'), ('SQL', 'Server'), ('Server', '.')]

>> Trigrams are: 
 [('•', 'Microsoft', ':'), ('Microsoft', ':', 'Microsoft'), (':', 'Microsoft', 'platform'), ('Microsoft', 'platform', 'provides'), ('platform', 'provides', 'predictive'), ('provides', 'predictive', 'analytics'), ('predictive', 'analytics', 'capability'), ('analytics', 'capability', 'called'), ('capability', 'called', 'SSAS'), ('called', 'SSAS', 'integrated'), ('SSAS', 'integrated', 'SQL'), ('integrated', 'SQL', 'Server'), ('SQL', 'Server', '.')]

>> POS Tags are: 
 [('•', 'JJ'), ('Microsoft', 'NNP'), (':', ':'), ('Microsoft', 'JJ'), ('platform', 'NN'), ('provides', 'VBZ'), ('predictive', 'JJ'), ('analytics', 'NNS'), ('capability', 'NN'), ('called', 'VBN'), ('SSAS', 'NNP'), ('integrated', 'VBD'), ('SQL', 'NNP'), ('Server', 'NNP'), ('.', '.')]

 (S
  (NP •/JJ Microsoft/NNP)
  :/:
  (NP Microsoft/JJ platform/NN)
  provides/VBZ
  (NP predictive/JJ analytics/NNS capability/NN)
  called/VBN
  (NP SSAS/NNP)
  integrated/VBD
  (NP SQL/NNP Server/NNP)
  ./.) 


>> Noun Phrases are: 
 ['• Microsoft', 'Microsoft platform', 'predictive analytics capability', 'SSAS', 'SQL Server']

>> Named Entities are: 
 [('PERSON', 'Microsoft'), ('PERSON', 'Microsoft'), ('ORGANIZATION', 'SSAS'), ('ORGANIZATION', 'SQL Server')] 

>> Stemming using Porter Stemmer: 
 [('•', '•'), ('Microsoft', 'microsoft'), (':', ':'), ('Microsoft', 'microsoft'), ('platform', 'platform'), ('provides', 'provid'), ('predictive', 'predict'), ('analytics', 'analyt'), ('capability', 'capabl'), ('called', 'call'), ('SSAS', 'ssa'), ('integrated', 'integr'), ('SQL', 'sql'), ('Server', 'server'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('•', '•'), ('Microsoft', 'microsoft'), (':', ':'), ('Microsoft', 'microsoft'), ('platform', 'platform'), ('provides', 'provid'), ('predictive', 'predict'), ('analytics', 'analyt'), ('capability', 'capabl'), ('called', 'call'), ('SSAS', 'ssas'), ('integrated', 'integr'), ('SQL', 'sql'), ('Server', 'server'), ('.', '.')]

>> Lemmatization: 
 [('•', '•'), ('Microsoft', 'Microsoft'), (':', ':'), ('Microsoft', 'Microsoft'), ('platform', 'platform'), ('provides', 'provides'), ('predictive', 'predictive'), ('analytics', 'analytics'), ('capability', 'capability'), ('called', 'called'), ('SSAS', 'SSAS'), ('integrated', 'integrated'), ('SQL', 'SQL'), ('Server', 'Server'), ('.', '.')]



============================ Sentence 397 =============================

This platform offers "efficiency in Azure’s cloud data   source’s integration and deployments as a web service" also, the simplicity of utilizing for   data scientists (ur Rehman et al., 2016). 


>> Tokens are: 
 ['This', 'platform', 'offers', '``', 'efficiency', 'Azure', '’', 'cloud', 'data', 'source', '’', 'integration', 'deployments', 'web', 'service', "''", 'also', ',', 'simplicity', 'utilizing', 'data', 'scientists', '(', 'ur', 'Rehman', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('This', 'platform'), ('platform', 'offers'), ('offers', '``'), ('``', 'efficiency'), ('efficiency', 'Azure'), ('Azure', '’'), ('’', 'cloud'), ('cloud', 'data'), ('data', 'source'), ('source', '’'), ('’', 'integration'), ('integration', 'deployments'), ('deployments', 'web'), ('web', 'service'), ('service', "''"), ("''", 'also'), ('also', ','), (',', 'simplicity'), ('simplicity', 'utilizing'), ('utilizing', 'data'), ('data', 'scientists'), ('scientists', '('), ('(', 'ur'), ('ur', 'Rehman'), ('Rehman', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'platform', 'offers'), ('platform', 'offers', '``'), ('offers', '``', 'efficiency'), ('``', 'efficiency', 'Azure'), ('efficiency', 'Azure', '’'), ('Azure', '’', 'cloud'), ('’', 'cloud', 'data'), ('cloud', 'data', 'source'), ('data', 'source', '’'), ('source', '’', 'integration'), ('’', 'integration', 'deployments'), ('integration', 'deployments', 'web'), ('deployments', 'web', 'service'), ('web', 'service', "''"), ('service', "''", 'also'), ("''", 'also', ','), ('also', ',', 'simplicity'), (',', 'simplicity', 'utilizing'), ('simplicity', 'utilizing', 'data'), ('utilizing', 'data', 'scientists'), ('data', 'scientists', '('), ('scientists', '(', 'ur'), ('(', 'ur', 'Rehman'), ('ur', 'Rehman', 'et'), ('Rehman', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('platform', 'NN'), ('offers', 'VBZ'), ('``', '``'), ('efficiency', 'NN'), ('Azure', 'NNP'), ('’', 'NNP'), ('cloud', 'NN'), ('data', 'NNS'), ('source', 'NN'), ('’', 'JJ'), ('integration', 'NN'), ('deployments', 'NNS'), ('web', 'VBP'), ('service', 'NN'), ("''", "''"), ('also', 'RB'), (',', ','), ('simplicity', 'NN'), ('utilizing', 'VBG'), ('data', 'NNS'), ('scientists', 'NNS'), ('(', '('), ('ur', 'JJ'), ('Rehman', 'NNP'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT platform/NN)
  offers/VBZ
  ``/``
  (NP efficiency/NN Azure/NNP ’/NNP cloud/NN data/NNS source/NN)
  (NP ’/JJ integration/NN deployments/NNS)
  web/VBP
  (NP service/NN)
  ''/''
  also/RB
  ,/,
  (NP simplicity/NN)
  utilizing/VBG
  (NP data/NNS scientists/NNS)
  (/(
  (NP ur/JJ Rehman/NNP et/NN al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This platform', 'efficiency Azure ’ cloud data source', '’ integration deployments', 'service', 'simplicity', 'data scientists', 'ur Rehman et al.']

>> Named Entities are: 
 [('PERSON', 'Azure')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('platform', 'platform'), ('offers', 'offer'), ('``', '``'), ('efficiency', 'effici'), ('Azure', 'azur'), ('’', '’'), ('cloud', 'cloud'), ('data', 'data'), ('source', 'sourc'), ('’', '’'), ('integration', 'integr'), ('deployments', 'deploy'), ('web', 'web'), ('service', 'servic'), ("''", "''"), ('also', 'also'), (',', ','), ('simplicity', 'simplic'), ('utilizing', 'util'), ('data', 'data'), ('scientists', 'scientist'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('platform', 'platform'), ('offers', 'offer'), ('``', '``'), ('efficiency', 'effici'), ('Azure', 'azur'), ('’', '’'), ('cloud', 'cloud'), ('data', 'data'), ('source', 'sourc'), ('’', '’'), ('integration', 'integr'), ('deployments', 'deploy'), ('web', 'web'), ('service', 'servic'), ("''", "''"), ('also', 'also'), (',', ','), ('simplicity', 'simplic'), ('utilizing', 'util'), ('data', 'data'), ('scientists', 'scientist'), ('(', '('), ('ur', 'ur'), ('Rehman', 'rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('platform', 'platform'), ('offers', 'offer'), ('``', '``'), ('efficiency', 'efficiency'), ('Azure', 'Azure'), ('’', '’'), ('cloud', 'cloud'), ('data', 'data'), ('source', 'source'), ('’', '’'), ('integration', 'integration'), ('deployments', 'deployment'), ('web', 'web'), ('service', 'service'), ("''", "''"), ('also', 'also'), (',', ','), ('simplicity', 'simplicity'), ('utilizing', 'utilizing'), ('data', 'data'), ('scientists', 'scientist'), ('(', '('), ('ur', 'ur'), ('Rehman', 'Rehman'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 398 =============================

Sarah Al-Shiakhli   32      Figure 19 is adopted  from (Raghupathi, W. and Raghupathi, V., 2014) and shows 1) data sources;   2) the big data states that need to be processed and transformed; 3) big data tools and platforms   wherein these decisions are made depending on the inputs, tool selection, and analytical models   chosen; and  4) the big data analytics applications. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '32', 'Figure', '19', 'adopted', '(', 'Raghupathi', ',', 'W.', 'Raghupathi', ',', 'V.', ',', '2014', ')', 'shows', '1', ')', 'data', 'sources', ';', '2', ')', 'big', 'data', 'states', 'need', 'processed', 'transformed', ';', '3', ')', 'big', 'data', 'tools', 'platforms', 'wherein', 'decisions', 'made', 'depending', 'inputs', ',', 'tool', 'selection', ',', 'analytical', 'models', 'chosen', ';', '4', ')', 'big', 'data', 'analytics', 'applications', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '32'), ('32', 'Figure'), ('Figure', '19'), ('19', 'adopted'), ('adopted', '('), ('(', 'Raghupathi'), ('Raghupathi', ','), (',', 'W.'), ('W.', 'Raghupathi'), ('Raghupathi', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', ')'), (')', 'shows'), ('shows', '1'), ('1', ')'), (')', 'data'), ('data', 'sources'), ('sources', ';'), (';', '2'), ('2', ')'), (')', 'big'), ('big', 'data'), ('data', 'states'), ('states', 'need'), ('need', 'processed'), ('processed', 'transformed'), ('transformed', ';'), (';', '3'), ('3', ')'), (')', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'platforms'), ('platforms', 'wherein'), ('wherein', 'decisions'), ('decisions', 'made'), ('made', 'depending'), ('depending', 'inputs'), ('inputs', ','), (',', 'tool'), ('tool', 'selection'), ('selection', ','), (',', 'analytical'), ('analytical', 'models'), ('models', 'chosen'), ('chosen', ';'), (';', '4'), ('4', ')'), (')', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '32'), ('Al-Shiakhli', '32', 'Figure'), ('32', 'Figure', '19'), ('Figure', '19', 'adopted'), ('19', 'adopted', '('), ('adopted', '(', 'Raghupathi'), ('(', 'Raghupathi', ','), ('Raghupathi', ',', 'W.'), (',', 'W.', 'Raghupathi'), ('W.', 'Raghupathi', ','), ('Raghupathi', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', ')'), ('2014', ')', 'shows'), (')', 'shows', '1'), ('shows', '1', ')'), ('1', ')', 'data'), (')', 'data', 'sources'), ('data', 'sources', ';'), ('sources', ';', '2'), (';', '2', ')'), ('2', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'states'), ('data', 'states', 'need'), ('states', 'need', 'processed'), ('need', 'processed', 'transformed'), ('processed', 'transformed', ';'), ('transformed', ';', '3'), (';', '3', ')'), ('3', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'platforms'), ('tools', 'platforms', 'wherein'), ('platforms', 'wherein', 'decisions'), ('wherein', 'decisions', 'made'), ('decisions', 'made', 'depending'), ('made', 'depending', 'inputs'), ('depending', 'inputs', ','), ('inputs', ',', 'tool'), (',', 'tool', 'selection'), ('tool', 'selection', ','), ('selection', ',', 'analytical'), (',', 'analytical', 'models'), ('analytical', 'models', 'chosen'), ('models', 'chosen', ';'), ('chosen', ';', '4'), (';', '4', ')'), ('4', ')', 'big'), (')', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('32', 'CD'), ('Figure', 'NNP'), ('19', 'CD'), ('adopted', 'VBN'), ('(', '('), ('Raghupathi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('shows', 'VBZ'), ('1', 'CD'), (')', ')'), ('data', 'NN'), ('sources', 'NNS'), (';', ':'), ('2', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('states', 'NNS'), ('need', 'VBP'), ('processed', 'VBN'), ('transformed', 'VBD'), (';', ':'), ('3', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), ('platforms', 'NNS'), ('wherein', 'VBP'), ('decisions', 'NNS'), ('made', 'VBD'), ('depending', 'VBG'), ('inputs', 'NNS'), (',', ','), ('tool', 'NN'), ('selection', 'NN'), (',', ','), ('analytical', 'JJ'), ('models', 'NNS'), ('chosen', 'VBN'), (';', ':'), ('4', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  32/CD
  (NP Figure/NNP)
  19/CD
  adopted/VBN
  (/(
  (NP Raghupathi/NNP)
  ,/,
  (NP W./NNP Raghupathi/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  2014/CD
  )/)
  shows/VBZ
  1/CD
  )/)
  (NP data/NN sources/NNS)
  ;/:
  2/CD
  )/)
  (NP big/JJ data/NNS states/NNS)
  need/VBP
  processed/VBN
  transformed/VBD
  ;/:
  3/CD
  )/)
  (NP big/JJ data/NN tools/NNS platforms/NNS)
  wherein/VBP
  (NP decisions/NNS)
  made/VBD
  depending/VBG
  (NP inputs/NNS)
  ,/,
  (NP tool/NN selection/NN)
  ,/,
  (NP analytical/JJ models/NNS)
  chosen/VBN
  ;/:
  4/CD
  )/)
  (NP big/JJ data/NNS analytics/NNS applications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Figure', 'Raghupathi', 'W. Raghupathi', 'V.', 'data sources', 'big data states', 'big data tools platforms', 'decisions', 'inputs', 'tool selection', 'analytical models', 'big data analytics applications']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('32', '32'), ('Figure', 'figur'), ('19', '19'), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')'), ('shows', 'show'), ('1', '1'), (')', ')'), ('data', 'data'), ('sources', 'sourc'), (';', ';'), ('2', '2'), (')', ')'), ('big', 'big'), ('data', 'data'), ('states', 'state'), ('need', 'need'), ('processed', 'process'), ('transformed', 'transform'), (';', ';'), ('3', '3'), (')', ')'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform'), ('wherein', 'wherein'), ('decisions', 'decis'), ('made', 'made'), ('depending', 'depend'), ('inputs', 'input'), (',', ','), ('tool', 'tool'), ('selection', 'select'), (',', ','), ('analytical', 'analyt'), ('models', 'model'), ('chosen', 'chosen'), (';', ';'), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('32', '32'), ('Figure', 'figur'), ('19', '19'), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')'), ('shows', 'show'), ('1', '1'), (')', ')'), ('data', 'data'), ('sources', 'sourc'), (';', ';'), ('2', '2'), (')', ')'), ('big', 'big'), ('data', 'data'), ('states', 'state'), ('need', 'need'), ('processed', 'process'), ('transformed', 'transform'), (';', ';'), ('3', '3'), (')', ')'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform'), ('wherein', 'wherein'), ('decisions', 'decis'), ('made', 'made'), ('depending', 'depend'), ('inputs', 'input'), (',', ','), ('tool', 'tool'), ('selection', 'select'), (',', ','), ('analytical', 'analyt'), ('models', 'model'), ('chosen', 'chosen'), (';', ';'), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('32', '32'), ('Figure', 'Figure'), ('19', '19'), ('adopted', 'adopted'), ('(', '('), ('Raghupathi', 'Raghupathi'), (',', ','), ('W.', 'W.'), ('Raghupathi', 'Raghupathi'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), (')', ')'), ('shows', 'show'), ('1', '1'), (')', ')'), ('data', 'data'), ('sources', 'source'), (';', ';'), ('2', '2'), (')', ')'), ('big', 'big'), ('data', 'data'), ('states', 'state'), ('need', 'need'), ('processed', 'processed'), ('transformed', 'transformed'), (';', ';'), ('3', '3'), (')', ')'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform'), ('wherein', 'wherein'), ('decisions', 'decision'), ('made', 'made'), ('depending', 'depending'), ('inputs', 'input'), (',', ','), ('tool', 'tool'), ('selection', 'selection'), (',', ','), ('analytical', 'analytical'), ('models', 'model'), ('chosen', 'chosen'), (';', ';'), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('.', '.')]



============================ Sentence 399 =============================

Figure 20 shows the big data and AI Landscape   in 2018 which is adopted from (Goncharov, 2019). 


>> Tokens are: 
 ['Figure', '20', 'shows', 'big', 'data', 'AI', 'Landscape', '2018', 'adopted', '(', 'Goncharov', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Figure', '20'), ('20', 'shows'), ('shows', 'big'), ('big', 'data'), ('data', 'AI'), ('AI', 'Landscape'), ('Landscape', '2018'), ('2018', 'adopted'), ('adopted', '('), ('(', 'Goncharov'), ('Goncharov', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '20', 'shows'), ('20', 'shows', 'big'), ('shows', 'big', 'data'), ('big', 'data', 'AI'), ('data', 'AI', 'Landscape'), ('AI', 'Landscape', '2018'), ('Landscape', '2018', 'adopted'), ('2018', 'adopted', '('), ('adopted', '(', 'Goncharov'), ('(', 'Goncharov', ','), ('Goncharov', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('20', 'CD'), ('shows', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('AI', 'NNP'), ('Landscape', 'NNP'), ('2018', 'CD'), ('adopted', 'VBD'), ('(', '('), ('Goncharov', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  20/CD
  shows/VBZ
  (NP big/JJ data/NNS AI/NNP Landscape/NNP)
  2018/CD
  adopted/VBD
  (/(
  (NP Goncharov/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'big data AI Landscape', 'Goncharov']

>> Named Entities are: 
 [('ORGANIZATION', 'AI'), ('ORGANIZATION', 'Goncharov')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('20', '20'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('20', '20'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('20', '20'), ('shows', 'show'), ('big', 'big'), ('data', 'data'), ('AI', 'AI'), ('Landscape', 'Landscape'), ('2018', '2018'), ('adopted', 'adopted'), ('(', '('), ('Goncharov', 'Goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 400 =============================

Figure 19: An applied conceptual architecture of data analytics, adopted from (Raghupathi and   Raghupathi, 2014). 


>> Tokens are: 
 ['Figure', '19', ':', 'An', 'applied', 'conceptual', 'architecture', 'data', 'analytics', ',', 'adopted', '(', 'Raghupathi', 'Raghupathi', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Figure', '19'), ('19', ':'), (':', 'An'), ('An', 'applied'), ('applied', 'conceptual'), ('conceptual', 'architecture'), ('architecture', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), ('Raghupathi', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '19', ':'), ('19', ':', 'An'), (':', 'An', 'applied'), ('An', 'applied', 'conceptual'), ('applied', 'conceptual', 'architecture'), ('conceptual', 'architecture', 'data'), ('architecture', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Raghupathi'), ('(', 'Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi', ','), ('Raghupathi', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('19', 'CD'), (':', ':'), ('An', 'DT'), ('applied', 'JJ'), ('conceptual', 'JJ'), ('architecture', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  19/CD
  :/:
  (NP
    An/DT
    applied/JJ
    conceptual/JJ
    architecture/NN
    data/NNS
    analytics/NNS)
  ,/,
  adopted/VBN
  (/(
  (NP Raghupathi/NNP Raghupathi/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'An applied conceptual architecture data analytics', 'Raghupathi Raghupathi']

>> Named Entities are: 
 [('ORGANIZATION', 'Raghupathi Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('19', '19'), (':', ':'), ('An', 'an'), ('applied', 'appli'), ('conceptual', 'conceptu'), ('architecture', 'architectur'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('19', '19'), (':', ':'), ('An', 'an'), ('applied', 'appli'), ('conceptual', 'conceptu'), ('architecture', 'architectur'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('19', '19'), (':', ':'), ('An', 'An'), ('applied', 'applied'), ('conceptual', 'conceptual'), ('architecture', 'architecture'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 401 =============================

Sarah Al-Shiakhli   33               Figure 20:  Big Data and AI Landscape in 2018, adopted from (Goncharov, 2019)         Sarah Al-Shiakhli   34         8. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '33', 'Figure', '20', ':', 'Big', 'Data', 'AI', 'Landscape', '2018', ',', 'adopted', '(', 'Goncharov', ',', '2019', ')', 'Sarah', 'Al-Shiakhli', '34', '8', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '33'), ('33', 'Figure'), ('Figure', '20'), ('20', ':'), (':', 'Big'), ('Big', 'Data'), ('Data', 'AI'), ('AI', 'Landscape'), ('Landscape', '2018'), ('2018', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Goncharov'), ('Goncharov', ','), (',', '2019'), ('2019', ')'), (')', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '34'), ('34', '8'), ('8', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '33'), ('Al-Shiakhli', '33', 'Figure'), ('33', 'Figure', '20'), ('Figure', '20', ':'), ('20', ':', 'Big'), (':', 'Big', 'Data'), ('Big', 'Data', 'AI'), ('Data', 'AI', 'Landscape'), ('AI', 'Landscape', '2018'), ('Landscape', '2018', ','), ('2018', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Goncharov'), ('(', 'Goncharov', ','), ('Goncharov', ',', '2019'), (',', '2019', ')'), ('2019', ')', 'Sarah'), (')', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '34'), ('Al-Shiakhli', '34', '8'), ('34', '8', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('33', 'CD'), ('Figure', 'NNP'), ('20', 'CD'), (':', ':'), ('Big', 'JJ'), ('Data', 'NNS'), ('AI', 'NNP'), ('Landscape', 'NNP'), ('2018', 'CD'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Goncharov', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('34', 'CD'), ('8', 'CD'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  33/CD
  (NP Figure/NNP)
  20/CD
  :/:
  (NP Big/JJ Data/NNS AI/NNP Landscape/NNP)
  2018/CD
  ,/,
  adopted/VBN
  (/(
  (NP Goncharov/NNP)
  ,/,
  2019/CD
  )/)
  (NP Sarah/NNP Al-Shiakhli/NNP)
  34/CD
  8/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Figure', 'Big Data AI Landscape', 'Goncharov', 'Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'AI'), ('ORGANIZATION', 'Goncharov'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('33', '33'), ('Figure', 'figur'), ('20', '20'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('34', '34'), ('8', '8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('33', '33'), ('Figure', 'figur'), ('20', '20'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Goncharov', 'goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('34', '34'), ('8', '8'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('33', '33'), ('Figure', 'Figure'), ('20', '20'), (':', ':'), ('Big', 'Big'), ('Data', 'Data'), ('AI', 'AI'), ('Landscape', 'Landscape'), ('2018', '2018'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Goncharov', 'Goncharov'), (',', ','), ('2019', '2019'), (')', ')'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('34', '34'), ('8', '8'), ('.', '.')]



============================ Sentence 402 =============================

Big Data Analytics and Decision Making   LaValle et al. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Decision', 'Making', 'LaValle', 'et', 'al', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Decision'), ('Decision', 'Making'), ('Making', 'LaValle'), ('LaValle', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Decision'), ('Analytics', 'Decision', 'Making'), ('Decision', 'Making', 'LaValle'), ('Making', 'LaValle', 'et'), ('LaValle', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('LaValle', 'NNP'), ('et', 'FW'), ('al', 'NN'), ('.', '.')]

 (S
  (NP
    Big/NNP
    Data/NNP
    Analytics/NNP
    Decision/NNP
    Making/NNP
    LaValle/NNP)
  et/FW
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics Decision Making LaValle', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make'), ('LaValle', 'laval'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Decision', 'decis'), ('Making', 'make'), ('LaValle', 'lavall'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Decision', 'Decision'), ('Making', 'Making'), ('LaValle', 'LaValle'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 403 =============================

(2011) examined big data analytics capability (BDAC) and defined it as the ability   to use big data in decision making. 


>> Tokens are: 
 ['(', '2011', ')', 'examined', 'big', 'data', 'analytics', 'capability', '(', 'BDAC', ')', 'defined', 'ability', 'use', 'big', 'data', 'decision', 'making', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', 'examined'), ('examined', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'capability'), ('capability', '('), ('(', 'BDAC'), ('BDAC', ')'), (')', 'defined'), ('defined', 'ability'), ('ability', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', 'examined'), (')', 'examined', 'big'), ('examined', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'capability'), ('analytics', 'capability', '('), ('capability', '(', 'BDAC'), ('(', 'BDAC', ')'), ('BDAC', ')', 'defined'), (')', 'defined', 'ability'), ('defined', 'ability', 'use'), ('ability', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'decision'), ('data', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('examined', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('capability', 'NN'), ('(', '('), ('BDAC', 'NNP'), (')', ')'), ('defined', 'VBD'), ('ability', 'NN'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

 (S
  (/(
  2011/CD
  )/)
  examined/VBD
  (NP big/JJ data/NNS analytics/NNS capability/NN)
  (/(
  (NP BDAC/NNP)
  )/)
  defined/VBD
  (NP ability/NN use/NN)
  (NP big/JJ data/NNS decision/NN making/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data analytics capability', 'BDAC', 'ability use', 'big data decision making']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('examined', 'examin'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('(', '('), ('BDAC', 'bdac'), (')', ')'), ('defined', 'defin'), ('ability', 'abil'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('examined', 'examin'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('(', '('), ('BDAC', 'bdac'), (')', ')'), ('defined', 'defin'), ('ability', 'abil'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('examined', 'examined'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('capability', 'capability'), ('(', '('), ('BDAC', 'BDAC'), (')', ')'), ('defined', 'defined'), ('ability', 'ability'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



============================ Sentence 404 =============================

The study by Wixom et al. 


>> Tokens are: 
 ['The', 'study', 'Wixom', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', 'Wixom'), ('Wixom', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'study', 'Wixom'), ('study', 'Wixom', 'et'), ('Wixom', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('Wixom', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP The/DT study/NN Wixom/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['The study Wixom', 'al']

>> Named Entities are: 
 [('PERSON', 'Wixom')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('Wixom', 'wixom'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('Wixom', 'wixom'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('Wixom', 'Wixom'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 405 =============================

(2013) similarly focused on BDAC   in terms of driving business value, recognising the value of BDAC in terms of strategy, data   management, and human impact by conceptualising BDAC dimensions. 


>> Tokens are: 
 ['(', '2013', ')', 'similarly', 'focused', 'BDAC', 'terms', 'driving', 'business', 'value', ',', 'recognising', 'value', 'BDAC', 'terms', 'strategy', ',', 'data', 'management', ',', 'human', 'impact', 'conceptualising', 'BDAC', 'dimensions', '.']

>> Bigrams are: 
 [('(', '2013'), ('2013', ')'), (')', 'similarly'), ('similarly', 'focused'), ('focused', 'BDAC'), ('BDAC', 'terms'), ('terms', 'driving'), ('driving', 'business'), ('business', 'value'), ('value', ','), (',', 'recognising'), ('recognising', 'value'), ('value', 'BDAC'), ('BDAC', 'terms'), ('terms', 'strategy'), ('strategy', ','), (',', 'data'), ('data', 'management'), ('management', ','), (',', 'human'), ('human', 'impact'), ('impact', 'conceptualising'), ('conceptualising', 'BDAC'), ('BDAC', 'dimensions'), ('dimensions', '.')]

>> Trigrams are: 
 [('(', '2013', ')'), ('2013', ')', 'similarly'), (')', 'similarly', 'focused'), ('similarly', 'focused', 'BDAC'), ('focused', 'BDAC', 'terms'), ('BDAC', 'terms', 'driving'), ('terms', 'driving', 'business'), ('driving', 'business', 'value'), ('business', 'value', ','), ('value', ',', 'recognising'), (',', 'recognising', 'value'), ('recognising', 'value', 'BDAC'), ('value', 'BDAC', 'terms'), ('BDAC', 'terms', 'strategy'), ('terms', 'strategy', ','), ('strategy', ',', 'data'), (',', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'human'), (',', 'human', 'impact'), ('human', 'impact', 'conceptualising'), ('impact', 'conceptualising', 'BDAC'), ('conceptualising', 'BDAC', 'dimensions'), ('BDAC', 'dimensions', '.')]

>> POS Tags are: 
 [('(', '('), ('2013', 'CD'), (')', ')'), ('similarly', 'RB'), ('focused', 'VBD'), ('BDAC', 'NNP'), ('terms', 'NNS'), ('driving', 'VBG'), ('business', 'NN'), ('value', 'NN'), (',', ','), ('recognising', 'VBG'), ('value', 'NN'), ('BDAC', 'NNP'), ('terms', 'NNS'), ('strategy', 'NN'), (',', ','), ('data', 'NN'), ('management', 'NN'), (',', ','), ('human', 'JJ'), ('impact', 'NN'), ('conceptualising', 'VBG'), ('BDAC', 'NNP'), ('dimensions', 'NNS'), ('.', '.')]

 (S
  (/(
  2013/CD
  )/)
  similarly/RB
  focused/VBD
  (NP BDAC/NNP terms/NNS)
  driving/VBG
  (NP business/NN value/NN)
  ,/,
  recognising/VBG
  (NP value/NN BDAC/NNP terms/NNS strategy/NN)
  ,/,
  (NP data/NN management/NN)
  ,/,
  (NP human/JJ impact/NN)
  conceptualising/VBG
  (NP BDAC/NNP dimensions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['BDAC terms', 'business value', 'value BDAC terms strategy', 'data management', 'human impact', 'BDAC dimensions']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC'), ('ORGANIZATION', 'BDAC'), ('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2013', '2013'), (')', ')'), ('similarly', 'similarli'), ('focused', 'focus'), ('BDAC', 'bdac'), ('terms', 'term'), ('driving', 'drive'), ('business', 'busi'), ('value', 'valu'), (',', ','), ('recognising', 'recognis'), ('value', 'valu'), ('BDAC', 'bdac'), ('terms', 'term'), ('strategy', 'strategi'), (',', ','), ('data', 'data'), ('management', 'manag'), (',', ','), ('human', 'human'), ('impact', 'impact'), ('conceptualising', 'conceptualis'), ('BDAC', 'bdac'), ('dimensions', 'dimens'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2013', '2013'), (')', ')'), ('similarly', 'similar'), ('focused', 'focus'), ('BDAC', 'bdac'), ('terms', 'term'), ('driving', 'drive'), ('business', 'busi'), ('value', 'valu'), (',', ','), ('recognising', 'recognis'), ('value', 'valu'), ('BDAC', 'bdac'), ('terms', 'term'), ('strategy', 'strategi'), (',', ','), ('data', 'data'), ('management', 'manag'), (',', ','), ('human', 'human'), ('impact', 'impact'), ('conceptualising', 'conceptualis'), ('BDAC', 'bdac'), ('dimensions', 'dimens'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2013', '2013'), (')', ')'), ('similarly', 'similarly'), ('focused', 'focused'), ('BDAC', 'BDAC'), ('terms', 'term'), ('driving', 'driving'), ('business', 'business'), ('value', 'value'), (',', ','), ('recognising', 'recognising'), ('value', 'value'), ('BDAC', 'BDAC'), ('terms', 'term'), ('strategy', 'strategy'), (',', ','), ('data', 'data'), ('management', 'management'), (',', ','), ('human', 'human'), ('impact', 'impact'), ('conceptualising', 'conceptualising'), ('BDAC', 'BDAC'), ('dimensions', 'dimension'), ('.', '.')]



============================ Sentence 406 =============================

That study showed that   establishing BDAC leads to maximising business value by increasing decision speed and allowing   big data usage to spread more widely through an enterprise. 


>> Tokens are: 
 ['That', 'study', 'showed', 'establishing', 'BDAC', 'leads', 'maximising', 'business', 'value', 'increasing', 'decision', 'speed', 'allowing', 'big', 'data', 'usage', 'spread', 'widely', 'enterprise', '.']

>> Bigrams are: 
 [('That', 'study'), ('study', 'showed'), ('showed', 'establishing'), ('establishing', 'BDAC'), ('BDAC', 'leads'), ('leads', 'maximising'), ('maximising', 'business'), ('business', 'value'), ('value', 'increasing'), ('increasing', 'decision'), ('decision', 'speed'), ('speed', 'allowing'), ('allowing', 'big'), ('big', 'data'), ('data', 'usage'), ('usage', 'spread'), ('spread', 'widely'), ('widely', 'enterprise'), ('enterprise', '.')]

>> Trigrams are: 
 [('That', 'study', 'showed'), ('study', 'showed', 'establishing'), ('showed', 'establishing', 'BDAC'), ('establishing', 'BDAC', 'leads'), ('BDAC', 'leads', 'maximising'), ('leads', 'maximising', 'business'), ('maximising', 'business', 'value'), ('business', 'value', 'increasing'), ('value', 'increasing', 'decision'), ('increasing', 'decision', 'speed'), ('decision', 'speed', 'allowing'), ('speed', 'allowing', 'big'), ('allowing', 'big', 'data'), ('big', 'data', 'usage'), ('data', 'usage', 'spread'), ('usage', 'spread', 'widely'), ('spread', 'widely', 'enterprise'), ('widely', 'enterprise', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('study', 'NN'), ('showed', 'VBD'), ('establishing', 'VBG'), ('BDAC', 'NNP'), ('leads', 'VBZ'), ('maximising', 'VBG'), ('business', 'NN'), ('value', 'NN'), ('increasing', 'VBG'), ('decision', 'NN'), ('speed', 'NN'), ('allowing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('usage', 'NN'), ('spread', 'NN'), ('widely', 'RB'), ('enterprise', 'NN'), ('.', '.')]

 (S
  (NP That/DT study/NN)
  showed/VBD
  establishing/VBG
  (NP BDAC/NNP)
  leads/VBZ
  maximising/VBG
  (NP business/NN value/NN)
  increasing/VBG
  (NP decision/NN speed/NN)
  allowing/VBG
  (NP big/JJ data/NNS usage/NN spread/NN)
  widely/RB
  (NP enterprise/NN)
  ./.) 


>> Noun Phrases are: 
 ['That study', 'BDAC', 'business value', 'decision speed', 'big data usage spread', 'enterprise']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('study', 'studi'), ('showed', 'show'), ('establishing', 'establish'), ('BDAC', 'bdac'), ('leads', 'lead'), ('maximising', 'maximis'), ('business', 'busi'), ('value', 'valu'), ('increasing', 'increas'), ('decision', 'decis'), ('speed', 'speed'), ('allowing', 'allow'), ('big', 'big'), ('data', 'data'), ('usage', 'usag'), ('spread', 'spread'), ('widely', 'wide'), ('enterprise', 'enterpris'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('study', 'studi'), ('showed', 'show'), ('establishing', 'establish'), ('BDAC', 'bdac'), ('leads', 'lead'), ('maximising', 'maximis'), ('business', 'busi'), ('value', 'valu'), ('increasing', 'increas'), ('decision', 'decis'), ('speed', 'speed'), ('allowing', 'allow'), ('big', 'big'), ('data', 'data'), ('usage', 'usag'), ('spread', 'spread'), ('widely', 'wide'), ('enterprise', 'enterpris'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('study', 'study'), ('showed', 'showed'), ('establishing', 'establishing'), ('BDAC', 'BDAC'), ('leads', 'lead'), ('maximising', 'maximising'), ('business', 'business'), ('value', 'value'), ('increasing', 'increasing'), ('decision', 'decision'), ('speed', 'speed'), ('allowing', 'allowing'), ('big', 'big'), ('data', 'data'), ('usage', 'usage'), ('spread', 'spread'), ('widely', 'widely'), ('enterprise', 'enterprise'), ('.', '.')]



============================ Sentence 407 =============================

Chen et al. 


>> Tokens are: 
 ['Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Chen/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Chen', 'al']

>> Named Entities are: 
 [('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 408 =============================

(2012) showed that business analytics and related technologies help organisations   develop better understanding of their own businesses and markets, while LaValle et al. 


>> Tokens are: 
 ['(', '2012', ')', 'showed', 'business', 'analytics', 'related', 'technologies', 'help', 'organisations', 'develop', 'better', 'understanding', 'businesses', 'markets', ',', 'LaValle', 'et', 'al', '.']

>> Bigrams are: 
 [('(', '2012'), ('2012', ')'), (')', 'showed'), ('showed', 'business'), ('business', 'analytics'), ('analytics', 'related'), ('related', 'technologies'), ('technologies', 'help'), ('help', 'organisations'), ('organisations', 'develop'), ('develop', 'better'), ('better', 'understanding'), ('understanding', 'businesses'), ('businesses', 'markets'), ('markets', ','), (',', 'LaValle'), ('LaValle', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('(', '2012', ')'), ('2012', ')', 'showed'), (')', 'showed', 'business'), ('showed', 'business', 'analytics'), ('business', 'analytics', 'related'), ('analytics', 'related', 'technologies'), ('related', 'technologies', 'help'), ('technologies', 'help', 'organisations'), ('help', 'organisations', 'develop'), ('organisations', 'develop', 'better'), ('develop', 'better', 'understanding'), ('better', 'understanding', 'businesses'), ('understanding', 'businesses', 'markets'), ('businesses', 'markets', ','), ('markets', ',', 'LaValle'), (',', 'LaValle', 'et'), ('LaValle', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('(', '('), ('2012', 'CD'), (')', ')'), ('showed', 'VBD'), ('business', 'NN'), ('analytics', 'NNS'), ('related', 'JJ'), ('technologies', 'NNS'), ('help', 'VBP'), ('organisations', 'NNS'), ('develop', 'VB'), ('better', 'RBR'), ('understanding', 'JJ'), ('businesses', 'NNS'), ('markets', 'NNS'), (',', ','), ('LaValle', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S
  (/(
  2012/CD
  )/)
  showed/VBD
  (NP business/NN analytics/NNS)
  (NP related/JJ technologies/NNS)
  help/VBP
  (NP organisations/NNS)
  develop/VB
  better/RBR
  (NP understanding/JJ businesses/NNS markets/NNS)
  ,/,
  (NP LaValle/NNP)
  et/CC
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['business analytics', 'related technologies', 'organisations', 'understanding businesses markets', 'LaValle', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'LaValle')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2012', '2012'), (')', ')'), ('showed', 'show'), ('business', 'busi'), ('analytics', 'analyt'), ('related', 'relat'), ('technologies', 'technolog'), ('help', 'help'), ('organisations', 'organis'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('businesses', 'busi'), ('markets', 'market'), (',', ','), ('LaValle', 'laval'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2012', '2012'), (')', ')'), ('showed', 'show'), ('business', 'busi'), ('analytics', 'analyt'), ('related', 'relat'), ('technologies', 'technolog'), ('help', 'help'), ('organisations', 'organis'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('businesses', 'busi'), ('markets', 'market'), (',', ','), ('LaValle', 'lavall'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2012', '2012'), (')', ')'), ('showed', 'showed'), ('business', 'business'), ('analytics', 'analytics'), ('related', 'related'), ('technologies', 'technology'), ('help', 'help'), ('organisations', 'organisation'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understanding'), ('businesses', 'business'), ('markets', 'market'), (',', ','), ('LaValle', 'LaValle'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 409 =============================

(2011)   showed that “top-performing organisations make decisions based on rigorous analysis at more than   double the rate of lower performing organisations” (Sharma et al., 2014). 


>> Tokens are: 
 ['(', '2011', ')', 'showed', '“', 'top-performing', 'organisations', 'make', 'decisions', 'based', 'rigorous', 'analysis', 'double', 'rate', 'lower', 'performing', 'organisations', '”', '(', 'Sharma', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('(', '2011'), ('2011', ')'), (')', 'showed'), ('showed', '“'), ('“', 'top-performing'), ('top-performing', 'organisations'), ('organisations', 'make'), ('make', 'decisions'), ('decisions', 'based'), ('based', 'rigorous'), ('rigorous', 'analysis'), ('analysis', 'double'), ('double', 'rate'), ('rate', 'lower'), ('lower', 'performing'), ('performing', 'organisations'), ('organisations', '”'), ('”', '('), ('(', 'Sharma'), ('Sharma', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '2011', ')'), ('2011', ')', 'showed'), (')', 'showed', '“'), ('showed', '“', 'top-performing'), ('“', 'top-performing', 'organisations'), ('top-performing', 'organisations', 'make'), ('organisations', 'make', 'decisions'), ('make', 'decisions', 'based'), ('decisions', 'based', 'rigorous'), ('based', 'rigorous', 'analysis'), ('rigorous', 'analysis', 'double'), ('analysis', 'double', 'rate'), ('double', 'rate', 'lower'), ('rate', 'lower', 'performing'), ('lower', 'performing', 'organisations'), ('performing', 'organisations', '”'), ('organisations', '”', '('), ('”', '(', 'Sharma'), ('(', 'Sharma', 'et'), ('Sharma', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('2011', 'CD'), (')', ')'), ('showed', 'VBD'), ('“', 'JJ'), ('top-performing', 'JJ'), ('organisations', 'NNS'), ('make', 'VBP'), ('decisions', 'NNS'), ('based', 'VBN'), ('rigorous', 'JJ'), ('analysis', 'NN'), ('double', 'JJ'), ('rate', 'NN'), ('lower', 'RBR'), ('performing', 'NN'), ('organisations', 'NNS'), ('”', 'VBP'), ('(', '('), ('Sharma', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (/(
  2011/CD
  )/)
  showed/VBD
  (NP “/JJ top-performing/JJ organisations/NNS)
  make/VBP
  (NP decisions/NNS)
  based/VBN
  (NP rigorous/JJ analysis/NN)
  (NP double/JJ rate/NN)
  lower/RBR
  (NP performing/NN organisations/NNS)
  ”/VBP
  (/(
  (NP Sharma/NNP)
  et/RB
  al./RB
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['“ top-performing organisations', 'decisions', 'rigorous analysis', 'double rate', 'performing organisations', 'Sharma']

>> Named Entities are: 
 [('PERSON', 'Sharma')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'show'), ('“', '“'), ('top-performing', 'top-perform'), ('organisations', 'organis'), ('make', 'make'), ('decisions', 'decis'), ('based', 'base'), ('rigorous', 'rigor'), ('analysis', 'analysi'), ('double', 'doubl'), ('rate', 'rate'), ('lower', 'lower'), ('performing', 'perform'), ('organisations', 'organis'), ('”', '”'), ('(', '('), ('Sharma', 'sharma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'show'), ('“', '“'), ('top-performing', 'top-perform'), ('organisations', 'organis'), ('make', 'make'), ('decisions', 'decis'), ('based', 'base'), ('rigorous', 'rigor'), ('analysis', 'analysi'), ('double', 'doubl'), ('rate', 'rate'), ('lower', 'lower'), ('performing', 'perform'), ('organisations', 'organis'), ('”', '”'), ('(', '('), ('Sharma', 'sharma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'showed'), ('“', '“'), ('top-performing', 'top-performing'), ('organisations', 'organisation'), ('make', 'make'), ('decisions', 'decision'), ('based', 'based'), ('rigorous', 'rigorous'), ('analysis', 'analysis'), ('double', 'double'), ('rate', 'rate'), ('lower', 'lower'), ('performing', 'performing'), ('organisations', 'organisation'), ('”', '”'), ('(', '('), ('Sharma', 'Sharma'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 410 =============================

Similarly, according to   Kiron et al. 


>> Tokens are: 
 ['Similarly', ',', 'according', 'Kiron', 'et', 'al', '.']

>> Bigrams are: 
 [('Similarly', ','), (',', 'according'), ('according', 'Kiron'), ('Kiron', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Similarly', ',', 'according'), (',', 'according', 'Kiron'), ('according', 'Kiron', 'et'), ('Kiron', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Similarly', 'RB'), (',', ','), ('according', 'VBG'), ('Kiron', 'NNP'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

 (S Similarly/RB ,/, according/VBG (NP Kiron/NNP et/NN al/NN) ./.) 


>> Noun Phrases are: 
 ['Kiron et al']

>> Named Entities are: 
 [('PERSON', 'Kiron')] 

>> Stemming using Porter Stemmer: 
 [('Similarly', 'similarli'), (',', ','), ('according', 'accord'), ('Kiron', 'kiron'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Similarly', 'similar'), (',', ','), ('according', 'accord'), ('Kiron', 'kiron'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Similarly', 'Similarly'), (',', ','), ('according', 'according'), ('Kiron', 'Kiron'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 411 =============================

(2014) BDAC is “the competence to provide business insights using data management,   infrastructure (technology) and talent (personnel) capability to transform business into a   competitive force”. 


>> Tokens are: 
 ['(', '2014', ')', 'BDAC', '“', 'competence', 'provide', 'business', 'insights', 'using', 'data', 'management', ',', 'infrastructure', '(', 'technology', ')', 'talent', '(', 'personnel', ')', 'capability', 'transform', 'business', 'competitive', 'force', '”', '.']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'BDAC'), ('BDAC', '“'), ('“', 'competence'), ('competence', 'provide'), ('provide', 'business'), ('business', 'insights'), ('insights', 'using'), ('using', 'data'), ('data', 'management'), ('management', ','), (',', 'infrastructure'), ('infrastructure', '('), ('(', 'technology'), ('technology', ')'), (')', 'talent'), ('talent', '('), ('(', 'personnel'), ('personnel', ')'), (')', 'capability'), ('capability', 'transform'), ('transform', 'business'), ('business', 'competitive'), ('competitive', 'force'), ('force', '”'), ('”', '.')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'BDAC'), (')', 'BDAC', '“'), ('BDAC', '“', 'competence'), ('“', 'competence', 'provide'), ('competence', 'provide', 'business'), ('provide', 'business', 'insights'), ('business', 'insights', 'using'), ('insights', 'using', 'data'), ('using', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'infrastructure'), (',', 'infrastructure', '('), ('infrastructure', '(', 'technology'), ('(', 'technology', ')'), ('technology', ')', 'talent'), (')', 'talent', '('), ('talent', '(', 'personnel'), ('(', 'personnel', ')'), ('personnel', ')', 'capability'), (')', 'capability', 'transform'), ('capability', 'transform', 'business'), ('transform', 'business', 'competitive'), ('business', 'competitive', 'force'), ('competitive', 'force', '”'), ('force', '”', '.')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('BDAC', 'NNP'), ('“', 'NNP'), ('competence', 'NN'), ('provide', 'NN'), ('business', 'NN'), ('insights', 'NNS'), ('using', 'VBG'), ('data', 'NNS'), ('management', 'NN'), (',', ','), ('infrastructure', 'NN'), ('(', '('), ('technology', 'NN'), (')', ')'), ('talent', 'NN'), ('(', '('), ('personnel', 'NNS'), (')', ')'), ('capability', 'NN'), ('transform', 'NN'), ('business', 'NN'), ('competitive', 'JJ'), ('force', 'NN'), ('”', 'NN'), ('.', '.')]

 (S
  (/(
  2014/CD
  )/)
  (NP
    BDAC/NNP
    “/NNP
    competence/NN
    provide/NN
    business/NN
    insights/NNS)
  using/VBG
  (NP data/NNS management/NN)
  ,/,
  (NP infrastructure/NN)
  (/(
  (NP technology/NN)
  )/)
  (NP talent/NN)
  (/(
  (NP personnel/NNS)
  )/)
  (NP capability/NN transform/NN business/NN)
  (NP competitive/JJ force/NN ”/NN)
  ./.) 


>> Noun Phrases are: 
 ['BDAC “ competence provide business insights', 'data management', 'infrastructure', 'technology', 'talent', 'personnel', 'capability transform business', 'competitive force ”']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('BDAC', 'bdac'), ('“', '“'), ('competence', 'compet'), ('provide', 'provid'), ('business', 'busi'), ('insights', 'insight'), ('using', 'use'), ('data', 'data'), ('management', 'manag'), (',', ','), ('infrastructure', 'infrastructur'), ('(', '('), ('technology', 'technolog'), (')', ')'), ('talent', 'talent'), ('(', '('), ('personnel', 'personnel'), (')', ')'), ('capability', 'capabl'), ('transform', 'transform'), ('business', 'busi'), ('competitive', 'competit'), ('force', 'forc'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('BDAC', 'bdac'), ('“', '“'), ('competence', 'compet'), ('provide', 'provid'), ('business', 'busi'), ('insights', 'insight'), ('using', 'use'), ('data', 'data'), ('management', 'manag'), (',', ','), ('infrastructure', 'infrastructur'), ('(', '('), ('technology', 'technolog'), (')', ')'), ('talent', 'talent'), ('(', '('), ('personnel', 'personnel'), (')', ')'), ('capability', 'capabl'), ('transform', 'transform'), ('business', 'busi'), ('competitive', 'competit'), ('force', 'forc'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('BDAC', 'BDAC'), ('“', '“'), ('competence', 'competence'), ('provide', 'provide'), ('business', 'business'), ('insights', 'insight'), ('using', 'using'), ('data', 'data'), ('management', 'management'), (',', ','), ('infrastructure', 'infrastructure'), ('(', '('), ('technology', 'technology'), (')', ')'), ('talent', 'talent'), ('(', '('), ('personnel', 'personnel'), (')', ')'), ('capability', 'capability'), ('transform', 'transform'), ('business', 'business'), ('competitive', 'competitive'), ('force', 'force'), ('”', '”'), ('.', '.')]



============================ Sentence 412 =============================

Research by Akter et al. 


>> Tokens are: 
 ['Research', 'Akter', 'et', 'al', '.']

>> Bigrams are: 
 [('Research', 'Akter'), ('Akter', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Research', 'Akter', 'et'), ('Akter', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Research', 'NN'), ('Akter', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Research/NN Akter/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Research Akter', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Research', 'research'), ('Akter', 'akter'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Research', 'research'), ('Akter', 'akter'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Research', 'Research'), ('Akter', 'Akter'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 413 =============================

(2016) built a BDAC strategy based on previous studies which showed   the importance of management and technology in the big data environment. 


>> Tokens are: 
 ['(', '2016', ')', 'built', 'BDAC', 'strategy', 'based', 'previous', 'studies', 'showed', 'importance', 'management', 'technology', 'big', 'data', 'environment', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'built'), ('built', 'BDAC'), ('BDAC', 'strategy'), ('strategy', 'based'), ('based', 'previous'), ('previous', 'studies'), ('studies', 'showed'), ('showed', 'importance'), ('importance', 'management'), ('management', 'technology'), ('technology', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'built'), (')', 'built', 'BDAC'), ('built', 'BDAC', 'strategy'), ('BDAC', 'strategy', 'based'), ('strategy', 'based', 'previous'), ('based', 'previous', 'studies'), ('previous', 'studies', 'showed'), ('studies', 'showed', 'importance'), ('showed', 'importance', 'management'), ('importance', 'management', 'technology'), ('management', 'technology', 'big'), ('technology', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('built', 'VBN'), ('BDAC', 'NNP'), ('strategy', 'NN'), ('based', 'VBN'), ('previous', 'JJ'), ('studies', 'NNS'), ('showed', 'VBD'), ('importance', 'JJ'), ('management', 'NN'), ('technology', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('environment', 'NN'), ('.', '.')]

 (S
  (/(
  2016/CD
  )/)
  built/VBN
  (NP BDAC/NNP strategy/NN)
  based/VBN
  (NP previous/JJ studies/NNS)
  showed/VBD
  (NP importance/JJ management/NN technology/NN)
  (NP big/JJ data/NNS environment/NN)
  ./.) 


>> Noun Phrases are: 
 ['BDAC strategy', 'previous studies', 'importance management technology', 'big data environment']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('built', 'built'), ('BDAC', 'bdac'), ('strategy', 'strategi'), ('based', 'base'), ('previous', 'previou'), ('studies', 'studi'), ('showed', 'show'), ('importance', 'import'), ('management', 'manag'), ('technology', 'technolog'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('built', 'built'), ('BDAC', 'bdac'), ('strategy', 'strategi'), ('based', 'base'), ('previous', 'previous'), ('studies', 'studi'), ('showed', 'show'), ('importance', 'import'), ('management', 'manag'), ('technology', 'technolog'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('built', 'built'), ('BDAC', 'BDAC'), ('strategy', 'strategy'), ('based', 'based'), ('previous', 'previous'), ('studies', 'study'), ('showed', 'showed'), ('importance', 'importance'), ('management', 'management'), ('technology', 'technology'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('.', '.')]



============================ Sentence 414 =============================

This study proposed   an integrated BDAC model and examined its impact. 


>> Tokens are: 
 ['This', 'study', 'proposed', 'integrated', 'BDAC', 'model', 'examined', 'impact', '.']

>> Bigrams are: 
 [('This', 'study'), ('study', 'proposed'), ('proposed', 'integrated'), ('integrated', 'BDAC'), ('BDAC', 'model'), ('model', 'examined'), ('examined', 'impact'), ('impact', '.')]

>> Trigrams are: 
 [('This', 'study', 'proposed'), ('study', 'proposed', 'integrated'), ('proposed', 'integrated', 'BDAC'), ('integrated', 'BDAC', 'model'), ('BDAC', 'model', 'examined'), ('model', 'examined', 'impact'), ('examined', 'impact', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('study', 'NN'), ('proposed', 'VBD'), ('integrated', 'VBN'), ('BDAC', 'NNP'), ('model', 'NN'), ('examined', 'VBD'), ('impact', 'NN'), ('.', '.')]

 (S
  (NP This/DT study/NN)
  proposed/VBD
  integrated/VBN
  (NP BDAC/NNP model/NN)
  examined/VBD
  (NP impact/NN)
  ./.) 


>> Noun Phrases are: 
 ['This study', 'BDAC model', 'impact']

>> Named Entities are: 
 [('ORGANIZATION', 'BDAC')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('study', 'studi'), ('proposed', 'propos'), ('integrated', 'integr'), ('BDAC', 'bdac'), ('model', 'model'), ('examined', 'examin'), ('impact', 'impact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('study', 'studi'), ('proposed', 'propos'), ('integrated', 'integr'), ('BDAC', 'bdac'), ('model', 'model'), ('examined', 'examin'), ('impact', 'impact'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('study', 'study'), ('proposed', 'proposed'), ('integrated', 'integrated'), ('BDAC', 'BDAC'), ('model', 'model'), ('examined', 'examined'), ('impact', 'impact'), ('.', '.')]



============================ Sentence 415 =============================

Elgendy (2013) further proposed a Big Data,   Analytics, and Decisions (B-DAD) framework wherein big data analytics tools and methods are   combined in the decision-making process. 


>> Tokens are: 
 ['Elgendy', '(', '2013', ')', 'proposed', 'Big', 'Data', ',', 'Analytics', ',', 'Decisions', '(', 'B-DAD', ')', 'framework', 'wherein', 'big', 'data', 'analytics', 'tools', 'methods', 'combined', 'decision-making', 'process', '.']

>> Bigrams are: 
 [('Elgendy', '('), ('(', '2013'), ('2013', ')'), (')', 'proposed'), ('proposed', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'Analytics'), ('Analytics', ','), (',', 'Decisions'), ('Decisions', '('), ('(', 'B-DAD'), ('B-DAD', ')'), (')', 'framework'), ('framework', 'wherein'), ('wherein', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', 'methods'), ('methods', 'combined'), ('combined', 'decision-making'), ('decision-making', 'process'), ('process', '.')]

>> Trigrams are: 
 [('Elgendy', '(', '2013'), ('(', '2013', ')'), ('2013', ')', 'proposed'), (')', 'proposed', 'Big'), ('proposed', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'Analytics'), (',', 'Analytics', ','), ('Analytics', ',', 'Decisions'), (',', 'Decisions', '('), ('Decisions', '(', 'B-DAD'), ('(', 'B-DAD', ')'), ('B-DAD', ')', 'framework'), (')', 'framework', 'wherein'), ('framework', 'wherein', 'big'), ('wherein', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', 'methods'), ('tools', 'methods', 'combined'), ('methods', 'combined', 'decision-making'), ('combined', 'decision-making', 'process'), ('decision-making', 'process', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), ('(', '('), ('2013', 'CD'), (')', ')'), ('proposed', 'VBD'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('Analytics', 'NNP'), (',', ','), ('Decisions', 'NNP'), ('(', '('), ('B-DAD', 'NNP'), (')', ')'), ('framework', 'NN'), ('wherein', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), ('methods', 'NNS'), ('combined', 'VBD'), ('decision-making', 'JJ'), ('process', 'NN'), ('.', '.')]

 (S
  (NP Elgendy/NNP)
  (/(
  2013/CD
  )/)
  proposed/VBD
  (NP Big/NNP Data/NNP)
  ,/,
  (NP Analytics/NNP)
  ,/,
  (NP Decisions/NNP)
  (/(
  (NP B-DAD/NNP)
  )/)
  (NP framework/NN)
  wherein/VBP
  (NP big/JJ data/NNS analytics/NNS tools/NNS methods/NNS)
  combined/VBD
  (NP decision-making/JJ process/NN)
  ./.) 


>> Noun Phrases are: 
 ['Elgendy', 'Big Data', 'Analytics', 'Decisions', 'B-DAD', 'framework', 'big data analytics tools methods', 'decision-making process']

>> Named Entities are: 
 [('GPE', 'Elgendy'), ('PERSON', 'Analytics'), ('GPE', 'Decisions')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Analytics', 'analyt'), (',', ','), ('Decisions', 'decis'), ('(', '('), ('B-DAD', 'b-dad'), (')', ')'), ('framework', 'framework'), ('wherein', 'wherein'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method'), ('combined', 'combin'), ('decision-making', 'decision-mak'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Analytics', 'analyt'), (',', ','), ('Decisions', 'decis'), ('(', '('), ('B-DAD', 'b-dad'), (')', ')'), ('framework', 'framework'), ('wherein', 'wherein'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method'), ('combined', 'combin'), ('decision-making', 'decision-mak'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'proposed'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('Analytics', 'Analytics'), (',', ','), ('Decisions', 'Decisions'), ('(', '('), ('B-DAD', 'B-DAD'), (')', ')'), ('framework', 'framework'), ('wherein', 'wherein'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), ('methods', 'method'), ('combined', 'combined'), ('decision-making', 'decision-making'), ('process', 'process'), ('.', '.')]



============================ Sentence 416 =============================

In all of the models examined, the intelligence phase is the first phase of the decision-making   process. 


>> Tokens are: 
 ['In', 'models', 'examined', ',', 'intelligence', 'phase', 'first', 'phase', 'decision-making', 'process', '.']

>> Bigrams are: 
 [('In', 'models'), ('models', 'examined'), ('examined', ','), (',', 'intelligence'), ('intelligence', 'phase'), ('phase', 'first'), ('first', 'phase'), ('phase', 'decision-making'), ('decision-making', 'process'), ('process', '.')]

>> Trigrams are: 
 [('In', 'models', 'examined'), ('models', 'examined', ','), ('examined', ',', 'intelligence'), (',', 'intelligence', 'phase'), ('intelligence', 'phase', 'first'), ('phase', 'first', 'phase'), ('first', 'phase', 'decision-making'), ('phase', 'decision-making', 'process'), ('decision-making', 'process', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('models', 'NNS'), ('examined', 'VBN'), (',', ','), ('intelligence', 'NN'), ('phase', 'NN'), ('first', 'JJ'), ('phase', 'NN'), ('decision-making', 'JJ'), ('process', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP models/NNS)
  examined/VBN
  ,/,
  (NP intelligence/NN phase/NN)
  (NP first/JJ phase/NN)
  (NP decision-making/JJ process/NN)
  ./.) 


>> Noun Phrases are: 
 ['models', 'intelligence phase', 'first phase', 'decision-making process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('models', 'model'), ('examined', 'examin'), (',', ','), ('intelligence', 'intellig'), ('phase', 'phase'), ('first', 'first'), ('phase', 'phase'), ('decision-making', 'decision-mak'), ('process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('models', 'model'), ('examined', 'examin'), (',', ','), ('intelligence', 'intellig'), ('phase', 'phase'), ('first', 'first'), ('phase', 'phase'), ('decision-making', 'decision-mak'), ('process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('models', 'model'), ('examined', 'examined'), (',', ','), ('intelligence', 'intelligence'), ('phase', 'phase'), ('first', 'first'), ('phase', 'phase'), ('decision-making', 'decision-making'), ('process', 'process'), ('.', '.')]



============================ Sentence 417 =============================

In this phase   • data collected from internal and external sources are used to identify problems and  opportunities;   • big data sources are clearly identified;   • further data are collected and gathered from different sources, being stored and sent to the  user;   • after defining the data sources and types of the data required for the analysis, the data is  processed through big data storage and management tools;   • organizing, preparing, and processing the big data is completed using either big data  processing tools or a high-speed network using Extract, Transform, Load or Extract, Load,   Transform (ETL/ELT) processes. 


>> Tokens are: 
 ['In', 'phase', '•', 'data', 'collected', 'internal', 'external', 'sources', 'used', 'identify', 'problems', 'opportunities', ';', '•', 'big', 'data', 'sources', 'clearly', 'identified', ';', '•', 'data', 'collected', 'gathered', 'different', 'sources', ',', 'stored', 'sent', 'user', ';', '•', 'defining', 'data', 'sources', 'types', 'data', 'required', 'analysis', ',', 'data', 'processed', 'big', 'data', 'storage', 'management', 'tools', ';', '•', 'organizing', ',', 'preparing', ',', 'processing', 'big', 'data', 'completed', 'using', 'either', 'big', 'data', 'processing', 'tools', 'high-speed', 'network', 'using', 'Extract', ',', 'Transform', ',', 'Load', 'Extract', ',', 'Load', ',', 'Transform', '(', 'ETL/ELT', ')', 'processes', '.']

>> Bigrams are: 
 [('In', 'phase'), ('phase', '•'), ('•', 'data'), ('data', 'collected'), ('collected', 'internal'), ('internal', 'external'), ('external', 'sources'), ('sources', 'used'), ('used', 'identify'), ('identify', 'problems'), ('problems', 'opportunities'), ('opportunities', ';'), (';', '•'), ('•', 'big'), ('big', 'data'), ('data', 'sources'), ('sources', 'clearly'), ('clearly', 'identified'), ('identified', ';'), (';', '•'), ('•', 'data'), ('data', 'collected'), ('collected', 'gathered'), ('gathered', 'different'), ('different', 'sources'), ('sources', ','), (',', 'stored'), ('stored', 'sent'), ('sent', 'user'), ('user', ';'), (';', '•'), ('•', 'defining'), ('defining', 'data'), ('data', 'sources'), ('sources', 'types'), ('types', 'data'), ('data', 'required'), ('required', 'analysis'), ('analysis', ','), (',', 'data'), ('data', 'processed'), ('processed', 'big'), ('big', 'data'), ('data', 'storage'), ('storage', 'management'), ('management', 'tools'), ('tools', ';'), (';', '•'), ('•', 'organizing'), ('organizing', ','), (',', 'preparing'), ('preparing', ','), (',', 'processing'), ('processing', 'big'), ('big', 'data'), ('data', 'completed'), ('completed', 'using'), ('using', 'either'), ('either', 'big'), ('big', 'data'), ('data', 'processing'), ('processing', 'tools'), ('tools', 'high-speed'), ('high-speed', 'network'), ('network', 'using'), ('using', 'Extract'), ('Extract', ','), (',', 'Transform'), ('Transform', ','), (',', 'Load'), ('Load', 'Extract'), ('Extract', ','), (',', 'Load'), ('Load', ','), (',', 'Transform'), ('Transform', '('), ('(', 'ETL/ELT'), ('ETL/ELT', ')'), (')', 'processes'), ('processes', '.')]

>> Trigrams are: 
 [('In', 'phase', '•'), ('phase', '•', 'data'), ('•', 'data', 'collected'), ('data', 'collected', 'internal'), ('collected', 'internal', 'external'), ('internal', 'external', 'sources'), ('external', 'sources', 'used'), ('sources', 'used', 'identify'), ('used', 'identify', 'problems'), ('identify', 'problems', 'opportunities'), ('problems', 'opportunities', ';'), ('opportunities', ';', '•'), (';', '•', 'big'), ('•', 'big', 'data'), ('big', 'data', 'sources'), ('data', 'sources', 'clearly'), ('sources', 'clearly', 'identified'), ('clearly', 'identified', ';'), ('identified', ';', '•'), (';', '•', 'data'), ('•', 'data', 'collected'), ('data', 'collected', 'gathered'), ('collected', 'gathered', 'different'), ('gathered', 'different', 'sources'), ('different', 'sources', ','), ('sources', ',', 'stored'), (',', 'stored', 'sent'), ('stored', 'sent', 'user'), ('sent', 'user', ';'), ('user', ';', '•'), (';', '•', 'defining'), ('•', 'defining', 'data'), ('defining', 'data', 'sources'), ('data', 'sources', 'types'), ('sources', 'types', 'data'), ('types', 'data', 'required'), ('data', 'required', 'analysis'), ('required', 'analysis', ','), ('analysis', ',', 'data'), (',', 'data', 'processed'), ('data', 'processed', 'big'), ('processed', 'big', 'data'), ('big', 'data', 'storage'), ('data', 'storage', 'management'), ('storage', 'management', 'tools'), ('management', 'tools', ';'), ('tools', ';', '•'), (';', '•', 'organizing'), ('•', 'organizing', ','), ('organizing', ',', 'preparing'), (',', 'preparing', ','), ('preparing', ',', 'processing'), (',', 'processing', 'big'), ('processing', 'big', 'data'), ('big', 'data', 'completed'), ('data', 'completed', 'using'), ('completed', 'using', 'either'), ('using', 'either', 'big'), ('either', 'big', 'data'), ('big', 'data', 'processing'), ('data', 'processing', 'tools'), ('processing', 'tools', 'high-speed'), ('tools', 'high-speed', 'network'), ('high-speed', 'network', 'using'), ('network', 'using', 'Extract'), ('using', 'Extract', ','), ('Extract', ',', 'Transform'), (',', 'Transform', ','), ('Transform', ',', 'Load'), (',', 'Load', 'Extract'), ('Load', 'Extract', ','), ('Extract', ',', 'Load'), (',', 'Load', ','), ('Load', ',', 'Transform'), (',', 'Transform', '('), ('Transform', '(', 'ETL/ELT'), ('(', 'ETL/ELT', ')'), ('ETL/ELT', ')', 'processes'), (')', 'processes', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('phase', 'NN'), ('•', 'NNP'), ('data', 'NNS'), ('collected', 'VBD'), ('internal', 'JJ'), ('external', 'JJ'), ('sources', 'NNS'), ('used', 'VBD'), ('identify', 'VB'), ('problems', 'NNS'), ('opportunities', 'NNS'), (';', ':'), ('•', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('clearly', 'RB'), ('identified', 'VBN'), (';', ':'), ('•', 'NNP'), ('data', 'NNS'), ('collected', 'VBD'), ('gathered', 'JJ'), ('different', 'JJ'), ('sources', 'NNS'), (',', ','), ('stored', 'VBD'), ('sent', 'VBN'), ('user', 'NN'), (';', ':'), ('•', 'CC'), ('defining', 'VBG'), ('data', 'NNS'), ('sources', 'NNS'), ('types', 'NNS'), ('data', 'NNS'), ('required', 'VBN'), ('analysis', 'NN'), (',', ','), ('data', 'NNS'), ('processed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('storage', 'NN'), ('management', 'NN'), ('tools', 'NNS'), (';', ':'), ('•', 'NNP'), ('organizing', 'NN'), (',', ','), ('preparing', 'VBG'), (',', ','), ('processing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('completed', 'VBD'), ('using', 'VBG'), ('either', 'CC'), ('big', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('tools', 'NNS'), ('high-speed', 'JJ'), ('network', 'NN'), ('using', 'VBG'), ('Extract', 'NNP'), (',', ','), ('Transform', 'NNP'), (',', ','), ('Load', 'NNP'), ('Extract', 'NNP'), (',', ','), ('Load', 'NNP'), (',', ','), ('Transform', 'NNP'), ('(', '('), ('ETL/ELT', 'NNP'), (')', ')'), ('processes', 'VBZ'), ('.', '.')]

 (S
  In/IN
  (NP phase/NN •/NNP data/NNS)
  collected/VBD
  (NP internal/JJ external/JJ sources/NNS)
  used/VBD
  identify/VB
  (NP problems/NNS opportunities/NNS)
  ;/:
  (NP •/NNP)
  (NP big/JJ data/NNS sources/NNS)
  clearly/RB
  identified/VBN
  ;/:
  (NP •/NNP data/NNS)
  collected/VBD
  (NP gathered/JJ different/JJ sources/NNS)
  ,/,
  stored/VBD
  sent/VBN
  (NP user/NN)
  ;/:
  •/CC
  defining/VBG
  (NP data/NNS sources/NNS types/NNS data/NNS)
  required/VBN
  (NP analysis/NN)
  ,/,
  (NP data/NNS)
  processed/VBD
  (NP big/JJ data/NNS storage/NN management/NN tools/NNS)
  ;/:
  (NP •/NNP organizing/NN)
  ,/,
  preparing/VBG
  ,/,
  processing/VBG
  (NP big/JJ data/NNS)
  completed/VBD
  using/VBG
  either/CC
  (NP big/JJ data/NNS processing/NN tools/NNS)
  (NP high-speed/JJ network/NN)
  using/VBG
  (NP Extract/NNP)
  ,/,
  (NP Transform/NNP)
  ,/,
  (NP Load/NNP Extract/NNP)
  ,/,
  (NP Load/NNP)
  ,/,
  (NP Transform/NNP)
  (/(
  (NP ETL/ELT/NNP)
  )/)
  processes/VBZ
  ./.) 


>> Noun Phrases are: 
 ['phase • data', 'internal external sources', 'problems opportunities', '•', 'big data sources', '• data', 'gathered different sources', 'user', 'data sources types data', 'analysis', 'data', 'big data storage management tools', '• organizing', 'big data', 'big data processing tools', 'high-speed network', 'Extract', 'Transform', 'Load Extract', 'Load', 'Transform', 'ETL/ELT']

>> Named Entities are: 
 [('PERSON', 'Extract'), ('PERSON', 'Transform'), ('PERSON', 'Load Extract'), ('PERSON', 'Load'), ('GPE', 'Transform')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('phase', 'phase'), ('•', '•'), ('data', 'data'), ('collected', 'collect'), ('internal', 'intern'), ('external', 'extern'), ('sources', 'sourc'), ('used', 'use'), ('identify', 'identifi'), ('problems', 'problem'), ('opportunities', 'opportun'), (';', ';'), ('•', '•'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('clearly', 'clearli'), ('identified', 'identifi'), (';', ';'), ('•', '•'), ('data', 'data'), ('collected', 'collect'), ('gathered', 'gather'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('stored', 'store'), ('sent', 'sent'), ('user', 'user'), (';', ';'), ('•', '•'), ('defining', 'defin'), ('data', 'data'), ('sources', 'sourc'), ('types', 'type'), ('data', 'data'), ('required', 'requir'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('processed', 'process'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('tools', 'tool'), (';', ';'), ('•', '•'), ('organizing', 'organ'), (',', ','), ('preparing', 'prepar'), (',', ','), ('processing', 'process'), ('big', 'big'), ('data', 'data'), ('completed', 'complet'), ('using', 'use'), ('either', 'either'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('tools', 'tool'), ('high-speed', 'high-spe'), ('network', 'network'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ','), ('Transform', 'transform'), ('(', '('), ('ETL/ELT', 'etl/elt'), (')', ')'), ('processes', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('phase', 'phase'), ('•', '•'), ('data', 'data'), ('collected', 'collect'), ('internal', 'intern'), ('external', 'extern'), ('sources', 'sourc'), ('used', 'use'), ('identify', 'identifi'), ('problems', 'problem'), ('opportunities', 'opportun'), (';', ';'), ('•', '•'), ('big', 'big'), ('data', 'data'), ('sources', 'sourc'), ('clearly', 'clear'), ('identified', 'identifi'), (';', ';'), ('•', '•'), ('data', 'data'), ('collected', 'collect'), ('gathered', 'gather'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('stored', 'store'), ('sent', 'sent'), ('user', 'user'), (';', ';'), ('•', '•'), ('defining', 'defin'), ('data', 'data'), ('sources', 'sourc'), ('types', 'type'), ('data', 'data'), ('required', 'requir'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('processed', 'process'), ('big', 'big'), ('data', 'data'), ('storage', 'storag'), ('management', 'manag'), ('tools', 'tool'), (';', ';'), ('•', '•'), ('organizing', 'organ'), (',', ','), ('preparing', 'prepar'), (',', ','), ('processing', 'process'), ('big', 'big'), ('data', 'data'), ('completed', 'complet'), ('using', 'use'), ('either', 'either'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('tools', 'tool'), ('high-speed', 'high-spe'), ('network', 'network'), ('using', 'use'), ('Extract', 'extract'), (',', ','), ('Transform', 'transform'), (',', ','), ('Load', 'load'), ('Extract', 'extract'), (',', ','), ('Load', 'load'), (',', ','), ('Transform', 'transform'), ('(', '('), ('ETL/ELT', 'etl/elt'), (')', ')'), ('processes', 'process'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('phase', 'phase'), ('•', '•'), ('data', 'data'), ('collected', 'collected'), ('internal', 'internal'), ('external', 'external'), ('sources', 'source'), ('used', 'used'), ('identify', 'identify'), ('problems', 'problem'), ('opportunities', 'opportunity'), (';', ';'), ('•', '•'), ('big', 'big'), ('data', 'data'), ('sources', 'source'), ('clearly', 'clearly'), ('identified', 'identified'), (';', ';'), ('•', '•'), ('data', 'data'), ('collected', 'collected'), ('gathered', 'gathered'), ('different', 'different'), ('sources', 'source'), (',', ','), ('stored', 'stored'), ('sent', 'sent'), ('user', 'user'), (';', ';'), ('•', '•'), ('defining', 'defining'), ('data', 'data'), ('sources', 'source'), ('types', 'type'), ('data', 'data'), ('required', 'required'), ('analysis', 'analysis'), (',', ','), ('data', 'data'), ('processed', 'processed'), ('big', 'big'), ('data', 'data'), ('storage', 'storage'), ('management', 'management'), ('tools', 'tool'), (';', ';'), ('•', '•'), ('organizing', 'organizing'), (',', ','), ('preparing', 'preparing'), (',', ','), ('processing', 'processing'), ('big', 'big'), ('data', 'data'), ('completed', 'completed'), ('using', 'using'), ('either', 'either'), ('big', 'big'), ('data', 'data'), ('processing', 'processing'), ('tools', 'tool'), ('high-speed', 'high-speed'), ('network', 'network'), ('using', 'using'), ('Extract', 'Extract'), (',', ','), ('Transform', 'Transform'), (',', ','), ('Load', 'Load'), ('Extract', 'Extract'), (',', ','), ('Load', 'Load'), (',', ','), ('Transform', 'Transform'), ('(', '('), ('ETL/ELT', 'ETL/ELT'), (')', ')'), ('processes', 'process'), ('.', '.')]



============================ Sentence 418 =============================

These phases are shown in detail in Figure 21. 


>> Tokens are: 
 ['These', 'phases', 'shown', 'detail', 'Figure', '21', '.']

>> Bigrams are: 
 [('These', 'phases'), ('phases', 'shown'), ('shown', 'detail'), ('detail', 'Figure'), ('Figure', '21'), ('21', '.')]

>> Trigrams are: 
 [('These', 'phases', 'shown'), ('phases', 'shown', 'detail'), ('shown', 'detail', 'Figure'), ('detail', 'Figure', '21'), ('Figure', '21', '.')]

>> POS Tags are: 
 [('These', 'DT'), ('phases', 'NNS'), ('shown', 'VBN'), ('detail', 'JJ'), ('Figure', 'NN'), ('21', 'CD'), ('.', '.')]

 (S
  (NP These/DT phases/NNS)
  shown/VBN
  (NP detail/JJ Figure/NN)
  21/CD
  ./.) 


>> Noun Phrases are: 
 ['These phases', 'detail Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('These', 'these'), ('phases', 'phase'), ('shown', 'shown'), ('detail', 'detail'), ('Figure', 'figur'), ('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('These', 'these'), ('phases', 'phase'), ('shown', 'shown'), ('detail', 'detail'), ('Figure', 'figur'), ('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('These', 'These'), ('phases', 'phase'), ('shown', 'shown'), ('detail', 'detail'), ('Figure', 'Figure'), ('21', '21'), ('.', '.')]



============================ Sentence 419 =============================

The next phase is the design phase, in which developing and analysing the possible courses of   actions is done by means of conceptualization or developing a problem representative model. 


>> Tokens are: 
 ['The', 'next', 'phase', 'design', 'phase', ',', 'developing', 'analysing', 'possible', 'courses', 'actions', 'done', 'means', 'conceptualization', 'developing', 'problem', 'representative', 'model', '.']

>> Bigrams are: 
 [('The', 'next'), ('next', 'phase'), ('phase', 'design'), ('design', 'phase'), ('phase', ','), (',', 'developing'), ('developing', 'analysing'), ('analysing', 'possible'), ('possible', 'courses'), ('courses', 'actions'), ('actions', 'done'), ('done', 'means'), ('means', 'conceptualization'), ('conceptualization', 'developing'), ('developing', 'problem'), ('problem', 'representative'), ('representative', 'model'), ('model', '.')]

>> Trigrams are: 
 [('The', 'next', 'phase'), ('next', 'phase', 'design'), ('phase', 'design', 'phase'), ('design', 'phase', ','), ('phase', ',', 'developing'), (',', 'developing', 'analysing'), ('developing', 'analysing', 'possible'), ('analysing', 'possible', 'courses'), ('possible', 'courses', 'actions'), ('courses', 'actions', 'done'), ('actions', 'done', 'means'), ('done', 'means', 'conceptualization'), ('means', 'conceptualization', 'developing'), ('conceptualization', 'developing', 'problem'), ('developing', 'problem', 'representative'), ('problem', 'representative', 'model'), ('representative', 'model', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('next', 'JJ'), ('phase', 'NN'), ('design', 'NN'), ('phase', 'NN'), (',', ','), ('developing', 'VBG'), ('analysing', 'VBG'), ('possible', 'JJ'), ('courses', 'NNS'), ('actions', 'NNS'), ('done', 'VBN'), ('means', 'VBZ'), ('conceptualization', 'NN'), ('developing', 'VBG'), ('problem', 'NN'), ('representative', 'NN'), ('model', 'NN'), ('.', '.')]

 (S
  (NP The/DT next/JJ phase/NN design/NN phase/NN)
  ,/,
  developing/VBG
  analysing/VBG
  (NP possible/JJ courses/NNS actions/NNS)
  done/VBN
  means/VBZ
  (NP conceptualization/NN)
  developing/VBG
  (NP problem/NN representative/NN model/NN)
  ./.) 


>> Noun Phrases are: 
 ['The next phase design phase', 'possible courses actions', 'conceptualization', 'problem representative model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('next', 'next'), ('phase', 'phase'), ('design', 'design'), ('phase', 'phase'), (',', ','), ('developing', 'develop'), ('analysing', 'analys'), ('possible', 'possibl'), ('courses', 'cours'), ('actions', 'action'), ('done', 'done'), ('means', 'mean'), ('conceptualization', 'conceptu'), ('developing', 'develop'), ('problem', 'problem'), ('representative', 'repres'), ('model', 'model'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('next', 'next'), ('phase', 'phase'), ('design', 'design'), ('phase', 'phase'), (',', ','), ('developing', 'develop'), ('analysing', 'analys'), ('possible', 'possibl'), ('courses', 'cours'), ('actions', 'action'), ('done', 'done'), ('means', 'mean'), ('conceptualization', 'conceptu'), ('developing', 'develop'), ('problem', 'problem'), ('representative', 'repres'), ('model', 'model'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('next', 'next'), ('phase', 'phase'), ('design', 'design'), ('phase', 'phase'), (',', ','), ('developing', 'developing'), ('analysing', 'analysing'), ('possible', 'possible'), ('courses', 'course'), ('actions', 'action'), ('done', 'done'), ('means', 'mean'), ('conceptualization', 'conceptualization'), ('developing', 'developing'), ('problem', 'problem'), ('representative', 'representative'), ('model', 'model'), ('.', '.')]



============================ Sentence 420 =============================

In   this phase, the framework divided into model planning, data analytics, and analysis. 


>> Tokens are: 
 ['In', 'phase', ',', 'framework', 'divided', 'model', 'planning', ',', 'data', 'analytics', ',', 'analysis', '.']

>> Bigrams are: 
 [('In', 'phase'), ('phase', ','), (',', 'framework'), ('framework', 'divided'), ('divided', 'model'), ('model', 'planning'), ('planning', ','), (',', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('In', 'phase', ','), ('phase', ',', 'framework'), (',', 'framework', 'divided'), ('framework', 'divided', 'model'), ('divided', 'model', 'planning'), ('model', 'planning', ','), ('planning', ',', 'data'), (',', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'analysis'), (',', 'analysis', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('phase', 'NN'), (',', ','), ('framework', 'NN'), ('divided', 'VBD'), ('model', 'NN'), ('planning', 'NN'), (',', ','), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('analysis', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP phase/NN)
  ,/,
  (NP framework/NN)
  divided/VBD
  (NP model/NN planning/NN)
  ,/,
  (NP data/NN analytics/NNS)
  ,/,
  (NP analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['phase', 'framework', 'model planning', 'data analytics', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('phase', 'phase'), (',', ','), ('framework', 'framework'), ('divided', 'divid'), ('model', 'model'), ('planning', 'plan'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('phase', 'phase'), (',', ','), ('framework', 'framework'), ('divided', 'divid'), ('model', 'model'), ('planning', 'plan'), (',', ','), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('phase', 'phase'), (',', ','), ('framework', 'framework'), ('divided', 'divided'), ('model', 'model'), ('planning', 'planning'), (',', ','), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 421 =============================

Where a data   analytics model is selected, this is planned, applied, and then analysed. 


>> Tokens are: 
 ['Where', 'data', 'analytics', 'model', 'selected', ',', 'planned', ',', 'applied', ',', 'analysed', '.']

>> Bigrams are: 
 [('Where', 'data'), ('data', 'analytics'), ('analytics', 'model'), ('model', 'selected'), ('selected', ','), (',', 'planned'), ('planned', ','), (',', 'applied'), ('applied', ','), (',', 'analysed'), ('analysed', '.')]

>> Trigrams are: 
 [('Where', 'data', 'analytics'), ('data', 'analytics', 'model'), ('analytics', 'model', 'selected'), ('model', 'selected', ','), ('selected', ',', 'planned'), (',', 'planned', ','), ('planned', ',', 'applied'), (',', 'applied', ','), ('applied', ',', 'analysed'), (',', 'analysed', '.')]

>> POS Tags are: 
 [('Where', 'WRB'), ('data', 'NNS'), ('analytics', 'NNS'), ('model', 'NN'), ('selected', 'VBN'), (',', ','), ('planned', 'VBN'), (',', ','), ('applied', 'VBN'), (',', ','), ('analysed', 'VBN'), ('.', '.')]

 (S
  Where/WRB
  (NP data/NNS analytics/NNS model/NN)
  selected/VBN
  ,/,
  planned/VBN
  ,/,
  applied/VBN
  ,/,
  analysed/VBN
  ./.) 


>> Noun Phrases are: 
 ['data analytics model']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('analytics', 'analyt'), ('model', 'model'), ('selected', 'select'), (',', ','), ('planned', 'plan'), (',', ','), ('applied', 'appli'), (',', ','), ('analysed', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Where', 'where'), ('data', 'data'), ('analytics', 'analyt'), ('model', 'model'), ('selected', 'select'), (',', ','), ('planned', 'plan'), (',', ','), ('applied', 'appli'), (',', ','), ('analysed', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('Where', 'Where'), ('data', 'data'), ('analytics', 'analytics'), ('model', 'model'), ('selected', 'selected'), (',', ','), ('planned', 'planned'), (',', ','), ('applied', 'applied'), (',', ','), ('analysed', 'analysed'), ('.', '.')]



============================ Sentence 422 =============================

The third phase of decision making is the choice phase, and in this phase, the proposed solution   impact is evaluated. 


>> Tokens are: 
 ['The', 'third', 'phase', 'decision', 'making', 'choice', 'phase', ',', 'phase', ',', 'proposed', 'solution', 'impact', 'evaluated', '.']

>> Bigrams are: 
 [('The', 'third'), ('third', 'phase'), ('phase', 'decision'), ('decision', 'making'), ('making', 'choice'), ('choice', 'phase'), ('phase', ','), (',', 'phase'), ('phase', ','), (',', 'proposed'), ('proposed', 'solution'), ('solution', 'impact'), ('impact', 'evaluated'), ('evaluated', '.')]

>> Trigrams are: 
 [('The', 'third', 'phase'), ('third', 'phase', 'decision'), ('phase', 'decision', 'making'), ('decision', 'making', 'choice'), ('making', 'choice', 'phase'), ('choice', 'phase', ','), ('phase', ',', 'phase'), (',', 'phase', ','), ('phase', ',', 'proposed'), (',', 'proposed', 'solution'), ('proposed', 'solution', 'impact'), ('solution', 'impact', 'evaluated'), ('impact', 'evaluated', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('third', 'JJ'), ('phase', 'NN'), ('decision', 'NN'), ('making', 'VBG'), ('choice', 'NN'), ('phase', 'NN'), (',', ','), ('phase', 'NN'), (',', ','), ('proposed', 'VBN'), ('solution', 'NN'), ('impact', 'NN'), ('evaluated', 'VBN'), ('.', '.')]

 (S
  (NP The/DT third/JJ phase/NN decision/NN)
  making/VBG
  (NP choice/NN phase/NN)
  ,/,
  (NP phase/NN)
  ,/,
  proposed/VBN
  (NP solution/NN impact/NN)
  evaluated/VBN
  ./.) 


>> Noun Phrases are: 
 ['The third phase decision', 'choice phase', 'phase', 'solution impact']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('third', 'third'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('choice', 'choic'), ('phase', 'phase'), (',', ','), ('phase', 'phase'), (',', ','), ('proposed', 'propos'), ('solution', 'solut'), ('impact', 'impact'), ('evaluated', 'evalu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('third', 'third'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('choice', 'choic'), ('phase', 'phase'), (',', ','), ('phase', 'phase'), (',', ','), ('proposed', 'propos'), ('solution', 'solut'), ('impact', 'impact'), ('evaluated', 'evalu'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('third', 'third'), ('phase', 'phase'), ('decision', 'decision'), ('making', 'making'), ('choice', 'choice'), ('phase', 'phase'), (',', ','), ('phase', 'phase'), (',', ','), ('proposed', 'proposed'), ('solution', 'solution'), ('impact', 'impact'), ('evaluated', 'evaluated'), ('.', '.')]



============================ Sentence 423 =============================

The final phase in decision making is the implementation phase; in this phase,   the proposed solution is implemented (Elgendy, N. and Elragal, A., 2016). 


>> Tokens are: 
 ['The', 'final', 'phase', 'decision', 'making', 'implementation', 'phase', ';', 'phase', ',', 'proposed', 'solution', 'implemented', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('The', 'final'), ('final', 'phase'), ('phase', 'decision'), ('decision', 'making'), ('making', 'implementation'), ('implementation', 'phase'), ('phase', ';'), (';', 'phase'), ('phase', ','), (',', 'proposed'), ('proposed', 'solution'), ('solution', 'implemented'), ('implemented', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'final', 'phase'), ('final', 'phase', 'decision'), ('phase', 'decision', 'making'), ('decision', 'making', 'implementation'), ('making', 'implementation', 'phase'), ('implementation', 'phase', ';'), ('phase', ';', 'phase'), (';', 'phase', ','), ('phase', ',', 'proposed'), (',', 'proposed', 'solution'), ('proposed', 'solution', 'implemented'), ('solution', 'implemented', '('), ('implemented', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('final', 'JJ'), ('phase', 'NN'), ('decision', 'NN'), ('making', 'VBG'), ('implementation', 'JJ'), ('phase', 'NN'), (';', ':'), ('phase', 'NN'), (',', ','), ('proposed', 'VBN'), ('solution', 'NN'), ('implemented', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT final/JJ phase/NN decision/NN)
  making/VBG
  (NP implementation/JJ phase/NN)
  ;/:
  (NP phase/NN)
  ,/,
  proposed/VBN
  (NP solution/NN)
  implemented/VBN
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The final phase decision', 'implementation phase', 'phase', 'solution', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('final', 'final'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('implementation', 'implement'), ('phase', 'phase'), (';', ';'), ('phase', 'phase'), (',', ','), ('proposed', 'propos'), ('solution', 'solut'), ('implemented', 'implement'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('final', 'final'), ('phase', 'phase'), ('decision', 'decis'), ('making', 'make'), ('implementation', 'implement'), ('phase', 'phase'), (';', ';'), ('phase', 'phase'), (',', ','), ('proposed', 'propos'), ('solution', 'solut'), ('implemented', 'implement'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('final', 'final'), ('phase', 'phase'), ('decision', 'decision'), ('making', 'making'), ('implementation', 'implementation'), ('phase', 'phase'), (';', ';'), ('phase', 'phase'), (',', ','), ('proposed', 'proposed'), ('solution', 'solution'), ('implemented', 'implemented'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 424 =============================

Sarah Al-Shiakhli   35                Figure 21: B-DAD framework, adopted from (Elgendy and Elragal, 2016). 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '35', 'Figure', '21', ':', 'B-DAD', 'framework', ',', 'adopted', '(', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '35'), ('35', 'Figure'), ('Figure', '21'), ('21', ':'), (':', 'B-DAD'), ('B-DAD', 'framework'), ('framework', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '35'), ('Al-Shiakhli', '35', 'Figure'), ('35', 'Figure', '21'), ('Figure', '21', ':'), ('21', ':', 'B-DAD'), (':', 'B-DAD', 'framework'), ('B-DAD', 'framework', ','), ('framework', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('35', 'CD'), ('Figure', 'NNP'), ('21', 'CD'), (':', ':'), ('B-DAD', 'JJ'), ('framework', 'NN'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  35/CD
  (NP Figure/NNP)
  21/CD
  :/:
  (NP B-DAD/JJ framework/NN)
  ,/,
  adopted/VBN
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Figure', 'B-DAD framework', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('35', '35'), ('Figure', 'figur'), ('21', '21'), (':', ':'), ('B-DAD', 'b-dad'), ('framework', 'framework'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('35', '35'), ('Figure', 'figur'), ('21', '21'), (':', ':'), ('B-DAD', 'b-dad'), ('framework', 'framework'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('35', '35'), ('Figure', 'Figure'), ('21', '21'), (':', ':'), ('B-DAD', 'B-DAD'), ('framework', 'framework'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 425 =============================

Sarah Al-Shiakhli   36      Elgendy and Elragal (2016) shows the decision-making process and how big data analytics can be   integrated into it. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '36', 'Elgendy', 'Elragal', '(', '2016', ')', 'shows', 'decision-making', 'process', 'big', 'data', 'analytics', 'integrated', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '36'), ('36', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', '('), ('(', '2016'), ('2016', ')'), (')', 'shows'), ('shows', 'decision-making'), ('decision-making', 'process'), ('process', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'integrated'), ('integrated', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '36'), ('Al-Shiakhli', '36', 'Elgendy'), ('36', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', '('), ('Elragal', '(', '2016'), ('(', '2016', ')'), ('2016', ')', 'shows'), (')', 'shows', 'decision-making'), ('shows', 'decision-making', 'process'), ('decision-making', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'integrated'), ('analytics', 'integrated', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('36', 'CD'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), ('(', '('), ('2016', 'CD'), (')', ')'), ('shows', 'VBZ'), ('decision-making', 'JJ'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('integrated', 'VBN'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  36/CD
  (NP Elgendy/NNP Elragal/NNP)
  (/(
  2016/CD
  )/)
  shows/VBZ
  (NP decision-making/JJ process/NN)
  (NP big/JJ data/NNS analytics/NNS)
  integrated/VBN
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Elgendy Elragal', 'decision-making process', 'big data analytics']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('36', '36'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), ('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('decision-making', 'decision-mak'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('integrated', 'integr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('36', '36'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), ('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('decision-making', 'decision-mak'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('integrated', 'integr'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('36', '36'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), ('(', '('), ('2016', '2016'), (')', ')'), ('shows', 'show'), ('decision-making', 'decision-making'), ('process', 'process'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('integrated', 'integrated'), ('.', '.')]



============================ Sentence 426 =============================

Using the methodology of design science, the B-DAD can be used to map big   data tools and analytics to various decision-making phases. 


>> Tokens are: 
 ['Using', 'methodology', 'design', 'science', ',', 'B-DAD', 'used', 'map', 'big', 'data', 'tools', 'analytics', 'various', 'decision-making', 'phases', '.']

>> Bigrams are: 
 [('Using', 'methodology'), ('methodology', 'design'), ('design', 'science'), ('science', ','), (',', 'B-DAD'), ('B-DAD', 'used'), ('used', 'map'), ('map', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'analytics'), ('analytics', 'various'), ('various', 'decision-making'), ('decision-making', 'phases'), ('phases', '.')]

>> Trigrams are: 
 [('Using', 'methodology', 'design'), ('methodology', 'design', 'science'), ('design', 'science', ','), ('science', ',', 'B-DAD'), (',', 'B-DAD', 'used'), ('B-DAD', 'used', 'map'), ('used', 'map', 'big'), ('map', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'analytics'), ('tools', 'analytics', 'various'), ('analytics', 'various', 'decision-making'), ('various', 'decision-making', 'phases'), ('decision-making', 'phases', '.')]

>> POS Tags are: 
 [('Using', 'VBG'), ('methodology', 'NN'), ('design', 'NN'), ('science', 'NN'), (',', ','), ('B-DAD', 'NNP'), ('used', 'VBD'), ('map', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), ('analytics', 'NNS'), ('various', 'JJ'), ('decision-making', 'JJ'), ('phases', 'NNS'), ('.', '.')]

 (S
  Using/VBG
  (NP methodology/NN design/NN science/NN)
  ,/,
  (NP B-DAD/NNP)
  used/VBD
  (NP map/NN)
  (NP big/JJ data/NN tools/NNS analytics/NNS)
  (NP various/JJ decision-making/JJ phases/NNS)
  ./.) 


>> Noun Phrases are: 
 ['methodology design science', 'B-DAD', 'map', 'big data tools analytics', 'various decision-making phases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Using', 'use'), ('methodology', 'methodolog'), ('design', 'design'), ('science', 'scienc'), (',', ','), ('B-DAD', 'b-dad'), ('used', 'use'), ('map', 'map'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('analytics', 'analyt'), ('various', 'variou'), ('decision-making', 'decision-mak'), ('phases', 'phase'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Using', 'use'), ('methodology', 'methodolog'), ('design', 'design'), ('science', 'scienc'), (',', ','), ('B-DAD', 'b-dad'), ('used', 'use'), ('map', 'map'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('analytics', 'analyt'), ('various', 'various'), ('decision-making', 'decision-mak'), ('phases', 'phase'), ('.', '.')]

>> Lemmatization: 
 [('Using', 'Using'), ('methodology', 'methodology'), ('design', 'design'), ('science', 'science'), (',', ','), ('B-DAD', 'B-DAD'), ('used', 'used'), ('map', 'map'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('analytics', 'analytics'), ('various', 'various'), ('decision-making', 'decision-making'), ('phases', 'phase'), ('.', '.')]



============================ Sentence 427 =============================

As a result, the added value gained by   integrating big data analytics into the decision-making process can be identified (Elgendy and   Elragal, 2014; Elgendy and Elragal, 2016). 


>> Tokens are: 
 ['As', 'result', ',', 'added', 'value', 'gained', 'integrating', 'big', 'data', 'analytics', 'decision-making', 'process', 'identified', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Elgendy', 'Elragal', ',', '2016', ')', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'added'), ('added', 'value'), ('value', 'gained'), ('gained', 'integrating'), ('integrating', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'decision-making'), ('decision-making', 'process'), ('process', 'identified'), ('identified', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'added'), (',', 'added', 'value'), ('added', 'value', 'gained'), ('value', 'gained', 'integrating'), ('gained', 'integrating', 'big'), ('integrating', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'decision-making'), ('analytics', 'decision-making', 'process'), ('decision-making', 'process', 'identified'), ('process', 'identified', '('), ('identified', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('added', 'VBD'), ('value', 'NN'), ('gained', 'VBN'), ('integrating', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('decision-making', 'JJ'), ('process', 'NN'), ('identified', 'VBN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  As/IN
  (NP result/NN)
  ,/,
  added/VBD
  (NP value/NN)
  gained/VBN
  integrating/VBG
  (NP big/JJ data/NNS analytics/NNS)
  (NP decision-making/JJ process/NN)
  identified/VBN
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['result', 'value', 'big data analytics', 'decision-making process', 'Elgendy Elragal', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('added', 'ad'), ('value', 'valu'), ('gained', 'gain'), ('integrating', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('decision-making', 'decision-mak'), ('process', 'process'), ('identified', 'identifi'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('added', 'ad'), ('value', 'valu'), ('gained', 'gain'), ('integrating', 'integr'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('decision-making', 'decision-mak'), ('process', 'process'), ('identified', 'identifi'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('added', 'added'), ('value', 'value'), ('gained', 'gained'), ('integrating', 'integrating'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('decision-making', 'decision-making'), ('process', 'process'), ('identified', 'identified'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 428 =============================

Despite certain challenges, decision making is supported by advanced technologies and tools in   each phase of processing and applying big data, and the use of big data now plays an important   role in many decisions making and forecasting domains such as healthcare, retail, tourism,   marketing, the financial sector, and transportation (Elgendy and Elragal, 2014). 


>> Tokens are: 
 ['Despite', 'certain', 'challenges', ',', 'decision', 'making', 'supported', 'advanced', 'technologies', 'tools', 'phase', 'processing', 'applying', 'big', 'data', ',', 'use', 'big', 'data', 'plays', 'important', 'role', 'many', 'decisions', 'making', 'forecasting', 'domains', 'healthcare', ',', 'retail', ',', 'tourism', ',', 'marketing', ',', 'financial', 'sector', ',', 'transportation', '(', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Despite', 'certain'), ('certain', 'challenges'), ('challenges', ','), (',', 'decision'), ('decision', 'making'), ('making', 'supported'), ('supported', 'advanced'), ('advanced', 'technologies'), ('technologies', 'tools'), ('tools', 'phase'), ('phase', 'processing'), ('processing', 'applying'), ('applying', 'big'), ('big', 'data'), ('data', ','), (',', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'plays'), ('plays', 'important'), ('important', 'role'), ('role', 'many'), ('many', 'decisions'), ('decisions', 'making'), ('making', 'forecasting'), ('forecasting', 'domains'), ('domains', 'healthcare'), ('healthcare', ','), (',', 'retail'), ('retail', ','), (',', 'tourism'), ('tourism', ','), (',', 'marketing'), ('marketing', ','), (',', 'financial'), ('financial', 'sector'), ('sector', ','), (',', 'transportation'), ('transportation', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Despite', 'certain', 'challenges'), ('certain', 'challenges', ','), ('challenges', ',', 'decision'), (',', 'decision', 'making'), ('decision', 'making', 'supported'), ('making', 'supported', 'advanced'), ('supported', 'advanced', 'technologies'), ('advanced', 'technologies', 'tools'), ('technologies', 'tools', 'phase'), ('tools', 'phase', 'processing'), ('phase', 'processing', 'applying'), ('processing', 'applying', 'big'), ('applying', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'use'), (',', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'plays'), ('data', 'plays', 'important'), ('plays', 'important', 'role'), ('important', 'role', 'many'), ('role', 'many', 'decisions'), ('many', 'decisions', 'making'), ('decisions', 'making', 'forecasting'), ('making', 'forecasting', 'domains'), ('forecasting', 'domains', 'healthcare'), ('domains', 'healthcare', ','), ('healthcare', ',', 'retail'), (',', 'retail', ','), ('retail', ',', 'tourism'), (',', 'tourism', ','), ('tourism', ',', 'marketing'), (',', 'marketing', ','), ('marketing', ',', 'financial'), (',', 'financial', 'sector'), ('financial', 'sector', ','), ('sector', ',', 'transportation'), (',', 'transportation', '('), ('transportation', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Despite', 'IN'), ('certain', 'JJ'), ('challenges', 'NNS'), (',', ','), ('decision', 'NN'), ('making', 'NN'), ('supported', 'VBD'), ('advanced', 'JJ'), ('technologies', 'NNS'), ('tools', 'IN'), ('phase', 'NN'), ('processing', 'NN'), ('applying', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('plays', 'NNS'), ('important', 'JJ'), ('role', 'NN'), ('many', 'JJ'), ('decisions', 'NNS'), ('making', 'VBG'), ('forecasting', 'NN'), ('domains', 'NNS'), ('healthcare', 'NN'), (',', ','), ('retail', 'JJ'), (',', ','), ('tourism', 'NN'), (',', ','), ('marketing', 'NN'), (',', ','), ('financial', 'JJ'), ('sector', 'NN'), (',', ','), ('transportation', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  Despite/IN
  (NP certain/JJ challenges/NNS)
  ,/,
  (NP decision/NN making/NN)
  supported/VBD
  (NP advanced/JJ technologies/NNS)
  tools/IN
  (NP phase/NN processing/NN)
  applying/VBG
  (NP big/JJ data/NNS)
  ,/,
  (NP use/NN)
  (NP big/JJ data/NNS plays/NNS)
  (NP important/JJ role/NN)
  (NP many/JJ decisions/NNS)
  making/VBG
  (NP forecasting/NN domains/NNS healthcare/NN)
  ,/,
  retail/JJ
  ,/,
  (NP tourism/NN)
  ,/,
  (NP marketing/NN)
  ,/,
  (NP financial/JJ sector/NN)
  ,/,
  (NP transportation/NN)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['certain challenges', 'decision making', 'advanced technologies', 'phase processing', 'big data', 'use', 'big data plays', 'important role', 'many decisions', 'forecasting domains healthcare', 'tourism', 'marketing', 'financial sector', 'transportation', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Despite', 'despit'), ('certain', 'certain'), ('challenges', 'challeng'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('supported', 'support'), ('advanced', 'advanc'), ('technologies', 'technolog'), ('tools', 'tool'), ('phase', 'phase'), ('processing', 'process'), ('applying', 'appli'), ('big', 'big'), ('data', 'data'), (',', ','), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('plays', 'play'), ('important', 'import'), ('role', 'role'), ('many', 'mani'), ('decisions', 'decis'), ('making', 'make'), ('forecasting', 'forecast'), ('domains', 'domain'), ('healthcare', 'healthcar'), (',', ','), ('retail', 'retail'), (',', ','), ('tourism', 'tourism'), (',', ','), ('marketing', 'market'), (',', ','), ('financial', 'financi'), ('sector', 'sector'), (',', ','), ('transportation', 'transport'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Despite', 'despit'), ('certain', 'certain'), ('challenges', 'challeng'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('supported', 'support'), ('advanced', 'advanc'), ('technologies', 'technolog'), ('tools', 'tool'), ('phase', 'phase'), ('processing', 'process'), ('applying', 'appli'), ('big', 'big'), ('data', 'data'), (',', ','), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('plays', 'play'), ('important', 'import'), ('role', 'role'), ('many', 'mani'), ('decisions', 'decis'), ('making', 'make'), ('forecasting', 'forecast'), ('domains', 'domain'), ('healthcare', 'healthcar'), (',', ','), ('retail', 'retail'), (',', ','), ('tourism', 'tourism'), (',', ','), ('marketing', 'market'), (',', ','), ('financial', 'financi'), ('sector', 'sector'), (',', ','), ('transportation', 'transport'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Despite', 'Despite'), ('certain', 'certain'), ('challenges', 'challenge'), (',', ','), ('decision', 'decision'), ('making', 'making'), ('supported', 'supported'), ('advanced', 'advanced'), ('technologies', 'technology'), ('tools', 'tool'), ('phase', 'phase'), ('processing', 'processing'), ('applying', 'applying'), ('big', 'big'), ('data', 'data'), (',', ','), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('plays', 'play'), ('important', 'important'), ('role', 'role'), ('many', 'many'), ('decisions', 'decision'), ('making', 'making'), ('forecasting', 'forecasting'), ('domains', 'domain'), ('healthcare', 'healthcare'), (',', ','), ('retail', 'retail'), (',', ','), ('tourism', 'tourism'), (',', ','), ('marketing', 'marketing'), (',', ','), ('financial', 'financial'), ('sector', 'sector'), (',', ','), ('transportation', 'transportation'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 429 =============================

Big data use requires decision support, however. 


>> Tokens are: 
 ['Big', 'data', 'use', 'requires', 'decision', 'support', ',', 'however', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'use'), ('use', 'requires'), ('requires', 'decision'), ('decision', 'support'), ('support', ','), (',', 'however'), ('however', '.')]

>> Trigrams are: 
 [('Big', 'data', 'use'), ('data', 'use', 'requires'), ('use', 'requires', 'decision'), ('requires', 'decision', 'support'), ('decision', 'support', ','), ('support', ',', 'however'), (',', 'however', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('use', 'NN'), ('requires', 'VBZ'), ('decision', 'NN'), ('support', 'NN'), (',', ','), ('however', 'RB'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS use/NN)
  requires/VBZ
  (NP decision/NN support/NN)
  ,/,
  however/RB
  ./.) 


>> Noun Phrases are: 
 ['Big data use', 'decision support']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('use', 'use'), ('requires', 'requir'), ('decision', 'decis'), ('support', 'support'), (',', ','), ('however', 'howev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('use', 'use'), ('requires', 'requir'), ('decision', 'decis'), ('support', 'support'), (',', ','), ('however', 'howev'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('use', 'use'), ('requires', 'requires'), ('decision', 'decision'), ('support', 'support'), (',', ','), ('however', 'however'), ('.', '.')]



============================ Sentence 430 =============================

The decision maker must identify the values   required and focus on finding methodologies, technologies, and tools that allow them to select the   best decision; this process thus relies on the assumption that the decision maker is sensible and   reasonable (Wang et al., 2016). 


>> Tokens are: 
 ['The', 'decision', 'maker', 'must', 'identify', 'values', 'required', 'focus', 'finding', 'methodologies', ',', 'technologies', ',', 'tools', 'allow', 'select', 'best', 'decision', ';', 'process', 'thus', 'relies', 'assumption', 'decision', 'maker', 'sensible', 'reasonable', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('The', 'decision'), ('decision', 'maker'), ('maker', 'must'), ('must', 'identify'), ('identify', 'values'), ('values', 'required'), ('required', 'focus'), ('focus', 'finding'), ('finding', 'methodologies'), ('methodologies', ','), (',', 'technologies'), ('technologies', ','), (',', 'tools'), ('tools', 'allow'), ('allow', 'select'), ('select', 'best'), ('best', 'decision'), ('decision', ';'), (';', 'process'), ('process', 'thus'), ('thus', 'relies'), ('relies', 'assumption'), ('assumption', 'decision'), ('decision', 'maker'), ('maker', 'sensible'), ('sensible', 'reasonable'), ('reasonable', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'decision', 'maker'), ('decision', 'maker', 'must'), ('maker', 'must', 'identify'), ('must', 'identify', 'values'), ('identify', 'values', 'required'), ('values', 'required', 'focus'), ('required', 'focus', 'finding'), ('focus', 'finding', 'methodologies'), ('finding', 'methodologies', ','), ('methodologies', ',', 'technologies'), (',', 'technologies', ','), ('technologies', ',', 'tools'), (',', 'tools', 'allow'), ('tools', 'allow', 'select'), ('allow', 'select', 'best'), ('select', 'best', 'decision'), ('best', 'decision', ';'), ('decision', ';', 'process'), (';', 'process', 'thus'), ('process', 'thus', 'relies'), ('thus', 'relies', 'assumption'), ('relies', 'assumption', 'decision'), ('assumption', 'decision', 'maker'), ('decision', 'maker', 'sensible'), ('maker', 'sensible', 'reasonable'), ('sensible', 'reasonable', '('), ('reasonable', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('decision', 'NN'), ('maker', 'NN'), ('must', 'MD'), ('identify', 'VB'), ('values', 'NNS'), ('required', 'VBN'), ('focus', 'RB'), ('finding', 'VBG'), ('methodologies', 'NNS'), (',', ','), ('technologies', 'NNS'), (',', ','), ('tools', 'NNS'), ('allow', 'VBP'), ('select', 'JJ'), ('best', 'JJS'), ('decision', 'NN'), (';', ':'), ('process', 'NN'), ('thus', 'RB'), ('relies', 'VBZ'), ('assumption', 'NN'), ('decision', 'NN'), ('maker', 'NN'), ('sensible', 'JJ'), ('reasonable', 'JJ'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT decision/NN maker/NN)
  must/MD
  identify/VB
  (NP values/NNS)
  required/VBN
  focus/RB
  finding/VBG
  (NP methodologies/NNS)
  ,/,
  (NP technologies/NNS)
  ,/,
  (NP tools/NNS)
  allow/VBP
  select/JJ
  best/JJS
  (NP decision/NN)
  ;/:
  (NP process/NN)
  thus/RB
  relies/VBZ
  (NP assumption/NN decision/NN maker/NN)
  sensible/JJ
  reasonable/JJ
  (/(
  (NP Wang/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The decision maker', 'values', 'methodologies', 'technologies', 'tools', 'decision', 'process', 'assumption decision maker', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('decision', 'decis'), ('maker', 'maker'), ('must', 'must'), ('identify', 'identifi'), ('values', 'valu'), ('required', 'requir'), ('focus', 'focu'), ('finding', 'find'), ('methodologies', 'methodolog'), (',', ','), ('technologies', 'technolog'), (',', ','), ('tools', 'tool'), ('allow', 'allow'), ('select', 'select'), ('best', 'best'), ('decision', 'decis'), (';', ';'), ('process', 'process'), ('thus', 'thu'), ('relies', 'reli'), ('assumption', 'assumpt'), ('decision', 'decis'), ('maker', 'maker'), ('sensible', 'sensibl'), ('reasonable', 'reason'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('decision', 'decis'), ('maker', 'maker'), ('must', 'must'), ('identify', 'identifi'), ('values', 'valu'), ('required', 'requir'), ('focus', 'focus'), ('finding', 'find'), ('methodologies', 'methodolog'), (',', ','), ('technologies', 'technolog'), (',', ','), ('tools', 'tool'), ('allow', 'allow'), ('select', 'select'), ('best', 'best'), ('decision', 'decis'), (';', ';'), ('process', 'process'), ('thus', 'thus'), ('relies', 'reli'), ('assumption', 'assumpt'), ('decision', 'decis'), ('maker', 'maker'), ('sensible', 'sensibl'), ('reasonable', 'reason'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('decision', 'decision'), ('maker', 'maker'), ('must', 'must'), ('identify', 'identify'), ('values', 'value'), ('required', 'required'), ('focus', 'focus'), ('finding', 'finding'), ('methodologies', 'methodology'), (',', ','), ('technologies', 'technology'), (',', ','), ('tools', 'tool'), ('allow', 'allow'), ('select', 'select'), ('best', 'best'), ('decision', 'decision'), (';', ';'), ('process', 'process'), ('thus', 'thus'), ('relies', 'relies'), ('assumption', 'assumption'), ('decision', 'decision'), ('maker', 'maker'), ('sensible', 'sensible'), ('reasonable', 'reasonable'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 431 =============================

Generally, decision making occurs at the stage of each big data procedure, including data storage,   data cleaning, data analysis, data visualisation, and prediction. 


>> Tokens are: 
 ['Generally', ',', 'decision', 'making', 'occurs', 'stage', 'big', 'data', 'procedure', ',', 'including', 'data', 'storage', ',', 'data', 'cleaning', ',', 'data', 'analysis', ',', 'data', 'visualisation', ',', 'prediction', '.']

>> Bigrams are: 
 [('Generally', ','), (',', 'decision'), ('decision', 'making'), ('making', 'occurs'), ('occurs', 'stage'), ('stage', 'big'), ('big', 'data'), ('data', 'procedure'), ('procedure', ','), (',', 'including'), ('including', 'data'), ('data', 'storage'), ('storage', ','), (',', 'data'), ('data', 'cleaning'), ('cleaning', ','), (',', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'data'), ('data', 'visualisation'), ('visualisation', ','), (',', 'prediction'), ('prediction', '.')]

>> Trigrams are: 
 [('Generally', ',', 'decision'), (',', 'decision', 'making'), ('decision', 'making', 'occurs'), ('making', 'occurs', 'stage'), ('occurs', 'stage', 'big'), ('stage', 'big', 'data'), ('big', 'data', 'procedure'), ('data', 'procedure', ','), ('procedure', ',', 'including'), (',', 'including', 'data'), ('including', 'data', 'storage'), ('data', 'storage', ','), ('storage', ',', 'data'), (',', 'data', 'cleaning'), ('data', 'cleaning', ','), ('cleaning', ',', 'data'), (',', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'data'), (',', 'data', 'visualisation'), ('data', 'visualisation', ','), ('visualisation', ',', 'prediction'), (',', 'prediction', '.')]

>> POS Tags are: 
 [('Generally', 'RB'), (',', ','), ('decision', 'NN'), ('making', 'NN'), ('occurs', 'VBZ'), ('stage', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('procedure', 'NN'), (',', ','), ('including', 'VBG'), ('data', 'NNS'), ('storage', 'NN'), (',', ','), ('data', 'NNS'), ('cleaning', 'NN'), (',', ','), ('data', 'NN'), ('analysis', 'NN'), (',', ','), ('data', 'NNS'), ('visualisation', 'NN'), (',', ','), ('prediction', 'NN'), ('.', '.')]

 (S
  Generally/RB
  ,/,
  (NP decision/NN making/NN)
  occurs/VBZ
  (NP stage/NN)
  (NP big/JJ data/NNS procedure/NN)
  ,/,
  including/VBG
  (NP data/NNS storage/NN)
  ,/,
  (NP data/NNS cleaning/NN)
  ,/,
  (NP data/NN analysis/NN)
  ,/,
  (NP data/NNS visualisation/NN)
  ,/,
  (NP prediction/NN)
  ./.) 


>> Noun Phrases are: 
 ['decision making', 'stage', 'big data procedure', 'data storage', 'data cleaning', 'data analysis', 'data visualisation', 'prediction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Generally', 'gener'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('occurs', 'occur'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('procedure', 'procedur'), (',', ','), ('including', 'includ'), ('data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('cleaning', 'clean'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('visualisation', 'visualis'), (',', ','), ('prediction', 'predict'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Generally', 'general'), (',', ','), ('decision', 'decis'), ('making', 'make'), ('occurs', 'occur'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('procedure', 'procedur'), (',', ','), ('including', 'includ'), ('data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('cleaning', 'clean'), (',', ','), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('data', 'data'), ('visualisation', 'visualis'), (',', ','), ('prediction', 'predict'), ('.', '.')]

>> Lemmatization: 
 [('Generally', 'Generally'), (',', ','), ('decision', 'decision'), ('making', 'making'), ('occurs', 'occurs'), ('stage', 'stage'), ('big', 'big'), ('data', 'data'), ('procedure', 'procedure'), (',', ','), ('including', 'including'), ('data', 'data'), ('storage', 'storage'), (',', ','), ('data', 'data'), ('cleaning', 'cleaning'), (',', ','), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('data', 'data'), ('visualisation', 'visualisation'), (',', ','), ('prediction', 'prediction'), ('.', '.')]



============================ Sentence 432 =============================

However, it is sometimes difficult   to achieve a suitable solution for each procedure, and many technologies and techniques can be   used for decision making in big data work. 


>> Tokens are: 
 ['However', ',', 'sometimes', 'difficult', 'achieve', 'suitable', 'solution', 'procedure', ',', 'many', 'technologies', 'techniques', 'used', 'decision', 'making', 'big', 'data', 'work', '.']

>> Bigrams are: 
 [('However', ','), (',', 'sometimes'), ('sometimes', 'difficult'), ('difficult', 'achieve'), ('achieve', 'suitable'), ('suitable', 'solution'), ('solution', 'procedure'), ('procedure', ','), (',', 'many'), ('many', 'technologies'), ('technologies', 'techniques'), ('techniques', 'used'), ('used', 'decision'), ('decision', 'making'), ('making', 'big'), ('big', 'data'), ('data', 'work'), ('work', '.')]

>> Trigrams are: 
 [('However', ',', 'sometimes'), (',', 'sometimes', 'difficult'), ('sometimes', 'difficult', 'achieve'), ('difficult', 'achieve', 'suitable'), ('achieve', 'suitable', 'solution'), ('suitable', 'solution', 'procedure'), ('solution', 'procedure', ','), ('procedure', ',', 'many'), (',', 'many', 'technologies'), ('many', 'technologies', 'techniques'), ('technologies', 'techniques', 'used'), ('techniques', 'used', 'decision'), ('used', 'decision', 'making'), ('decision', 'making', 'big'), ('making', 'big', 'data'), ('big', 'data', 'work'), ('data', 'work', '.')]

>> POS Tags are: 
 [('However', 'RB'), (',', ','), ('sometimes', 'RB'), ('difficult', 'JJ'), ('achieve', 'VBP'), ('suitable', 'JJ'), ('solution', 'NN'), ('procedure', 'NN'), (',', ','), ('many', 'JJ'), ('technologies', 'NNS'), ('techniques', 'NNS'), ('used', 'VBN'), ('decision', 'NN'), ('making', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('work', 'NN'), ('.', '.')]

 (S
  However/RB
  ,/,
  sometimes/RB
  difficult/JJ
  achieve/VBP
  (NP suitable/JJ solution/NN procedure/NN)
  ,/,
  (NP many/JJ technologies/NNS techniques/NNS)
  used/VBN
  (NP decision/NN)
  making/VBG
  (NP big/JJ data/NNS work/NN)
  ./.) 


>> Noun Phrases are: 
 ['suitable solution procedure', 'many technologies techniques', 'decision', 'big data work']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('However', 'howev'), (',', ','), ('sometimes', 'sometim'), ('difficult', 'difficult'), ('achieve', 'achiev'), ('suitable', 'suitabl'), ('solution', 'solut'), ('procedure', 'procedur'), (',', ','), ('many', 'mani'), ('technologies', 'technolog'), ('techniques', 'techniqu'), ('used', 'use'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), ('work', 'work'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('However', 'howev'), (',', ','), ('sometimes', 'sometim'), ('difficult', 'difficult'), ('achieve', 'achiev'), ('suitable', 'suitabl'), ('solution', 'solut'), ('procedure', 'procedur'), (',', ','), ('many', 'mani'), ('technologies', 'technolog'), ('techniques', 'techniqu'), ('used', 'use'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), ('work', 'work'), ('.', '.')]

>> Lemmatization: 
 [('However', 'However'), (',', ','), ('sometimes', 'sometimes'), ('difficult', 'difficult'), ('achieve', 'achieve'), ('suitable', 'suitable'), ('solution', 'solution'), ('procedure', 'procedure'), (',', ','), ('many', 'many'), ('technologies', 'technology'), ('techniques', 'technique'), ('used', 'used'), ('decision', 'decision'), ('making', 'making'), ('big', 'big'), ('data', 'data'), ('work', 'work'), ('.', '.')]



============================ Sentence 433 =============================

Some decision making requires input from many   disciplines, including data mining, statistics, machine learning, visualisation, and social network   analysis. 


>> Tokens are: 
 ['Some', 'decision', 'making', 'requires', 'input', 'many', 'disciplines', ',', 'including', 'data', 'mining', ',', 'statistics', ',', 'machine', 'learning', ',', 'visualisation', ',', 'social', 'network', 'analysis', '.']

>> Bigrams are: 
 [('Some', 'decision'), ('decision', 'making'), ('making', 'requires'), ('requires', 'input'), ('input', 'many'), ('many', 'disciplines'), ('disciplines', ','), (',', 'including'), ('including', 'data'), ('data', 'mining'), ('mining', ','), (',', 'statistics'), ('statistics', ','), (',', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'visualisation'), ('visualisation', ','), (',', 'social'), ('social', 'network'), ('network', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Some', 'decision', 'making'), ('decision', 'making', 'requires'), ('making', 'requires', 'input'), ('requires', 'input', 'many'), ('input', 'many', 'disciplines'), ('many', 'disciplines', ','), ('disciplines', ',', 'including'), (',', 'including', 'data'), ('including', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'statistics'), (',', 'statistics', ','), ('statistics', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'visualisation'), (',', 'visualisation', ','), ('visualisation', ',', 'social'), (',', 'social', 'network'), ('social', 'network', 'analysis'), ('network', 'analysis', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('decision', 'NN'), ('making', 'NN'), ('requires', 'VBZ'), ('input', 'VB'), ('many', 'JJ'), ('disciplines', 'NNS'), (',', ','), ('including', 'VBG'), ('data', 'NNS'), ('mining', 'NN'), (',', ','), ('statistics', 'NNS'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('visualisation', 'NN'), (',', ','), ('social', 'JJ'), ('network', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP Some/DT decision/NN making/NN)
  requires/VBZ
  input/VB
  (NP many/JJ disciplines/NNS)
  ,/,
  including/VBG
  (NP data/NNS mining/NN)
  ,/,
  (NP statistics/NNS)
  ,/,
  (NP machine/NN learning/NN)
  ,/,
  (NP visualisation/NN)
  ,/,
  (NP social/JJ network/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some decision making', 'many disciplines', 'data mining', 'statistics', 'machine learning', 'visualisation', 'social network analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('decision', 'decis'), ('making', 'make'), ('requires', 'requir'), ('input', 'input'), ('many', 'mani'), ('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('statistics', 'statist'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('visualisation', 'visualis'), (',', ','), ('social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('decision', 'decis'), ('making', 'make'), ('requires', 'requir'), ('input', 'input'), ('many', 'mani'), ('disciplines', 'disciplin'), (',', ','), ('including', 'includ'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('statistics', 'statist'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('visualisation', 'visualis'), (',', ','), ('social', 'social'), ('network', 'network'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('decision', 'decision'), ('making', 'making'), ('requires', 'requires'), ('input', 'input'), ('many', 'many'), ('disciplines', 'discipline'), (',', ','), ('including', 'including'), ('data', 'data'), ('mining', 'mining'), (',', ','), ('statistics', 'statistic'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('visualisation', 'visualisation'), (',', ','), ('social', 'social'), ('network', 'network'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 434 =============================

Specific big data tools come in three classifications types: batch processing, stream   processing, and hybrid processing tools (Wang, et al., 2016). 


>> Tokens are: 
 ['Specific', 'big', 'data', 'tools', 'come', 'three', 'classifications', 'types', ':', 'batch', 'processing', ',', 'stream', 'processing', ',', 'hybrid', 'processing', 'tools', '(', 'Wang', ',', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Specific', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'come'), ('come', 'three'), ('three', 'classifications'), ('classifications', 'types'), ('types', ':'), (':', 'batch'), ('batch', 'processing'), ('processing', ','), (',', 'stream'), ('stream', 'processing'), ('processing', ','), (',', 'hybrid'), ('hybrid', 'processing'), ('processing', 'tools'), ('tools', '('), ('(', 'Wang'), ('Wang', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Specific', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'come'), ('tools', 'come', 'three'), ('come', 'three', 'classifications'), ('three', 'classifications', 'types'), ('classifications', 'types', ':'), ('types', ':', 'batch'), (':', 'batch', 'processing'), ('batch', 'processing', ','), ('processing', ',', 'stream'), (',', 'stream', 'processing'), ('stream', 'processing', ','), ('processing', ',', 'hybrid'), (',', 'hybrid', 'processing'), ('hybrid', 'processing', 'tools'), ('processing', 'tools', '('), ('tools', '(', 'Wang'), ('(', 'Wang', ','), ('Wang', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Specific', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), ('come', 'VBP'), ('three', 'CD'), ('classifications', 'NNS'), ('types', 'NNS'), (':', ':'), ('batch', 'NN'), ('processing', 'NN'), (',', ','), ('stream', 'NN'), ('processing', 'NN'), (',', ','), ('hybrid', 'JJ'), ('processing', 'NN'), ('tools', 'NNS'), ('(', '('), ('Wang', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Specific/JJ big/JJ data/NN tools/NNS)
  come/VBP
  three/CD
  (NP classifications/NNS types/NNS)
  :/:
  (NP batch/NN processing/NN)
  ,/,
  (NP stream/NN processing/NN)
  ,/,
  (NP hybrid/JJ processing/NN tools/NNS)
  (/(
  (NP Wang/NNP)
  ,/,
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Specific big data tools', 'classifications types', 'batch processing', 'stream processing', 'hybrid processing tools', 'Wang', 'al.']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Specific', 'specif'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('come', 'come'), ('three', 'three'), ('classifications', 'classif'), ('types', 'type'), (':', ':'), ('batch', 'batch'), ('processing', 'process'), (',', ','), ('stream', 'stream'), ('processing', 'process'), (',', ','), ('hybrid', 'hybrid'), ('processing', 'process'), ('tools', 'tool'), ('(', '('), ('Wang', 'wang'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Specific', 'specif'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('come', 'come'), ('three', 'three'), ('classifications', 'classif'), ('types', 'type'), (':', ':'), ('batch', 'batch'), ('processing', 'process'), (',', ','), ('stream', 'stream'), ('processing', 'process'), (',', ','), ('hybrid', 'hybrid'), ('processing', 'process'), ('tools', 'tool'), ('(', '('), ('Wang', 'wang'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Specific', 'Specific'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('come', 'come'), ('three', 'three'), ('classifications', 'classification'), ('types', 'type'), (':', ':'), ('batch', 'batch'), ('processing', 'processing'), (',', ','), ('stream', 'stream'), ('processing', 'processing'), (',', ','), ('hybrid', 'hybrid'), ('processing', 'processing'), ('tools', 'tool'), ('(', '('), ('Wang', 'Wang'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 435 =============================

The relationship between decision   science and big data is clarified in Figure 22. 


>> Tokens are: 
 ['The', 'relationship', 'decision', 'science', 'big', 'data', 'clarified', 'Figure', '22', '.']

>> Bigrams are: 
 [('The', 'relationship'), ('relationship', 'decision'), ('decision', 'science'), ('science', 'big'), ('big', 'data'), ('data', 'clarified'), ('clarified', 'Figure'), ('Figure', '22'), ('22', '.')]

>> Trigrams are: 
 [('The', 'relationship', 'decision'), ('relationship', 'decision', 'science'), ('decision', 'science', 'big'), ('science', 'big', 'data'), ('big', 'data', 'clarified'), ('data', 'clarified', 'Figure'), ('clarified', 'Figure', '22'), ('Figure', '22', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('relationship', 'NN'), ('decision', 'NN'), ('science', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('clarified', 'VBD'), ('Figure', 'NNP'), ('22', 'CD'), ('.', '.')]

 (S
  (NP The/DT relationship/NN decision/NN science/NN)
  (NP big/JJ data/NNS)
  clarified/VBD
  (NP Figure/NNP)
  22/CD
  ./.) 


>> Noun Phrases are: 
 ['The relationship decision science', 'big data', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('relationship', 'relationship'), ('decision', 'decis'), ('science', 'scienc'), ('big', 'big'), ('data', 'data'), ('clarified', 'clarifi'), ('Figure', 'figur'), ('22', '22'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('relationship', 'relationship'), ('decision', 'decis'), ('science', 'scienc'), ('big', 'big'), ('data', 'data'), ('clarified', 'clarifi'), ('Figure', 'figur'), ('22', '22'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('relationship', 'relationship'), ('decision', 'decision'), ('science', 'science'), ('big', 'big'), ('data', 'data'), ('clarified', 'clarified'), ('Figure', 'Figure'), ('22', '22'), ('.', '.')]



============================ Sentence 436 =============================

Figure 22: The relation between big data and decision sciences, adopted from (Wang et al., 2016)         Sarah Al-Shiakhli   37      9. 


>> Tokens are: 
 ['Figure', '22', ':', 'The', 'relation', 'big', 'data', 'decision', 'sciences', ',', 'adopted', '(', 'Wang', 'et', 'al.', ',', '2016', ')', 'Sarah', 'Al-Shiakhli', '37', '9', '.']

>> Bigrams are: 
 [('Figure', '22'), ('22', ':'), (':', 'The'), ('The', 'relation'), ('relation', 'big'), ('big', 'data'), ('data', 'decision'), ('decision', 'sciences'), ('sciences', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '37'), ('37', '9'), ('9', '.')]

>> Trigrams are: 
 [('Figure', '22', ':'), ('22', ':', 'The'), (':', 'The', 'relation'), ('The', 'relation', 'big'), ('relation', 'big', 'data'), ('big', 'data', 'decision'), ('data', 'decision', 'sciences'), ('decision', 'sciences', ','), ('sciences', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', 'Sarah'), (')', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '37'), ('Al-Shiakhli', '37', '9'), ('37', '9', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('22', 'CD'), (':', ':'), ('The', 'DT'), ('relation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('decision', 'NN'), ('sciences', 'NNS'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('37', 'CD'), ('9', 'CD'), ('.', '.')]

 (S
  (NP Figure/NN)
  22/CD
  :/:
  (NP The/DT relation/NN)
  (NP big/JJ data/NNS decision/NN sciences/NNS)
  ,/,
  adopted/VBN
  (/(
  (NP Wang/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  (NP Sarah/NNP Al-Shiakhli/NNP)
  37/CD
  9/CD
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'The relation', 'big data decision sciences', 'Wang', 'Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Wang'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('22', '22'), (':', ':'), ('The', 'the'), ('relation', 'relat'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('sciences', 'scienc'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('37', '37'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('22', '22'), (':', ':'), ('The', 'the'), ('relation', 'relat'), ('big', 'big'), ('data', 'data'), ('decision', 'decis'), ('sciences', 'scienc'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('37', '37'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('22', '22'), (':', ':'), ('The', 'The'), ('relation', 'relation'), ('big', 'big'), ('data', 'data'), ('decision', 'decision'), ('sciences', 'science'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('37', '37'), ('9', '9'), ('.', '.')]



============================ Sentence 437 =============================

Big data analytics challenges   Many studies have focused on the use of analytics techniques such as data mining, visualisation,   statistical analysis, and machine learning; however, there is a need to develop new analytic   approaches in order to handle big data challenges such as the time required for processing when   the volume of the data is very large (Oussous et al., 2018). 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'challenges', 'Many', 'studies', 'focused', 'use', 'analytics', 'techniques', 'data', 'mining', ',', 'visualisation', ',', 'statistical', 'analysis', ',', 'machine', 'learning', ';', 'however', ',', 'need', 'develop', 'new', 'analytic', 'approaches', 'order', 'handle', 'big', 'data', 'challenges', 'time', 'required', 'processing', 'volume', 'data', 'large', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'Many'), ('Many', 'studies'), ('studies', 'focused'), ('focused', 'use'), ('use', 'analytics'), ('analytics', 'techniques'), ('techniques', 'data'), ('data', 'mining'), ('mining', ','), (',', 'visualisation'), ('visualisation', ','), (',', 'statistical'), ('statistical', 'analysis'), ('analysis', ','), (',', 'machine'), ('machine', 'learning'), ('learning', ';'), (';', 'however'), ('however', ','), (',', 'need'), ('need', 'develop'), ('develop', 'new'), ('new', 'analytic'), ('analytic', 'approaches'), ('approaches', 'order'), ('order', 'handle'), ('handle', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'time'), ('time', 'required'), ('required', 'processing'), ('processing', 'volume'), ('volume', 'data'), ('data', 'large'), ('large', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'Many'), ('challenges', 'Many', 'studies'), ('Many', 'studies', 'focused'), ('studies', 'focused', 'use'), ('focused', 'use', 'analytics'), ('use', 'analytics', 'techniques'), ('analytics', 'techniques', 'data'), ('techniques', 'data', 'mining'), ('data', 'mining', ','), ('mining', ',', 'visualisation'), (',', 'visualisation', ','), ('visualisation', ',', 'statistical'), (',', 'statistical', 'analysis'), ('statistical', 'analysis', ','), ('analysis', ',', 'machine'), (',', 'machine', 'learning'), ('machine', 'learning', ';'), ('learning', ';', 'however'), (';', 'however', ','), ('however', ',', 'need'), (',', 'need', 'develop'), ('need', 'develop', 'new'), ('develop', 'new', 'analytic'), ('new', 'analytic', 'approaches'), ('analytic', 'approaches', 'order'), ('approaches', 'order', 'handle'), ('order', 'handle', 'big'), ('handle', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'time'), ('challenges', 'time', 'required'), ('time', 'required', 'processing'), ('required', 'processing', 'volume'), ('processing', 'volume', 'data'), ('volume', 'data', 'large'), ('data', 'large', '('), ('large', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('Many', 'JJ'), ('studies', 'NNS'), ('focused', 'VBD'), ('use', 'NN'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('data', 'NNS'), ('mining', 'NN'), (',', ','), ('visualisation', 'NN'), (',', ','), ('statistical', 'JJ'), ('analysis', 'NN'), (',', ','), ('machine', 'NN'), ('learning', 'NN'), (';', ':'), ('however', 'RB'), (',', ','), ('need', 'VBP'), ('develop', 'VB'), ('new', 'JJ'), ('analytic', 'JJ'), ('approaches', 'NNS'), ('order', 'NN'), ('handle', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('time', 'NN'), ('required', 'VBN'), ('processing', 'NN'), ('volume', 'NN'), ('data', 'NNS'), ('large', 'JJ'), ('(', '('), ('Oussous', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS challenges/NNS)
  (NP Many/JJ studies/NNS)
  focused/VBD
  (NP use/NN analytics/NNS techniques/NNS data/NNS mining/NN)
  ,/,
  (NP visualisation/NN)
  ,/,
  (NP statistical/JJ analysis/NN)
  ,/,
  (NP machine/NN learning/NN)
  ;/:
  however/RB
  ,/,
  need/VBP
  develop/VB
  (NP new/JJ analytic/JJ approaches/NNS order/NN)
  handle/VBP
  (NP big/JJ data/NNS challenges/NNS time/NN)
  required/VBN
  (NP processing/NN volume/NN data/NNS)
  large/JJ
  (/(
  (NP Oussous/JJ et/NN al./NN)
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics challenges', 'Many studies', 'use analytics techniques data mining', 'visualisation', 'statistical analysis', 'machine learning', 'new analytic approaches order', 'big data challenges time', 'processing volume data', 'Oussous et al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('Many', 'mani'), ('studies', 'studi'), ('focused', 'focus'), ('use', 'use'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('visualisation', 'visualis'), (',', ','), ('statistical', 'statist'), ('analysis', 'analysi'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (';', ';'), ('however', 'howev'), (',', ','), ('need', 'need'), ('develop', 'develop'), ('new', 'new'), ('analytic', 'analyt'), ('approaches', 'approach'), ('order', 'order'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('time', 'time'), ('required', 'requir'), ('processing', 'process'), ('volume', 'volum'), ('data', 'data'), ('large', 'larg'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('Many', 'mani'), ('studies', 'studi'), ('focused', 'focus'), ('use', 'use'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('data', 'data'), ('mining', 'mine'), (',', ','), ('visualisation', 'visualis'), (',', ','), ('statistical', 'statist'), ('analysis', 'analysi'), (',', ','), ('machine', 'machin'), ('learning', 'learn'), (';', ';'), ('however', 'howev'), (',', ','), ('need', 'need'), ('develop', 'develop'), ('new', 'new'), ('analytic', 'analyt'), ('approaches', 'approach'), ('order', 'order'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('time', 'time'), ('required', 'requir'), ('processing', 'process'), ('volume', 'volum'), ('data', 'data'), ('large', 'larg'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('Many', 'Many'), ('studies', 'study'), ('focused', 'focused'), ('use', 'use'), ('analytics', 'analytics'), ('techniques', 'technique'), ('data', 'data'), ('mining', 'mining'), (',', ','), ('visualisation', 'visualisation'), (',', ','), ('statistical', 'statistical'), ('analysis', 'analysis'), (',', ','), ('machine', 'machine'), ('learning', 'learning'), (';', ';'), ('however', 'however'), (',', ','), ('need', 'need'), ('develop', 'develop'), ('new', 'new'), ('analytic', 'analytic'), ('approaches', 'approach'), ('order', 'order'), ('handle', 'handle'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('time', 'time'), ('required', 'required'), ('processing', 'processing'), ('volume', 'volume'), ('data', 'data'), ('large', 'large'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 438 =============================

Oussous et al. 


>> Tokens are: 
 ['Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Oussous', 'JJ'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

 (S (NP Oussous/JJ et/NN al/NN) ./.) 


>> Noun Phrases are: 
 ['Oussous et al']

>> Named Entities are: 
 [('GPE', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 439 =============================

thus presented the   difficulties in applying current analytical solutions, including machine learning, deep learning,   incremental approaches, and granular computing. 


>> Tokens are: 
 ['thus', 'presented', 'difficulties', 'applying', 'current', 'analytical', 'solutions', ',', 'including', 'machine', 'learning', ',', 'deep', 'learning', ',', 'incremental', 'approaches', ',', 'granular', 'computing', '.']

>> Bigrams are: 
 [('thus', 'presented'), ('presented', 'difficulties'), ('difficulties', 'applying'), ('applying', 'current'), ('current', 'analytical'), ('analytical', 'solutions'), ('solutions', ','), (',', 'including'), ('including', 'machine'), ('machine', 'learning'), ('learning', ','), (',', 'deep'), ('deep', 'learning'), ('learning', ','), (',', 'incremental'), ('incremental', 'approaches'), ('approaches', ','), (',', 'granular'), ('granular', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('thus', 'presented', 'difficulties'), ('presented', 'difficulties', 'applying'), ('difficulties', 'applying', 'current'), ('applying', 'current', 'analytical'), ('current', 'analytical', 'solutions'), ('analytical', 'solutions', ','), ('solutions', ',', 'including'), (',', 'including', 'machine'), ('including', 'machine', 'learning'), ('machine', 'learning', ','), ('learning', ',', 'deep'), (',', 'deep', 'learning'), ('deep', 'learning', ','), ('learning', ',', 'incremental'), (',', 'incremental', 'approaches'), ('incremental', 'approaches', ','), ('approaches', ',', 'granular'), (',', 'granular', 'computing'), ('granular', 'computing', '.')]

>> POS Tags are: 
 [('thus', 'RB'), ('presented', 'VBN'), ('difficulties', 'NNS'), ('applying', 'VBG'), ('current', 'JJ'), ('analytical', 'JJ'), ('solutions', 'NNS'), (',', ','), ('including', 'VBG'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('deep', 'JJ'), ('learning', 'NN'), (',', ','), ('incremental', 'JJ'), ('approaches', 'NNS'), (',', ','), ('granular', 'JJ'), ('computing', 'NN'), ('.', '.')]

 (S
  thus/RB
  presented/VBN
  (NP difficulties/NNS)
  applying/VBG
  (NP current/JJ analytical/JJ solutions/NNS)
  ,/,
  including/VBG
  (NP machine/NN learning/NN)
  ,/,
  (NP deep/JJ learning/NN)
  ,/,
  (NP incremental/JJ approaches/NNS)
  ,/,
  (NP granular/JJ computing/NN)
  ./.) 


>> Noun Phrases are: 
 ['difficulties', 'current analytical solutions', 'machine learning', 'deep learning', 'incremental approaches', 'granular computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('thus', 'thu'), ('presented', 'present'), ('difficulties', 'difficulti'), ('applying', 'appli'), ('current', 'current'), ('analytical', 'analyt'), ('solutions', 'solut'), (',', ','), ('including', 'includ'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('incremental', 'increment'), ('approaches', 'approach'), (',', ','), ('granular', 'granular'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('thus', 'thus'), ('presented', 'present'), ('difficulties', 'difficulti'), ('applying', 'appli'), ('current', 'current'), ('analytical', 'analyt'), ('solutions', 'solut'), (',', ','), ('including', 'includ'), ('machine', 'machin'), ('learning', 'learn'), (',', ','), ('deep', 'deep'), ('learning', 'learn'), (',', ','), ('incremental', 'increment'), ('approaches', 'approach'), (',', ','), ('granular', 'granular'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('thus', 'thus'), ('presented', 'presented'), ('difficulties', 'difficulty'), ('applying', 'applying'), ('current', 'current'), ('analytical', 'analytical'), ('solutions', 'solution'), (',', ','), ('including', 'including'), ('machine', 'machine'), ('learning', 'learning'), (',', ','), ('deep', 'deep'), ('learning', 'learning'), (',', ','), ('incremental', 'incremental'), ('approaches', 'approach'), (',', ','), ('granular', 'granular'), ('computing', 'computing'), ('.', '.')]



============================ Sentence 440 =============================

Chen et al. 


>> Tokens are: 
 ['Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Chen/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Chen', 'al']

>> Named Entities are: 
 [('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 441 =============================

(2014) similarly addressed big data applications, opportunities, and challenges, and   examined several techniques to handle big data challenges, such as cloud computing and quantum   computing, to examine their efficacy. 


>> Tokens are: 
 ['(', '2014', ')', 'similarly', 'addressed', 'big', 'data', 'applications', ',', 'opportunities', ',', 'challenges', ',', 'examined', 'several', 'techniques', 'handle', 'big', 'data', 'challenges', ',', 'cloud', 'computing', 'quantum', 'computing', ',', 'examine', 'efficacy', '.']

>> Bigrams are: 
 [('(', '2014'), ('2014', ')'), (')', 'similarly'), ('similarly', 'addressed'), ('addressed', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', ','), (',', 'opportunities'), ('opportunities', ','), (',', 'challenges'), ('challenges', ','), (',', 'examined'), ('examined', 'several'), ('several', 'techniques'), ('techniques', 'handle'), ('handle', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', ','), (',', 'cloud'), ('cloud', 'computing'), ('computing', 'quantum'), ('quantum', 'computing'), ('computing', ','), (',', 'examine'), ('examine', 'efficacy'), ('efficacy', '.')]

>> Trigrams are: 
 [('(', '2014', ')'), ('2014', ')', 'similarly'), (')', 'similarly', 'addressed'), ('similarly', 'addressed', 'big'), ('addressed', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', ','), ('applications', ',', 'opportunities'), (',', 'opportunities', ','), ('opportunities', ',', 'challenges'), (',', 'challenges', ','), ('challenges', ',', 'examined'), (',', 'examined', 'several'), ('examined', 'several', 'techniques'), ('several', 'techniques', 'handle'), ('techniques', 'handle', 'big'), ('handle', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', ','), ('challenges', ',', 'cloud'), (',', 'cloud', 'computing'), ('cloud', 'computing', 'quantum'), ('computing', 'quantum', 'computing'), ('quantum', 'computing', ','), ('computing', ',', 'examine'), (',', 'examine', 'efficacy'), ('examine', 'efficacy', '.')]

>> POS Tags are: 
 [('(', '('), ('2014', 'CD'), (')', ')'), ('similarly', 'RB'), ('addressed', 'VBD'), ('big', 'JJ'), ('data', 'NN'), ('applications', 'NNS'), (',', ','), ('opportunities', 'NNS'), (',', ','), ('challenges', 'NNS'), (',', ','), ('examined', 'VBD'), ('several', 'JJ'), ('techniques', 'NNS'), ('handle', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), (',', ','), ('cloud', 'NN'), ('computing', 'VBG'), ('quantum', 'NN'), ('computing', 'NN'), (',', ','), ('examine', 'JJ'), ('efficacy', 'NN'), ('.', '.')]

 (S
  (/(
  2014/CD
  )/)
  similarly/RB
  addressed/VBD
  (NP big/JJ data/NN applications/NNS)
  ,/,
  (NP opportunities/NNS)
  ,/,
  (NP challenges/NNS)
  ,/,
  examined/VBD
  (NP several/JJ techniques/NNS)
  handle/VBP
  (NP big/JJ data/NNS challenges/NNS)
  ,/,
  (NP cloud/NN)
  computing/VBG
  (NP quantum/NN computing/NN)
  ,/,
  (NP examine/JJ efficacy/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data applications', 'opportunities', 'challenges', 'several techniques', 'big data challenges', 'cloud', 'quantum computing', 'examine efficacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('similarly', 'similarli'), ('addressed', 'address'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), (',', ','), ('examined', 'examin'), ('several', 'sever'), ('techniques', 'techniqu'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), (',', ','), ('cloud', 'cloud'), ('computing', 'comput'), ('quantum', 'quantum'), ('computing', 'comput'), (',', ','), ('examine', 'examin'), ('efficacy', 'efficaci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('similarly', 'similar'), ('addressed', 'address'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), (',', ','), ('examined', 'examin'), ('several', 'sever'), ('techniques', 'techniqu'), ('handle', 'handl'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), (',', ','), ('cloud', 'cloud'), ('computing', 'comput'), ('quantum', 'quantum'), ('computing', 'comput'), (',', ','), ('examine', 'examin'), ('efficacy', 'efficaci'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2014', '2014'), (')', ')'), ('similarly', 'similarly'), ('addressed', 'addressed'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), (',', ','), ('opportunities', 'opportunity'), (',', ','), ('challenges', 'challenge'), (',', ','), ('examined', 'examined'), ('several', 'several'), ('techniques', 'technique'), ('handle', 'handle'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), (',', ','), ('cloud', 'cloud'), ('computing', 'computing'), ('quantum', 'quantum'), ('computing', 'computing'), (',', ','), ('examine', 'examine'), ('efficacy', 'efficacy'), ('.', '.')]



============================ Sentence 442 =============================

Wang.et al. 


>> Tokens are: 
 ['Wang.et', 'al', '.']

>> Bigrams are: 
 [('Wang.et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Wang.et', 'al', '.')]

>> POS Tags are: 
 [('Wang.et', 'NNP'), ('al', 'NN'), ('.', '.')]

 (S (NP Wang.et/NNP al/NN) ./.) 


>> Noun Phrases are: 
 ['Wang.et al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Wang.et', 'wang.et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wang.et', 'wang.et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Wang.et', 'Wang.et'), ('al', 'al'), ('.', '.')]



============================ Sentence 443 =============================

(2016) presented a big data overview that   included four categories: 1) concepts, big data characteristics, and processing paradigms; (2) state-  of-the-art techniques for decision making in big data; (3) decision making applications of big data   in social science; and (4) big data’s current challenges and future directions. 


>> Tokens are: 
 ['(', '2016', ')', 'presented', 'big', 'data', 'overview', 'included', 'four', 'categories', ':', '1', ')', 'concepts', ',', 'big', 'data', 'characteristics', ',', 'processing', 'paradigms', ';', '(', '2', ')', 'state-', 'of-the-art', 'techniques', 'decision', 'making', 'big', 'data', ';', '(', '3', ')', 'decision', 'making', 'applications', 'big', 'data', 'social', 'science', ';', '(', '4', ')', 'big', 'data', '’', 'current', 'challenges', 'future', 'directions', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'overview'), ('overview', 'included'), ('included', 'four'), ('four', 'categories'), ('categories', ':'), (':', '1'), ('1', ')'), (')', 'concepts'), ('concepts', ','), (',', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', ','), (',', 'processing'), ('processing', 'paradigms'), ('paradigms', ';'), (';', '('), ('(', '2'), ('2', ')'), (')', 'state-'), ('state-', 'of-the-art'), ('of-the-art', 'techniques'), ('techniques', 'decision'), ('decision', 'making'), ('making', 'big'), ('big', 'data'), ('data', ';'), (';', '('), ('(', '3'), ('3', ')'), (')', 'decision'), ('decision', 'making'), ('making', 'applications'), ('applications', 'big'), ('big', 'data'), ('data', 'social'), ('social', 'science'), ('science', ';'), (';', '('), ('(', '4'), ('4', ')'), (')', 'big'), ('big', 'data'), ('data', '’'), ('’', 'current'), ('current', 'challenges'), ('challenges', 'future'), ('future', 'directions'), ('directions', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'presented'), (')', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'overview'), ('data', 'overview', 'included'), ('overview', 'included', 'four'), ('included', 'four', 'categories'), ('four', 'categories', ':'), ('categories', ':', '1'), (':', '1', ')'), ('1', ')', 'concepts'), (')', 'concepts', ','), ('concepts', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', ','), ('characteristics', ',', 'processing'), (',', 'processing', 'paradigms'), ('processing', 'paradigms', ';'), ('paradigms', ';', '('), (';', '(', '2'), ('(', '2', ')'), ('2', ')', 'state-'), (')', 'state-', 'of-the-art'), ('state-', 'of-the-art', 'techniques'), ('of-the-art', 'techniques', 'decision'), ('techniques', 'decision', 'making'), ('decision', 'making', 'big'), ('making', 'big', 'data'), ('big', 'data', ';'), ('data', ';', '('), (';', '(', '3'), ('(', '3', ')'), ('3', ')', 'decision'), (')', 'decision', 'making'), ('decision', 'making', 'applications'), ('making', 'applications', 'big'), ('applications', 'big', 'data'), ('big', 'data', 'social'), ('data', 'social', 'science'), ('social', 'science', ';'), ('science', ';', '('), (';', '(', '4'), ('(', '4', ')'), ('4', ')', 'big'), (')', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'current'), ('’', 'current', 'challenges'), ('current', 'challenges', 'future'), ('challenges', 'future', 'directions'), ('future', 'directions', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('overview', 'NN'), ('included', 'VBD'), ('four', 'CD'), ('categories', 'NNS'), (':', ':'), ('1', 'CD'), (')', ')'), ('concepts', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('characteristics', 'NNS'), (',', ','), ('processing', 'VBG'), ('paradigms', 'NN'), (';', ':'), ('(', '('), ('2', 'CD'), (')', ')'), ('state-', 'JJ'), ('of-the-art', 'JJ'), ('techniques', 'NNS'), ('decision', 'NN'), ('making', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (';', ':'), ('(', '('), ('3', 'CD'), (')', ')'), ('decision', 'NN'), ('making', 'VBG'), ('applications', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('social', 'JJ'), ('science', 'NN'), (';', ':'), ('(', '('), ('4', 'CD'), (')', ')'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'FW'), ('current', 'JJ'), ('challenges', 'NNS'), ('future', 'JJ'), ('directions', 'NNS'), ('.', '.')]

 (S
  (/(
  2016/CD
  )/)
  presented/VBD
  (NP big/JJ data/NNS overview/NN)
  included/VBD
  four/CD
  (NP categories/NNS)
  :/:
  1/CD
  )/)
  (NP concepts/NNS)
  ,/,
  (NP big/JJ data/NN characteristics/NNS)
  ,/,
  processing/VBG
  (NP paradigms/NN)
  ;/:
  (/(
  2/CD
  )/)
  (NP state-/JJ of-the-art/JJ techniques/NNS decision/NN)
  making/VBG
  (NP big/JJ data/NNS)
  ;/:
  (/(
  3/CD
  )/)
  (NP decision/NN)
  making/VBG
  (NP applications/NNS)
  (NP big/JJ data/NNS)
  (NP social/JJ science/NN)
  ;/:
  (/(
  4/CD
  )/)
  (NP big/JJ data/NNS)
  ’/FW
  (NP current/JJ challenges/NNS)
  (NP future/JJ directions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data overview', 'categories', 'concepts', 'big data characteristics', 'paradigms', 'state- of-the-art techniques decision', 'big data', 'decision', 'applications', 'big data', 'social science', 'big data', 'current challenges', 'future directions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('overview', 'overview'), ('included', 'includ'), ('four', 'four'), ('categories', 'categori'), (':', ':'), ('1', '1'), (')', ')'), ('concepts', 'concept'), (',', ','), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('processing', 'process'), ('paradigms', 'paradigm'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('state-', 'state-'), ('of-the-art', 'of-the-art'), ('techniques', 'techniqu'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), (';', ';'), ('(', '('), ('3', '3'), (')', ')'), ('decision', 'decis'), ('making', 'make'), ('applications', 'applic'), ('big', 'big'), ('data', 'data'), ('social', 'social'), ('science', 'scienc'), (';', ';'), ('(', '('), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('current', 'current'), ('challenges', 'challeng'), ('future', 'futur'), ('directions', 'direct'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('overview', 'overview'), ('included', 'includ'), ('four', 'four'), ('categories', 'categori'), (':', ':'), ('1', '1'), (')', ')'), ('concepts', 'concept'), (',', ','), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), (',', ','), ('processing', 'process'), ('paradigms', 'paradigm'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('state-', 'state-'), ('of-the-art', 'of-the-art'), ('techniques', 'techniqu'), ('decision', 'decis'), ('making', 'make'), ('big', 'big'), ('data', 'data'), (';', ';'), ('(', '('), ('3', '3'), (')', ')'), ('decision', 'decis'), ('making', 'make'), ('applications', 'applic'), ('big', 'big'), ('data', 'data'), ('social', 'social'), ('science', 'scienc'), (';', ';'), ('(', '('), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('current', 'current'), ('challenges', 'challeng'), ('future', 'futur'), ('directions', 'direct'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('overview', 'overview'), ('included', 'included'), ('four', 'four'), ('categories', 'category'), (':', ':'), ('1', '1'), (')', ')'), ('concepts', 'concept'), (',', ','), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), (',', ','), ('processing', 'processing'), ('paradigms', 'paradigm'), (';', ';'), ('(', '('), ('2', '2'), (')', ')'), ('state-', 'state-'), ('of-the-art', 'of-the-art'), ('techniques', 'technique'), ('decision', 'decision'), ('making', 'making'), ('big', 'big'), ('data', 'data'), (';', ';'), ('(', '('), ('3', '3'), (')', ')'), ('decision', 'decision'), ('making', 'making'), ('applications', 'application'), ('big', 'big'), ('data', 'data'), ('social', 'social'), ('science', 'science'), (';', ';'), ('(', '('), ('4', '4'), (')', ')'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('current', 'current'), ('challenges', 'challenge'), ('future', 'future'), ('directions', 'direction'), ('.', '.')]



============================ Sentence 444 =============================

The work of Ali et al. 


>> Tokens are: 
 ['The', 'work', 'Ali', 'et', 'al', '.']

>> Bigrams are: 
 [('The', 'work'), ('work', 'Ali'), ('Ali', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('The', 'work', 'Ali'), ('work', 'Ali', 'et'), ('Ali', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('work', 'NN'), ('Ali', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP The/DT work/NN Ali/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['The work Ali', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('work', 'work'), ('Ali', 'ali'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('work', 'work'), ('Ali', 'ali'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('work', 'work'), ('Ali', 'Ali'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 445 =============================

(2016) explained big data’s potential and applications. 


>> Tokens are: 
 ['(', '2016', ')', 'explained', 'big', 'data', '’', 'potential', 'applications', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'explained'), ('explained', 'big'), ('big', 'data'), ('data', '’'), ('’', 'potential'), ('potential', 'applications'), ('applications', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'explained'), (')', 'explained', 'big'), ('explained', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'potential'), ('’', 'potential', 'applications'), ('potential', 'applications', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('explained', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'VBP'), ('potential', 'JJ'), ('applications', 'NNS'), ('.', '.')]

 (S
  (/(
  2016/CD
  )/)
  explained/VBD
  (NP big/JJ data/NNS)
  ’/VBP
  (NP potential/JJ applications/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'potential applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('explained', 'explain'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), ('applications', 'applic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('explained', 'explain'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potenti'), ('applications', 'applic'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('explained', 'explained'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('potential', 'potential'), ('applications', 'application'), ('.', '.')]



============================ Sentence 446 =============================

It presented big data   techniques and offered some background to big data analytical approaches. 


>> Tokens are: 
 ['It', 'presented', 'big', 'data', 'techniques', 'offered', 'background', 'big', 'data', 'analytical', 'approaches', '.']

>> Bigrams are: 
 [('It', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'techniques'), ('techniques', 'offered'), ('offered', 'background'), ('background', 'big'), ('big', 'data'), ('data', 'analytical'), ('analytical', 'approaches'), ('approaches', '.')]

>> Trigrams are: 
 [('It', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'techniques'), ('data', 'techniques', 'offered'), ('techniques', 'offered', 'background'), ('offered', 'background', 'big'), ('background', 'big', 'data'), ('big', 'data', 'analytical'), ('data', 'analytical', 'approaches'), ('analytical', 'approaches', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('techniques', 'NNS'), ('offered', 'VBN'), ('background', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('analytical', 'JJ'), ('approaches', 'NNS'), ('.', '.')]

 (S
  It/PRP
  presented/VBD
  (NP big/JJ data/NNS techniques/NNS)
  offered/VBN
  background/RB
  (NP big/JJ data/NNS)
  (NP analytical/JJ approaches/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data techniques', 'big data', 'analytical approaches']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('offered', 'offer'), ('background', 'background'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('approaches', 'approach'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('offered', 'offer'), ('background', 'background'), ('big', 'big'), ('data', 'data'), ('analytical', 'analyt'), ('approaches', 'approach'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('techniques', 'technique'), ('offered', 'offered'), ('background', 'background'), ('big', 'big'), ('data', 'data'), ('analytical', 'analytical'), ('approaches', 'approach'), ('.', '.')]



============================ Sentence 447 =============================

The study highlighted   several big data technical challenges such as crowdsourcing, bias and polarization, technology   usage, and scaling. 


>> Tokens are: 
 ['The', 'study', 'highlighted', 'several', 'big', 'data', 'technical', 'challenges', 'crowdsourcing', ',', 'bias', 'polarization', ',', 'technology', 'usage', ',', 'scaling', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', 'highlighted'), ('highlighted', 'several'), ('several', 'big'), ('big', 'data'), ('data', 'technical'), ('technical', 'challenges'), ('challenges', 'crowdsourcing'), ('crowdsourcing', ','), (',', 'bias'), ('bias', 'polarization'), ('polarization', ','), (',', 'technology'), ('technology', 'usage'), ('usage', ','), (',', 'scaling'), ('scaling', '.')]

>> Trigrams are: 
 [('The', 'study', 'highlighted'), ('study', 'highlighted', 'several'), ('highlighted', 'several', 'big'), ('several', 'big', 'data'), ('big', 'data', 'technical'), ('data', 'technical', 'challenges'), ('technical', 'challenges', 'crowdsourcing'), ('challenges', 'crowdsourcing', ','), ('crowdsourcing', ',', 'bias'), (',', 'bias', 'polarization'), ('bias', 'polarization', ','), ('polarization', ',', 'technology'), (',', 'technology', 'usage'), ('technology', 'usage', ','), ('usage', ',', 'scaling'), (',', 'scaling', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('highlighted', 'VBD'), ('several', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('technical', 'JJ'), ('challenges', 'NNS'), ('crowdsourcing', 'VBG'), (',', ','), ('bias', 'JJ'), ('polarization', 'NN'), (',', ','), ('technology', 'NN'), ('usage', 'NN'), (',', ','), ('scaling', 'NN'), ('.', '.')]

 (S
  (NP The/DT study/NN)
  highlighted/VBD
  (NP several/JJ big/JJ data/NNS)
  (NP technical/JJ challenges/NNS)
  crowdsourcing/VBG
  ,/,
  (NP bias/JJ polarization/NN)
  ,/,
  (NP technology/NN usage/NN)
  ,/,
  (NP scaling/NN)
  ./.) 


>> Noun Phrases are: 
 ['The study', 'several big data', 'technical challenges', 'bias polarization', 'technology usage', 'scaling']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('highlighted', 'highlight'), ('several', 'sever'), ('big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('crowdsourcing', 'crowdsourc'), (',', ','), ('bias', 'bia'), ('polarization', 'polar'), (',', ','), ('technology', 'technolog'), ('usage', 'usag'), (',', ','), ('scaling', 'scale'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('highlighted', 'highlight'), ('several', 'sever'), ('big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('crowdsourcing', 'crowdsourc'), (',', ','), ('bias', 'bias'), ('polarization', 'polar'), (',', ','), ('technology', 'technolog'), ('usage', 'usag'), (',', ','), ('scaling', 'scale'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('highlighted', 'highlighted'), ('several', 'several'), ('big', 'big'), ('data', 'data'), ('technical', 'technical'), ('challenges', 'challenge'), ('crowdsourcing', 'crowdsourcing'), (',', ','), ('bias', 'bias'), ('polarization', 'polarization'), (',', ','), ('technology', 'technology'), ('usage', 'usage'), (',', ','), ('scaling', 'scaling'), ('.', '.')]



============================ Sentence 448 =============================

New technologies and services such as cloud computing and hardware price   reductions have also increased the information rates available from the Internet, representing a big   challenge to the data analytics community. 


>> Tokens are: 
 ['New', 'technologies', 'services', 'cloud', 'computing', 'hardware', 'price', 'reductions', 'also', 'increased', 'information', 'rates', 'available', 'Internet', ',', 'representing', 'big', 'challenge', 'data', 'analytics', 'community', '.']

>> Bigrams are: 
 [('New', 'technologies'), ('technologies', 'services'), ('services', 'cloud'), ('cloud', 'computing'), ('computing', 'hardware'), ('hardware', 'price'), ('price', 'reductions'), ('reductions', 'also'), ('also', 'increased'), ('increased', 'information'), ('information', 'rates'), ('rates', 'available'), ('available', 'Internet'), ('Internet', ','), (',', 'representing'), ('representing', 'big'), ('big', 'challenge'), ('challenge', 'data'), ('data', 'analytics'), ('analytics', 'community'), ('community', '.')]

>> Trigrams are: 
 [('New', 'technologies', 'services'), ('technologies', 'services', 'cloud'), ('services', 'cloud', 'computing'), ('cloud', 'computing', 'hardware'), ('computing', 'hardware', 'price'), ('hardware', 'price', 'reductions'), ('price', 'reductions', 'also'), ('reductions', 'also', 'increased'), ('also', 'increased', 'information'), ('increased', 'information', 'rates'), ('information', 'rates', 'available'), ('rates', 'available', 'Internet'), ('available', 'Internet', ','), ('Internet', ',', 'representing'), (',', 'representing', 'big'), ('representing', 'big', 'challenge'), ('big', 'challenge', 'data'), ('challenge', 'data', 'analytics'), ('data', 'analytics', 'community'), ('analytics', 'community', '.')]

>> POS Tags are: 
 [('New', 'NNP'), ('technologies', 'NNS'), ('services', 'NNS'), ('cloud', 'VBP'), ('computing', 'VBG'), ('hardware', 'NN'), ('price', 'NN'), ('reductions', 'NNS'), ('also', 'RB'), ('increased', 'VBD'), ('information', 'NN'), ('rates', 'NNS'), ('available', 'JJ'), ('Internet', 'NNP'), (',', ','), ('representing', 'VBG'), ('big', 'JJ'), ('challenge', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('community', 'NN'), ('.', '.')]

 (S
  (NP New/NNP technologies/NNS services/NNS)
  cloud/VBP
  computing/VBG
  (NP hardware/NN price/NN reductions/NNS)
  also/RB
  increased/VBD
  (NP information/NN rates/NNS)
  (NP available/JJ Internet/NNP)
  ,/,
  representing/VBG
  (NP big/JJ challenge/NN data/NNS analytics/NNS community/NN)
  ./.) 


>> Noun Phrases are: 
 ['New technologies services', 'hardware price reductions', 'information rates', 'available Internet', 'big challenge data analytics community']

>> Named Entities are: 
 [('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('technologies', 'technolog'), ('services', 'servic'), ('cloud', 'cloud'), ('computing', 'comput'), ('hardware', 'hardwar'), ('price', 'price'), ('reductions', 'reduct'), ('also', 'also'), ('increased', 'increas'), ('information', 'inform'), ('rates', 'rate'), ('available', 'avail'), ('Internet', 'internet'), (',', ','), ('representing', 'repres'), ('big', 'big'), ('challenge', 'challeng'), ('data', 'data'), ('analytics', 'analyt'), ('community', 'commun'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('technologies', 'technolog'), ('services', 'servic'), ('cloud', 'cloud'), ('computing', 'comput'), ('hardware', 'hardwar'), ('price', 'price'), ('reductions', 'reduct'), ('also', 'also'), ('increased', 'increas'), ('information', 'inform'), ('rates', 'rate'), ('available', 'avail'), ('Internet', 'internet'), (',', ','), ('representing', 'repres'), ('big', 'big'), ('challenge', 'challeng'), ('data', 'data'), ('analytics', 'analyt'), ('community', 'communiti'), ('.', '.')]

>> Lemmatization: 
 [('New', 'New'), ('technologies', 'technology'), ('services', 'service'), ('cloud', 'cloud'), ('computing', 'computing'), ('hardware', 'hardware'), ('price', 'price'), ('reductions', 'reduction'), ('also', 'also'), ('increased', 'increased'), ('information', 'information'), ('rates', 'rate'), ('available', 'available'), ('Internet', 'Internet'), (',', ','), ('representing', 'representing'), ('big', 'big'), ('challenge', 'challenge'), ('data', 'data'), ('analytics', 'analytics'), ('community', 'community'), ('.', '.')]



============================ Sentence 449 =============================

The main challenges of using big data, which need to be resolved before it can be used   effectively, include   9.1. 


>> Tokens are: 
 ['The', 'main', 'challenges', 'using', 'big', 'data', ',', 'need', 'resolved', 'used', 'effectively', ',', 'include', '9.1', '.']

>> Bigrams are: 
 [('The', 'main'), ('main', 'challenges'), ('challenges', 'using'), ('using', 'big'), ('big', 'data'), ('data', ','), (',', 'need'), ('need', 'resolved'), ('resolved', 'used'), ('used', 'effectively'), ('effectively', ','), (',', 'include'), ('include', '9.1'), ('9.1', '.')]

>> Trigrams are: 
 [('The', 'main', 'challenges'), ('main', 'challenges', 'using'), ('challenges', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'need'), (',', 'need', 'resolved'), ('need', 'resolved', 'used'), ('resolved', 'used', 'effectively'), ('used', 'effectively', ','), ('effectively', ',', 'include'), (',', 'include', '9.1'), ('include', '9.1', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('challenges', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('need', 'VBP'), ('resolved', 'VBN'), ('used', 'JJ'), ('effectively', 'RB'), (',', ','), ('include', 'VBP'), ('9.1', 'CD'), ('.', '.')]

 (S
  (NP The/DT main/JJ challenges/NNS)
  using/VBG
  (NP big/JJ data/NNS)
  ,/,
  need/VBP
  resolved/VBN
  used/JJ
  effectively/RB
  ,/,
  include/VBP
  9.1/CD
  ./.) 


>> Noun Phrases are: 
 ['The main challenges', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use'), ('effectively', 'effect'), (',', ','), ('include', 'includ'), ('9.1', '9.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('challenges', 'challeng'), ('using', 'use'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolv'), ('used', 'use'), ('effectively', 'effect'), (',', ','), ('include', 'includ'), ('9.1', '9.1'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('challenges', 'challenge'), ('using', 'using'), ('big', 'big'), ('data', 'data'), (',', ','), ('need', 'need'), ('resolved', 'resolved'), ('used', 'used'), ('effectively', 'effectively'), (',', ','), ('include', 'include'), ('9.1', '9.1'), ('.', '.')]



============================ Sentence 450 =============================

Data Security issues   In public affairs, privacy, internet access disparities, and legal and security issues are key concerns,   and managers and policymakers in these areas should work to overcome these limitations. 


>> Tokens are: 
 ['Data', 'Security', 'issues', 'In', 'public', 'affairs', ',', 'privacy', ',', 'internet', 'access', 'disparities', ',', 'legal', 'security', 'issues', 'key', 'concerns', ',', 'managers', 'policymakers', 'areas', 'work', 'overcome', 'limitations', '.']

>> Bigrams are: 
 [('Data', 'Security'), ('Security', 'issues'), ('issues', 'In'), ('In', 'public'), ('public', 'affairs'), ('affairs', ','), (',', 'privacy'), ('privacy', ','), (',', 'internet'), ('internet', 'access'), ('access', 'disparities'), ('disparities', ','), (',', 'legal'), ('legal', 'security'), ('security', 'issues'), ('issues', 'key'), ('key', 'concerns'), ('concerns', ','), (',', 'managers'), ('managers', 'policymakers'), ('policymakers', 'areas'), ('areas', 'work'), ('work', 'overcome'), ('overcome', 'limitations'), ('limitations', '.')]

>> Trigrams are: 
 [('Data', 'Security', 'issues'), ('Security', 'issues', 'In'), ('issues', 'In', 'public'), ('In', 'public', 'affairs'), ('public', 'affairs', ','), ('affairs', ',', 'privacy'), (',', 'privacy', ','), ('privacy', ',', 'internet'), (',', 'internet', 'access'), ('internet', 'access', 'disparities'), ('access', 'disparities', ','), ('disparities', ',', 'legal'), (',', 'legal', 'security'), ('legal', 'security', 'issues'), ('security', 'issues', 'key'), ('issues', 'key', 'concerns'), ('key', 'concerns', ','), ('concerns', ',', 'managers'), (',', 'managers', 'policymakers'), ('managers', 'policymakers', 'areas'), ('policymakers', 'areas', 'work'), ('areas', 'work', 'overcome'), ('work', 'overcome', 'limitations'), ('overcome', 'limitations', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('Security', 'NNP'), ('issues', 'NNS'), ('In', 'IN'), ('public', 'JJ'), ('affairs', 'NNS'), (',', ','), ('privacy', 'NN'), (',', ','), ('internet', 'JJ'), ('access', 'NN'), ('disparities', 'NNS'), (',', ','), ('legal', 'JJ'), ('security', 'NN'), ('issues', 'NNS'), ('key', 'JJ'), ('concerns', 'NNS'), (',', ','), ('managers', 'NNS'), ('policymakers', 'NNS'), ('areas', 'NNS'), ('work', 'VBP'), ('overcome', 'JJ'), ('limitations', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP Security/NNP issues/NNS)
  In/IN
  (NP public/JJ affairs/NNS)
  ,/,
  (NP privacy/NN)
  ,/,
  (NP internet/JJ access/NN disparities/NNS)
  ,/,
  (NP legal/JJ security/NN issues/NNS)
  (NP key/JJ concerns/NNS)
  ,/,
  (NP managers/NNS policymakers/NNS areas/NNS)
  work/VBP
  (NP overcome/JJ limitations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data Security issues', 'public affairs', 'privacy', 'internet access disparities', 'legal security issues', 'key concerns', 'managers policymakers areas', 'overcome limitations']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu'), ('In', 'in'), ('public', 'public'), ('affairs', 'affair'), (',', ','), ('privacy', 'privaci'), (',', ','), ('internet', 'internet'), ('access', 'access'), ('disparities', 'dispar'), (',', ','), ('legal', 'legal'), ('security', 'secur'), ('issues', 'issu'), ('key', 'key'), ('concerns', 'concern'), (',', ','), ('managers', 'manag'), ('policymakers', 'policymak'), ('areas', 'area'), ('work', 'work'), ('overcome', 'overcom'), ('limitations', 'limit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('Security', 'secur'), ('issues', 'issu'), ('In', 'in'), ('public', 'public'), ('affairs', 'affair'), (',', ','), ('privacy', 'privaci'), (',', ','), ('internet', 'internet'), ('access', 'access'), ('disparities', 'dispar'), (',', ','), ('legal', 'legal'), ('security', 'secur'), ('issues', 'issu'), ('key', 'key'), ('concerns', 'concern'), (',', ','), ('managers', 'manag'), ('policymakers', 'policymak'), ('areas', 'area'), ('work', 'work'), ('overcome', 'overcom'), ('limitations', 'limit'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('Security', 'Security'), ('issues', 'issue'), ('In', 'In'), ('public', 'public'), ('affairs', 'affair'), (',', ','), ('privacy', 'privacy'), (',', ','), ('internet', 'internet'), ('access', 'access'), ('disparities', 'disparity'), (',', ','), ('legal', 'legal'), ('security', 'security'), ('issues', 'issue'), ('key', 'key'), ('concerns', 'concern'), (',', ','), ('managers', 'manager'), ('policymakers', 'policymakers'), ('areas', 'area'), ('work', 'work'), ('overcome', 'overcome'), ('limitations', 'limitation'), ('.', '.')]



============================ Sentence 451 =============================

Public   managers and policymakers are also, however, generally working under the restrictions of a limited   budget, multiple constituencies, and short time frames for extracting knowledge big data (Mergel,   Rethemeyer, and Isett, 2016; Grover and Kar, 2017). 


>> Tokens are: 
 ['Public', 'managers', 'policymakers', 'also', ',', 'however', ',', 'generally', 'working', 'restrictions', 'limited', 'budget', ',', 'multiple', 'constituencies', ',', 'short', 'time', 'frames', 'extracting', 'knowledge', 'big', 'data', '(', 'Mergel', ',', 'Rethemeyer', ',', 'Isett', ',', '2016', ';', 'Grover', 'Kar', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Public', 'managers'), ('managers', 'policymakers'), ('policymakers', 'also'), ('also', ','), (',', 'however'), ('however', ','), (',', 'generally'), ('generally', 'working'), ('working', 'restrictions'), ('restrictions', 'limited'), ('limited', 'budget'), ('budget', ','), (',', 'multiple'), ('multiple', 'constituencies'), ('constituencies', ','), (',', 'short'), ('short', 'time'), ('time', 'frames'), ('frames', 'extracting'), ('extracting', 'knowledge'), ('knowledge', 'big'), ('big', 'data'), ('data', '('), ('(', 'Mergel'), ('Mergel', ','), (',', 'Rethemeyer'), ('Rethemeyer', ','), (',', 'Isett'), ('Isett', ','), (',', '2016'), ('2016', ';'), (';', 'Grover'), ('Grover', 'Kar'), ('Kar', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Public', 'managers', 'policymakers'), ('managers', 'policymakers', 'also'), ('policymakers', 'also', ','), ('also', ',', 'however'), (',', 'however', ','), ('however', ',', 'generally'), (',', 'generally', 'working'), ('generally', 'working', 'restrictions'), ('working', 'restrictions', 'limited'), ('restrictions', 'limited', 'budget'), ('limited', 'budget', ','), ('budget', ',', 'multiple'), (',', 'multiple', 'constituencies'), ('multiple', 'constituencies', ','), ('constituencies', ',', 'short'), (',', 'short', 'time'), ('short', 'time', 'frames'), ('time', 'frames', 'extracting'), ('frames', 'extracting', 'knowledge'), ('extracting', 'knowledge', 'big'), ('knowledge', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Mergel'), ('(', 'Mergel', ','), ('Mergel', ',', 'Rethemeyer'), (',', 'Rethemeyer', ','), ('Rethemeyer', ',', 'Isett'), (',', 'Isett', ','), ('Isett', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Grover'), (';', 'Grover', 'Kar'), ('Grover', 'Kar', ','), ('Kar', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Public', 'JJ'), ('managers', 'NNS'), ('policymakers', 'NNS'), ('also', 'RB'), (',', ','), ('however', 'RB'), (',', ','), ('generally', 'RB'), ('working', 'VBG'), ('restrictions', 'NNS'), ('limited', 'JJ'), ('budget', 'NN'), (',', ','), ('multiple', 'JJ'), ('constituencies', 'NNS'), (',', ','), ('short', 'JJ'), ('time', 'NN'), ('frames', 'NNS'), ('extracting', 'VBG'), ('knowledge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Mergel', 'NNP'), (',', ','), ('Rethemeyer', 'NNP'), (',', ','), ('Isett', 'NNP'), (',', ','), ('2016', 'CD'), (';', ':'), ('Grover', 'NNP'), ('Kar', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Public/JJ managers/NNS policymakers/NNS)
  also/RB
  ,/,
  however/RB
  ,/,
  generally/RB
  working/VBG
  (NP restrictions/NNS)
  (NP limited/JJ budget/NN)
  ,/,
  (NP multiple/JJ constituencies/NNS)
  ,/,
  (NP short/JJ time/NN frames/NNS)
  extracting/VBG
  (NP knowledge/NN)
  (NP big/JJ data/NNS)
  (/(
  (NP Mergel/NNP)
  ,/,
  (NP Rethemeyer/NNP)
  ,/,
  (NP Isett/NNP)
  ,/,
  2016/CD
  ;/:
  (NP Grover/NNP Kar/NNP)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Public managers policymakers', 'restrictions', 'limited budget', 'multiple constituencies', 'short time frames', 'knowledge', 'big data', 'Mergel', 'Rethemeyer', 'Isett', 'Grover Kar']

>> Named Entities are: 
 [('GPE', 'Public'), ('ORGANIZATION', 'Mergel'), ('GPE', 'Rethemeyer'), ('PERSON', 'Isett'), ('PERSON', 'Grover Kar')] 

>> Stemming using Porter Stemmer: 
 [('Public', 'public'), ('managers', 'manag'), ('policymakers', 'policymak'), ('also', 'also'), (',', ','), ('however', 'howev'), (',', ','), ('generally', 'gener'), ('working', 'work'), ('restrictions', 'restrict'), ('limited', 'limit'), ('budget', 'budget'), (',', ','), ('multiple', 'multipl'), ('constituencies', 'constitu'), (',', ','), ('short', 'short'), ('time', 'time'), ('frames', 'frame'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Mergel', 'mergel'), (',', ','), ('Rethemeyer', 'rethemey'), (',', ','), ('Isett', 'isett'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Public', 'public'), ('managers', 'manag'), ('policymakers', 'policymak'), ('also', 'also'), (',', ','), ('however', 'howev'), (',', ','), ('generally', 'general'), ('working', 'work'), ('restrictions', 'restrict'), ('limited', 'limit'), ('budget', 'budget'), (',', ','), ('multiple', 'multipl'), ('constituencies', 'constitu'), (',', ','), ('short', 'short'), ('time', 'time'), ('frames', 'frame'), ('extracting', 'extract'), ('knowledge', 'knowledg'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Mergel', 'mergel'), (',', ','), ('Rethemeyer', 'rethemey'), (',', ','), ('Isett', 'isett'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'grover'), ('Kar', 'kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Public', 'Public'), ('managers', 'manager'), ('policymakers', 'policymakers'), ('also', 'also'), (',', ','), ('however', 'however'), (',', ','), ('generally', 'generally'), ('working', 'working'), ('restrictions', 'restriction'), ('limited', 'limited'), ('budget', 'budget'), (',', ','), ('multiple', 'multiple'), ('constituencies', 'constituency'), (',', ','), ('short', 'short'), ('time', 'time'), ('frames', 'frame'), ('extracting', 'extracting'), ('knowledge', 'knowledge'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Mergel', 'Mergel'), (',', ','), ('Rethemeyer', 'Rethemeyer'), (',', ','), ('Isett', 'Isett'), (',', ','), ('2016', '2016'), (';', ';'), ('Grover', 'Grover'), ('Kar', 'Kar'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 452 =============================

Watson (2019) presented some security issues with big data and gave some suggestions for   avoiding big data security risks. 


>> Tokens are: 
 ['Watson', '(', '2019', ')', 'presented', 'security', 'issues', 'big', 'data', 'gave', 'suggestions', 'avoiding', 'big', 'data', 'security', 'risks', '.']

>> Bigrams are: 
 [('Watson', '('), ('(', '2019'), ('2019', ')'), (')', 'presented'), ('presented', 'security'), ('security', 'issues'), ('issues', 'big'), ('big', 'data'), ('data', 'gave'), ('gave', 'suggestions'), ('suggestions', 'avoiding'), ('avoiding', 'big'), ('big', 'data'), ('data', 'security'), ('security', 'risks'), ('risks', '.')]

>> Trigrams are: 
 [('Watson', '(', '2019'), ('(', '2019', ')'), ('2019', ')', 'presented'), (')', 'presented', 'security'), ('presented', 'security', 'issues'), ('security', 'issues', 'big'), ('issues', 'big', 'data'), ('big', 'data', 'gave'), ('data', 'gave', 'suggestions'), ('gave', 'suggestions', 'avoiding'), ('suggestions', 'avoiding', 'big'), ('avoiding', 'big', 'data'), ('big', 'data', 'security'), ('data', 'security', 'risks'), ('security', 'risks', '.')]

>> POS Tags are: 
 [('Watson', 'NNP'), ('(', '('), ('2019', 'CD'), (')', ')'), ('presented', 'VBD'), ('security', 'NN'), ('issues', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('gave', 'VBD'), ('suggestions', 'NNS'), ('avoiding', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('security', 'NN'), ('risks', 'NNS'), ('.', '.')]

 (S
  (NP Watson/NNP)
  (/(
  2019/CD
  )/)
  presented/VBD
  (NP security/NN issues/NNS)
  (NP big/JJ data/NNS)
  gave/VBD
  (NP suggestions/NNS)
  avoiding/VBG
  (NP big/JJ data/NNS security/NN risks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Watson', 'security issues', 'big data', 'suggestions', 'big data security risks']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2019', '2019'), (')', ')'), ('presented', 'present'), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('gave', 'gave'), ('suggestions', 'suggest'), ('avoiding', 'avoid'), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2019', '2019'), (')', ')'), ('presented', 'present'), ('security', 'secur'), ('issues', 'issu'), ('big', 'big'), ('data', 'data'), ('gave', 'gave'), ('suggestions', 'suggest'), ('avoiding', 'avoid'), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Lemmatization: 
 [('Watson', 'Watson'), ('(', '('), ('2019', '2019'), (')', ')'), ('presented', 'presented'), ('security', 'security'), ('issues', 'issue'), ('big', 'big'), ('data', 'data'), ('gave', 'gave'), ('suggestions', 'suggestion'), ('avoiding', 'avoiding'), ('big', 'big'), ('data', 'data'), ('security', 'security'), ('risks', 'risk'), ('.', '.')]



============================ Sentence 453 =============================

The security concern inherent in big data include the fact that big   data comes from many different sources, some of which may have weak security as well as a   variety of formats and large volumes. 


>> Tokens are: 
 ['The', 'security', 'concern', 'inherent', 'big', 'data', 'include', 'fact', 'big', 'data', 'comes', 'many', 'different', 'sources', ',', 'may', 'weak', 'security', 'well', 'variety', 'formats', 'large', 'volumes', '.']

>> Bigrams are: 
 [('The', 'security'), ('security', 'concern'), ('concern', 'inherent'), ('inherent', 'big'), ('big', 'data'), ('data', 'include'), ('include', 'fact'), ('fact', 'big'), ('big', 'data'), ('data', 'comes'), ('comes', 'many'), ('many', 'different'), ('different', 'sources'), ('sources', ','), (',', 'may'), ('may', 'weak'), ('weak', 'security'), ('security', 'well'), ('well', 'variety'), ('variety', 'formats'), ('formats', 'large'), ('large', 'volumes'), ('volumes', '.')]

>> Trigrams are: 
 [('The', 'security', 'concern'), ('security', 'concern', 'inherent'), ('concern', 'inherent', 'big'), ('inherent', 'big', 'data'), ('big', 'data', 'include'), ('data', 'include', 'fact'), ('include', 'fact', 'big'), ('fact', 'big', 'data'), ('big', 'data', 'comes'), ('data', 'comes', 'many'), ('comes', 'many', 'different'), ('many', 'different', 'sources'), ('different', 'sources', ','), ('sources', ',', 'may'), (',', 'may', 'weak'), ('may', 'weak', 'security'), ('weak', 'security', 'well'), ('security', 'well', 'variety'), ('well', 'variety', 'formats'), ('variety', 'formats', 'large'), ('formats', 'large', 'volumes'), ('large', 'volumes', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('security', 'NN'), ('concern', 'NN'), ('inherent', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('include', 'VBP'), ('fact', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('comes', 'VBZ'), ('many', 'JJ'), ('different', 'JJ'), ('sources', 'NNS'), (',', ','), ('may', 'MD'), ('weak', 'JJ'), ('security', 'NN'), ('well', 'RB'), ('variety', 'NN'), ('formats', 'NNS'), ('large', 'JJ'), ('volumes', 'NNS'), ('.', '.')]

 (S
  (NP The/DT security/NN concern/NN)
  (NP inherent/JJ big/JJ data/NNS)
  include/VBP
  (NP fact/NN)
  (NP big/JJ data/NNS)
  comes/VBZ
  (NP many/JJ different/JJ sources/NNS)
  ,/,
  may/MD
  (NP weak/JJ security/NN)
  well/RB
  (NP variety/NN formats/NNS)
  (NP large/JJ volumes/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The security concern', 'inherent big data', 'fact', 'big data', 'many different sources', 'weak security', 'variety formats', 'large volumes']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('security', 'secur'), ('concern', 'concern'), ('inherent', 'inher'), ('big', 'big'), ('data', 'data'), ('include', 'includ'), ('fact', 'fact'), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('may', 'may'), ('weak', 'weak'), ('security', 'secur'), ('well', 'well'), ('variety', 'varieti'), ('formats', 'format'), ('large', 'larg'), ('volumes', 'volum'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('security', 'secur'), ('concern', 'concern'), ('inherent', 'inher'), ('big', 'big'), ('data', 'data'), ('include', 'includ'), ('fact', 'fact'), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (',', ','), ('may', 'may'), ('weak', 'weak'), ('security', 'secur'), ('well', 'well'), ('variety', 'varieti'), ('formats', 'format'), ('large', 'larg'), ('volumes', 'volum'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('security', 'security'), ('concern', 'concern'), ('inherent', 'inherent'), ('big', 'big'), ('data', 'data'), ('include', 'include'), ('fact', 'fact'), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('many', 'many'), ('different', 'different'), ('sources', 'source'), (',', ','), ('may', 'may'), ('weak', 'weak'), ('security', 'security'), ('well', 'well'), ('variety', 'variety'), ('formats', 'format'), ('large', 'large'), ('volumes', 'volume'), ('.', '.')]



============================ Sentence 454 =============================

Any security breaches may thus affect multiple companies   and result in financial losses, and thus, appropriate actions should be taken to reduce such big data   security risks. 


>> Tokens are: 
 ['Any', 'security', 'breaches', 'may', 'thus', 'affect', 'multiple', 'companies', 'result', 'financial', 'losses', ',', 'thus', ',', 'appropriate', 'actions', 'taken', 'reduce', 'big', 'data', 'security', 'risks', '.']

>> Bigrams are: 
 [('Any', 'security'), ('security', 'breaches'), ('breaches', 'may'), ('may', 'thus'), ('thus', 'affect'), ('affect', 'multiple'), ('multiple', 'companies'), ('companies', 'result'), ('result', 'financial'), ('financial', 'losses'), ('losses', ','), (',', 'thus'), ('thus', ','), (',', 'appropriate'), ('appropriate', 'actions'), ('actions', 'taken'), ('taken', 'reduce'), ('reduce', 'big'), ('big', 'data'), ('data', 'security'), ('security', 'risks'), ('risks', '.')]

>> Trigrams are: 
 [('Any', 'security', 'breaches'), ('security', 'breaches', 'may'), ('breaches', 'may', 'thus'), ('may', 'thus', 'affect'), ('thus', 'affect', 'multiple'), ('affect', 'multiple', 'companies'), ('multiple', 'companies', 'result'), ('companies', 'result', 'financial'), ('result', 'financial', 'losses'), ('financial', 'losses', ','), ('losses', ',', 'thus'), (',', 'thus', ','), ('thus', ',', 'appropriate'), (',', 'appropriate', 'actions'), ('appropriate', 'actions', 'taken'), ('actions', 'taken', 'reduce'), ('taken', 'reduce', 'big'), ('reduce', 'big', 'data'), ('big', 'data', 'security'), ('data', 'security', 'risks'), ('security', 'risks', '.')]

>> POS Tags are: 
 [('Any', 'DT'), ('security', 'NN'), ('breaches', 'NNS'), ('may', 'MD'), ('thus', 'RB'), ('affect', 'VB'), ('multiple', 'JJ'), ('companies', 'NNS'), ('result', 'VBP'), ('financial', 'JJ'), ('losses', 'NNS'), (',', ','), ('thus', 'RB'), (',', ','), ('appropriate', 'JJ'), ('actions', 'NNS'), ('taken', 'VBN'), ('reduce', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('security', 'NN'), ('risks', 'NNS'), ('.', '.')]

 (S
  (NP Any/DT security/NN breaches/NNS)
  may/MD
  thus/RB
  affect/VB
  (NP multiple/JJ companies/NNS)
  result/VBP
  (NP financial/JJ losses/NNS)
  ,/,
  thus/RB
  ,/,
  (NP appropriate/JJ actions/NNS)
  taken/VBN
  reduce/VB
  (NP big/JJ data/NNS security/NN risks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Any security breaches', 'multiple companies', 'financial losses', 'appropriate actions', 'big data security risks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Any', 'ani'), ('security', 'secur'), ('breaches', 'breach'), ('may', 'may'), ('thus', 'thu'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani'), ('result', 'result'), ('financial', 'financi'), ('losses', 'loss'), (',', ','), ('thus', 'thu'), (',', ','), ('appropriate', 'appropri'), ('actions', 'action'), ('taken', 'taken'), ('reduce', 'reduc'), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Any', 'ani'), ('security', 'secur'), ('breaches', 'breach'), ('may', 'may'), ('thus', 'thus'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani'), ('result', 'result'), ('financial', 'financi'), ('losses', 'loss'), (',', ','), ('thus', 'thus'), (',', ','), ('appropriate', 'appropri'), ('actions', 'action'), ('taken', 'taken'), ('reduce', 'reduc'), ('big', 'big'), ('data', 'data'), ('security', 'secur'), ('risks', 'risk'), ('.', '.')]

>> Lemmatization: 
 [('Any', 'Any'), ('security', 'security'), ('breaches', 'breach'), ('may', 'may'), ('thus', 'thus'), ('affect', 'affect'), ('multiple', 'multiple'), ('companies', 'company'), ('result', 'result'), ('financial', 'financial'), ('losses', 'loss'), (',', ','), ('thus', 'thus'), (',', ','), ('appropriate', 'appropriate'), ('actions', 'action'), ('taken', 'taken'), ('reduce', 'reduce'), ('big', 'big'), ('data', 'data'), ('security', 'security'), ('risks', 'risk'), ('.', '.')]



============================ Sentence 455 =============================

Data sources should be monitored by organisations, with end-to-end encryption used to prevent   anyone from accessing the data in transit. 


>> Tokens are: 
 ['Data', 'sources', 'monitored', 'organisations', ',', 'end-to-end', 'encryption', 'used', 'prevent', 'anyone', 'accessing', 'data', 'transit', '.']

>> Bigrams are: 
 [('Data', 'sources'), ('sources', 'monitored'), ('monitored', 'organisations'), ('organisations', ','), (',', 'end-to-end'), ('end-to-end', 'encryption'), ('encryption', 'used'), ('used', 'prevent'), ('prevent', 'anyone'), ('anyone', 'accessing'), ('accessing', 'data'), ('data', 'transit'), ('transit', '.')]

>> Trigrams are: 
 [('Data', 'sources', 'monitored'), ('sources', 'monitored', 'organisations'), ('monitored', 'organisations', ','), ('organisations', ',', 'end-to-end'), (',', 'end-to-end', 'encryption'), ('end-to-end', 'encryption', 'used'), ('encryption', 'used', 'prevent'), ('used', 'prevent', 'anyone'), ('prevent', 'anyone', 'accessing'), ('anyone', 'accessing', 'data'), ('accessing', 'data', 'transit'), ('data', 'transit', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('sources', 'NNS'), ('monitored', 'VBD'), ('organisations', 'NNS'), (',', ','), ('end-to-end', 'JJ'), ('encryption', 'NN'), ('used', 'VBN'), ('prevent', 'NN'), ('anyone', 'NN'), ('accessing', 'VBG'), ('data', 'NNS'), ('transit', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP sources/NNS)
  monitored/VBD
  (NP organisations/NNS)
  ,/,
  (NP end-to-end/JJ encryption/NN)
  used/VBN
  (NP prevent/NN anyone/NN)
  accessing/VBG
  (NP data/NNS transit/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data sources', 'organisations', 'end-to-end encryption', 'prevent anyone', 'data transit']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('sources', 'sourc'), ('monitored', 'monitor'), ('organisations', 'organis'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent'), ('anyone', 'anyon'), ('accessing', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('sources', 'sourc'), ('monitored', 'monitor'), ('organisations', 'organis'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encrypt'), ('used', 'use'), ('prevent', 'prevent'), ('anyone', 'anyon'), ('accessing', 'access'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('sources', 'source'), ('monitored', 'monitored'), ('organisations', 'organisation'), (',', ','), ('end-to-end', 'end-to-end'), ('encryption', 'encryption'), ('used', 'used'), ('prevent', 'prevent'), ('anyone', 'anyone'), ('accessing', 'accessing'), ('data', 'data'), ('transit', 'transit'), ('.', '.')]



============================ Sentence 456 =============================

Companies should also check their cloud providers, as   many cloud providers do not encrypt the data due to the quantity of data transferred at any given   time, as encryption/decryption slows down the flow of data. 


>> Tokens are: 
 ['Companies', 'also', 'check', 'cloud', 'providers', ',', 'many', 'cloud', 'providers', 'encrypt', 'data', 'due', 'quantity', 'data', 'transferred', 'given', 'time', ',', 'encryption/decryption', 'slows', 'flow', 'data', '.']

>> Bigrams are: 
 [('Companies', 'also'), ('also', 'check'), ('check', 'cloud'), ('cloud', 'providers'), ('providers', ','), (',', 'many'), ('many', 'cloud'), ('cloud', 'providers'), ('providers', 'encrypt'), ('encrypt', 'data'), ('data', 'due'), ('due', 'quantity'), ('quantity', 'data'), ('data', 'transferred'), ('transferred', 'given'), ('given', 'time'), ('time', ','), (',', 'encryption/decryption'), ('encryption/decryption', 'slows'), ('slows', 'flow'), ('flow', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Companies', 'also', 'check'), ('also', 'check', 'cloud'), ('check', 'cloud', 'providers'), ('cloud', 'providers', ','), ('providers', ',', 'many'), (',', 'many', 'cloud'), ('many', 'cloud', 'providers'), ('cloud', 'providers', 'encrypt'), ('providers', 'encrypt', 'data'), ('encrypt', 'data', 'due'), ('data', 'due', 'quantity'), ('due', 'quantity', 'data'), ('quantity', 'data', 'transferred'), ('data', 'transferred', 'given'), ('transferred', 'given', 'time'), ('given', 'time', ','), ('time', ',', 'encryption/decryption'), (',', 'encryption/decryption', 'slows'), ('encryption/decryption', 'slows', 'flow'), ('slows', 'flow', 'data'), ('flow', 'data', '.')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('also', 'RB'), ('check', 'VBP'), ('cloud', 'JJ'), ('providers', 'NNS'), (',', ','), ('many', 'JJ'), ('cloud', 'VBP'), ('providers', 'NNS'), ('encrypt', 'VBP'), ('data', 'NNS'), ('due', 'JJ'), ('quantity', 'NN'), ('data', 'NNS'), ('transferred', 'VBD'), ('given', 'VBN'), ('time', 'NN'), (',', ','), ('encryption/decryption', 'NN'), ('slows', 'NNS'), ('flow', 'VBP'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Companies/NNS)
  also/RB
  check/VBP
  (NP cloud/JJ providers/NNS)
  ,/,
  many/JJ
  cloud/VBP
  (NP providers/NNS)
  encrypt/VBP
  (NP data/NNS)
  (NP due/JJ quantity/NN data/NNS)
  transferred/VBD
  given/VBN
  (NP time/NN)
  ,/,
  (NP encryption/decryption/NN slows/NNS)
  flow/VBP
  (NP data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Companies', 'cloud providers', 'providers', 'data', 'due quantity data', 'time', 'encryption/decryption slows', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('also', 'also'), ('check', 'check'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ','), ('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data'), ('due', 'due'), ('quantity', 'quantiti'), ('data', 'data'), ('transferred', 'transfer'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt'), ('slows', 'slow'), ('flow', 'flow'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('also', 'also'), ('check', 'check'), ('cloud', 'cloud'), ('providers', 'provid'), (',', ','), ('many', 'mani'), ('cloud', 'cloud'), ('providers', 'provid'), ('encrypt', 'encrypt'), ('data', 'data'), ('due', 'due'), ('quantity', 'quantiti'), ('data', 'data'), ('transferred', 'transfer'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decrypt'), ('slows', 'slow'), ('flow', 'flow'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('also', 'also'), ('check', 'check'), ('cloud', 'cloud'), ('providers', 'provider'), (',', ','), ('many', 'many'), ('cloud', 'cloud'), ('providers', 'provider'), ('encrypt', 'encrypt'), ('data', 'data'), ('due', 'due'), ('quantity', 'quantity'), ('data', 'data'), ('transferred', 'transferred'), ('given', 'given'), ('time', 'time'), (',', ','), ('encryption/decryption', 'encryption/decryption'), ('slows', 'slows'), ('flow', 'flow'), ('data', 'data'), ('.', '.')]



============================ Sentence 457 =============================

Sarah Al-Shiakhli   38      Big data is defined by the 5V’s, and these charecteristics, especially the volume aspect, mean that   it cannot be processed with traditional data analytic techniques. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '38', 'Big', 'data', 'defined', '5V', '’', ',', 'charecteristics', ',', 'especially', 'volume', 'aspect', ',', 'mean', 'processed', 'traditional', 'data', 'analytic', 'techniques', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '38'), ('38', 'Big'), ('Big', 'data'), ('data', 'defined'), ('defined', '5V'), ('5V', '’'), ('’', ','), (',', 'charecteristics'), ('charecteristics', ','), (',', 'especially'), ('especially', 'volume'), ('volume', 'aspect'), ('aspect', ','), (',', 'mean'), ('mean', 'processed'), ('processed', 'traditional'), ('traditional', 'data'), ('data', 'analytic'), ('analytic', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '38'), ('Al-Shiakhli', '38', 'Big'), ('38', 'Big', 'data'), ('Big', 'data', 'defined'), ('data', 'defined', '5V'), ('defined', '5V', '’'), ('5V', '’', ','), ('’', ',', 'charecteristics'), (',', 'charecteristics', ','), ('charecteristics', ',', 'especially'), (',', 'especially', 'volume'), ('especially', 'volume', 'aspect'), ('volume', 'aspect', ','), ('aspect', ',', 'mean'), (',', 'mean', 'processed'), ('mean', 'processed', 'traditional'), ('processed', 'traditional', 'data'), ('traditional', 'data', 'analytic'), ('data', 'analytic', 'techniques'), ('analytic', 'techniques', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('38', 'CD'), ('Big', 'NNP'), ('data', 'NNS'), ('defined', 'VBD'), ('5V', 'CD'), ('’', 'NN'), (',', ','), ('charecteristics', 'NNS'), (',', ','), ('especially', 'RB'), ('volume', 'NN'), ('aspect', 'NN'), (',', ','), ('mean', 'NN'), ('processed', 'VBD'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytic', 'JJ'), ('techniques', 'NNS'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  38/CD
  (NP Big/NNP data/NNS)
  defined/VBD
  5V/CD
  (NP ’/NN)
  ,/,
  (NP charecteristics/NNS)
  ,/,
  especially/RB
  (NP volume/NN aspect/NN)
  ,/,
  (NP mean/NN)
  processed/VBD
  (NP traditional/JJ data/NNS)
  (NP analytic/JJ techniques/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Big data', '’', 'charecteristics', 'volume aspect', 'mean', 'traditional data', 'analytic techniques']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('38', '38'), ('Big', 'big'), ('data', 'data'), ('defined', 'defin'), ('5V', '5v'), ('’', '’'), (',', ','), ('charecteristics', 'charecterist'), (',', ','), ('especially', 'especi'), ('volume', 'volum'), ('aspect', 'aspect'), (',', ','), ('mean', 'mean'), ('processed', 'process'), ('traditional', 'tradit'), ('data', 'data'), ('analytic', 'analyt'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('38', '38'), ('Big', 'big'), ('data', 'data'), ('defined', 'defin'), ('5V', '5v'), ('’', '’'), (',', ','), ('charecteristics', 'charecterist'), (',', ','), ('especially', 'especi'), ('volume', 'volum'), ('aspect', 'aspect'), (',', ','), ('mean', 'mean'), ('processed', 'process'), ('traditional', 'tradit'), ('data', 'data'), ('analytic', 'analyt'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('38', '38'), ('Big', 'Big'), ('data', 'data'), ('defined', 'defined'), ('5V', '5V'), ('’', '’'), (',', ','), ('charecteristics', 'charecteristics'), (',', ','), ('especially', 'especially'), ('volume', 'volume'), ('aspect', 'aspect'), (',', ','), ('mean', 'mean'), ('processed', 'processed'), ('traditional', 'traditional'), ('data', 'data'), ('analytic', 'analytic'), ('techniques', 'technique'), ('.', '.')]



============================ Sentence 458 =============================

Large amounts of complex data   need time for analysis. 


>> Tokens are: 
 ['Large', 'amounts', 'complex', 'data', 'need', 'time', 'analysis', '.']

>> Bigrams are: 
 [('Large', 'amounts'), ('amounts', 'complex'), ('complex', 'data'), ('data', 'need'), ('need', 'time'), ('time', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Large', 'amounts', 'complex'), ('amounts', 'complex', 'data'), ('complex', 'data', 'need'), ('data', 'need', 'time'), ('need', 'time', 'analysis'), ('time', 'analysis', '.')]

>> POS Tags are: 
 [('Large', 'JJ'), ('amounts', 'NNS'), ('complex', 'JJ'), ('data', 'NNS'), ('need', 'NN'), ('time', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP Large/JJ amounts/NNS)
  (NP complex/JJ data/NNS need/NN time/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['Large amounts', 'complex data need time analysis']

>> Named Entities are: 
 [('GPE', 'Large')] 

>> Stemming using Porter Stemmer: 
 [('Large', 'larg'), ('amounts', 'amount'), ('complex', 'complex'), ('data', 'data'), ('need', 'need'), ('time', 'time'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Large', 'larg'), ('amounts', 'amount'), ('complex', 'complex'), ('data', 'data'), ('need', 'need'), ('time', 'time'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Large', 'Large'), ('amounts', 'amount'), ('complex', 'complex'), ('data', 'data'), ('need', 'need'), ('time', 'time'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 459 =============================

Therefore, big data faces intrusion detection challenges, as the system busy   times are extended. 


>> Tokens are: 
 ['Therefore', ',', 'big', 'data', 'faces', 'intrusion', 'detection', 'challenges', ',', 'system', 'busy', 'times', 'extended', '.']

>> Bigrams are: 
 [('Therefore', ','), (',', 'big'), ('big', 'data'), ('data', 'faces'), ('faces', 'intrusion'), ('intrusion', 'detection'), ('detection', 'challenges'), ('challenges', ','), (',', 'system'), ('system', 'busy'), ('busy', 'times'), ('times', 'extended'), ('extended', '.')]

>> Trigrams are: 
 [('Therefore', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'faces'), ('data', 'faces', 'intrusion'), ('faces', 'intrusion', 'detection'), ('intrusion', 'detection', 'challenges'), ('detection', 'challenges', ','), ('challenges', ',', 'system'), (',', 'system', 'busy'), ('system', 'busy', 'times'), ('busy', 'times', 'extended'), ('times', 'extended', '.')]

>> POS Tags are: 
 [('Therefore', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('faces', 'VBZ'), ('intrusion', 'NN'), ('detection', 'NN'), ('challenges', 'NNS'), (',', ','), ('system', 'NN'), ('busy', 'JJ'), ('times', 'NNS'), ('extended', 'VBN'), ('.', '.')]

 (S
  Therefore/RB
  ,/,
  (NP big/JJ data/NNS)
  faces/VBZ
  (NP intrusion/NN detection/NN challenges/NNS)
  ,/,
  (NP system/NN)
  (NP busy/JJ times/NNS)
  extended/VBN
  ./.) 


>> Noun Phrases are: 
 ['big data', 'intrusion detection challenges', 'system', 'busy times']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('big', 'big'), ('data', 'data'), ('faces', 'face'), ('intrusion', 'intrus'), ('detection', 'detect'), ('challenges', 'challeng'), (',', ','), ('system', 'system'), ('busy', 'busi'), ('times', 'time'), ('extended', 'extend'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Therefore', 'therefor'), (',', ','), ('big', 'big'), ('data', 'data'), ('faces', 'face'), ('intrusion', 'intrus'), ('detection', 'detect'), ('challenges', 'challeng'), (',', ','), ('system', 'system'), ('busy', 'busi'), ('times', 'time'), ('extended', 'extend'), ('.', '.')]

>> Lemmatization: 
 [('Therefore', 'Therefore'), (',', ','), ('big', 'big'), ('data', 'data'), ('faces', 'face'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('challenges', 'challenge'), (',', ','), ('system', 'system'), ('busy', 'busy'), ('times', 'time'), ('extended', 'extended'), ('.', '.')]



============================ Sentence 460 =============================

Although many security monitoring systems have been developed to improve   data security, intrusion detection is still challenging, even for isolated systems. 


>> Tokens are: 
 ['Although', 'many', 'security', 'monitoring', 'systems', 'developed', 'improve', 'data', 'security', ',', 'intrusion', 'detection', 'still', 'challenging', ',', 'even', 'isolated', 'systems', '.']

>> Bigrams are: 
 [('Although', 'many'), ('many', 'security'), ('security', 'monitoring'), ('monitoring', 'systems'), ('systems', 'developed'), ('developed', 'improve'), ('improve', 'data'), ('data', 'security'), ('security', ','), (',', 'intrusion'), ('intrusion', 'detection'), ('detection', 'still'), ('still', 'challenging'), ('challenging', ','), (',', 'even'), ('even', 'isolated'), ('isolated', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('Although', 'many', 'security'), ('many', 'security', 'monitoring'), ('security', 'monitoring', 'systems'), ('monitoring', 'systems', 'developed'), ('systems', 'developed', 'improve'), ('developed', 'improve', 'data'), ('improve', 'data', 'security'), ('data', 'security', ','), ('security', ',', 'intrusion'), (',', 'intrusion', 'detection'), ('intrusion', 'detection', 'still'), ('detection', 'still', 'challenging'), ('still', 'challenging', ','), ('challenging', ',', 'even'), (',', 'even', 'isolated'), ('even', 'isolated', 'systems'), ('isolated', 'systems', '.')]

>> POS Tags are: 
 [('Although', 'IN'), ('many', 'JJ'), ('security', 'NN'), ('monitoring', 'VBG'), ('systems', 'NNS'), ('developed', 'VBN'), ('improve', 'VB'), ('data', 'NNS'), ('security', 'NN'), (',', ','), ('intrusion', 'NN'), ('detection', 'NN'), ('still', 'RB'), ('challenging', 'VBG'), (',', ','), ('even', 'RB'), ('isolated', 'JJ'), ('systems', 'NNS'), ('.', '.')]

 (S
  Although/IN
  (NP many/JJ security/NN)
  monitoring/VBG
  (NP systems/NNS)
  developed/VBN
  improve/VB
  (NP data/NNS security/NN)
  ,/,
  (NP intrusion/NN detection/NN)
  still/RB
  challenging/VBG
  ,/,
  even/RB
  (NP isolated/JJ systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['many security', 'systems', 'data security', 'intrusion detection', 'isolated systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Although', 'although'), ('many', 'mani'), ('security', 'secur'), ('monitoring', 'monitor'), ('systems', 'system'), ('developed', 'develop'), ('improve', 'improv'), ('data', 'data'), ('security', 'secur'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), ('still', 'still'), ('challenging', 'challeng'), (',', ','), ('even', 'even'), ('isolated', 'isol'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Although', 'although'), ('many', 'mani'), ('security', 'secur'), ('monitoring', 'monitor'), ('systems', 'system'), ('developed', 'develop'), ('improve', 'improv'), ('data', 'data'), ('security', 'secur'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), ('still', 'still'), ('challenging', 'challeng'), (',', ','), ('even', 'even'), ('isolated', 'isol'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('Although', 'Although'), ('many', 'many'), ('security', 'security'), ('monitoring', 'monitoring'), ('systems', 'system'), ('developed', 'developed'), ('improve', 'improve'), ('data', 'data'), ('security', 'security'), (',', ','), ('intrusion', 'intrusion'), ('detection', 'detection'), ('still', 'still'), ('challenging', 'challenging'), (',', ','), ('even', 'even'), ('isolated', 'isolated'), ('systems', 'system'), ('.', '.')]



============================ Sentence 461 =============================

The issues include   how to store large quantities of data safely, how to maintain security, and how to track data that   flows quickly from different sources. 


>> Tokens are: 
 ['The', 'issues', 'include', 'store', 'large', 'quantities', 'data', 'safely', ',', 'maintain', 'security', ',', 'track', 'data', 'flows', 'quickly', 'different', 'sources', '.']

>> Bigrams are: 
 [('The', 'issues'), ('issues', 'include'), ('include', 'store'), ('store', 'large'), ('large', 'quantities'), ('quantities', 'data'), ('data', 'safely'), ('safely', ','), (',', 'maintain'), ('maintain', 'security'), ('security', ','), (',', 'track'), ('track', 'data'), ('data', 'flows'), ('flows', 'quickly'), ('quickly', 'different'), ('different', 'sources'), ('sources', '.')]

>> Trigrams are: 
 [('The', 'issues', 'include'), ('issues', 'include', 'store'), ('include', 'store', 'large'), ('store', 'large', 'quantities'), ('large', 'quantities', 'data'), ('quantities', 'data', 'safely'), ('data', 'safely', ','), ('safely', ',', 'maintain'), (',', 'maintain', 'security'), ('maintain', 'security', ','), ('security', ',', 'track'), (',', 'track', 'data'), ('track', 'data', 'flows'), ('data', 'flows', 'quickly'), ('flows', 'quickly', 'different'), ('quickly', 'different', 'sources'), ('different', 'sources', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('issues', 'NNS'), ('include', 'VBP'), ('store', 'RB'), ('large', 'JJ'), ('quantities', 'NNS'), ('data', 'NNS'), ('safely', 'RB'), (',', ','), ('maintain', 'VBP'), ('security', 'NN'), (',', ','), ('track', 'NN'), ('data', 'NNS'), ('flows', 'VBZ'), ('quickly', 'RB'), ('different', 'JJ'), ('sources', 'NNS'), ('.', '.')]

 (S
  (NP The/DT issues/NNS)
  include/VBP
  store/RB
  (NP large/JJ quantities/NNS data/NNS)
  safely/RB
  ,/,
  maintain/VBP
  (NP security/NN)
  ,/,
  (NP track/NN data/NNS)
  flows/VBZ
  quickly/RB
  (NP different/JJ sources/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The issues', 'large quantities data', 'security', 'track data', 'different sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('issues', 'issu'), ('include', 'includ'), ('store', 'store'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('safely', 'safe'), (',', ','), ('maintain', 'maintain'), ('security', 'secur'), (',', ','), ('track', 'track'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quickli'), ('different', 'differ'), ('sources', 'sourc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('issues', 'issu'), ('include', 'includ'), ('store', 'store'), ('large', 'larg'), ('quantities', 'quantiti'), ('data', 'data'), ('safely', 'safe'), (',', ','), ('maintain', 'maintain'), ('security', 'secur'), (',', ','), ('track', 'track'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quick'), ('different', 'differ'), ('sources', 'sourc'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('issues', 'issue'), ('include', 'include'), ('store', 'store'), ('large', 'large'), ('quantities', 'quantity'), ('data', 'data'), ('safely', 'safely'), (',', ','), ('maintain', 'maintain'), ('security', 'security'), (',', ','), ('track', 'track'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quickly'), ('different', 'different'), ('sources', 'source'), ('.', '.')]



============================ Sentence 462 =============================

Solution to these challenges include taking a more   comprehensive approach to monitoring the data that comes from different sources in order to   develop better situational awareness of the threats in cyberspace. 


>> Tokens are: 
 ['Solution', 'challenges', 'include', 'taking', 'comprehensive', 'approach', 'monitoring', 'data', 'comes', 'different', 'sources', 'order', 'develop', 'better', 'situational', 'awareness', 'threats', 'cyberspace', '.']

>> Bigrams are: 
 [('Solution', 'challenges'), ('challenges', 'include'), ('include', 'taking'), ('taking', 'comprehensive'), ('comprehensive', 'approach'), ('approach', 'monitoring'), ('monitoring', 'data'), ('data', 'comes'), ('comes', 'different'), ('different', 'sources'), ('sources', 'order'), ('order', 'develop'), ('develop', 'better'), ('better', 'situational'), ('situational', 'awareness'), ('awareness', 'threats'), ('threats', 'cyberspace'), ('cyberspace', '.')]

>> Trigrams are: 
 [('Solution', 'challenges', 'include'), ('challenges', 'include', 'taking'), ('include', 'taking', 'comprehensive'), ('taking', 'comprehensive', 'approach'), ('comprehensive', 'approach', 'monitoring'), ('approach', 'monitoring', 'data'), ('monitoring', 'data', 'comes'), ('data', 'comes', 'different'), ('comes', 'different', 'sources'), ('different', 'sources', 'order'), ('sources', 'order', 'develop'), ('order', 'develop', 'better'), ('develop', 'better', 'situational'), ('better', 'situational', 'awareness'), ('situational', 'awareness', 'threats'), ('awareness', 'threats', 'cyberspace'), ('threats', 'cyberspace', '.')]

>> POS Tags are: 
 [('Solution', 'NN'), ('challenges', 'NNS'), ('include', 'VBP'), ('taking', 'VBG'), ('comprehensive', 'JJ'), ('approach', 'NN'), ('monitoring', 'NN'), ('data', 'NNS'), ('comes', 'VBZ'), ('different', 'JJ'), ('sources', 'NNS'), ('order', 'NN'), ('develop', 'VBP'), ('better', 'RBR'), ('situational', 'JJ'), ('awareness', 'NN'), ('threats', 'NNS'), ('cyberspace', 'VBP'), ('.', '.')]

 (S
  (NP Solution/NN challenges/NNS)
  include/VBP
  taking/VBG
  (NP comprehensive/JJ approach/NN monitoring/NN data/NNS)
  comes/VBZ
  (NP different/JJ sources/NNS order/NN)
  develop/VBP
  better/RBR
  (NP situational/JJ awareness/NN threats/NNS)
  cyberspace/VBP
  ./.) 


>> Noun Phrases are: 
 ['Solution challenges', 'comprehensive approach monitoring data', 'different sources order', 'situational awareness threats']

>> Named Entities are: 
 [('GPE', 'Solution')] 

>> Stemming using Porter Stemmer: 
 [('Solution', 'solut'), ('challenges', 'challeng'), ('include', 'includ'), ('taking', 'take'), ('comprehensive', 'comprehens'), ('approach', 'approach'), ('monitoring', 'monitor'), ('data', 'data'), ('comes', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('order', 'order'), ('develop', 'develop'), ('better', 'better'), ('situational', 'situat'), ('awareness', 'awar'), ('threats', 'threat'), ('cyberspace', 'cyberspac'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Solution', 'solut'), ('challenges', 'challeng'), ('include', 'includ'), ('taking', 'take'), ('comprehensive', 'comprehens'), ('approach', 'approach'), ('monitoring', 'monitor'), ('data', 'data'), ('comes', 'come'), ('different', 'differ'), ('sources', 'sourc'), ('order', 'order'), ('develop', 'develop'), ('better', 'better'), ('situational', 'situat'), ('awareness', 'awar'), ('threats', 'threat'), ('cyberspace', 'cyberspac'), ('.', '.')]

>> Lemmatization: 
 [('Solution', 'Solution'), ('challenges', 'challenge'), ('include', 'include'), ('taking', 'taking'), ('comprehensive', 'comprehensive'), ('approach', 'approach'), ('monitoring', 'monitoring'), ('data', 'data'), ('comes', 'come'), ('different', 'different'), ('sources', 'source'), ('order', 'order'), ('develop', 'develop'), ('better', 'better'), ('situational', 'situational'), ('awareness', 'awareness'), ('threats', 'threat'), ('cyberspace', 'cyberspace'), ('.', '.')]



============================ Sentence 463 =============================

This helps minimise false alarms   and maximise intrusion detection. 


>> Tokens are: 
 ['This', 'helps', 'minimise', 'false', 'alarms', 'maximise', 'intrusion', 'detection', '.']

>> Bigrams are: 
 [('This', 'helps'), ('helps', 'minimise'), ('minimise', 'false'), ('false', 'alarms'), ('alarms', 'maximise'), ('maximise', 'intrusion'), ('intrusion', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('This', 'helps', 'minimise'), ('helps', 'minimise', 'false'), ('minimise', 'false', 'alarms'), ('false', 'alarms', 'maximise'), ('alarms', 'maximise', 'intrusion'), ('maximise', 'intrusion', 'detection'), ('intrusion', 'detection', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('helps', 'VBZ'), ('minimise', 'VB'), ('false', 'JJ'), ('alarms', 'NNS'), ('maximise', 'VBP'), ('intrusion', 'NN'), ('detection', 'NN'), ('.', '.')]

 (S
  This/DT
  helps/VBZ
  minimise/VB
  (NP false/JJ alarms/NNS)
  maximise/VBP
  (NP intrusion/NN detection/NN)
  ./.) 


>> Noun Phrases are: 
 ['false alarms', 'intrusion detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('helps', 'help'), ('minimise', 'minimis'), ('false', 'fals'), ('alarms', 'alarm'), ('maximise', 'maximis'), ('intrusion', 'intrus'), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('helps', 'help'), ('minimise', 'minimis'), ('false', 'fals'), ('alarms', 'alarm'), ('maximise', 'maximis'), ('intrusion', 'intrus'), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('helps', 'help'), ('minimise', 'minimise'), ('false', 'false'), ('alarms', 'alarm'), ('maximise', 'maximise'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('.', '.')]



============================ Sentence 464 =============================

The big data challenges for intrusion detection can also be   addressed by using traditional computing storage platforms such as Hadoop, an open source   distributed storage platform used for storing large amounts of data that flows quickly (Suthaharan,   2014; Zuech et al., 2015). 


>> Tokens are: 
 ['The', 'big', 'data', 'challenges', 'intrusion', 'detection', 'also', 'addressed', 'using', 'traditional', 'computing', 'storage', 'platforms', 'Hadoop', ',', 'open', 'source', 'distributed', 'storage', 'platform', 'used', 'storing', 'large', 'amounts', 'data', 'flows', 'quickly', '(', 'Suthaharan', ',', '2014', ';', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'intrusion'), ('intrusion', 'detection'), ('detection', 'also'), ('also', 'addressed'), ('addressed', 'using'), ('using', 'traditional'), ('traditional', 'computing'), ('computing', 'storage'), ('storage', 'platforms'), ('platforms', 'Hadoop'), ('Hadoop', ','), (',', 'open'), ('open', 'source'), ('source', 'distributed'), ('distributed', 'storage'), ('storage', 'platform'), ('platform', 'used'), ('used', 'storing'), ('storing', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', 'flows'), ('flows', 'quickly'), ('quickly', '('), ('(', 'Suthaharan'), ('Suthaharan', ','), (',', '2014'), ('2014', ';'), (';', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'intrusion'), ('challenges', 'intrusion', 'detection'), ('intrusion', 'detection', 'also'), ('detection', 'also', 'addressed'), ('also', 'addressed', 'using'), ('addressed', 'using', 'traditional'), ('using', 'traditional', 'computing'), ('traditional', 'computing', 'storage'), ('computing', 'storage', 'platforms'), ('storage', 'platforms', 'Hadoop'), ('platforms', 'Hadoop', ','), ('Hadoop', ',', 'open'), (',', 'open', 'source'), ('open', 'source', 'distributed'), ('source', 'distributed', 'storage'), ('distributed', 'storage', 'platform'), ('storage', 'platform', 'used'), ('platform', 'used', 'storing'), ('used', 'storing', 'large'), ('storing', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', 'flows'), ('data', 'flows', 'quickly'), ('flows', 'quickly', '('), ('quickly', '(', 'Suthaharan'), ('(', 'Suthaharan', ','), ('Suthaharan', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Zuech'), (';', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('intrusion', 'NN'), ('detection', 'NN'), ('also', 'RB'), ('addressed', 'VBD'), ('using', 'VBG'), ('traditional', 'JJ'), ('computing', 'NN'), ('storage', 'NN'), ('platforms', 'NNS'), ('Hadoop', 'NNP'), (',', ','), ('open', 'JJ'), ('source', 'NN'), ('distributed', 'VBN'), ('storage', 'NN'), ('platform', 'NN'), ('used', 'VBN'), ('storing', 'VBG'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('flows', 'NNS'), ('quickly', 'RB'), ('(', '('), ('Suthaharan', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Zuech', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP
    The/DT
    big/JJ
    data/NNS
    challenges/NNS
    intrusion/NN
    detection/NN)
  also/RB
  addressed/VBD
  using/VBG
  (NP
    traditional/JJ
    computing/NN
    storage/NN
    platforms/NNS
    Hadoop/NNP)
  ,/,
  (NP open/JJ source/NN)
  distributed/VBN
  (NP storage/NN platform/NN)
  used/VBN
  storing/VBG
  (NP large/JJ amounts/NNS data/NNS flows/NNS)
  quickly/RB
  (/(
  (NP Suthaharan/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Zuech/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The big data challenges intrusion detection', 'traditional computing storage platforms Hadoop', 'open source', 'storage platform', 'large amounts data flows', 'Suthaharan', 'Zuech', 'al.']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('ORGANIZATION', 'Suthaharan'), ('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('intrusion', 'intrus'), ('detection', 'detect'), ('also', 'also'), ('addressed', 'address'), ('using', 'use'), ('traditional', 'tradit'), ('computing', 'comput'), ('storage', 'storag'), ('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('open', 'open'), ('source', 'sourc'), ('distributed', 'distribut'), ('storage', 'storag'), ('platform', 'platform'), ('used', 'use'), ('storing', 'store'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quickli'), ('(', '('), ('Suthaharan', 'suthaharan'), (',', ','), ('2014', '2014'), (';', ';'), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('intrusion', 'intrus'), ('detection', 'detect'), ('also', 'also'), ('addressed', 'address'), ('using', 'use'), ('traditional', 'tradit'), ('computing', 'comput'), ('storage', 'storag'), ('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('open', 'open'), ('source', 'sourc'), ('distributed', 'distribut'), ('storage', 'storag'), ('platform', 'platform'), ('used', 'use'), ('storing', 'store'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quick'), ('(', '('), ('Suthaharan', 'suthaharan'), (',', ','), ('2014', '2014'), (';', ';'), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('also', 'also'), ('addressed', 'addressed'), ('using', 'using'), ('traditional', 'traditional'), ('computing', 'computing'), ('storage', 'storage'), ('platforms', 'platform'), ('Hadoop', 'Hadoop'), (',', ','), ('open', 'open'), ('source', 'source'), ('distributed', 'distributed'), ('storage', 'storage'), ('platform', 'platform'), ('used', 'used'), ('storing', 'storing'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('flows', 'flow'), ('quickly', 'quickly'), ('(', '('), ('Suthaharan', 'Suthaharan'), (',', ','), ('2014', '2014'), (';', ';'), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 465 =============================

Suthaharan (2014) proposed using big data technologies such as Hadoop to address intrusion   detection issues, and in addition, he proposed the 3Cs, Cardinality, Continuity, and Complexity,   for use in developing mathematical and statistical tools. 


>> Tokens are: 
 ['Suthaharan', '(', '2014', ')', 'proposed', 'using', 'big', 'data', 'technologies', 'Hadoop', 'address', 'intrusion', 'detection', 'issues', ',', 'addition', ',', 'proposed', '3Cs', ',', 'Cardinality', ',', 'Continuity', ',', 'Complexity', ',', 'use', 'developing', 'mathematical', 'statistical', 'tools', '.']

>> Bigrams are: 
 [('Suthaharan', '('), ('(', '2014'), ('2014', ')'), (')', 'proposed'), ('proposed', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'technologies'), ('technologies', 'Hadoop'), ('Hadoop', 'address'), ('address', 'intrusion'), ('intrusion', 'detection'), ('detection', 'issues'), ('issues', ','), (',', 'addition'), ('addition', ','), (',', 'proposed'), ('proposed', '3Cs'), ('3Cs', ','), (',', 'Cardinality'), ('Cardinality', ','), (',', 'Continuity'), ('Continuity', ','), (',', 'Complexity'), ('Complexity', ','), (',', 'use'), ('use', 'developing'), ('developing', 'mathematical'), ('mathematical', 'statistical'), ('statistical', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('Suthaharan', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'proposed'), (')', 'proposed', 'using'), ('proposed', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'technologies'), ('data', 'technologies', 'Hadoop'), ('technologies', 'Hadoop', 'address'), ('Hadoop', 'address', 'intrusion'), ('address', 'intrusion', 'detection'), ('intrusion', 'detection', 'issues'), ('detection', 'issues', ','), ('issues', ',', 'addition'), (',', 'addition', ','), ('addition', ',', 'proposed'), (',', 'proposed', '3Cs'), ('proposed', '3Cs', ','), ('3Cs', ',', 'Cardinality'), (',', 'Cardinality', ','), ('Cardinality', ',', 'Continuity'), (',', 'Continuity', ','), ('Continuity', ',', 'Complexity'), (',', 'Complexity', ','), ('Complexity', ',', 'use'), (',', 'use', 'developing'), ('use', 'developing', 'mathematical'), ('developing', 'mathematical', 'statistical'), ('mathematical', 'statistical', 'tools'), ('statistical', 'tools', '.')]

>> POS Tags are: 
 [('Suthaharan', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('proposed', 'VBN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('technologies', 'NNS'), ('Hadoop', 'NNP'), ('address', 'NN'), ('intrusion', 'NN'), ('detection', 'NN'), ('issues', 'NNS'), (',', ','), ('addition', 'NN'), (',', ','), ('proposed', 'VBD'), ('3Cs', 'CD'), (',', ','), ('Cardinality', 'NNP'), (',', ','), ('Continuity', 'NNP'), (',', ','), ('Complexity', 'NNP'), (',', ','), ('use', 'NN'), ('developing', 'VBG'), ('mathematical', 'JJ'), ('statistical', 'JJ'), ('tools', 'NNS'), ('.', '.')]

 (S
  (NP Suthaharan/NNP)
  (/(
  2014/CD
  )/)
  proposed/VBN
  using/VBG
  (NP
    big/JJ
    data/NNS
    technologies/NNS
    Hadoop/NNP
    address/NN
    intrusion/NN
    detection/NN
    issues/NNS)
  ,/,
  (NP addition/NN)
  ,/,
  proposed/VBD
  3Cs/CD
  ,/,
  (NP Cardinality/NNP)
  ,/,
  (NP Continuity/NNP)
  ,/,
  (NP Complexity/NNP)
  ,/,
  (NP use/NN)
  developing/VBG
  (NP mathematical/JJ statistical/JJ tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Suthaharan', 'big data technologies Hadoop address intrusion detection issues', 'addition', 'Cardinality', 'Continuity', 'Complexity', 'use', 'mathematical statistical tools']

>> Named Entities are: 
 [('GPE', 'Suthaharan'), ('PERSON', 'Hadoop'), ('GPE', 'Cardinality'), ('ORGANIZATION', 'Continuity'), ('ORGANIZATION', 'Complexity')] 

>> Stemming using Porter Stemmer: 
 [('Suthaharan', 'suthaharan'), ('(', '('), ('2014', '2014'), (')', ')'), ('proposed', 'propos'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('technologies', 'technolog'), ('Hadoop', 'hadoop'), ('address', 'address'), ('intrusion', 'intrus'), ('detection', 'detect'), ('issues', 'issu'), (',', ','), ('addition', 'addit'), (',', ','), ('proposed', 'propos'), ('3Cs', '3c'), (',', ','), ('Cardinality', 'cardin'), (',', ','), ('Continuity', 'continu'), (',', ','), ('Complexity', 'complex'), (',', ','), ('use', 'use'), ('developing', 'develop'), ('mathematical', 'mathemat'), ('statistical', 'statist'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Suthaharan', 'suthaharan'), ('(', '('), ('2014', '2014'), (')', ')'), ('proposed', 'propos'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('technologies', 'technolog'), ('Hadoop', 'hadoop'), ('address', 'address'), ('intrusion', 'intrus'), ('detection', 'detect'), ('issues', 'issu'), (',', ','), ('addition', 'addit'), (',', ','), ('proposed', 'propos'), ('3Cs', '3cs'), (',', ','), ('Cardinality', 'cardin'), (',', ','), ('Continuity', 'continu'), (',', ','), ('Complexity', 'complex'), (',', ','), ('use', 'use'), ('developing', 'develop'), ('mathematical', 'mathemat'), ('statistical', 'statist'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('Suthaharan', 'Suthaharan'), ('(', '('), ('2014', '2014'), (')', ')'), ('proposed', 'proposed'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('technologies', 'technology'), ('Hadoop', 'Hadoop'), ('address', 'address'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('issues', 'issue'), (',', ','), ('addition', 'addition'), (',', ','), ('proposed', 'proposed'), ('3Cs', '3Cs'), (',', ','), ('Cardinality', 'Cardinality'), (',', ','), ('Continuity', 'Continuity'), (',', ','), ('Complexity', 'Complexity'), (',', ','), ('use', 'use'), ('developing', 'developing'), ('mathematical', 'mathematical'), ('statistical', 'statistical'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 466 =============================

Here, Cardinality refers to the number of   records, Continuity refers to the data’s continuous growth over time, and Complexity refers to the   data type variety (Zuech et al., 2015). 


>> Tokens are: 
 ['Here', ',', 'Cardinality', 'refers', 'number', 'records', ',', 'Continuity', 'refers', 'data', '’', 'continuous', 'growth', 'time', ',', 'Complexity', 'refers', 'data', 'type', 'variety', '(', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Here', ','), (',', 'Cardinality'), ('Cardinality', 'refers'), ('refers', 'number'), ('number', 'records'), ('records', ','), (',', 'Continuity'), ('Continuity', 'refers'), ('refers', 'data'), ('data', '’'), ('’', 'continuous'), ('continuous', 'growth'), ('growth', 'time'), ('time', ','), (',', 'Complexity'), ('Complexity', 'refers'), ('refers', 'data'), ('data', 'type'), ('type', 'variety'), ('variety', '('), ('(', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Here', ',', 'Cardinality'), (',', 'Cardinality', 'refers'), ('Cardinality', 'refers', 'number'), ('refers', 'number', 'records'), ('number', 'records', ','), ('records', ',', 'Continuity'), (',', 'Continuity', 'refers'), ('Continuity', 'refers', 'data'), ('refers', 'data', '’'), ('data', '’', 'continuous'), ('’', 'continuous', 'growth'), ('continuous', 'growth', 'time'), ('growth', 'time', ','), ('time', ',', 'Complexity'), (',', 'Complexity', 'refers'), ('Complexity', 'refers', 'data'), ('refers', 'data', 'type'), ('data', 'type', 'variety'), ('type', 'variety', '('), ('variety', '(', 'Zuech'), ('(', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Here', 'RB'), (',', ','), ('Cardinality', 'NNP'), ('refers', 'VBZ'), ('number', 'NN'), ('records', 'NNS'), (',', ','), ('Continuity', 'NNP'), ('refers', 'VBZ'), ('data', 'NNS'), ('’', 'NNP'), ('continuous', 'JJ'), ('growth', 'NN'), ('time', 'NN'), (',', ','), ('Complexity', 'NNP'), ('refers', 'VBZ'), ('data', 'NNS'), ('type', 'NN'), ('variety', 'NN'), ('(', '('), ('Zuech', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  Here/RB
  ,/,
  (NP Cardinality/NNP)
  refers/VBZ
  (NP number/NN records/NNS)
  ,/,
  (NP Continuity/NNP)
  refers/VBZ
  (NP data/NNS ’/NNP)
  (NP continuous/JJ growth/NN time/NN)
  ,/,
  (NP Complexity/NNP)
  refers/VBZ
  (NP data/NNS type/NN variety/NN)
  (/(
  (NP Zuech/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Cardinality', 'number records', 'Continuity', 'data ’', 'continuous growth time', 'Complexity', 'data type variety', 'Zuech']

>> Named Entities are: 
 [('GPE', 'Cardinality'), ('ORGANIZATION', 'Continuity'), ('ORGANIZATION', 'Complexity'), ('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('Here', 'here'), (',', ','), ('Cardinality', 'cardin'), ('refers', 'refer'), ('number', 'number'), ('records', 'record'), (',', ','), ('Continuity', 'continu'), ('refers', 'refer'), ('data', 'data'), ('’', '’'), ('continuous', 'continu'), ('growth', 'growth'), ('time', 'time'), (',', ','), ('Complexity', 'complex'), ('refers', 'refer'), ('data', 'data'), ('type', 'type'), ('variety', 'varieti'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Here', 'here'), (',', ','), ('Cardinality', 'cardin'), ('refers', 'refer'), ('number', 'number'), ('records', 'record'), (',', ','), ('Continuity', 'continu'), ('refers', 'refer'), ('data', 'data'), ('’', '’'), ('continuous', 'continu'), ('growth', 'growth'), ('time', 'time'), (',', ','), ('Complexity', 'complex'), ('refers', 'refer'), ('data', 'data'), ('type', 'type'), ('variety', 'varieti'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Here', 'Here'), (',', ','), ('Cardinality', 'Cardinality'), ('refers', 'refers'), ('number', 'number'), ('records', 'record'), (',', ','), ('Continuity', 'Continuity'), ('refers', 'refers'), ('data', 'data'), ('’', '’'), ('continuous', 'continuous'), ('growth', 'growth'), ('time', 'time'), (',', ','), ('Complexity', 'Complexity'), ('refers', 'refers'), ('data', 'data'), ('type', 'type'), ('variety', 'variety'), ('(', '('), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 467 =============================

Learning from the data is executed by the User Interaction   and Learning System (UILS) which gives the user permissions to interact with the system and   control the storage requirements. 


>> Tokens are: 
 ['Learning', 'data', 'executed', 'User', 'Interaction', 'Learning', 'System', '(', 'UILS', ')', 'gives', 'user', 'permissions', 'interact', 'system', 'control', 'storage', 'requirements', '.']

>> Bigrams are: 
 [('Learning', 'data'), ('data', 'executed'), ('executed', 'User'), ('User', 'Interaction'), ('Interaction', 'Learning'), ('Learning', 'System'), ('System', '('), ('(', 'UILS'), ('UILS', ')'), (')', 'gives'), ('gives', 'user'), ('user', 'permissions'), ('permissions', 'interact'), ('interact', 'system'), ('system', 'control'), ('control', 'storage'), ('storage', 'requirements'), ('requirements', '.')]

>> Trigrams are: 
 [('Learning', 'data', 'executed'), ('data', 'executed', 'User'), ('executed', 'User', 'Interaction'), ('User', 'Interaction', 'Learning'), ('Interaction', 'Learning', 'System'), ('Learning', 'System', '('), ('System', '(', 'UILS'), ('(', 'UILS', ')'), ('UILS', ')', 'gives'), (')', 'gives', 'user'), ('gives', 'user', 'permissions'), ('user', 'permissions', 'interact'), ('permissions', 'interact', 'system'), ('interact', 'system', 'control'), ('system', 'control', 'storage'), ('control', 'storage', 'requirements'), ('storage', 'requirements', '.')]

>> POS Tags are: 
 [('Learning', 'VBG'), ('data', 'NNS'), ('executed', 'VBN'), ('User', 'NNP'), ('Interaction', 'NNP'), ('Learning', 'NNP'), ('System', 'NNP'), ('(', '('), ('UILS', 'NNP'), (')', ')'), ('gives', 'VBZ'), ('user', 'JJ'), ('permissions', 'NNS'), ('interact', 'JJ'), ('system', 'NN'), ('control', 'NN'), ('storage', 'NN'), ('requirements', 'NNS'), ('.', '.')]

 (S
  Learning/VBG
  (NP data/NNS)
  executed/VBN
  (NP User/NNP Interaction/NNP Learning/NNP System/NNP)
  (/(
  (NP UILS/NNP)
  )/)
  gives/VBZ
  (NP user/JJ permissions/NNS)
  (NP interact/JJ system/NN control/NN storage/NN requirements/NNS)
  ./.) 


>> Noun Phrases are: 
 ['data', 'User Interaction Learning System', 'UILS', 'user permissions', 'interact system control storage requirements']

>> Named Entities are: 
 [('PERSON', 'User Interaction Learning System'), ('ORGANIZATION', 'UILS')] 

>> Stemming using Porter Stemmer: 
 [('Learning', 'learn'), ('data', 'data'), ('executed', 'execut'), ('User', 'user'), ('Interaction', 'interact'), ('Learning', 'learn'), ('System', 'system'), ('(', '('), ('UILS', 'uil'), (')', ')'), ('gives', 'give'), ('user', 'user'), ('permissions', 'permiss'), ('interact', 'interact'), ('system', 'system'), ('control', 'control'), ('storage', 'storag'), ('requirements', 'requir'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Learning', 'learn'), ('data', 'data'), ('executed', 'execut'), ('User', 'user'), ('Interaction', 'interact'), ('Learning', 'learn'), ('System', 'system'), ('(', '('), ('UILS', 'uil'), (')', ')'), ('gives', 'give'), ('user', 'user'), ('permissions', 'permiss'), ('interact', 'interact'), ('system', 'system'), ('control', 'control'), ('storage', 'storag'), ('requirements', 'requir'), ('.', '.')]

>> Lemmatization: 
 [('Learning', 'Learning'), ('data', 'data'), ('executed', 'executed'), ('User', 'User'), ('Interaction', 'Interaction'), ('Learning', 'Learning'), ('System', 'System'), ('(', '('), ('UILS', 'UILS'), (')', ')'), ('gives', 'give'), ('user', 'user'), ('permissions', 'permission'), ('interact', 'interact'), ('system', 'system'), ('control', 'control'), ('storage', 'storage'), ('requirements', 'requirement'), ('.', '.')]



============================ Sentence 468 =============================

The network traffic is captured by a Network Traffic Recording   System (NTRS), which stores it locally in the Hadoop Distributed File System (HDFS) or the   Cloud Computing Storage System (CCSS). 


>> Tokens are: 
 ['The', 'network', 'traffic', 'captured', 'Network', 'Traffic', 'Recording', 'System', '(', 'NTRS', ')', ',', 'stores', 'locally', 'Hadoop', 'Distributed', 'File', 'System', '(', 'HDFS', ')', 'Cloud', 'Computing', 'Storage', 'System', '(', 'CCSS', ')', '.']

>> Bigrams are: 
 [('The', 'network'), ('network', 'traffic'), ('traffic', 'captured'), ('captured', 'Network'), ('Network', 'Traffic'), ('Traffic', 'Recording'), ('Recording', 'System'), ('System', '('), ('(', 'NTRS'), ('NTRS', ')'), (')', ','), (',', 'stores'), ('stores', 'locally'), ('locally', 'Hadoop'), ('Hadoop', 'Distributed'), ('Distributed', 'File'), ('File', 'System'), ('System', '('), ('(', 'HDFS'), ('HDFS', ')'), (')', 'Cloud'), ('Cloud', 'Computing'), ('Computing', 'Storage'), ('Storage', 'System'), ('System', '('), ('(', 'CCSS'), ('CCSS', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'network', 'traffic'), ('network', 'traffic', 'captured'), ('traffic', 'captured', 'Network'), ('captured', 'Network', 'Traffic'), ('Network', 'Traffic', 'Recording'), ('Traffic', 'Recording', 'System'), ('Recording', 'System', '('), ('System', '(', 'NTRS'), ('(', 'NTRS', ')'), ('NTRS', ')', ','), (')', ',', 'stores'), (',', 'stores', 'locally'), ('stores', 'locally', 'Hadoop'), ('locally', 'Hadoop', 'Distributed'), ('Hadoop', 'Distributed', 'File'), ('Distributed', 'File', 'System'), ('File', 'System', '('), ('System', '(', 'HDFS'), ('(', 'HDFS', ')'), ('HDFS', ')', 'Cloud'), (')', 'Cloud', 'Computing'), ('Cloud', 'Computing', 'Storage'), ('Computing', 'Storage', 'System'), ('Storage', 'System', '('), ('System', '(', 'CCSS'), ('(', 'CCSS', ')'), ('CCSS', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('network', 'NN'), ('traffic', 'NN'), ('captured', 'VBD'), ('Network', 'NNP'), ('Traffic', 'NNP'), ('Recording', 'NNP'), ('System', 'NNP'), ('(', '('), ('NTRS', 'NNP'), (')', ')'), (',', ','), ('stores', 'NNS'), ('locally', 'RB'), ('Hadoop', 'NNP'), ('Distributed', 'NNP'), ('File', 'NNP'), ('System', 'NNP'), ('(', '('), ('HDFS', 'NNP'), (')', ')'), ('Cloud', 'NNP'), ('Computing', 'NNP'), ('Storage', 'NNP'), ('System', 'NNP'), ('(', '('), ('CCSS', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT network/NN traffic/NN)
  captured/VBD
  (NP Network/NNP Traffic/NNP Recording/NNP System/NNP)
  (/(
  (NP NTRS/NNP)
  )/)
  ,/,
  (NP stores/NNS)
  locally/RB
  (NP Hadoop/NNP Distributed/NNP File/NNP System/NNP)
  (/(
  (NP HDFS/NNP)
  )/)
  (NP Cloud/NNP Computing/NNP Storage/NNP System/NNP)
  (/(
  (NP CCSS/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The network traffic', 'Network Traffic Recording System', 'NTRS', 'stores', 'Hadoop Distributed File System', 'HDFS', 'Cloud Computing Storage System', 'CCSS']

>> Named Entities are: 
 [('PERSON', 'Network Traffic Recording System'), ('ORGANIZATION', 'NTRS'), ('PERSON', 'Hadoop Distributed File System'), ('ORGANIZATION', 'HDFS'), ('PERSON', 'Cloud Computing Storage System'), ('ORGANIZATION', 'CCSS')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('network', 'network'), ('traffic', 'traffic'), ('captured', 'captur'), ('Network', 'network'), ('Traffic', 'traffic'), ('Recording', 'record'), ('System', 'system'), ('(', '('), ('NTRS', 'ntr'), (')', ')'), (',', ','), ('stores', 'store'), ('locally', 'local'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdf'), (')', ')'), ('Cloud', 'cloud'), ('Computing', 'comput'), ('Storage', 'storag'), ('System', 'system'), ('(', '('), ('CCSS', 'ccss'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('network', 'network'), ('traffic', 'traffic'), ('captured', 'captur'), ('Network', 'network'), ('Traffic', 'traffic'), ('Recording', 'record'), ('System', 'system'), ('(', '('), ('NTRS', 'ntrs'), (')', ')'), (',', ','), ('stores', 'store'), ('locally', 'local'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdfs'), (')', ')'), ('Cloud', 'cloud'), ('Computing', 'comput'), ('Storage', 'storag'), ('System', 'system'), ('(', '('), ('CCSS', 'ccss'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('network', 'network'), ('traffic', 'traffic'), ('captured', 'captured'), ('Network', 'Network'), ('Traffic', 'Traffic'), ('Recording', 'Recording'), ('System', 'System'), ('(', '('), ('NTRS', 'NTRS'), (')', ')'), (',', ','), ('stores', 'store'), ('locally', 'locally'), ('Hadoop', 'Hadoop'), ('Distributed', 'Distributed'), ('File', 'File'), ('System', 'System'), ('(', '('), ('HDFS', 'HDFS'), (')', ')'), ('Cloud', 'Cloud'), ('Computing', 'Computing'), ('Storage', 'Storage'), ('System', 'System'), ('(', '('), ('CCSS', 'CCSS'), (')', ')'), ('.', '.')]



============================ Sentence 469 =============================

Based on Hadoop technology, Cheon and Choe (2013) proposed an intrusion detection system   architecture. 


>> Tokens are: 
 ['Based', 'Hadoop', 'technology', ',', 'Cheon', 'Choe', '(', '2013', ')', 'proposed', 'intrusion', 'detection', 'system', 'architecture', '.']

>> Bigrams are: 
 [('Based', 'Hadoop'), ('Hadoop', 'technology'), ('technology', ','), (',', 'Cheon'), ('Cheon', 'Choe'), ('Choe', '('), ('(', '2013'), ('2013', ')'), (')', 'proposed'), ('proposed', 'intrusion'), ('intrusion', 'detection'), ('detection', 'system'), ('system', 'architecture'), ('architecture', '.')]

>> Trigrams are: 
 [('Based', 'Hadoop', 'technology'), ('Hadoop', 'technology', ','), ('technology', ',', 'Cheon'), (',', 'Cheon', 'Choe'), ('Cheon', 'Choe', '('), ('Choe', '(', '2013'), ('(', '2013', ')'), ('2013', ')', 'proposed'), (')', 'proposed', 'intrusion'), ('proposed', 'intrusion', 'detection'), ('intrusion', 'detection', 'system'), ('detection', 'system', 'architecture'), ('system', 'architecture', '.')]

>> POS Tags are: 
 [('Based', 'VBN'), ('Hadoop', 'NNP'), ('technology', 'NN'), (',', ','), ('Cheon', 'NNP'), ('Choe', 'NNP'), ('(', '('), ('2013', 'CD'), (')', ')'), ('proposed', 'VBN'), ('intrusion', 'NN'), ('detection', 'NN'), ('system', 'NN'), ('architecture', 'NN'), ('.', '.')]

 (S
  Based/VBN
  (NP Hadoop/NNP technology/NN)
  ,/,
  (NP Cheon/NNP Choe/NNP)
  (/(
  2013/CD
  )/)
  proposed/VBN
  (NP intrusion/NN detection/NN system/NN architecture/NN)
  ./.) 


>> Noun Phrases are: 
 ['Hadoop technology', 'Cheon Choe', 'intrusion detection system architecture']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Cheon Choe')] 

>> Stemming using Porter Stemmer: 
 [('Based', 'base'), ('Hadoop', 'hadoop'), ('technology', 'technolog'), (',', ','), ('Cheon', 'cheon'), ('Choe', 'choe'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('intrusion', 'intrus'), ('detection', 'detect'), ('system', 'system'), ('architecture', 'architectur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Based', 'base'), ('Hadoop', 'hadoop'), ('technology', 'technolog'), (',', ','), ('Cheon', 'cheon'), ('Choe', 'choe'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'propos'), ('intrusion', 'intrus'), ('detection', 'detect'), ('system', 'system'), ('architecture', 'architectur'), ('.', '.')]

>> Lemmatization: 
 [('Based', 'Based'), ('Hadoop', 'Hadoop'), ('technology', 'technology'), (',', ','), ('Cheon', 'Cheon'), ('Choe', 'Choe'), ('(', '('), ('2013', '2013'), (')', ')'), ('proposed', 'proposed'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('system', 'system'), ('architecture', 'architecture'), ('.', '.')]



============================ Sentence 470 =============================

They added additional Hadoop-based nodes to those used in analyses, varying from   zero to eight replays of files; they then evaluated their efficiency. 


>> Tokens are: 
 ['They', 'added', 'additional', 'Hadoop-based', 'nodes', 'used', 'analyses', ',', 'varying', 'zero', 'eight', 'replays', 'files', ';', 'evaluated', 'efficiency', '.']

>> Bigrams are: 
 [('They', 'added'), ('added', 'additional'), ('additional', 'Hadoop-based'), ('Hadoop-based', 'nodes'), ('nodes', 'used'), ('used', 'analyses'), ('analyses', ','), (',', 'varying'), ('varying', 'zero'), ('zero', 'eight'), ('eight', 'replays'), ('replays', 'files'), ('files', ';'), (';', 'evaluated'), ('evaluated', 'efficiency'), ('efficiency', '.')]

>> Trigrams are: 
 [('They', 'added', 'additional'), ('added', 'additional', 'Hadoop-based'), ('additional', 'Hadoop-based', 'nodes'), ('Hadoop-based', 'nodes', 'used'), ('nodes', 'used', 'analyses'), ('used', 'analyses', ','), ('analyses', ',', 'varying'), (',', 'varying', 'zero'), ('varying', 'zero', 'eight'), ('zero', 'eight', 'replays'), ('eight', 'replays', 'files'), ('replays', 'files', ';'), ('files', ';', 'evaluated'), (';', 'evaluated', 'efficiency'), ('evaluated', 'efficiency', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('added', 'VBD'), ('additional', 'JJ'), ('Hadoop-based', 'JJ'), ('nodes', 'NNS'), ('used', 'VBN'), ('analyses', 'NNS'), (',', ','), ('varying', 'VBG'), ('zero', 'CD'), ('eight', 'CD'), ('replays', 'NNS'), ('files', 'VBZ'), (';', ':'), ('evaluated', 'VBN'), ('efficiency', 'NN'), ('.', '.')]

 (S
  They/PRP
  added/VBD
  (NP additional/JJ Hadoop-based/JJ nodes/NNS)
  used/VBN
  (NP analyses/NNS)
  ,/,
  varying/VBG
  zero/CD
  eight/CD
  (NP replays/NNS)
  files/VBZ
  ;/:
  evaluated/VBN
  (NP efficiency/NN)
  ./.) 


>> Noun Phrases are: 
 ['additional Hadoop-based nodes', 'analyses', 'replays', 'efficiency']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('added', 'ad'), ('additional', 'addit'), ('Hadoop-based', 'hadoop-bas'), ('nodes', 'node'), ('used', 'use'), ('analyses', 'analys'), (',', ','), ('varying', 'vari'), ('zero', 'zero'), ('eight', 'eight'), ('replays', 'replay'), ('files', 'file'), (';', ';'), ('evaluated', 'evalu'), ('efficiency', 'effici'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('added', 'ad'), ('additional', 'addit'), ('Hadoop-based', 'hadoop-bas'), ('nodes', 'node'), ('used', 'use'), ('analyses', 'analys'), (',', ','), ('varying', 'vari'), ('zero', 'zero'), ('eight', 'eight'), ('replays', 'replay'), ('files', 'file'), (';', ';'), ('evaluated', 'evalu'), ('efficiency', 'effici'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('added', 'added'), ('additional', 'additional'), ('Hadoop-based', 'Hadoop-based'), ('nodes', 'node'), ('used', 'used'), ('analyses', 'analysis'), (',', ','), ('varying', 'varying'), ('zero', 'zero'), ('eight', 'eight'), ('replays', 'replay'), ('files', 'file'), (';', ';'), ('evaluated', 'evaluated'), ('efficiency', 'efficiency'), ('.', '.')]



============================ Sentence 471 =============================

They found that the efficiency   of performance was increased, and that the system spent less time processing the datasets (Zuech,   et al., 2015). 


>> Tokens are: 
 ['They', 'found', 'efficiency', 'performance', 'increased', ',', 'system', 'spent', 'less', 'time', 'processing', 'datasets', '(', 'Zuech', ',', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('They', 'found'), ('found', 'efficiency'), ('efficiency', 'performance'), ('performance', 'increased'), ('increased', ','), (',', 'system'), ('system', 'spent'), ('spent', 'less'), ('less', 'time'), ('time', 'processing'), ('processing', 'datasets'), ('datasets', '('), ('(', 'Zuech'), ('Zuech', ','), (',', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('They', 'found', 'efficiency'), ('found', 'efficiency', 'performance'), ('efficiency', 'performance', 'increased'), ('performance', 'increased', ','), ('increased', ',', 'system'), (',', 'system', 'spent'), ('system', 'spent', 'less'), ('spent', 'less', 'time'), ('less', 'time', 'processing'), ('time', 'processing', 'datasets'), ('processing', 'datasets', '('), ('datasets', '(', 'Zuech'), ('(', 'Zuech', ','), ('Zuech', ',', 'et'), (',', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('found', 'VBD'), ('efficiency', 'NN'), ('performance', 'NN'), ('increased', 'VBD'), (',', ','), ('system', 'NN'), ('spent', 'VBD'), ('less', 'JJR'), ('time', 'NN'), ('processing', 'VBG'), ('datasets', 'NNS'), ('(', '('), ('Zuech', 'NNP'), (',', ','), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  They/PRP
  found/VBD
  (NP efficiency/NN performance/NN)
  increased/VBD
  ,/,
  (NP system/NN)
  spent/VBD
  less/JJR
  (NP time/NN)
  processing/VBG
  (NP datasets/NNS)
  (/(
  (NP Zuech/NNP)
  ,/,
  et/FW
  (NP al./NN)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['efficiency performance', 'system', 'time', 'datasets', 'Zuech', 'al.']

>> Named Entities are: 
 [('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('found', 'found'), ('efficiency', 'effici'), ('performance', 'perform'), ('increased', 'increas'), (',', ','), ('system', 'system'), ('spent', 'spent'), ('less', 'less'), ('time', 'time'), ('processing', 'process'), ('datasets', 'dataset'), ('(', '('), ('Zuech', 'zuech'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('found', 'found'), ('efficiency', 'effici'), ('performance', 'perform'), ('increased', 'increas'), (',', ','), ('system', 'system'), ('spent', 'spent'), ('less', 'less'), ('time', 'time'), ('processing', 'process'), ('datasets', 'dataset'), ('(', '('), ('Zuech', 'zuech'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('found', 'found'), ('efficiency', 'efficiency'), ('performance', 'performance'), ('increased', 'increased'), (',', ','), ('system', 'system'), ('spent', 'spent'), ('less', 'le'), ('time', 'time'), ('processing', 'processing'), ('datasets', 'datasets'), ('(', '('), ('Zuech', 'Zuech'), (',', ','), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 472 =============================

Blazquez and Domenech (2018) proposed a big data architecture based on an analysis of economic   and social behaviour in the digital era. 


>> Tokens are: 
 ['Blazquez', 'Domenech', '(', '2018', ')', 'proposed', 'big', 'data', 'architecture', 'based', 'analysis', 'economic', 'social', 'behaviour', 'digital', 'era', '.']

>> Bigrams are: 
 [('Blazquez', 'Domenech'), ('Domenech', '('), ('(', '2018'), ('2018', ')'), (')', 'proposed'), ('proposed', 'big'), ('big', 'data'), ('data', 'architecture'), ('architecture', 'based'), ('based', 'analysis'), ('analysis', 'economic'), ('economic', 'social'), ('social', 'behaviour'), ('behaviour', 'digital'), ('digital', 'era'), ('era', '.')]

>> Trigrams are: 
 [('Blazquez', 'Domenech', '('), ('Domenech', '(', '2018'), ('(', '2018', ')'), ('2018', ')', 'proposed'), (')', 'proposed', 'big'), ('proposed', 'big', 'data'), ('big', 'data', 'architecture'), ('data', 'architecture', 'based'), ('architecture', 'based', 'analysis'), ('based', 'analysis', 'economic'), ('analysis', 'economic', 'social'), ('economic', 'social', 'behaviour'), ('social', 'behaviour', 'digital'), ('behaviour', 'digital', 'era'), ('digital', 'era', '.')]

>> POS Tags are: 
 [('Blazquez', 'NNP'), ('Domenech', 'NNP'), ('(', '('), ('2018', 'CD'), (')', ')'), ('proposed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('architecture', 'NN'), ('based', 'VBN'), ('analysis', 'NN'), ('economic', 'JJ'), ('social', 'JJ'), ('behaviour', 'NN'), ('digital', 'JJ'), ('era', 'NN'), ('.', '.')]

 (S
  (NP Blazquez/NNP Domenech/NNP)
  (/(
  2018/CD
  )/)
  proposed/VBD
  (NP big/JJ data/NNS architecture/NN)
  based/VBN
  (NP analysis/NN)
  (NP economic/JJ social/JJ behaviour/NN)
  (NP digital/JJ era/NN)
  ./.) 


>> Noun Phrases are: 
 ['Blazquez Domenech', 'big data architecture', 'analysis', 'economic social behaviour', 'digital era']

>> Named Entities are: 
 [('PERSON', 'Blazquez'), ('ORGANIZATION', 'Domenech')] 

>> Stemming using Porter Stemmer: 
 [('Blazquez', 'blazquez'), ('Domenech', 'domenech'), ('(', '('), ('2018', '2018'), (')', ')'), ('proposed', 'propos'), ('big', 'big'), ('data', 'data'), ('architecture', 'architectur'), ('based', 'base'), ('analysis', 'analysi'), ('economic', 'econom'), ('social', 'social'), ('behaviour', 'behaviour'), ('digital', 'digit'), ('era', 'era'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Blazquez', 'blazquez'), ('Domenech', 'domenech'), ('(', '('), ('2018', '2018'), (')', ')'), ('proposed', 'propos'), ('big', 'big'), ('data', 'data'), ('architecture', 'architectur'), ('based', 'base'), ('analysis', 'analysi'), ('economic', 'econom'), ('social', 'social'), ('behaviour', 'behaviour'), ('digital', 'digit'), ('era', 'era'), ('.', '.')]

>> Lemmatization: 
 [('Blazquez', 'Blazquez'), ('Domenech', 'Domenech'), ('(', '('), ('2018', '2018'), (')', ')'), ('proposed', 'proposed'), ('big', 'big'), ('data', 'data'), ('architecture', 'architecture'), ('based', 'based'), ('analysis', 'analysis'), ('economic', 'economic'), ('social', 'social'), ('behaviour', 'behaviour'), ('digital', 'digital'), ('era', 'era'), ('.', '.')]



============================ Sentence 473 =============================

This study addressed the issues raised by several economic   and social topics by presenting multiple data sources and proposing a taxonomy for classifying   these depending on the purpose of the agent used to generate the data. 


>> Tokens are: 
 ['This', 'study', 'addressed', 'issues', 'raised', 'several', 'economic', 'social', 'topics', 'presenting', 'multiple', 'data', 'sources', 'proposing', 'taxonomy', 'classifying', 'depending', 'purpose', 'agent', 'used', 'generate', 'data', '.']

>> Bigrams are: 
 [('This', 'study'), ('study', 'addressed'), ('addressed', 'issues'), ('issues', 'raised'), ('raised', 'several'), ('several', 'economic'), ('economic', 'social'), ('social', 'topics'), ('topics', 'presenting'), ('presenting', 'multiple'), ('multiple', 'data'), ('data', 'sources'), ('sources', 'proposing'), ('proposing', 'taxonomy'), ('taxonomy', 'classifying'), ('classifying', 'depending'), ('depending', 'purpose'), ('purpose', 'agent'), ('agent', 'used'), ('used', 'generate'), ('generate', 'data'), ('data', '.')]

>> Trigrams are: 
 [('This', 'study', 'addressed'), ('study', 'addressed', 'issues'), ('addressed', 'issues', 'raised'), ('issues', 'raised', 'several'), ('raised', 'several', 'economic'), ('several', 'economic', 'social'), ('economic', 'social', 'topics'), ('social', 'topics', 'presenting'), ('topics', 'presenting', 'multiple'), ('presenting', 'multiple', 'data'), ('multiple', 'data', 'sources'), ('data', 'sources', 'proposing'), ('sources', 'proposing', 'taxonomy'), ('proposing', 'taxonomy', 'classifying'), ('taxonomy', 'classifying', 'depending'), ('classifying', 'depending', 'purpose'), ('depending', 'purpose', 'agent'), ('purpose', 'agent', 'used'), ('agent', 'used', 'generate'), ('used', 'generate', 'data'), ('generate', 'data', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('study', 'NN'), ('addressed', 'VBD'), ('issues', 'NNS'), ('raised', 'VBD'), ('several', 'JJ'), ('economic', 'JJ'), ('social', 'JJ'), ('topics', 'NNS'), ('presenting', 'VBG'), ('multiple', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('proposing', 'VBG'), ('taxonomy', 'NN'), ('classifying', 'VBG'), ('depending', 'VBG'), ('purpose', 'JJ'), ('agent', 'NN'), ('used', 'VBN'), ('generate', 'NN'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP This/DT study/NN)
  addressed/VBD
  (NP issues/NNS)
  raised/VBD
  (NP several/JJ economic/JJ social/JJ topics/NNS)
  presenting/VBG
  (NP multiple/JJ data/NNS sources/NNS)
  proposing/VBG
  (NP taxonomy/NN)
  classifying/VBG
  depending/VBG
  (NP purpose/JJ agent/NN)
  used/VBN
  (NP generate/NN data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['This study', 'issues', 'several economic social topics', 'multiple data sources', 'taxonomy', 'purpose agent', 'generate data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('study', 'studi'), ('addressed', 'address'), ('issues', 'issu'), ('raised', 'rais'), ('several', 'sever'), ('economic', 'econom'), ('social', 'social'), ('topics', 'topic'), ('presenting', 'present'), ('multiple', 'multipl'), ('data', 'data'), ('sources', 'sourc'), ('proposing', 'propos'), ('taxonomy', 'taxonomi'), ('classifying', 'classifi'), ('depending', 'depend'), ('purpose', 'purpos'), ('agent', 'agent'), ('used', 'use'), ('generate', 'gener'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('study', 'studi'), ('addressed', 'address'), ('issues', 'issu'), ('raised', 'rais'), ('several', 'sever'), ('economic', 'econom'), ('social', 'social'), ('topics', 'topic'), ('presenting', 'present'), ('multiple', 'multipl'), ('data', 'data'), ('sources', 'sourc'), ('proposing', 'propos'), ('taxonomy', 'taxonomi'), ('classifying', 'classifi'), ('depending', 'depend'), ('purpose', 'purpos'), ('agent', 'agent'), ('used', 'use'), ('generate', 'generat'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('study', 'study'), ('addressed', 'addressed'), ('issues', 'issue'), ('raised', 'raised'), ('several', 'several'), ('economic', 'economic'), ('social', 'social'), ('topics', 'topic'), ('presenting', 'presenting'), ('multiple', 'multiple'), ('data', 'data'), ('sources', 'source'), ('proposing', 'proposing'), ('taxonomy', 'taxonomy'), ('classifying', 'classifying'), ('depending', 'depending'), ('purpose', 'purpose'), ('agent', 'agent'), ('used', 'used'), ('generate', 'generate'), ('data', 'data'), ('.', '.')]



============================ Sentence 474 =============================

Lan, et al. 


>> Tokens are: 
 ['Lan', ',', 'et', 'al', '.']

>> Bigrams are: 
 [('Lan', ','), (',', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Lan', ',', 'et'), (',', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Lan', 'NNP'), (',', ','), ('et', 'RB'), ('al', 'NN'), ('.', '.')]

 (S (NP Lan/NNP) ,/, et/RB (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Lan', 'al']

>> Named Entities are: 
 [('GPE', 'Lan')] 

>> Stemming using Porter Stemmer: 
 [('Lan', 'lan'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lan', 'lan'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Lan', 'Lan'), (',', ','), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 475 =============================

(2010) used data fusion across diverse heterogeneous sources to improve intrusion   detection. 


>> Tokens are: 
 ['(', '2010', ')', 'used', 'data', 'fusion', 'across', 'diverse', 'heterogeneous', 'sources', 'improve', 'intrusion', 'detection', '.']

>> Bigrams are: 
 [('(', '2010'), ('2010', ')'), (')', 'used'), ('used', 'data'), ('data', 'fusion'), ('fusion', 'across'), ('across', 'diverse'), ('diverse', 'heterogeneous'), ('heterogeneous', 'sources'), ('sources', 'improve'), ('improve', 'intrusion'), ('intrusion', 'detection'), ('detection', '.')]

>> Trigrams are: 
 [('(', '2010', ')'), ('2010', ')', 'used'), (')', 'used', 'data'), ('used', 'data', 'fusion'), ('data', 'fusion', 'across'), ('fusion', 'across', 'diverse'), ('across', 'diverse', 'heterogeneous'), ('diverse', 'heterogeneous', 'sources'), ('heterogeneous', 'sources', 'improve'), ('sources', 'improve', 'intrusion'), ('improve', 'intrusion', 'detection'), ('intrusion', 'detection', '.')]

>> POS Tags are: 
 [('(', '('), ('2010', 'CD'), (')', ')'), ('used', 'VBN'), ('data', 'NNS'), ('fusion', 'NN'), ('across', 'IN'), ('diverse', 'JJ'), ('heterogeneous', 'JJ'), ('sources', 'NNS'), ('improve', 'VB'), ('intrusion', 'NN'), ('detection', 'NN'), ('.', '.')]

 (S
  (/(
  2010/CD
  )/)
  used/VBN
  (NP data/NNS fusion/NN)
  across/IN
  (NP diverse/JJ heterogeneous/JJ sources/NNS)
  improve/VB
  (NP intrusion/NN detection/NN)
  ./.) 


>> Noun Phrases are: 
 ['data fusion', 'diverse heterogeneous sources', 'intrusion detection']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2010', '2010'), (')', ')'), ('used', 'use'), ('data', 'data'), ('fusion', 'fusion'), ('across', 'across'), ('diverse', 'divers'), ('heterogeneous', 'heterogen'), ('sources', 'sourc'), ('improve', 'improv'), ('intrusion', 'intrus'), ('detection', 'detect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2010', '2010'), (')', ')'), ('used', 'use'), ('data', 'data'), ('fusion', 'fusion'), ('across', 'across'), ('diverse', 'divers'), ('heterogeneous', 'heterogen'), ('sources', 'sourc'), ('improve', 'improv'), ('intrusion', 'intrus'), ('detection', 'detect'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2010', '2010'), (')', ')'), ('used', 'used'), ('data', 'data'), ('fusion', 'fusion'), ('across', 'across'), ('diverse', 'diverse'), ('heterogeneous', 'heterogeneous'), ('sources', 'source'), ('improve', 'improve'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('.', '.')]



============================ Sentence 476 =============================

As a result, they found that traditional security products such as firewalls, intrusion   detection systems, and security scanners do not work together, and thus protecting networks with   minimal network knowledge. 


>> Tokens are: 
 ['As', 'result', ',', 'found', 'traditional', 'security', 'products', 'firewalls', ',', 'intrusion', 'detection', 'systems', ',', 'security', 'scanners', 'work', 'together', ',', 'thus', 'protecting', 'networks', 'minimal', 'network', 'knowledge', '.']

>> Bigrams are: 
 [('As', 'result'), ('result', ','), (',', 'found'), ('found', 'traditional'), ('traditional', 'security'), ('security', 'products'), ('products', 'firewalls'), ('firewalls', ','), (',', 'intrusion'), ('intrusion', 'detection'), ('detection', 'systems'), ('systems', ','), (',', 'security'), ('security', 'scanners'), ('scanners', 'work'), ('work', 'together'), ('together', ','), (',', 'thus'), ('thus', 'protecting'), ('protecting', 'networks'), ('networks', 'minimal'), ('minimal', 'network'), ('network', 'knowledge'), ('knowledge', '.')]

>> Trigrams are: 
 [('As', 'result', ','), ('result', ',', 'found'), (',', 'found', 'traditional'), ('found', 'traditional', 'security'), ('traditional', 'security', 'products'), ('security', 'products', 'firewalls'), ('products', 'firewalls', ','), ('firewalls', ',', 'intrusion'), (',', 'intrusion', 'detection'), ('intrusion', 'detection', 'systems'), ('detection', 'systems', ','), ('systems', ',', 'security'), (',', 'security', 'scanners'), ('security', 'scanners', 'work'), ('scanners', 'work', 'together'), ('work', 'together', ','), ('together', ',', 'thus'), (',', 'thus', 'protecting'), ('thus', 'protecting', 'networks'), ('protecting', 'networks', 'minimal'), ('networks', 'minimal', 'network'), ('minimal', 'network', 'knowledge'), ('network', 'knowledge', '.')]

>> POS Tags are: 
 [('As', 'IN'), ('result', 'NN'), (',', ','), ('found', 'VBD'), ('traditional', 'JJ'), ('security', 'NN'), ('products', 'NNS'), ('firewalls', 'NNS'), (',', ','), ('intrusion', 'NN'), ('detection', 'NN'), ('systems', 'NNS'), (',', ','), ('security', 'NN'), ('scanners', 'NNS'), ('work', 'VBP'), ('together', 'RB'), (',', ','), ('thus', 'RB'), ('protecting', 'VBG'), ('networks', 'NNS'), ('minimal', 'JJ'), ('network', 'NN'), ('knowledge', 'NN'), ('.', '.')]

 (S
  As/IN
  (NP result/NN)
  ,/,
  found/VBD
  (NP traditional/JJ security/NN products/NNS firewalls/NNS)
  ,/,
  (NP intrusion/NN detection/NN systems/NNS)
  ,/,
  (NP security/NN scanners/NNS)
  work/VBP
  together/RB
  ,/,
  thus/RB
  protecting/VBG
  (NP networks/NNS)
  (NP minimal/JJ network/NN knowledge/NN)
  ./.) 


>> Noun Phrases are: 
 ['result', 'traditional security products firewalls', 'intrusion detection systems', 'security scanners', 'networks', 'minimal network knowledge']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('found', 'found'), ('traditional', 'tradit'), ('security', 'secur'), ('products', 'product'), ('firewalls', 'firewal'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), ('systems', 'system'), (',', ','), ('security', 'secur'), ('scanners', 'scanner'), ('work', 'work'), ('together', 'togeth'), (',', ','), ('thus', 'thu'), ('protecting', 'protect'), ('networks', 'network'), ('minimal', 'minim'), ('network', 'network'), ('knowledge', 'knowledg'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('As', 'as'), ('result', 'result'), (',', ','), ('found', 'found'), ('traditional', 'tradit'), ('security', 'secur'), ('products', 'product'), ('firewalls', 'firewal'), (',', ','), ('intrusion', 'intrus'), ('detection', 'detect'), ('systems', 'system'), (',', ','), ('security', 'secur'), ('scanners', 'scanner'), ('work', 'work'), ('together', 'togeth'), (',', ','), ('thus', 'thus'), ('protecting', 'protect'), ('networks', 'network'), ('minimal', 'minim'), ('network', 'network'), ('knowledge', 'knowledg'), ('.', '.')]

>> Lemmatization: 
 [('As', 'As'), ('result', 'result'), (',', ','), ('found', 'found'), ('traditional', 'traditional'), ('security', 'security'), ('products', 'product'), ('firewalls', 'firewall'), (',', ','), ('intrusion', 'intrusion'), ('detection', 'detection'), ('systems', 'system'), (',', ','), ('security', 'security'), ('scanners', 'scanner'), ('work', 'work'), ('together', 'together'), (',', ','), ('thus', 'thus'), ('protecting', 'protecting'), ('networks', 'network'), ('minimal', 'minimal'), ('network', 'network'), ('knowledge', 'knowledge'), ('.', '.')]



============================ Sentence 477 =============================

The authors suggested utilising a form of data fusion known as   Dempster-Shafer (D-S) evidence theory in order to better understand heterogeneous sources   (Zuech et al., 2015). 


>> Tokens are: 
 ['The', 'authors', 'suggested', 'utilising', 'form', 'data', 'fusion', 'known', 'Dempster-Shafer', '(', 'D-S', ')', 'evidence', 'theory', 'order', 'better', 'understand', 'heterogeneous', 'sources', '(', 'Zuech', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('The', 'authors'), ('authors', 'suggested'), ('suggested', 'utilising'), ('utilising', 'form'), ('form', 'data'), ('data', 'fusion'), ('fusion', 'known'), ('known', 'Dempster-Shafer'), ('Dempster-Shafer', '('), ('(', 'D-S'), ('D-S', ')'), (')', 'evidence'), ('evidence', 'theory'), ('theory', 'order'), ('order', 'better'), ('better', 'understand'), ('understand', 'heterogeneous'), ('heterogeneous', 'sources'), ('sources', '('), ('(', 'Zuech'), ('Zuech', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'authors', 'suggested'), ('authors', 'suggested', 'utilising'), ('suggested', 'utilising', 'form'), ('utilising', 'form', 'data'), ('form', 'data', 'fusion'), ('data', 'fusion', 'known'), ('fusion', 'known', 'Dempster-Shafer'), ('known', 'Dempster-Shafer', '('), ('Dempster-Shafer', '(', 'D-S'), ('(', 'D-S', ')'), ('D-S', ')', 'evidence'), (')', 'evidence', 'theory'), ('evidence', 'theory', 'order'), ('theory', 'order', 'better'), ('order', 'better', 'understand'), ('better', 'understand', 'heterogeneous'), ('understand', 'heterogeneous', 'sources'), ('heterogeneous', 'sources', '('), ('sources', '(', 'Zuech'), ('(', 'Zuech', 'et'), ('Zuech', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('authors', 'NNS'), ('suggested', 'VBD'), ('utilising', 'JJ'), ('form', 'NN'), ('data', 'NNS'), ('fusion', 'NN'), ('known', 'VBN'), ('Dempster-Shafer', 'NNP'), ('(', '('), ('D-S', 'NNP'), (')', ')'), ('evidence', 'NN'), ('theory', 'NN'), ('order', 'NN'), ('better', 'RBR'), ('understand', 'VBP'), ('heterogeneous', 'JJ'), ('sources', 'NNS'), ('(', '('), ('Zuech', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT authors/NNS)
  suggested/VBD
  (NP utilising/JJ form/NN data/NNS fusion/NN)
  known/VBN
  (NP Dempster-Shafer/NNP)
  (/(
  (NP D-S/NNP)
  )/)
  (NP evidence/NN theory/NN order/NN)
  better/RBR
  understand/VBP
  (NP heterogeneous/JJ sources/NNS)
  (/(
  (NP Zuech/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The authors', 'utilising form data fusion', 'Dempster-Shafer', 'D-S', 'evidence theory order', 'heterogeneous sources', 'Zuech']

>> Named Entities are: 
 [('PERSON', 'Zuech')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('authors', 'author'), ('suggested', 'suggest'), ('utilising', 'utilis'), ('form', 'form'), ('data', 'data'), ('fusion', 'fusion'), ('known', 'known'), ('Dempster-Shafer', 'dempster-shaf'), ('(', '('), ('D-S', 'd-'), (')', ')'), ('evidence', 'evid'), ('theory', 'theori'), ('order', 'order'), ('better', 'better'), ('understand', 'understand'), ('heterogeneous', 'heterogen'), ('sources', 'sourc'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('authors', 'author'), ('suggested', 'suggest'), ('utilising', 'utilis'), ('form', 'form'), ('data', 'data'), ('fusion', 'fusion'), ('known', 'known'), ('Dempster-Shafer', 'dempster-shaf'), ('(', '('), ('D-S', 'd-s'), (')', ')'), ('evidence', 'evid'), ('theory', 'theori'), ('order', 'order'), ('better', 'better'), ('understand', 'understand'), ('heterogeneous', 'heterogen'), ('sources', 'sourc'), ('(', '('), ('Zuech', 'zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('authors', 'author'), ('suggested', 'suggested'), ('utilising', 'utilising'), ('form', 'form'), ('data', 'data'), ('fusion', 'fusion'), ('known', 'known'), ('Dempster-Shafer', 'Dempster-Shafer'), ('(', '('), ('D-S', 'D-S'), (')', ')'), ('evidence', 'evidence'), ('theory', 'theory'), ('order', 'order'), ('better', 'better'), ('understand', 'understand'), ('heterogeneous', 'heterogeneous'), ('sources', 'source'), ('(', '('), ('Zuech', 'Zuech'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 478 =============================

D-S evidence theory is a common data fusion technique used by researchers   within the Intrusion Detection domain, which applies probabilistic techniques to monitor the   system. 


>> Tokens are: 
 ['D-S', 'evidence', 'theory', 'common', 'data', 'fusion', 'technique', 'used', 'researchers', 'within', 'Intrusion', 'Detection', 'domain', ',', 'applies', 'probabilistic', 'techniques', 'monitor', 'system', '.']

>> Bigrams are: 
 [('D-S', 'evidence'), ('evidence', 'theory'), ('theory', 'common'), ('common', 'data'), ('data', 'fusion'), ('fusion', 'technique'), ('technique', 'used'), ('used', 'researchers'), ('researchers', 'within'), ('within', 'Intrusion'), ('Intrusion', 'Detection'), ('Detection', 'domain'), ('domain', ','), (',', 'applies'), ('applies', 'probabilistic'), ('probabilistic', 'techniques'), ('techniques', 'monitor'), ('monitor', 'system'), ('system', '.')]

>> Trigrams are: 
 [('D-S', 'evidence', 'theory'), ('evidence', 'theory', 'common'), ('theory', 'common', 'data'), ('common', 'data', 'fusion'), ('data', 'fusion', 'technique'), ('fusion', 'technique', 'used'), ('technique', 'used', 'researchers'), ('used', 'researchers', 'within'), ('researchers', 'within', 'Intrusion'), ('within', 'Intrusion', 'Detection'), ('Intrusion', 'Detection', 'domain'), ('Detection', 'domain', ','), ('domain', ',', 'applies'), (',', 'applies', 'probabilistic'), ('applies', 'probabilistic', 'techniques'), ('probabilistic', 'techniques', 'monitor'), ('techniques', 'monitor', 'system'), ('monitor', 'system', '.')]

>> POS Tags are: 
 [('D-S', 'JJ'), ('evidence', 'NN'), ('theory', 'NN'), ('common', 'JJ'), ('data', 'NNS'), ('fusion', 'NN'), ('technique', 'NN'), ('used', 'VBN'), ('researchers', 'NNS'), ('within', 'IN'), ('Intrusion', 'NNP'), ('Detection', 'NNP'), ('domain', 'NN'), (',', ','), ('applies', 'VBZ'), ('probabilistic', 'JJ'), ('techniques', 'NNS'), ('monitor', 'NN'), ('system', 'NN'), ('.', '.')]

 (S
  (NP D-S/JJ evidence/NN theory/NN)
  (NP common/JJ data/NNS fusion/NN technique/NN)
  used/VBN
  (NP researchers/NNS)
  within/IN
  (NP Intrusion/NNP Detection/NNP domain/NN)
  ,/,
  applies/VBZ
  (NP probabilistic/JJ techniques/NNS monitor/NN system/NN)
  ./.) 


>> Noun Phrases are: 
 ['D-S evidence theory', 'common data fusion technique', 'researchers', 'Intrusion Detection domain', 'probabilistic techniques monitor system']

>> Named Entities are: 
 [('ORGANIZATION', 'Intrusion Detection')] 

>> Stemming using Porter Stemmer: 
 [('D-S', 'd-'), ('evidence', 'evid'), ('theory', 'theori'), ('common', 'common'), ('data', 'data'), ('fusion', 'fusion'), ('technique', 'techniqu'), ('used', 'use'), ('researchers', 'research'), ('within', 'within'), ('Intrusion', 'intrus'), ('Detection', 'detect'), ('domain', 'domain'), (',', ','), ('applies', 'appli'), ('probabilistic', 'probabilist'), ('techniques', 'techniqu'), ('monitor', 'monitor'), ('system', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('D-S', 'd-s'), ('evidence', 'evid'), ('theory', 'theori'), ('common', 'common'), ('data', 'data'), ('fusion', 'fusion'), ('technique', 'techniqu'), ('used', 'use'), ('researchers', 'research'), ('within', 'within'), ('Intrusion', 'intrus'), ('Detection', 'detect'), ('domain', 'domain'), (',', ','), ('applies', 'appli'), ('probabilistic', 'probabilist'), ('techniques', 'techniqu'), ('monitor', 'monitor'), ('system', 'system'), ('.', '.')]

>> Lemmatization: 
 [('D-S', 'D-S'), ('evidence', 'evidence'), ('theory', 'theory'), ('common', 'common'), ('data', 'data'), ('fusion', 'fusion'), ('technique', 'technique'), ('used', 'used'), ('researchers', 'researcher'), ('within', 'within'), ('Intrusion', 'Intrusion'), ('Detection', 'Detection'), ('domain', 'domain'), (',', ','), ('applies', 'applies'), ('probabilistic', 'probabilistic'), ('techniques', 'technique'), ('monitor', 'monitor'), ('system', 'system'), ('.', '.')]



============================ Sentence 479 =============================

Sarah Al-Shiakhli   39      9.2. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '39', '9.2', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '39'), ('39', '9.2'), ('9.2', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '39'), ('Al-Shiakhli', '39', '9.2'), ('39', '9.2', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('39', 'CD'), ('9.2', 'CD'), ('.', '.')]

 (S (NP Sarah/NNP Al-Shiakhli/NNP) 39/CD 9.2/CD ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('39', '39'), ('9.2', '9.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('39', '39'), ('9.2', '9.2'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('39', '39'), ('9.2', '9.2'), ('.', '.')]



============================ Sentence 480 =============================

Data privacy issues   Gathering data from users might lead to privacy challenges where the gathering process may cause   the data context and semantics to be modified, leading to faulty and inefficient policies (Ali et al.,   2016). 


>> Tokens are: 
 ['Data', 'privacy', 'issues', 'Gathering', 'data', 'users', 'might', 'lead', 'privacy', 'challenges', 'gathering', 'process', 'may', 'cause', 'data', 'context', 'semantics', 'modified', ',', 'leading', 'faulty', 'inefficient', 'policies', '(', 'Ali', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Data', 'privacy'), ('privacy', 'issues'), ('issues', 'Gathering'), ('Gathering', 'data'), ('data', 'users'), ('users', 'might'), ('might', 'lead'), ('lead', 'privacy'), ('privacy', 'challenges'), ('challenges', 'gathering'), ('gathering', 'process'), ('process', 'may'), ('may', 'cause'), ('cause', 'data'), ('data', 'context'), ('context', 'semantics'), ('semantics', 'modified'), ('modified', ','), (',', 'leading'), ('leading', 'faulty'), ('faulty', 'inefficient'), ('inefficient', 'policies'), ('policies', '('), ('(', 'Ali'), ('Ali', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Data', 'privacy', 'issues'), ('privacy', 'issues', 'Gathering'), ('issues', 'Gathering', 'data'), ('Gathering', 'data', 'users'), ('data', 'users', 'might'), ('users', 'might', 'lead'), ('might', 'lead', 'privacy'), ('lead', 'privacy', 'challenges'), ('privacy', 'challenges', 'gathering'), ('challenges', 'gathering', 'process'), ('gathering', 'process', 'may'), ('process', 'may', 'cause'), ('may', 'cause', 'data'), ('cause', 'data', 'context'), ('data', 'context', 'semantics'), ('context', 'semantics', 'modified'), ('semantics', 'modified', ','), ('modified', ',', 'leading'), (',', 'leading', 'faulty'), ('leading', 'faulty', 'inefficient'), ('faulty', 'inefficient', 'policies'), ('inefficient', 'policies', '('), ('policies', '(', 'Ali'), ('(', 'Ali', 'et'), ('Ali', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('privacy', 'NN'), ('issues', 'NNS'), ('Gathering', 'NNP'), ('data', 'NNS'), ('users', 'NNS'), ('might', 'MD'), ('lead', 'VB'), ('privacy', 'NN'), ('challenges', 'NNS'), ('gathering', 'VBG'), ('process', 'NN'), ('may', 'MD'), ('cause', 'VB'), ('data', 'NNS'), ('context', 'JJ'), ('semantics', 'NNS'), ('modified', 'VBN'), (',', ','), ('leading', 'VBG'), ('faulty', 'JJ'), ('inefficient', 'JJ'), ('policies', 'NNS'), ('(', '('), ('Ali', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP
    Data/NNP
    privacy/NN
    issues/NNS
    Gathering/NNP
    data/NNS
    users/NNS)
  might/MD
  lead/VB
  (NP privacy/NN challenges/NNS)
  gathering/VBG
  (NP process/NN)
  may/MD
  cause/VB
  (NP data/NNS)
  (NP context/JJ semantics/NNS)
  modified/VBN
  ,/,
  leading/VBG
  (NP faulty/JJ inefficient/JJ policies/NNS)
  (/(
  (NP Ali/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Data privacy issues Gathering data users', 'privacy challenges', 'process', 'data', 'context semantics', 'faulty inefficient policies', 'Ali']

>> Named Entities are: 
 [('GPE', 'Data'), ('PERSON', 'Ali')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu'), ('Gathering', 'gather'), ('data', 'data'), ('users', 'user'), ('might', 'might'), ('lead', 'lead'), ('privacy', 'privaci'), ('challenges', 'challeng'), ('gathering', 'gather'), ('process', 'process'), ('may', 'may'), ('cause', 'caus'), ('data', 'data'), ('context', 'context'), ('semantics', 'semant'), ('modified', 'modifi'), (',', ','), ('leading', 'lead'), ('faulty', 'faulti'), ('inefficient', 'ineffici'), ('policies', 'polici'), ('(', '('), ('Ali', 'ali'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('privacy', 'privaci'), ('issues', 'issu'), ('Gathering', 'gather'), ('data', 'data'), ('users', 'user'), ('might', 'might'), ('lead', 'lead'), ('privacy', 'privaci'), ('challenges', 'challeng'), ('gathering', 'gather'), ('process', 'process'), ('may', 'may'), ('cause', 'caus'), ('data', 'data'), ('context', 'context'), ('semantics', 'semant'), ('modified', 'modifi'), (',', ','), ('leading', 'lead'), ('faulty', 'faulti'), ('inefficient', 'ineffici'), ('policies', 'polici'), ('(', '('), ('Ali', 'ali'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('privacy', 'privacy'), ('issues', 'issue'), ('Gathering', 'Gathering'), ('data', 'data'), ('users', 'user'), ('might', 'might'), ('lead', 'lead'), ('privacy', 'privacy'), ('challenges', 'challenge'), ('gathering', 'gathering'), ('process', 'process'), ('may', 'may'), ('cause', 'cause'), ('data', 'data'), ('context', 'context'), ('semantics', 'semantics'), ('modified', 'modified'), (',', ','), ('leading', 'leading'), ('faulty', 'faulty'), ('inefficient', 'inefficient'), ('policies', 'policy'), ('(', '('), ('Ali', 'Ali'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 481 =============================

Lv et al. 


>> Tokens are: 
 ['Lv', 'et', 'al', '.']

>> Bigrams are: 
 [('Lv', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Lv', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Lv', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Lv/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Lv', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Lv', 'lv'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lv', 'lv'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Lv', 'Lv'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 482 =============================

(2017) showed that one potential problem in big data is data security and privacy, as big   data applications often contain sensitive information such as medical records and banking   transactions which is not appropriate for normal data transmission protocols. 


>> Tokens are: 
 ['(', '2017', ')', 'showed', 'one', 'potential', 'problem', 'big', 'data', 'data', 'security', 'privacy', ',', 'big', 'data', 'applications', 'often', 'contain', 'sensitive', 'information', 'medical', 'records', 'banking', 'transactions', 'appropriate', 'normal', 'data', 'transmission', 'protocols', '.']

>> Bigrams are: 
 [('(', '2017'), ('2017', ')'), (')', 'showed'), ('showed', 'one'), ('one', 'potential'), ('potential', 'problem'), ('problem', 'big'), ('big', 'data'), ('data', 'data'), ('data', 'security'), ('security', 'privacy'), ('privacy', ','), (',', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', 'often'), ('often', 'contain'), ('contain', 'sensitive'), ('sensitive', 'information'), ('information', 'medical'), ('medical', 'records'), ('records', 'banking'), ('banking', 'transactions'), ('transactions', 'appropriate'), ('appropriate', 'normal'), ('normal', 'data'), ('data', 'transmission'), ('transmission', 'protocols'), ('protocols', '.')]

>> Trigrams are: 
 [('(', '2017', ')'), ('2017', ')', 'showed'), (')', 'showed', 'one'), ('showed', 'one', 'potential'), ('one', 'potential', 'problem'), ('potential', 'problem', 'big'), ('problem', 'big', 'data'), ('big', 'data', 'data'), ('data', 'data', 'security'), ('data', 'security', 'privacy'), ('security', 'privacy', ','), ('privacy', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', 'often'), ('applications', 'often', 'contain'), ('often', 'contain', 'sensitive'), ('contain', 'sensitive', 'information'), ('sensitive', 'information', 'medical'), ('information', 'medical', 'records'), ('medical', 'records', 'banking'), ('records', 'banking', 'transactions'), ('banking', 'transactions', 'appropriate'), ('transactions', 'appropriate', 'normal'), ('appropriate', 'normal', 'data'), ('normal', 'data', 'transmission'), ('data', 'transmission', 'protocols'), ('transmission', 'protocols', '.')]

>> POS Tags are: 
 [('(', '('), ('2017', 'CD'), (')', ')'), ('showed', 'VBD'), ('one', 'CD'), ('potential', 'NN'), ('problem', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('data', 'NNS'), ('security', 'NN'), ('privacy', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('applications', 'NNS'), ('often', 'RB'), ('contain', 'VBP'), ('sensitive', 'JJ'), ('information', 'NN'), ('medical', 'JJ'), ('records', 'NNS'), ('banking', 'VBG'), ('transactions', 'NNS'), ('appropriate', 'VBP'), ('normal', 'JJ'), ('data', 'NNS'), ('transmission', 'NN'), ('protocols', 'NNS'), ('.', '.')]

 (S
  (/(
  2017/CD
  )/)
  showed/VBD
  one/CD
  (NP potential/NN problem/NN)
  (NP big/JJ data/NNS data/NNS security/NN privacy/NN)
  ,/,
  (NP big/JJ data/NN applications/NNS)
  often/RB
  contain/VBP
  (NP sensitive/JJ information/NN)
  (NP medical/JJ records/NNS)
  banking/VBG
  (NP transactions/NNS)
  appropriate/VBP
  (NP normal/JJ data/NNS transmission/NN protocols/NNS)
  ./.) 


>> Noun Phrases are: 
 ['potential problem', 'big data data security privacy', 'big data applications', 'sensitive information', 'medical records', 'transactions', 'normal data transmission protocols']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('showed', 'show'), ('one', 'one'), ('potential', 'potenti'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), (',', ','), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('often', 'often'), ('contain', 'contain'), ('sensitive', 'sensit'), ('information', 'inform'), ('medical', 'medic'), ('records', 'record'), ('banking', 'bank'), ('transactions', 'transact'), ('appropriate', 'appropri'), ('normal', 'normal'), ('data', 'data'), ('transmission', 'transmiss'), ('protocols', 'protocol'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('showed', 'show'), ('one', 'one'), ('potential', 'potenti'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), (',', ','), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('often', 'often'), ('contain', 'contain'), ('sensitive', 'sensit'), ('information', 'inform'), ('medical', 'medic'), ('records', 'record'), ('banking', 'bank'), ('transactions', 'transact'), ('appropriate', 'appropri'), ('normal', 'normal'), ('data', 'data'), ('transmission', 'transmiss'), ('protocols', 'protocol'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('showed', 'showed'), ('one', 'one'), ('potential', 'potential'), ('problem', 'problem'), ('big', 'big'), ('data', 'data'), ('data', 'data'), ('security', 'security'), ('privacy', 'privacy'), (',', ','), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('often', 'often'), ('contain', 'contain'), ('sensitive', 'sensitive'), ('information', 'information'), ('medical', 'medical'), ('records', 'record'), ('banking', 'banking'), ('transactions', 'transaction'), ('appropriate', 'appropriate'), ('normal', 'normal'), ('data', 'data'), ('transmission', 'transmission'), ('protocols', 'protocol'), ('.', '.')]



============================ Sentence 483 =============================

Data security and   privacy must thus be considered before the adoption of any protocol for sharing information. 


>> Tokens are: 
 ['Data', 'security', 'privacy', 'must', 'thus', 'considered', 'adoption', 'protocol', 'sharing', 'information', '.']

>> Bigrams are: 
 [('Data', 'security'), ('security', 'privacy'), ('privacy', 'must'), ('must', 'thus'), ('thus', 'considered'), ('considered', 'adoption'), ('adoption', 'protocol'), ('protocol', 'sharing'), ('sharing', 'information'), ('information', '.')]

>> Trigrams are: 
 [('Data', 'security', 'privacy'), ('security', 'privacy', 'must'), ('privacy', 'must', 'thus'), ('must', 'thus', 'considered'), ('thus', 'considered', 'adoption'), ('considered', 'adoption', 'protocol'), ('adoption', 'protocol', 'sharing'), ('protocol', 'sharing', 'information'), ('sharing', 'information', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('security', 'NN'), ('privacy', 'NN'), ('must', 'MD'), ('thus', 'RB'), ('considered', 'VBN'), ('adoption', 'NN'), ('protocol', 'NN'), ('sharing', 'VBG'), ('information', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP security/NN privacy/NN)
  must/MD
  thus/RB
  considered/VBN
  (NP adoption/NN protocol/NN)
  sharing/VBG
  (NP information/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data security privacy', 'adoption protocol', 'information']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('must', 'must'), ('thus', 'thu'), ('considered', 'consid'), ('adoption', 'adopt'), ('protocol', 'protocol'), ('sharing', 'share'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('must', 'must'), ('thus', 'thus'), ('considered', 'consid'), ('adoption', 'adopt'), ('protocol', 'protocol'), ('sharing', 'share'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('security', 'security'), ('privacy', 'privacy'), ('must', 'must'), ('thus', 'thus'), ('considered', 'considered'), ('adoption', 'adoption'), ('protocol', 'protocol'), ('sharing', 'sharing'), ('information', 'information'), ('.', '.')]



============================ Sentence 484 =============================

The   challenges caused by the inclusion of sensitive information and the requirements for access control   or certification are generally well known; however, secured certification mechanisms remain   challenging to implement, and anonymisation approaches decrease data confidence (Wang et al.,   2016). 


>> Tokens are: 
 ['The', 'challenges', 'caused', 'inclusion', 'sensitive', 'information', 'requirements', 'access', 'control', 'certification', 'generally', 'well', 'known', ';', 'however', ',', 'secured', 'certification', 'mechanisms', 'remain', 'challenging', 'implement', ',', 'anonymisation', 'approaches', 'decrease', 'data', 'confidence', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('The', 'challenges'), ('challenges', 'caused'), ('caused', 'inclusion'), ('inclusion', 'sensitive'), ('sensitive', 'information'), ('information', 'requirements'), ('requirements', 'access'), ('access', 'control'), ('control', 'certification'), ('certification', 'generally'), ('generally', 'well'), ('well', 'known'), ('known', ';'), (';', 'however'), ('however', ','), (',', 'secured'), ('secured', 'certification'), ('certification', 'mechanisms'), ('mechanisms', 'remain'), ('remain', 'challenging'), ('challenging', 'implement'), ('implement', ','), (',', 'anonymisation'), ('anonymisation', 'approaches'), ('approaches', 'decrease'), ('decrease', 'data'), ('data', 'confidence'), ('confidence', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'challenges', 'caused'), ('challenges', 'caused', 'inclusion'), ('caused', 'inclusion', 'sensitive'), ('inclusion', 'sensitive', 'information'), ('sensitive', 'information', 'requirements'), ('information', 'requirements', 'access'), ('requirements', 'access', 'control'), ('access', 'control', 'certification'), ('control', 'certification', 'generally'), ('certification', 'generally', 'well'), ('generally', 'well', 'known'), ('well', 'known', ';'), ('known', ';', 'however'), (';', 'however', ','), ('however', ',', 'secured'), (',', 'secured', 'certification'), ('secured', 'certification', 'mechanisms'), ('certification', 'mechanisms', 'remain'), ('mechanisms', 'remain', 'challenging'), ('remain', 'challenging', 'implement'), ('challenging', 'implement', ','), ('implement', ',', 'anonymisation'), (',', 'anonymisation', 'approaches'), ('anonymisation', 'approaches', 'decrease'), ('approaches', 'decrease', 'data'), ('decrease', 'data', 'confidence'), ('data', 'confidence', '('), ('confidence', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('challenges', 'NNS'), ('caused', 'VBN'), ('inclusion', 'NN'), ('sensitive', 'JJ'), ('information', 'NN'), ('requirements', 'NNS'), ('access', 'NN'), ('control', 'NN'), ('certification', 'NN'), ('generally', 'RB'), ('well', 'RB'), ('known', 'VBN'), (';', ':'), ('however', 'RB'), (',', ','), ('secured', 'VBN'), ('certification', 'NN'), ('mechanisms', 'NNS'), ('remain', 'VBP'), ('challenging', 'JJ'), ('implement', 'NN'), (',', ','), ('anonymisation', 'NN'), ('approaches', 'NNS'), ('decrease', 'VBP'), ('data', 'NNS'), ('confidence', 'NN'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT challenges/NNS)
  caused/VBN
  (NP inclusion/NN)
  (NP
    sensitive/JJ
    information/NN
    requirements/NNS
    access/NN
    control/NN
    certification/NN)
  generally/RB
  well/RB
  known/VBN
  ;/:
  however/RB
  ,/,
  secured/VBN
  (NP certification/NN mechanisms/NNS)
  remain/VBP
  (NP challenging/JJ implement/NN)
  ,/,
  (NP anonymisation/NN approaches/NNS)
  decrease/VBP
  (NP data/NNS confidence/NN)
  (/(
  (NP Wang/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The challenges', 'inclusion', 'sensitive information requirements access control certification', 'certification mechanisms', 'challenging implement', 'anonymisation approaches', 'data confidence', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('challenges', 'challeng'), ('caused', 'caus'), ('inclusion', 'inclus'), ('sensitive', 'sensit'), ('information', 'inform'), ('requirements', 'requir'), ('access', 'access'), ('control', 'control'), ('certification', 'certif'), ('generally', 'gener'), ('well', 'well'), ('known', 'known'), (';', ';'), ('however', 'howev'), (',', ','), ('secured', 'secur'), ('certification', 'certif'), ('mechanisms', 'mechan'), ('remain', 'remain'), ('challenging', 'challeng'), ('implement', 'implement'), (',', ','), ('anonymisation', 'anonymis'), ('approaches', 'approach'), ('decrease', 'decreas'), ('data', 'data'), ('confidence', 'confid'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('challenges', 'challeng'), ('caused', 'caus'), ('inclusion', 'inclus'), ('sensitive', 'sensit'), ('information', 'inform'), ('requirements', 'requir'), ('access', 'access'), ('control', 'control'), ('certification', 'certif'), ('generally', 'general'), ('well', 'well'), ('known', 'known'), (';', ';'), ('however', 'howev'), (',', ','), ('secured', 'secur'), ('certification', 'certif'), ('mechanisms', 'mechan'), ('remain', 'remain'), ('challenging', 'challeng'), ('implement', 'implement'), (',', ','), ('anonymisation', 'anonymis'), ('approaches', 'approach'), ('decrease', 'decreas'), ('data', 'data'), ('confidence', 'confid'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('challenges', 'challenge'), ('caused', 'caused'), ('inclusion', 'inclusion'), ('sensitive', 'sensitive'), ('information', 'information'), ('requirements', 'requirement'), ('access', 'access'), ('control', 'control'), ('certification', 'certification'), ('generally', 'generally'), ('well', 'well'), ('known', 'known'), (';', ';'), ('however', 'however'), (',', ','), ('secured', 'secured'), ('certification', 'certification'), ('mechanisms', 'mechanism'), ('remain', 'remain'), ('challenging', 'challenging'), ('implement', 'implement'), (',', ','), ('anonymisation', 'anonymisation'), ('approaches', 'approach'), ('decrease', 'decrease'), ('data', 'data'), ('confidence', 'confidence'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 485 =============================

Big data privacy contains two aspects: the first is that the personal data privacy should be protected   during data gaining such as personal interests, habits, and body properties, etc. 


>> Tokens are: 
 ['Big', 'data', 'privacy', 'contains', 'two', 'aspects', ':', 'first', 'personal', 'data', 'privacy', 'protected', 'data', 'gaining', 'personal', 'interests', ',', 'habits', ',', 'body', 'properties', ',', 'etc', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'privacy'), ('privacy', 'contains'), ('contains', 'two'), ('two', 'aspects'), ('aspects', ':'), (':', 'first'), ('first', 'personal'), ('personal', 'data'), ('data', 'privacy'), ('privacy', 'protected'), ('protected', 'data'), ('data', 'gaining'), ('gaining', 'personal'), ('personal', 'interests'), ('interests', ','), (',', 'habits'), ('habits', ','), (',', 'body'), ('body', 'properties'), ('properties', ','), (',', 'etc'), ('etc', '.')]

>> Trigrams are: 
 [('Big', 'data', 'privacy'), ('data', 'privacy', 'contains'), ('privacy', 'contains', 'two'), ('contains', 'two', 'aspects'), ('two', 'aspects', ':'), ('aspects', ':', 'first'), (':', 'first', 'personal'), ('first', 'personal', 'data'), ('personal', 'data', 'privacy'), ('data', 'privacy', 'protected'), ('privacy', 'protected', 'data'), ('protected', 'data', 'gaining'), ('data', 'gaining', 'personal'), ('gaining', 'personal', 'interests'), ('personal', 'interests', ','), ('interests', ',', 'habits'), (',', 'habits', ','), ('habits', ',', 'body'), (',', 'body', 'properties'), ('body', 'properties', ','), ('properties', ',', 'etc'), (',', 'etc', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('privacy', 'NN'), ('contains', 'VBZ'), ('two', 'CD'), ('aspects', 'NNS'), (':', ':'), ('first', 'JJ'), ('personal', 'JJ'), ('data', 'NNS'), ('privacy', 'NN'), ('protected', 'VBN'), ('data', 'NNS'), ('gaining', 'VBG'), ('personal', 'JJ'), ('interests', 'NNS'), (',', ','), ('habits', 'NNS'), (',', ','), ('body', 'NN'), ('properties', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS privacy/NN)
  contains/VBZ
  two/CD
  (NP aspects/NNS)
  :/:
  (NP first/JJ personal/JJ data/NNS privacy/NN)
  protected/VBN
  (NP data/NNS)
  gaining/VBG
  (NP personal/JJ interests/NNS)
  ,/,
  (NP habits/NNS)
  ,/,
  (NP body/NN properties/NNS)
  ,/,
  etc/FW
  ./.) 


>> Noun Phrases are: 
 ['Big data privacy', 'aspects', 'first personal data privacy', 'data', 'personal interests', 'habits', 'body properties']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('contains', 'contain'), ('two', 'two'), ('aspects', 'aspect'), (':', ':'), ('first', 'first'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci'), ('protected', 'protect'), ('data', 'data'), ('gaining', 'gain'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('privacy', 'privaci'), ('contains', 'contain'), ('two', 'two'), ('aspects', 'aspect'), (':', ':'), ('first', 'first'), ('personal', 'person'), ('data', 'data'), ('privacy', 'privaci'), ('protected', 'protect'), ('data', 'data'), ('gaining', 'gain'), ('personal', 'person'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'bodi'), ('properties', 'properti'), (',', ','), ('etc', 'etc'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('privacy', 'privacy'), ('contains', 'contains'), ('two', 'two'), ('aspects', 'aspect'), (':', ':'), ('first', 'first'), ('personal', 'personal'), ('data', 'data'), ('privacy', 'privacy'), ('protected', 'protected'), ('data', 'data'), ('gaining', 'gaining'), ('personal', 'personal'), ('interests', 'interest'), (',', ','), ('habits', 'habit'), (',', ','), ('body', 'body'), ('properties', 'property'), (',', ','), ('etc', 'etc'), ('.', '.')]



============================ Sentence 486 =============================

of users who do   not aware or easy to gain information from them. 


>> Tokens are: 
 ['users', 'aware', 'easy', 'gain', 'information', '.']

>> Bigrams are: 
 [('users', 'aware'), ('aware', 'easy'), ('easy', 'gain'), ('gain', 'information'), ('information', '.')]

>> Trigrams are: 
 [('users', 'aware', 'easy'), ('aware', 'easy', 'gain'), ('easy', 'gain', 'information'), ('gain', 'information', '.')]

>> POS Tags are: 
 [('users', 'NNS'), ('aware', 'JJ'), ('easy', 'JJ'), ('gain', 'NN'), ('information', 'NN'), ('.', '.')]

 (S (NP users/NNS) (NP aware/JJ easy/JJ gain/NN information/NN) ./.) 


>> Noun Phrases are: 
 ['users', 'aware easy gain information']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('users', 'user'), ('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('users', 'user'), ('aware', 'awar'), ('easy', 'easi'), ('gain', 'gain'), ('information', 'inform'), ('.', '.')]

>> Lemmatization: 
 [('users', 'user'), ('aware', 'aware'), ('easy', 'easy'), ('gain', 'gain'), ('information', 'information'), ('.', '.')]



============================ Sentence 487 =============================

The second aspect is that the personal privacy   data might discharge during storage, transmission, and usage, even if it gained with the user   permission. 


>> Tokens are: 
 ['The', 'second', 'aspect', 'personal', 'privacy', 'data', 'might', 'discharge', 'storage', ',', 'transmission', ',', 'usage', ',', 'even', 'gained', 'user', 'permission', '.']

>> Bigrams are: 
 [('The', 'second'), ('second', 'aspect'), ('aspect', 'personal'), ('personal', 'privacy'), ('privacy', 'data'), ('data', 'might'), ('might', 'discharge'), ('discharge', 'storage'), ('storage', ','), (',', 'transmission'), ('transmission', ','), (',', 'usage'), ('usage', ','), (',', 'even'), ('even', 'gained'), ('gained', 'user'), ('user', 'permission'), ('permission', '.')]

>> Trigrams are: 
 [('The', 'second', 'aspect'), ('second', 'aspect', 'personal'), ('aspect', 'personal', 'privacy'), ('personal', 'privacy', 'data'), ('privacy', 'data', 'might'), ('data', 'might', 'discharge'), ('might', 'discharge', 'storage'), ('discharge', 'storage', ','), ('storage', ',', 'transmission'), (',', 'transmission', ','), ('transmission', ',', 'usage'), (',', 'usage', ','), ('usage', ',', 'even'), (',', 'even', 'gained'), ('even', 'gained', 'user'), ('gained', 'user', 'permission'), ('user', 'permission', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('second', 'JJ'), ('aspect', 'JJ'), ('personal', 'JJ'), ('privacy', 'NN'), ('data', 'NNS'), ('might', 'MD'), ('discharge', 'VB'), ('storage', 'NN'), (',', ','), ('transmission', 'NN'), (',', ','), ('usage', 'NN'), (',', ','), ('even', 'RB'), ('gained', 'VBD'), ('user', 'JJ'), ('permission', 'NN'), ('.', '.')]

 (S
  (NP The/DT second/JJ aspect/JJ personal/JJ privacy/NN data/NNS)
  might/MD
  discharge/VB
  (NP storage/NN)
  ,/,
  (NP transmission/NN)
  ,/,
  (NP usage/NN)
  ,/,
  even/RB
  gained/VBD
  (NP user/JJ permission/NN)
  ./.) 


>> Noun Phrases are: 
 ['The second aspect personal privacy data', 'storage', 'transmission', 'usage', 'user permission']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('second', 'second'), ('aspect', 'aspect'), ('personal', 'person'), ('privacy', 'privaci'), ('data', 'data'), ('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user'), ('permission', 'permiss'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('second', 'second'), ('aspect', 'aspect'), ('personal', 'person'), ('privacy', 'privaci'), ('data', 'data'), ('might', 'might'), ('discharge', 'discharg'), ('storage', 'storag'), (',', ','), ('transmission', 'transmiss'), (',', ','), ('usage', 'usag'), (',', ','), ('even', 'even'), ('gained', 'gain'), ('user', 'user'), ('permission', 'permiss'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('second', 'second'), ('aspect', 'aspect'), ('personal', 'personal'), ('privacy', 'privacy'), ('data', 'data'), ('might', 'might'), ('discharge', 'discharge'), ('storage', 'storage'), (',', ','), ('transmission', 'transmission'), (',', ','), ('usage', 'usage'), (',', ','), ('even', 'even'), ('gained', 'gained'), ('user', 'user'), ('permission', 'permission'), ('.', '.')]



============================ Sentence 488 =============================

For example, currently, Facebook is considered as a big data company with the most   social networking service SNS data. 


>> Tokens are: 
 ['For', 'example', ',', 'currently', ',', 'Facebook', 'considered', 'big', 'data', 'company', 'social', 'networking', 'service', 'SNS', 'data', '.']

>> Bigrams are: 
 [('For', 'example'), ('example', ','), (',', 'currently'), ('currently', ','), (',', 'Facebook'), ('Facebook', 'considered'), ('considered', 'big'), ('big', 'data'), ('data', 'company'), ('company', 'social'), ('social', 'networking'), ('networking', 'service'), ('service', 'SNS'), ('SNS', 'data'), ('data', '.')]

>> Trigrams are: 
 [('For', 'example', ','), ('example', ',', 'currently'), (',', 'currently', ','), ('currently', ',', 'Facebook'), (',', 'Facebook', 'considered'), ('Facebook', 'considered', 'big'), ('considered', 'big', 'data'), ('big', 'data', 'company'), ('data', 'company', 'social'), ('company', 'social', 'networking'), ('social', 'networking', 'service'), ('networking', 'service', 'SNS'), ('service', 'SNS', 'data'), ('SNS', 'data', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('example', 'NN'), (',', ','), ('currently', 'RB'), (',', ','), ('Facebook', 'NNP'), ('considered', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('company', 'NN'), ('social', 'JJ'), ('networking', 'NN'), ('service', 'NN'), ('SNS', 'NNP'), ('data', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP example/NN)
  ,/,
  currently/RB
  ,/,
  (NP Facebook/NNP)
  considered/VBD
  (NP big/JJ data/NNS company/NN)
  (NP social/JJ networking/NN service/NN SNS/NNP data/NN)
  ./.) 


>> Noun Phrases are: 
 ['example', 'Facebook', 'big data company', 'social networking service SNS data']

>> Named Entities are: 
 [('PERSON', 'Facebook'), ('ORGANIZATION', 'SNS')] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('currently', 'current'), (',', ','), ('Facebook', 'facebook'), ('considered', 'consid'), ('big', 'big'), ('data', 'data'), ('company', 'compani'), ('social', 'social'), ('networking', 'network'), ('service', 'servic'), ('SNS', 'sn'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('example', 'exampl'), (',', ','), ('currently', 'current'), (',', ','), ('Facebook', 'facebook'), ('considered', 'consid'), ('big', 'big'), ('data', 'data'), ('company', 'compani'), ('social', 'social'), ('networking', 'network'), ('service', 'servic'), ('SNS', 'sns'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('example', 'example'), (',', ','), ('currently', 'currently'), (',', ','), ('Facebook', 'Facebook'), ('considered', 'considered'), ('big', 'big'), ('data', 'data'), ('company', 'company'), ('social', 'social'), ('networking', 'networking'), ('service', 'service'), ('SNS', 'SNS'), ('data', 'data'), ('.', '.')]



============================ Sentence 489 =============================

Even though, some researchers gained data from public pages   of Facebook users who did not change their privacy setting through an information-gaining tool   (Chen, M., Mao, S. and Liu, Y., 2014). 


>> Tokens are: 
 ['Even', 'though', ',', 'researchers', 'gained', 'data', 'public', 'pages', 'Facebook', 'users', 'change', 'privacy', 'setting', 'information-gaining', 'tool', '(', 'Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Even', 'though'), ('though', ','), (',', 'researchers'), ('researchers', 'gained'), ('gained', 'data'), ('data', 'public'), ('public', 'pages'), ('pages', 'Facebook'), ('Facebook', 'users'), ('users', 'change'), ('change', 'privacy'), ('privacy', 'setting'), ('setting', 'information-gaining'), ('information-gaining', 'tool'), ('tool', '('), ('(', 'Chen'), ('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Even', 'though', ','), ('though', ',', 'researchers'), (',', 'researchers', 'gained'), ('researchers', 'gained', 'data'), ('gained', 'data', 'public'), ('data', 'public', 'pages'), ('public', 'pages', 'Facebook'), ('pages', 'Facebook', 'users'), ('Facebook', 'users', 'change'), ('users', 'change', 'privacy'), ('change', 'privacy', 'setting'), ('privacy', 'setting', 'information-gaining'), ('setting', 'information-gaining', 'tool'), ('information-gaining', 'tool', '('), ('tool', '(', 'Chen'), ('(', 'Chen', ','), ('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Even', 'RB'), ('though', 'IN'), (',', ','), ('researchers', 'NNS'), ('gained', 'VBD'), ('data', 'NNS'), ('public', 'JJ'), ('pages', 'NNS'), ('Facebook', 'NNP'), ('users', 'NNS'), ('change', 'VBP'), ('privacy', 'NN'), ('setting', 'VBG'), ('information-gaining', 'JJ'), ('tool', 'NN'), ('(', '('), ('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  Even/RB
  though/IN
  ,/,
  (NP researchers/NNS)
  gained/VBD
  (NP data/NNS)
  (NP public/JJ pages/NNS Facebook/NNP users/NNS)
  change/VBP
  (NP privacy/NN)
  setting/VBG
  (NP information-gaining/JJ tool/NN)
  (/(
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Mao/NNP)
  ,/,
  (NP S./NNP Liu/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['researchers', 'data', 'public pages Facebook users', 'privacy', 'information-gaining tool', 'Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('Even', 'even'), ('though', 'though'), (',', ','), ('researchers', 'research'), ('gained', 'gain'), ('data', 'data'), ('public', 'public'), ('pages', 'page'), ('Facebook', 'facebook'), ('users', 'user'), ('change', 'chang'), ('privacy', 'privaci'), ('setting', 'set'), ('information-gaining', 'information-gain'), ('tool', 'tool'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Even', 'even'), ('though', 'though'), (',', ','), ('researchers', 'research'), ('gained', 'gain'), ('data', 'data'), ('public', 'public'), ('pages', 'page'), ('Facebook', 'facebook'), ('users', 'user'), ('change', 'chang'), ('privacy', 'privaci'), ('setting', 'set'), ('information-gaining', 'information-gain'), ('tool', 'tool'), ('(', '('), ('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Even', 'Even'), ('though', 'though'), (',', ','), ('researchers', 'researcher'), ('gained', 'gained'), ('data', 'data'), ('public', 'public'), ('pages', 'page'), ('Facebook', 'Facebook'), ('users', 'user'), ('change', 'change'), ('privacy', 'privacy'), ('setting', 'setting'), ('information-gaining', 'information-gaining'), ('tool', 'tool'), ('(', '('), ('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 490 =============================

9.3. 


>> Tokens are: 
 ['9.3', '.']

>> Bigrams are: 
 [('9.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('9.3', 'CD'), ('.', '.')]

 (S 9.3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('9.3', '9.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('9.3', '9.3'), ('.', '.')]

>> Lemmatization: 
 [('9.3', '9.3'), ('.', '.')]



============================ Sentence 491 =============================

Data storage, data capture and quality of data   Capturing and storing data is not easy, especially as data sets are increasingly growing in size and   complexity. 


>> Tokens are: 
 ['Data', 'storage', ',', 'data', 'capture', 'quality', 'data', 'Capturing', 'storing', 'data', 'easy', ',', 'especially', 'data', 'sets', 'increasingly', 'growing', 'size', 'complexity', '.']

>> Bigrams are: 
 [('Data', 'storage'), ('storage', ','), (',', 'data'), ('data', 'capture'), ('capture', 'quality'), ('quality', 'data'), ('data', 'Capturing'), ('Capturing', 'storing'), ('storing', 'data'), ('data', 'easy'), ('easy', ','), (',', 'especially'), ('especially', 'data'), ('data', 'sets'), ('sets', 'increasingly'), ('increasingly', 'growing'), ('growing', 'size'), ('size', 'complexity'), ('complexity', '.')]

>> Trigrams are: 
 [('Data', 'storage', ','), ('storage', ',', 'data'), (',', 'data', 'capture'), ('data', 'capture', 'quality'), ('capture', 'quality', 'data'), ('quality', 'data', 'Capturing'), ('data', 'Capturing', 'storing'), ('Capturing', 'storing', 'data'), ('storing', 'data', 'easy'), ('data', 'easy', ','), ('easy', ',', 'especially'), (',', 'especially', 'data'), ('especially', 'data', 'sets'), ('data', 'sets', 'increasingly'), ('sets', 'increasingly', 'growing'), ('increasingly', 'growing', 'size'), ('growing', 'size', 'complexity'), ('size', 'complexity', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('storage', 'NN'), (',', ','), ('data', 'NNS'), ('capture', 'VBP'), ('quality', 'NN'), ('data', 'NNS'), ('Capturing', 'VBG'), ('storing', 'VBG'), ('data', 'NNS'), ('easy', 'RB'), (',', ','), ('especially', 'RB'), ('data', 'JJ'), ('sets', 'NNS'), ('increasingly', 'RB'), ('growing', 'VBG'), ('size', 'NN'), ('complexity', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP storage/NN)
  ,/,
  (NP data/NNS)
  capture/VBP
  (NP quality/NN data/NNS)
  Capturing/VBG
  storing/VBG
  (NP data/NNS)
  easy/RB
  ,/,
  especially/RB
  (NP data/JJ sets/NNS)
  increasingly/RB
  growing/VBG
  (NP size/NN complexity/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data storage', 'data', 'quality data', 'data', 'data sets', 'size complexity']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data'), ('Capturing', 'captur'), ('storing', 'store'), ('data', 'data'), ('easy', 'easi'), (',', ','), ('especially', 'especi'), ('data', 'data'), ('sets', 'set'), ('increasingly', 'increasingli'), ('growing', 'grow'), ('size', 'size'), ('complexity', 'complex'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('storage', 'storag'), (',', ','), ('data', 'data'), ('capture', 'captur'), ('quality', 'qualiti'), ('data', 'data'), ('Capturing', 'captur'), ('storing', 'store'), ('data', 'data'), ('easy', 'easi'), (',', ','), ('especially', 'especi'), ('data', 'data'), ('sets', 'set'), ('increasingly', 'increas'), ('growing', 'grow'), ('size', 'size'), ('complexity', 'complex'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('storage', 'storage'), (',', ','), ('data', 'data'), ('capture', 'capture'), ('quality', 'quality'), ('data', 'data'), ('Capturing', 'Capturing'), ('storing', 'storing'), ('data', 'data'), ('easy', 'easy'), (',', ','), ('especially', 'especially'), ('data', 'data'), ('sets', 'set'), ('increasingly', 'increasingly'), ('growing', 'growing'), ('size', 'size'), ('complexity', 'complexity'), ('.', '.')]



============================ Sentence 492 =============================

There is often not enough space to store such big data, and many sectors and fields   such as the financial and medical areas are forced to delete data. 


>> Tokens are: 
 ['There', 'often', 'enough', 'space', 'store', 'big', 'data', ',', 'many', 'sectors', 'fields', 'financial', 'medical', 'areas', 'forced', 'delete', 'data', '.']

>> Bigrams are: 
 [('There', 'often'), ('often', 'enough'), ('enough', 'space'), ('space', 'store'), ('store', 'big'), ('big', 'data'), ('data', ','), (',', 'many'), ('many', 'sectors'), ('sectors', 'fields'), ('fields', 'financial'), ('financial', 'medical'), ('medical', 'areas'), ('areas', 'forced'), ('forced', 'delete'), ('delete', 'data'), ('data', '.')]

>> Trigrams are: 
 [('There', 'often', 'enough'), ('often', 'enough', 'space'), ('enough', 'space', 'store'), ('space', 'store', 'big'), ('store', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'many'), (',', 'many', 'sectors'), ('many', 'sectors', 'fields'), ('sectors', 'fields', 'financial'), ('fields', 'financial', 'medical'), ('financial', 'medical', 'areas'), ('medical', 'areas', 'forced'), ('areas', 'forced', 'delete'), ('forced', 'delete', 'data'), ('delete', 'data', '.')]

>> POS Tags are: 
 [('There', 'EX'), ('often', 'RB'), ('enough', 'JJ'), ('space', 'NN'), ('store', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('many', 'JJ'), ('sectors', 'NNS'), ('fields', 'VBP'), ('financial', 'JJ'), ('medical', 'JJ'), ('areas', 'NNS'), ('forced', 'VBD'), ('delete', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  There/EX
  often/RB
  (NP enough/JJ space/NN store/NN)
  (NP big/JJ data/NNS)
  ,/,
  (NP many/JJ sectors/NNS)
  fields/VBP
  (NP financial/JJ medical/JJ areas/NNS)
  forced/VBD
  (NP delete/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['enough space store', 'big data', 'many sectors', 'financial medical areas', 'delete data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('There', 'there'), ('often', 'often'), ('enough', 'enough'), ('space', 'space'), ('store', 'store'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'mani'), ('sectors', 'sector'), ('fields', 'field'), ('financial', 'financi'), ('medical', 'medic'), ('areas', 'area'), ('forced', 'forc'), ('delete', 'delet'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('There', 'there'), ('often', 'often'), ('enough', 'enough'), ('space', 'space'), ('store', 'store'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'mani'), ('sectors', 'sector'), ('fields', 'field'), ('financial', 'financi'), ('medical', 'medic'), ('areas', 'area'), ('forced', 'forc'), ('delete', 'delet'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('There', 'There'), ('often', 'often'), ('enough', 'enough'), ('space', 'space'), ('store', 'store'), ('big', 'big'), ('data', 'data'), (',', ','), ('many', 'many'), ('sectors', 'sector'), ('fields', 'field'), ('financial', 'financial'), ('medical', 'medical'), ('areas', 'area'), ('forced', 'forced'), ('delete', 'delete'), ('data', 'data'), ('.', '.')]



============================ Sentence 493 =============================

Capturing and creating valuable   data is only done at a high cost (Chen et al., 2014). 


>> Tokens are: 
 ['Capturing', 'creating', 'valuable', 'data', 'done', 'high', 'cost', '(', 'Chen', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Capturing', 'creating'), ('creating', 'valuable'), ('valuable', 'data'), ('data', 'done'), ('done', 'high'), ('high', 'cost'), ('cost', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Capturing', 'creating', 'valuable'), ('creating', 'valuable', 'data'), ('valuable', 'data', 'done'), ('data', 'done', 'high'), ('done', 'high', 'cost'), ('high', 'cost', '('), ('cost', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Capturing', 'VBG'), ('creating', 'VBG'), ('valuable', 'JJ'), ('data', 'NNS'), ('done', 'VBN'), ('high', 'JJ'), ('cost', 'NN'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  Capturing/VBG
  creating/VBG
  (NP valuable/JJ data/NNS)
  done/VBN
  (NP high/JJ cost/NN)
  (/(
  (NP Chen/NNP)
  et/VBZ
  al./RB
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['valuable data', 'high cost', 'Chen']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Capturing', 'captur'), ('creating', 'creat'), ('valuable', 'valuabl'), ('data', 'data'), ('done', 'done'), ('high', 'high'), ('cost', 'cost'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Capturing', 'captur'), ('creating', 'creat'), ('valuable', 'valuabl'), ('data', 'data'), ('done', 'done'), ('high', 'high'), ('cost', 'cost'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Capturing', 'Capturing'), ('creating', 'creating'), ('valuable', 'valuable'), ('data', 'data'), ('done', 'done'), ('high', 'high'), ('cost', 'cost'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 494 =============================

Oussous et al. 


>> Tokens are: 
 ['Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Oussous', 'JJ'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

 (S (NP Oussous/JJ et/NN al/NN) ./.) 


>> Noun Phrases are: 
 ['Oussous et al']

>> Named Entities are: 
 [('GPE', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 495 =============================

(2018) discussed big data characteristics in terms of it being processed by many   analytics tools and visualisations. 


>> Tokens are: 
 ['(', '2018', ')', 'discussed', 'big', 'data', 'characteristics', 'terms', 'processed', 'many', 'analytics', 'tools', 'visualisations', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'discussed'), ('discussed', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', 'terms'), ('terms', 'processed'), ('processed', 'many'), ('many', 'analytics'), ('analytics', 'tools'), ('tools', 'visualisations'), ('visualisations', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'discussed'), (')', 'discussed', 'big'), ('discussed', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', 'terms'), ('characteristics', 'terms', 'processed'), ('terms', 'processed', 'many'), ('processed', 'many', 'analytics'), ('many', 'analytics', 'tools'), ('analytics', 'tools', 'visualisations'), ('tools', 'visualisations', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('discussed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), ('terms', 'NNS'), ('processed', 'VBD'), ('many', 'JJ'), ('analytics', 'NNS'), ('tools', 'JJ'), ('visualisations', 'NNS'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  discussed/VBD
  (NP big/JJ data/NNS characteristics/NNS terms/NNS)
  processed/VBD
  (NP many/JJ analytics/NNS)
  (NP tools/JJ visualisations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data characteristics terms', 'many analytics', 'tools visualisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('terms', 'term'), ('processed', 'process'), ('many', 'mani'), ('analytics', 'analyt'), ('tools', 'tool'), ('visualisations', 'visualis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('terms', 'term'), ('processed', 'process'), ('many', 'mani'), ('analytics', 'analyt'), ('tools', 'tool'), ('visualisations', 'visualis'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discussed'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), ('terms', 'term'), ('processed', 'processed'), ('many', 'many'), ('analytics', 'analytics'), ('tools', 'tool'), ('visualisations', 'visualisation'), ('.', '.')]



============================ Sentence 496 =============================

The big data platforms layer and its components and   technologies were explained. 


>> Tokens are: 
 ['The', 'big', 'data', 'platforms', 'layer', 'components', 'technologies', 'explained', '.']

>> Bigrams are: 
 [('The', 'big'), ('big', 'data'), ('data', 'platforms'), ('platforms', 'layer'), ('layer', 'components'), ('components', 'technologies'), ('technologies', 'explained'), ('explained', '.')]

>> Trigrams are: 
 [('The', 'big', 'data'), ('big', 'data', 'platforms'), ('data', 'platforms', 'layer'), ('platforms', 'layer', 'components'), ('layer', 'components', 'technologies'), ('components', 'technologies', 'explained'), ('technologies', 'explained', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('layer', 'JJ'), ('components', 'NNS'), ('technologies', 'NNS'), ('explained', 'VBD'), ('.', '.')]

 (S
  (NP The/DT big/JJ data/NNS platforms/NNS)
  (NP layer/JJ components/NNS technologies/NNS)
  explained/VBD
  ./.) 


>> Noun Phrases are: 
 ['The big data platforms', 'layer components technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('layer', 'layer'), ('components', 'compon'), ('technologies', 'technolog'), ('explained', 'explain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('layer', 'layer'), ('components', 'compon'), ('technologies', 'technolog'), ('explained', 'explain'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('layer', 'layer'), ('components', 'component'), ('technologies', 'technology'), ('explained', 'explained'), ('.', '.')]



============================ Sentence 497 =============================

In term of capabilities, different technologies were compared, and   big data systems categorised according to their features and the services provided to users. 


>> Tokens are: 
 ['In', 'term', 'capabilities', ',', 'different', 'technologies', 'compared', ',', 'big', 'data', 'systems', 'categorised', 'according', 'features', 'services', 'provided', 'users', '.']

>> Bigrams are: 
 [('In', 'term'), ('term', 'capabilities'), ('capabilities', ','), (',', 'different'), ('different', 'technologies'), ('technologies', 'compared'), ('compared', ','), (',', 'big'), ('big', 'data'), ('data', 'systems'), ('systems', 'categorised'), ('categorised', 'according'), ('according', 'features'), ('features', 'services'), ('services', 'provided'), ('provided', 'users'), ('users', '.')]

>> Trigrams are: 
 [('In', 'term', 'capabilities'), ('term', 'capabilities', ','), ('capabilities', ',', 'different'), (',', 'different', 'technologies'), ('different', 'technologies', 'compared'), ('technologies', 'compared', ','), ('compared', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'systems'), ('data', 'systems', 'categorised'), ('systems', 'categorised', 'according'), ('categorised', 'according', 'features'), ('according', 'features', 'services'), ('features', 'services', 'provided'), ('services', 'provided', 'users'), ('provided', 'users', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('term', 'NN'), ('capabilities', 'NNS'), (',', ','), ('different', 'JJ'), ('technologies', 'NNS'), ('compared', 'VBN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('systems', 'NNS'), ('categorised', 'VBD'), ('according', 'VBG'), ('features', 'NNS'), ('services', 'NNS'), ('provided', 'VBD'), ('users', 'NNS'), ('.', '.')]

 (S
  In/IN
  (NP term/NN capabilities/NNS)
  ,/,
  (NP different/JJ technologies/NNS)
  compared/VBN
  ,/,
  (NP big/JJ data/NNS systems/NNS)
  categorised/VBD
  according/VBG
  (NP features/NNS services/NNS)
  provided/VBD
  (NP users/NNS)
  ./.) 


>> Noun Phrases are: 
 ['term capabilities', 'different technologies', 'big data systems', 'features services', 'users']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('term', 'term'), ('capabilities', 'capabl'), (',', ','), ('different', 'differ'), ('technologies', 'technolog'), ('compared', 'compar'), (',', ','), ('big', 'big'), ('data', 'data'), ('systems', 'system'), ('categorised', 'categoris'), ('according', 'accord'), ('features', 'featur'), ('services', 'servic'), ('provided', 'provid'), ('users', 'user'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('term', 'term'), ('capabilities', 'capabl'), (',', ','), ('different', 'differ'), ('technologies', 'technolog'), ('compared', 'compar'), (',', ','), ('big', 'big'), ('data', 'data'), ('systems', 'system'), ('categorised', 'categoris'), ('according', 'accord'), ('features', 'featur'), ('services', 'servic'), ('provided', 'provid'), ('users', 'user'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('term', 'term'), ('capabilities', 'capability'), (',', ','), ('different', 'different'), ('technologies', 'technology'), ('compared', 'compared'), (',', ','), ('big', 'big'), ('data', 'data'), ('systems', 'system'), ('categorised', 'categorised'), ('according', 'according'), ('features', 'feature'), ('services', 'service'), ('provided', 'provided'), ('users', 'user'), ('.', '.')]



============================ Sentence 498 =============================

They   showed that big data use still has many technical issues that need to be studied. 


>> Tokens are: 
 ['They', 'showed', 'big', 'data', 'use', 'still', 'many', 'technical', 'issues', 'need', 'studied', '.']

>> Bigrams are: 
 [('They', 'showed'), ('showed', 'big'), ('big', 'data'), ('data', 'use'), ('use', 'still'), ('still', 'many'), ('many', 'technical'), ('technical', 'issues'), ('issues', 'need'), ('need', 'studied'), ('studied', '.')]

>> Trigrams are: 
 [('They', 'showed', 'big'), ('showed', 'big', 'data'), ('big', 'data', 'use'), ('data', 'use', 'still'), ('use', 'still', 'many'), ('still', 'many', 'technical'), ('many', 'technical', 'issues'), ('technical', 'issues', 'need'), ('issues', 'need', 'studied'), ('need', 'studied', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('showed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('use', 'NN'), ('still', 'RB'), ('many', 'JJ'), ('technical', 'JJ'), ('issues', 'NNS'), ('need', 'VBP'), ('studied', 'VBN'), ('.', '.')]

 (S
  They/PRP
  showed/VBD
  (NP big/JJ data/NNS use/NN)
  still/RB
  (NP many/JJ technical/JJ issues/NNS)
  need/VBP
  studied/VBN
  ./.) 


>> Noun Phrases are: 
 ['big data use', 'many technical issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('use', 'use'), ('still', 'still'), ('many', 'mani'), ('technical', 'technic'), ('issues', 'issu'), ('need', 'need'), ('studied', 'studi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('use', 'use'), ('still', 'still'), ('many', 'mani'), ('technical', 'technic'), ('issues', 'issu'), ('need', 'need'), ('studied', 'studi'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('showed', 'showed'), ('big', 'big'), ('data', 'data'), ('use', 'use'), ('still', 'still'), ('many', 'many'), ('technical', 'technical'), ('issues', 'issue'), ('need', 'need'), ('studied', 'studied'), ('.', '.')]



============================ Sentence 499 =============================

They also presented   big data computing systems’ challenges, examining difficulties on various different levels   “including data capture, storage, searching, sharing, analysis, management and visualisation”. 


>> Tokens are: 
 ['They', 'also', 'presented', 'big', 'data', 'computing', 'systems', '’', 'challenges', ',', 'examining', 'difficulties', 'various', 'different', 'levels', '“', 'including', 'data', 'capture', ',', 'storage', ',', 'searching', ',', 'sharing', ',', 'analysis', ',', 'management', 'visualisation', '”', '.']

>> Bigrams are: 
 [('They', 'also'), ('also', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'computing'), ('computing', 'systems'), ('systems', '’'), ('’', 'challenges'), ('challenges', ','), (',', 'examining'), ('examining', 'difficulties'), ('difficulties', 'various'), ('various', 'different'), ('different', 'levels'), ('levels', '“'), ('“', 'including'), ('including', 'data'), ('data', 'capture'), ('capture', ','), (',', 'storage'), ('storage', ','), (',', 'searching'), ('searching', ','), (',', 'sharing'), ('sharing', ','), (',', 'analysis'), ('analysis', ','), (',', 'management'), ('management', 'visualisation'), ('visualisation', '”'), ('”', '.')]

>> Trigrams are: 
 [('They', 'also', 'presented'), ('also', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'computing'), ('data', 'computing', 'systems'), ('computing', 'systems', '’'), ('systems', '’', 'challenges'), ('’', 'challenges', ','), ('challenges', ',', 'examining'), (',', 'examining', 'difficulties'), ('examining', 'difficulties', 'various'), ('difficulties', 'various', 'different'), ('various', 'different', 'levels'), ('different', 'levels', '“'), ('levels', '“', 'including'), ('“', 'including', 'data'), ('including', 'data', 'capture'), ('data', 'capture', ','), ('capture', ',', 'storage'), (',', 'storage', ','), ('storage', ',', 'searching'), (',', 'searching', ','), ('searching', ',', 'sharing'), (',', 'sharing', ','), ('sharing', ',', 'analysis'), (',', 'analysis', ','), ('analysis', ',', 'management'), (',', 'management', 'visualisation'), ('management', 'visualisation', '”'), ('visualisation', '”', '.')]

>> POS Tags are: 
 [('They', 'PRP'), ('also', 'RB'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('computing', 'VBG'), ('systems', 'NNS'), ('’', 'JJ'), ('challenges', 'NNS'), (',', ','), ('examining', 'VBG'), ('difficulties', 'NNS'), ('various', 'JJ'), ('different', 'JJ'), ('levels', 'NNS'), ('“', 'VBP'), ('including', 'VBG'), ('data', 'NNS'), ('capture', 'NN'), (',', ','), ('storage', 'NN'), (',', ','), ('searching', 'VBG'), (',', ','), ('sharing', 'VBG'), (',', ','), ('analysis', 'NN'), (',', ','), ('management', 'NN'), ('visualisation', 'NN'), ('”', 'NN'), ('.', '.')]

 (S
  They/PRP
  also/RB
  presented/VBD
  (NP big/JJ data/NNS)
  computing/VBG
  (NP systems/NNS)
  (NP ’/JJ challenges/NNS)
  ,/,
  examining/VBG
  (NP difficulties/NNS)
  (NP various/JJ different/JJ levels/NNS)
  “/VBP
  including/VBG
  (NP data/NNS capture/NN)
  ,/,
  (NP storage/NN)
  ,/,
  searching/VBG
  ,/,
  sharing/VBG
  ,/,
  (NP analysis/NN)
  ,/,
  (NP management/NN visualisation/NN ”/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'systems', '’ challenges', 'difficulties', 'various different levels', 'data capture', 'storage', 'analysis', 'management visualisation ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('They', 'they'), ('also', 'also'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('computing', 'comput'), ('systems', 'system'), ('’', '’'), ('challenges', 'challeng'), (',', ','), ('examining', 'examin'), ('difficulties', 'difficulti'), ('various', 'variou'), ('different', 'differ'), ('levels', 'level'), ('“', '“'), ('including', 'includ'), ('data', 'data'), ('capture', 'captur'), (',', ','), ('storage', 'storag'), (',', ','), ('searching', 'search'), (',', ','), ('sharing', 'share'), (',', ','), ('analysis', 'analysi'), (',', ','), ('management', 'manag'), ('visualisation', 'visualis'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('They', 'they'), ('also', 'also'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('computing', 'comput'), ('systems', 'system'), ('’', '’'), ('challenges', 'challeng'), (',', ','), ('examining', 'examin'), ('difficulties', 'difficulti'), ('various', 'various'), ('different', 'differ'), ('levels', 'level'), ('“', '“'), ('including', 'includ'), ('data', 'data'), ('capture', 'captur'), (',', ','), ('storage', 'storag'), (',', ','), ('searching', 'search'), (',', ','), ('sharing', 'share'), (',', ','), ('analysis', 'analysi'), (',', ','), ('management', 'manag'), ('visualisation', 'visualis'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('They', 'They'), ('also', 'also'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('computing', 'computing'), ('systems', 'system'), ('’', '’'), ('challenges', 'challenge'), (',', ','), ('examining', 'examining'), ('difficulties', 'difficulty'), ('various', 'various'), ('different', 'different'), ('levels', 'level'), ('“', '“'), ('including', 'including'), ('data', 'data'), ('capture', 'capture'), (',', ','), ('storage', 'storage'), (',', ','), ('searching', 'searching'), (',', ','), ('sharing', 'sharing'), (',', ','), ('analysis', 'analysis'), (',', ','), ('management', 'management'), ('visualisation', 'visualisation'), ('”', '”'), ('.', '.')]



============================ Sentence 500 =============================

This   included examining security and privacy issues. 


>> Tokens are: 
 ['This', 'included', 'examining', 'security', 'privacy', 'issues', '.']

>> Bigrams are: 
 [('This', 'included'), ('included', 'examining'), ('examining', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('This', 'included', 'examining'), ('included', 'examining', 'security'), ('examining', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('included', 'VBD'), ('examining', 'VBG'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), ('.', '.')]

 (S
  This/DT
  included/VBD
  examining/VBG
  (NP security/NN privacy/NN issues/NNS)
  ./.) 


>> Noun Phrases are: 
 ['security privacy issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('included', 'includ'), ('examining', 'examin'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('included', 'includ'), ('examining', 'examin'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('included', 'included'), ('examining', 'examining'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), ('.', '.')]



============================ Sentence 501 =============================

The size of big data is increasing exponentially,   and this makes the current technology unable to handle such big datasets. 


>> Tokens are: 
 ['The', 'size', 'big', 'data', 'increasing', 'exponentially', ',', 'makes', 'current', 'technology', 'unable', 'handle', 'big', 'datasets', '.']

>> Bigrams are: 
 [('The', 'size'), ('size', 'big'), ('big', 'data'), ('data', 'increasing'), ('increasing', 'exponentially'), ('exponentially', ','), (',', 'makes'), ('makes', 'current'), ('current', 'technology'), ('technology', 'unable'), ('unable', 'handle'), ('handle', 'big'), ('big', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('The', 'size', 'big'), ('size', 'big', 'data'), ('big', 'data', 'increasing'), ('data', 'increasing', 'exponentially'), ('increasing', 'exponentially', ','), ('exponentially', ',', 'makes'), (',', 'makes', 'current'), ('makes', 'current', 'technology'), ('current', 'technology', 'unable'), ('technology', 'unable', 'handle'), ('unable', 'handle', 'big'), ('handle', 'big', 'datasets'), ('big', 'datasets', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('size', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('increasing', 'VBG'), ('exponentially', 'RB'), (',', ','), ('makes', 'VBZ'), ('current', 'JJ'), ('technology', 'NN'), ('unable', 'JJ'), ('handle', 'NN'), ('big', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

 (S
  (NP The/DT size/NN)
  (NP big/JJ data/NNS)
  increasing/VBG
  exponentially/RB
  ,/,
  makes/VBZ
  (NP current/JJ technology/NN)
  (NP unable/JJ handle/NN)
  (NP big/JJ datasets/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The size', 'big data', 'current technology', 'unable handle', 'big datasets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('size', 'size'), ('big', 'big'), ('data', 'data'), ('increasing', 'increas'), ('exponentially', 'exponenti'), (',', ','), ('makes', 'make'), ('current', 'current'), ('technology', 'technolog'), ('unable', 'unabl'), ('handle', 'handl'), ('big', 'big'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('size', 'size'), ('big', 'big'), ('data', 'data'), ('increasing', 'increas'), ('exponentially', 'exponenti'), (',', ','), ('makes', 'make'), ('current', 'current'), ('technology', 'technolog'), ('unable', 'unabl'), ('handle', 'handl'), ('big', 'big'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('size', 'size'), ('big', 'big'), ('data', 'data'), ('increasing', 'increasing'), ('exponentially', 'exponentially'), (',', ','), ('makes', 'make'), ('current', 'current'), ('technology', 'technology'), ('unable', 'unable'), ('handle', 'handle'), ('big', 'big'), ('datasets', 'datasets'), ('.', '.')]



============================ Sentence 502 =============================

Modern big data challenges thus include big data management where the challenge lies in   collecting, integrating, and storing data with minimal requirements (hardware and software). 


>> Tokens are: 
 ['Modern', 'big', 'data', 'challenges', 'thus', 'include', 'big', 'data', 'management', 'challenge', 'lies', 'collecting', ',', 'integrating', ',', 'storing', 'data', 'minimal', 'requirements', '(', 'hardware', 'software', ')', '.']

>> Bigrams are: 
 [('Modern', 'big'), ('big', 'data'), ('data', 'challenges'), ('challenges', 'thus'), ('thus', 'include'), ('include', 'big'), ('big', 'data'), ('data', 'management'), ('management', 'challenge'), ('challenge', 'lies'), ('lies', 'collecting'), ('collecting', ','), (',', 'integrating'), ('integrating', ','), (',', 'storing'), ('storing', 'data'), ('data', 'minimal'), ('minimal', 'requirements'), ('requirements', '('), ('(', 'hardware'), ('hardware', 'software'), ('software', ')'), (')', '.')]

>> Trigrams are: 
 [('Modern', 'big', 'data'), ('big', 'data', 'challenges'), ('data', 'challenges', 'thus'), ('challenges', 'thus', 'include'), ('thus', 'include', 'big'), ('include', 'big', 'data'), ('big', 'data', 'management'), ('data', 'management', 'challenge'), ('management', 'challenge', 'lies'), ('challenge', 'lies', 'collecting'), ('lies', 'collecting', ','), ('collecting', ',', 'integrating'), (',', 'integrating', ','), ('integrating', ',', 'storing'), (',', 'storing', 'data'), ('storing', 'data', 'minimal'), ('data', 'minimal', 'requirements'), ('minimal', 'requirements', '('), ('requirements', '(', 'hardware'), ('(', 'hardware', 'software'), ('hardware', 'software', ')'), ('software', ')', '.')]

>> POS Tags are: 
 [('Modern', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), ('challenges', 'NNS'), ('thus', 'RB'), ('include', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('management', 'NN'), ('challenge', 'NN'), ('lies', 'VBZ'), ('collecting', 'VBG'), (',', ','), ('integrating', 'VBG'), (',', ','), ('storing', 'VBG'), ('data', 'NNS'), ('minimal', 'JJ'), ('requirements', 'NNS'), ('(', '('), ('hardware', 'NN'), ('software', 'NN'), (')', ')'), ('.', '.')]

 (S
  (NP Modern/NNP)
  (NP big/JJ data/NNS challenges/NNS)
  thus/RB
  include/VBP
  (NP big/JJ data/NNS management/NN challenge/NN)
  lies/VBZ
  collecting/VBG
  ,/,
  integrating/VBG
  ,/,
  storing/VBG
  (NP data/NNS)
  (NP minimal/JJ requirements/NNS)
  (/(
  (NP hardware/NN software/NN)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Modern', 'big data challenges', 'big data management challenge', 'data', 'minimal requirements', 'hardware software']

>> Named Entities are: 
 [('GPE', 'Modern')] 

>> Stemming using Porter Stemmer: 
 [('Modern', 'modern'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('thus', 'thu'), ('include', 'includ'), ('big', 'big'), ('data', 'data'), ('management', 'manag'), ('challenge', 'challeng'), ('lies', 'lie'), ('collecting', 'collect'), (',', ','), ('integrating', 'integr'), (',', ','), ('storing', 'store'), ('data', 'data'), ('minimal', 'minim'), ('requirements', 'requir'), ('(', '('), ('hardware', 'hardwar'), ('software', 'softwar'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Modern', 'modern'), ('big', 'big'), ('data', 'data'), ('challenges', 'challeng'), ('thus', 'thus'), ('include', 'includ'), ('big', 'big'), ('data', 'data'), ('management', 'manag'), ('challenge', 'challeng'), ('lies', 'lie'), ('collecting', 'collect'), (',', ','), ('integrating', 'integr'), (',', ','), ('storing', 'store'), ('data', 'data'), ('minimal', 'minim'), ('requirements', 'requir'), ('(', '('), ('hardware', 'hardwar'), ('software', 'softwar'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Modern', 'Modern'), ('big', 'big'), ('data', 'data'), ('challenges', 'challenge'), ('thus', 'thus'), ('include', 'include'), ('big', 'big'), ('data', 'data'), ('management', 'management'), ('challenge', 'challenge'), ('lies', 'lie'), ('collecting', 'collecting'), (',', ','), ('integrating', 'integrating'), (',', ','), ('storing', 'storing'), ('data', 'data'), ('minimal', 'minimal'), ('requirements', 'requirement'), ('(', '('), ('hardware', 'hardware'), ('software', 'software'), (')', ')'), ('.', '.')]



============================ Sentence 503 =============================

Big   data management also requires cleaning data for reliability then aggregating data from different   sources before encoding the data for security and privacy purposes (Chen et al., 2014; Najafabadi   et al., 2015). 


>> Tokens are: 
 ['Big', 'data', 'management', 'also', 'requires', 'cleaning', 'data', 'reliability', 'aggregating', 'data', 'different', 'sources', 'encoding', 'data', 'security', 'privacy', 'purposes', '(', 'Chen', 'et', 'al.', ',', '2014', ';', 'Najafabadi', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'management'), ('management', 'also'), ('also', 'requires'), ('requires', 'cleaning'), ('cleaning', 'data'), ('data', 'reliability'), ('reliability', 'aggregating'), ('aggregating', 'data'), ('data', 'different'), ('different', 'sources'), ('sources', 'encoding'), ('encoding', 'data'), ('data', 'security'), ('security', 'privacy'), ('privacy', 'purposes'), ('purposes', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Najafabadi'), ('Najafabadi', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'management'), ('data', 'management', 'also'), ('management', 'also', 'requires'), ('also', 'requires', 'cleaning'), ('requires', 'cleaning', 'data'), ('cleaning', 'data', 'reliability'), ('data', 'reliability', 'aggregating'), ('reliability', 'aggregating', 'data'), ('aggregating', 'data', 'different'), ('data', 'different', 'sources'), ('different', 'sources', 'encoding'), ('sources', 'encoding', 'data'), ('encoding', 'data', 'security'), ('data', 'security', 'privacy'), ('security', 'privacy', 'purposes'), ('privacy', 'purposes', '('), ('purposes', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Najafabadi'), (';', 'Najafabadi', 'et'), ('Najafabadi', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('management', 'NN'), ('also', 'RB'), ('requires', 'VBZ'), ('cleaning', 'VBG'), ('data', 'NNS'), ('reliability', 'NN'), ('aggregating', 'VBG'), ('data', 'NNS'), ('different', 'JJ'), ('sources', 'NNS'), ('encoding', 'VBG'), ('data', 'NNS'), ('security', 'NN'), ('privacy', 'NN'), ('purposes', 'NNS'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (';', ':'), ('Najafabadi', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS management/NN)
  also/RB
  requires/VBZ
  cleaning/VBG
  (NP data/NNS reliability/NN)
  aggregating/VBG
  (NP data/NNS)
  (NP different/JJ sources/NNS)
  encoding/VBG
  (NP data/NNS security/NN privacy/NN purposes/NNS)
  (/(
  (NP Chen/NNP)
  et/VBZ
  al./RB
  ,/,
  2014/CD
  ;/:
  (NP Najafabadi/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data management', 'data reliability', 'data', 'different sources', 'data security privacy purposes', 'Chen', 'Najafabadi', 'al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('management', 'manag'), ('also', 'also'), ('requires', 'requir'), ('cleaning', 'clean'), ('data', 'data'), ('reliability', 'reliabl'), ('aggregating', 'aggreg'), ('data', 'data'), ('different', 'differ'), ('sources', 'sourc'), ('encoding', 'encod'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('purposes', 'purpos'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Najafabadi', 'najafabadi'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('management', 'manag'), ('also', 'also'), ('requires', 'requir'), ('cleaning', 'clean'), ('data', 'data'), ('reliability', 'reliabl'), ('aggregating', 'aggreg'), ('data', 'data'), ('different', 'differ'), ('sources', 'sourc'), ('encoding', 'encod'), ('data', 'data'), ('security', 'secur'), ('privacy', 'privaci'), ('purposes', 'purpos'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Najafabadi', 'najafabadi'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('management', 'management'), ('also', 'also'), ('requires', 'requires'), ('cleaning', 'cleaning'), ('data', 'data'), ('reliability', 'reliability'), ('aggregating', 'aggregating'), ('data', 'data'), ('different', 'different'), ('sources', 'source'), ('encoding', 'encoding'), ('data', 'data'), ('security', 'security'), ('privacy', 'privacy'), ('purposes', 'purpose'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Najafabadi', 'Najafabadi'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 504 =============================

Big data cleaning challenge lies in the data’s complexity: velocity, volume, and variety (Khan et   al., 2014). 


>> Tokens are: 
 ['Big', 'data', 'cleaning', 'challenge', 'lies', 'data', '’', 'complexity', ':', 'velocity', ',', 'volume', ',', 'variety', '(', 'Khan', 'et', 'al.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'cleaning'), ('cleaning', 'challenge'), ('challenge', 'lies'), ('lies', 'data'), ('data', '’'), ('’', 'complexity'), ('complexity', ':'), (':', 'velocity'), ('velocity', ','), (',', 'volume'), ('volume', ','), (',', 'variety'), ('variety', '('), ('(', 'Khan'), ('Khan', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'cleaning'), ('data', 'cleaning', 'challenge'), ('cleaning', 'challenge', 'lies'), ('challenge', 'lies', 'data'), ('lies', 'data', '’'), ('data', '’', 'complexity'), ('’', 'complexity', ':'), ('complexity', ':', 'velocity'), (':', 'velocity', ','), ('velocity', ',', 'volume'), (',', 'volume', ','), ('volume', ',', 'variety'), (',', 'variety', '('), ('variety', '(', 'Khan'), ('(', 'Khan', 'et'), ('Khan', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('cleaning', 'NN'), ('challenge', 'NN'), ('lies', 'VBZ'), ('data', 'NNS'), ('’', 'JJ'), ('complexity', 'NN'), (':', ':'), ('velocity', 'NN'), (',', ','), ('volume', 'NN'), (',', ','), ('variety', 'NN'), ('(', '('), ('Khan', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS cleaning/NN challenge/NN)
  lies/VBZ
  (NP data/NNS)
  (NP ’/JJ complexity/NN)
  :/:
  (NP velocity/NN)
  ,/,
  (NP volume/NN)
  ,/,
  (NP variety/NN)
  (/(
  (NP Khan/NNP)
  et/RB
  al./RB
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data cleaning challenge', 'data', '’ complexity', 'velocity', 'volume', 'variety', 'Khan']

>> Named Entities are: 
 [('PERSON', 'Khan')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('cleaning', 'clean'), ('challenge', 'challeng'), ('lies', 'lie'), ('data', 'data'), ('’', '’'), ('complexity', 'complex'), (':', ':'), ('velocity', 'veloc'), (',', ','), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), ('(', '('), ('Khan', 'khan'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('cleaning', 'clean'), ('challenge', 'challeng'), ('lies', 'lie'), ('data', 'data'), ('’', '’'), ('complexity', 'complex'), (':', ':'), ('velocity', 'veloc'), (',', ','), ('volume', 'volum'), (',', ','), ('variety', 'varieti'), ('(', '('), ('Khan', 'khan'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('cleaning', 'cleaning'), ('challenge', 'challenge'), ('lies', 'lie'), ('data', 'data'), ('’', '’'), ('complexity', 'complexity'), (':', ':'), ('velocity', 'velocity'), (',', ','), ('volume', 'volume'), (',', ','), ('variety', 'variety'), ('(', '('), ('Khan', 'Khan'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 505 =============================

Big data aggregation challenges are involved synchronising outside data sources and     Sarah Al-Shiakhli   40      distributed big data platforms (including applications, repositories, sensors, networks, etc.) 


>> Tokens are: 
 ['Big', 'data', 'aggregation', 'challenges', 'involved', 'synchronising', 'outside', 'data', 'sources', 'Sarah', 'Al-Shiakhli', '40', 'distributed', 'big', 'data', 'platforms', '(', 'including', 'applications', ',', 'repositories', ',', 'sensors', ',', 'networks', ',', 'etc', '.', ')']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'aggregation'), ('aggregation', 'challenges'), ('challenges', 'involved'), ('involved', 'synchronising'), ('synchronising', 'outside'), ('outside', 'data'), ('data', 'sources'), ('sources', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '40'), ('40', 'distributed'), ('distributed', 'big'), ('big', 'data'), ('data', 'platforms'), ('platforms', '('), ('(', 'including'), ('including', 'applications'), ('applications', ','), (',', 'repositories'), ('repositories', ','), (',', 'sensors'), ('sensors', ','), (',', 'networks'), ('networks', ','), (',', 'etc'), ('etc', '.'), ('.', ')')]

>> Trigrams are: 
 [('Big', 'data', 'aggregation'), ('data', 'aggregation', 'challenges'), ('aggregation', 'challenges', 'involved'), ('challenges', 'involved', 'synchronising'), ('involved', 'synchronising', 'outside'), ('synchronising', 'outside', 'data'), ('outside', 'data', 'sources'), ('data', 'sources', 'Sarah'), ('sources', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '40'), ('Al-Shiakhli', '40', 'distributed'), ('40', 'distributed', 'big'), ('distributed', 'big', 'data'), ('big', 'data', 'platforms'), ('data', 'platforms', '('), ('platforms', '(', 'including'), ('(', 'including', 'applications'), ('including', 'applications', ','), ('applications', ',', 'repositories'), (',', 'repositories', ','), ('repositories', ',', 'sensors'), (',', 'sensors', ','), ('sensors', ',', 'networks'), (',', 'networks', ','), ('networks', ',', 'etc'), (',', 'etc', '.'), ('etc', '.', ')')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('aggregation', 'NN'), ('challenges', 'NNS'), ('involved', 'VBN'), ('synchronising', 'VBG'), ('outside', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('40', 'CD'), ('distributed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('platforms', 'NNS'), ('(', '('), ('including', 'VBG'), ('applications', 'NNS'), (',', ','), ('repositories', 'NNS'), (',', ','), ('sensors', 'NNS'), (',', ','), ('networks', 'NNS'), (',', ','), ('etc', 'FW'), ('.', '.'), (')', ')')]

 (S
  (NP Big/NNP data/NNS aggregation/NN challenges/NNS)
  involved/VBN
  synchronising/VBG
  (NP outside/JJ data/NNS sources/NNS Sarah/NNP Al-Shiakhli/NNP)
  40/CD
  distributed/VBD
  (NP big/JJ data/NNS platforms/NNS)
  (/(
  including/VBG
  (NP applications/NNS)
  ,/,
  (NP repositories/NNS)
  ,/,
  (NP sensors/NNS)
  ,/,
  (NP networks/NNS)
  ,/,
  etc/FW
  ./.
  )/)) 


>> Noun Phrases are: 
 ['Big data aggregation challenges', 'outside data sources Sarah Al-Shiakhli', 'big data platforms', 'applications', 'repositories', 'sensors', 'networks']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('aggregation', 'aggreg'), ('challenges', 'challeng'), ('involved', 'involv'), ('synchronising', 'synchronis'), ('outside', 'outsid'), ('data', 'data'), ('sources', 'sourc'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('40', '40'), ('distributed', 'distribut'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('(', '('), ('including', 'includ'), ('applications', 'applic'), (',', ','), ('repositories', 'repositori'), (',', ','), ('sensors', 'sensor'), (',', ','), ('networks', 'network'), (',', ','), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('aggregation', 'aggreg'), ('challenges', 'challeng'), ('involved', 'involv'), ('synchronising', 'synchronis'), ('outside', 'outsid'), ('data', 'data'), ('sources', 'sourc'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('40', '40'), ('distributed', 'distribut'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('(', '('), ('including', 'includ'), ('applications', 'applic'), (',', ','), ('repositories', 'repositori'), (',', ','), ('sensors', 'sensor'), (',', ','), ('networks', 'network'), (',', ','), ('etc', 'etc'), ('.', '.'), (')', ')')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('aggregation', 'aggregation'), ('challenges', 'challenge'), ('involved', 'involved'), ('synchronising', 'synchronising'), ('outside', 'outside'), ('data', 'data'), ('sources', 'source'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('40', '40'), ('distributed', 'distributed'), ('big', 'big'), ('data', 'data'), ('platforms', 'platform'), ('(', '('), ('including', 'including'), ('applications', 'application'), (',', ','), ('repositories', 'repository'), (',', ','), ('sensors', 'sensor'), (',', ','), ('networks', 'network'), (',', ','), ('etc', 'etc'), ('.', '.'), (')', ')')]



============================ Sentence 506 =============================

into a   cohesive system (Oussous et al., 2018). 


>> Tokens are: 
 ['cohesive', 'system', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('cohesive', 'system'), ('system', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('cohesive', 'system', '('), ('system', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('cohesive', 'JJ'), ('system', 'NN'), ('(', '('), ('Oussous', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP cohesive/JJ system/NN)
  (/(
  (NP Oussous/JJ et/NN al./NN)
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['cohesive system', 'Oussous et al.']

>> Named Entities are: 
 [('ORGANIZATION', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('cohesive', 'cohes'), ('system', 'system'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('cohesive', 'cohes'), ('system', 'system'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('cohesive', 'cohesive'), ('system', 'system'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 507 =============================

Also, in imbalanced system capacities, the challenge lies   in the computer architecture and capacity, as imbalanced system capacities might affect big data   application performance (Chen et al. 


>> Tokens are: 
 ['Also', ',', 'imbalanced', 'system', 'capacities', ',', 'challenge', 'lies', 'computer', 'architecture', 'capacity', ',', 'imbalanced', 'system', 'capacities', 'might', 'affect', 'big', 'data', 'application', 'performance', '(', 'Chen', 'et', 'al', '.']

>> Bigrams are: 
 [('Also', ','), (',', 'imbalanced'), ('imbalanced', 'system'), ('system', 'capacities'), ('capacities', ','), (',', 'challenge'), ('challenge', 'lies'), ('lies', 'computer'), ('computer', 'architecture'), ('architecture', 'capacity'), ('capacity', ','), (',', 'imbalanced'), ('imbalanced', 'system'), ('system', 'capacities'), ('capacities', 'might'), ('might', 'affect'), ('affect', 'big'), ('big', 'data'), ('data', 'application'), ('application', 'performance'), ('performance', '('), ('(', 'Chen'), ('Chen', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Also', ',', 'imbalanced'), (',', 'imbalanced', 'system'), ('imbalanced', 'system', 'capacities'), ('system', 'capacities', ','), ('capacities', ',', 'challenge'), (',', 'challenge', 'lies'), ('challenge', 'lies', 'computer'), ('lies', 'computer', 'architecture'), ('computer', 'architecture', 'capacity'), ('architecture', 'capacity', ','), ('capacity', ',', 'imbalanced'), (',', 'imbalanced', 'system'), ('imbalanced', 'system', 'capacities'), ('system', 'capacities', 'might'), ('capacities', 'might', 'affect'), ('might', 'affect', 'big'), ('affect', 'big', 'data'), ('big', 'data', 'application'), ('data', 'application', 'performance'), ('application', 'performance', '('), ('performance', '(', 'Chen'), ('(', 'Chen', 'et'), ('Chen', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('imbalanced', 'JJ'), ('system', 'NN'), ('capacities', 'NNS'), (',', ','), ('challenge', 'NN'), ('lies', 'VBZ'), ('computer', 'NN'), ('architecture', 'NN'), ('capacity', 'NN'), (',', ','), ('imbalanced', 'JJ'), ('system', 'NN'), ('capacities', 'NNS'), ('might', 'MD'), ('affect', 'VB'), ('big', 'JJ'), ('data', 'NNS'), ('application', 'NN'), ('performance', 'NN'), ('(', '('), ('Chen', 'NNP'), ('et', 'VBZ'), ('al', 'NN'), ('.', '.')]

 (S
  Also/RB
  ,/,
  (NP imbalanced/JJ system/NN capacities/NNS)
  ,/,
  (NP challenge/NN)
  lies/VBZ
  (NP computer/NN architecture/NN capacity/NN)
  ,/,
  (NP imbalanced/JJ system/NN capacities/NNS)
  might/MD
  affect/VB
  (NP big/JJ data/NNS application/NN performance/NN)
  (/(
  (NP Chen/NNP)
  et/VBZ
  (NP al/NN)
  ./.) 


>> Noun Phrases are: 
 ['imbalanced system capacities', 'challenge', 'computer architecture capacity', 'imbalanced system capacities', 'big data application performance', 'Chen', 'al']

>> Named Entities are: 
 [('ORGANIZATION', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), (',', ','), ('challenge', 'challeng'), ('lies', 'lie'), ('computer', 'comput'), ('architecture', 'architectur'), ('capacity', 'capac'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), ('might', 'might'), ('affect', 'affect'), ('big', 'big'), ('data', 'data'), ('application', 'applic'), ('performance', 'perform'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), (',', ','), ('challenge', 'challeng'), ('lies', 'lie'), ('computer', 'comput'), ('architecture', 'architectur'), ('capacity', 'capac'), (',', ','), ('imbalanced', 'imbalanc'), ('system', 'system'), ('capacities', 'capac'), ('might', 'might'), ('affect', 'affect'), ('big', 'big'), ('data', 'data'), ('application', 'applic'), ('performance', 'perform'), ('(', '('), ('Chen', 'chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('imbalanced', 'imbalanced'), ('system', 'system'), ('capacities', 'capacity'), (',', ','), ('challenge', 'challenge'), ('lies', 'lie'), ('computer', 'computer'), ('architecture', 'architecture'), ('capacity', 'capacity'), (',', ','), ('imbalanced', 'imbalanced'), ('system', 'system'), ('capacities', 'capacity'), ('might', 'might'), ('affect', 'affect'), ('big', 'big'), ('data', 'data'), ('application', 'application'), ('performance', 'performance'), ('(', '('), ('Chen', 'Chen'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 508 =============================

2014). 


>> Tokens are: 
 ['2014', ')', '.']

>> Bigrams are: 
 [('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('2014', ')', '.')]

>> POS Tags are: 
 [('2014', 'CD'), (')', ')'), ('.', '.')]

 (S 2014/CD )/) ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 509 =============================

Furthermore, the challenge in imbalanced big data is how to classify imbalanced datasets, as   “classical learning techniques are not adapted to imbalanced data sets” (Oussous et al., 2018). 


>> Tokens are: 
 ['Furthermore', ',', 'challenge', 'imbalanced', 'big', 'data', 'classify', 'imbalanced', 'datasets', ',', '“', 'classical', 'learning', 'techniques', 'adapted', 'imbalanced', 'data', 'sets', '”', '(', 'Oussous', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'challenge'), ('challenge', 'imbalanced'), ('imbalanced', 'big'), ('big', 'data'), ('data', 'classify'), ('classify', 'imbalanced'), ('imbalanced', 'datasets'), ('datasets', ','), (',', '“'), ('“', 'classical'), ('classical', 'learning'), ('learning', 'techniques'), ('techniques', 'adapted'), ('adapted', 'imbalanced'), ('imbalanced', 'data'), ('data', 'sets'), ('sets', '”'), ('”', '('), ('(', 'Oussous'), ('Oussous', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Furthermore', ',', 'challenge'), (',', 'challenge', 'imbalanced'), ('challenge', 'imbalanced', 'big'), ('imbalanced', 'big', 'data'), ('big', 'data', 'classify'), ('data', 'classify', 'imbalanced'), ('classify', 'imbalanced', 'datasets'), ('imbalanced', 'datasets', ','), ('datasets', ',', '“'), (',', '“', 'classical'), ('“', 'classical', 'learning'), ('classical', 'learning', 'techniques'), ('learning', 'techniques', 'adapted'), ('techniques', 'adapted', 'imbalanced'), ('adapted', 'imbalanced', 'data'), ('imbalanced', 'data', 'sets'), ('data', 'sets', '”'), ('sets', '”', '('), ('”', '(', 'Oussous'), ('(', 'Oussous', 'et'), ('Oussous', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('challenge', 'NN'), ('imbalanced', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('classify', 'NN'), ('imbalanced', 'JJ'), ('datasets', 'NNS'), (',', ','), ('“', 'NNP'), ('classical', 'JJ'), ('learning', 'NN'), ('techniques', 'NNS'), ('adapted', 'VBN'), ('imbalanced', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('”', 'NNP'), ('(', '('), ('Oussous', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  Furthermore/RB
  ,/,
  (NP challenge/NN)
  imbalanced/VBD
  (NP big/JJ data/NNS classify/NN)
  (NP imbalanced/JJ datasets/NNS)
  ,/,
  (NP “/NNP)
  (NP classical/JJ learning/NN techniques/NNS)
  adapted/VBN
  (NP imbalanced/JJ data/NNS sets/NNS ”/NNP)
  (/(
  (NP Oussous/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['challenge', 'big data classify', 'imbalanced datasets', '“', 'classical learning techniques', 'imbalanced data sets ”', 'Oussous']

>> Named Entities are: 
 [('PERSON', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('challenge', 'challeng'), ('imbalanced', 'imbalanc'), ('big', 'big'), ('data', 'data'), ('classify', 'classifi'), ('imbalanced', 'imbalanc'), ('datasets', 'dataset'), (',', ','), ('“', '“'), ('classical', 'classic'), ('learning', 'learn'), ('techniques', 'techniqu'), ('adapted', 'adapt'), ('imbalanced', 'imbalanc'), ('data', 'data'), ('sets', 'set'), ('”', '”'), ('(', '('), ('Oussous', 'oussou'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('challenge', 'challeng'), ('imbalanced', 'imbalanc'), ('big', 'big'), ('data', 'data'), ('classify', 'classifi'), ('imbalanced', 'imbalanc'), ('datasets', 'dataset'), (',', ','), ('“', '“'), ('classical', 'classic'), ('learning', 'learn'), ('techniques', 'techniqu'), ('adapted', 'adapt'), ('imbalanced', 'imbalanc'), ('data', 'data'), ('sets', 'set'), ('”', '”'), ('(', '('), ('Oussous', 'oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('challenge', 'challenge'), ('imbalanced', 'imbalanced'), ('big', 'big'), ('data', 'data'), ('classify', 'classify'), ('imbalanced', 'imbalanced'), ('datasets', 'datasets'), (',', ','), ('“', '“'), ('classical', 'classical'), ('learning', 'learning'), ('techniques', 'technique'), ('adapted', 'adapted'), ('imbalanced', 'imbalanced'), ('data', 'data'), ('sets', 'set'), ('”', '”'), ('(', '('), ('Oussous', 'Oussous'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 510 =============================

Big   data analytics challenges lie in the complex data analysis required to understand the relationships   among data features. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'challenges', 'lie', 'complex', 'data', 'analysis', 'required', 'understand', 'relationships', 'among', 'data', 'features', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'lie'), ('lie', 'complex'), ('complex', 'data'), ('data', 'analysis'), ('analysis', 'required'), ('required', 'understand'), ('understand', 'relationships'), ('relationships', 'among'), ('among', 'data'), ('data', 'features'), ('features', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'lie'), ('challenges', 'lie', 'complex'), ('lie', 'complex', 'data'), ('complex', 'data', 'analysis'), ('data', 'analysis', 'required'), ('analysis', 'required', 'understand'), ('required', 'understand', 'relationships'), ('understand', 'relationships', 'among'), ('relationships', 'among', 'data'), ('among', 'data', 'features'), ('data', 'features', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('lie', 'VBP'), ('complex', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('required', 'VBN'), ('understand', 'JJ'), ('relationships', 'NNS'), ('among', 'IN'), ('data', 'NNS'), ('features', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS challenges/NNS)
  lie/VBP
  (NP complex/JJ data/NNS analysis/NN)
  required/VBN
  (NP understand/JJ relationships/NNS)
  among/IN
  (NP data/NNS features/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics challenges', 'complex data analysis', 'understand relationships', 'data features']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('lie', 'lie'), ('complex', 'complex'), ('data', 'data'), ('analysis', 'analysi'), ('required', 'requir'), ('understand', 'understand'), ('relationships', 'relationship'), ('among', 'among'), ('data', 'data'), ('features', 'featur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('lie', 'lie'), ('complex', 'complex'), ('data', 'data'), ('analysis', 'analysi'), ('required', 'requir'), ('understand', 'understand'), ('relationships', 'relationship'), ('among', 'among'), ('data', 'data'), ('features', 'featur'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('lie', 'lie'), ('complex', 'complex'), ('data', 'data'), ('analysis', 'analysis'), ('required', 'required'), ('understand', 'understand'), ('relationships', 'relationship'), ('among', 'among'), ('data', 'data'), ('features', 'feature'), ('.', '.')]



============================ Sentence 511 =============================

Some data analysis requires real-time analysis, such as navigation, social   networks, finance, biomedicine, astronomy, and intelligent transport systems, while other analyses   require accurate result but not necessarily the same levels of speed. 


>> Tokens are: 
 ['Some', 'data', 'analysis', 'requires', 'real-time', 'analysis', ',', 'navigation', ',', 'social', 'networks', ',', 'finance', ',', 'biomedicine', ',', 'astronomy', ',', 'intelligent', 'transport', 'systems', ',', 'analyses', 'require', 'accurate', 'result', 'necessarily', 'levels', 'speed', '.']

>> Bigrams are: 
 [('Some', 'data'), ('data', 'analysis'), ('analysis', 'requires'), ('requires', 'real-time'), ('real-time', 'analysis'), ('analysis', ','), (',', 'navigation'), ('navigation', ','), (',', 'social'), ('social', 'networks'), ('networks', ','), (',', 'finance'), ('finance', ','), (',', 'biomedicine'), ('biomedicine', ','), (',', 'astronomy'), ('astronomy', ','), (',', 'intelligent'), ('intelligent', 'transport'), ('transport', 'systems'), ('systems', ','), (',', 'analyses'), ('analyses', 'require'), ('require', 'accurate'), ('accurate', 'result'), ('result', 'necessarily'), ('necessarily', 'levels'), ('levels', 'speed'), ('speed', '.')]

>> Trigrams are: 
 [('Some', 'data', 'analysis'), ('data', 'analysis', 'requires'), ('analysis', 'requires', 'real-time'), ('requires', 'real-time', 'analysis'), ('real-time', 'analysis', ','), ('analysis', ',', 'navigation'), (',', 'navigation', ','), ('navigation', ',', 'social'), (',', 'social', 'networks'), ('social', 'networks', ','), ('networks', ',', 'finance'), (',', 'finance', ','), ('finance', ',', 'biomedicine'), (',', 'biomedicine', ','), ('biomedicine', ',', 'astronomy'), (',', 'astronomy', ','), ('astronomy', ',', 'intelligent'), (',', 'intelligent', 'transport'), ('intelligent', 'transport', 'systems'), ('transport', 'systems', ','), ('systems', ',', 'analyses'), (',', 'analyses', 'require'), ('analyses', 'require', 'accurate'), ('require', 'accurate', 'result'), ('accurate', 'result', 'necessarily'), ('result', 'necessarily', 'levels'), ('necessarily', 'levels', 'speed'), ('levels', 'speed', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('data', 'NNS'), ('analysis', 'NN'), ('requires', 'VBZ'), ('real-time', 'JJ'), ('analysis', 'NN'), (',', ','), ('navigation', 'NN'), (',', ','), ('social', 'JJ'), ('networks', 'NNS'), (',', ','), ('finance', 'NN'), (',', ','), ('biomedicine', 'NN'), (',', ','), ('astronomy', 'NN'), (',', ','), ('intelligent', 'JJ'), ('transport', 'NN'), ('systems', 'NNS'), (',', ','), ('analyses', 'VBZ'), ('require', 'VBP'), ('accurate', 'JJ'), ('result', 'NN'), ('necessarily', 'RB'), ('levels', 'NNS'), ('speed', 'NN'), ('.', '.')]

 (S
  (NP Some/DT data/NNS analysis/NN)
  requires/VBZ
  (NP real-time/JJ analysis/NN)
  ,/,
  (NP navigation/NN)
  ,/,
  (NP social/JJ networks/NNS)
  ,/,
  (NP finance/NN)
  ,/,
  (NP biomedicine/NN)
  ,/,
  (NP astronomy/NN)
  ,/,
  (NP intelligent/JJ transport/NN systems/NNS)
  ,/,
  analyses/VBZ
  require/VBP
  (NP accurate/JJ result/NN)
  necessarily/RB
  (NP levels/NNS speed/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some data analysis', 'real-time analysis', 'navigation', 'social networks', 'finance', 'biomedicine', 'astronomy', 'intelligent transport systems', 'accurate result', 'levels speed']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('data', 'data'), ('analysis', 'analysi'), ('requires', 'requir'), ('real-time', 'real-tim'), ('analysis', 'analysi'), (',', ','), ('navigation', 'navig'), (',', ','), ('social', 'social'), ('networks', 'network'), (',', ','), ('finance', 'financ'), (',', ','), ('biomedicine', 'biomedicin'), (',', ','), ('astronomy', 'astronomi'), (',', ','), ('intelligent', 'intellig'), ('transport', 'transport'), ('systems', 'system'), (',', ','), ('analyses', 'analys'), ('require', 'requir'), ('accurate', 'accur'), ('result', 'result'), ('necessarily', 'necessarili'), ('levels', 'level'), ('speed', 'speed'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('data', 'data'), ('analysis', 'analysi'), ('requires', 'requir'), ('real-time', 'real-tim'), ('analysis', 'analysi'), (',', ','), ('navigation', 'navig'), (',', ','), ('social', 'social'), ('networks', 'network'), (',', ','), ('finance', 'financ'), (',', ','), ('biomedicine', 'biomedicin'), (',', ','), ('astronomy', 'astronomi'), (',', ','), ('intelligent', 'intellig'), ('transport', 'transport'), ('systems', 'system'), (',', ','), ('analyses', 'analys'), ('require', 'requir'), ('accurate', 'accur'), ('result', 'result'), ('necessarily', 'necessarili'), ('levels', 'level'), ('speed', 'speed'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('data', 'data'), ('analysis', 'analysis'), ('requires', 'requires'), ('real-time', 'real-time'), ('analysis', 'analysis'), (',', ','), ('navigation', 'navigation'), (',', ','), ('social', 'social'), ('networks', 'network'), (',', ','), ('finance', 'finance'), (',', ','), ('biomedicine', 'biomedicine'), (',', ','), ('astronomy', 'astronomy'), (',', ','), ('intelligent', 'intelligent'), ('transport', 'transport'), ('systems', 'system'), (',', ','), ('analyses', 'analysis'), ('require', 'require'), ('accurate', 'accurate'), ('result', 'result'), ('necessarily', 'necessarily'), ('levels', 'level'), ('speed', 'speed'), ('.', '.')]



============================ Sentence 512 =============================

The challenge with big data   analysis mainly arises due to the 5V’s and their effects on dataset performance (Qiu et al., 2016). 


>> Tokens are: 
 ['The', 'challenge', 'big', 'data', 'analysis', 'mainly', 'arises', 'due', '5V', '’', 'effects', 'dataset', 'performance', '(', 'Qiu', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('The', 'challenge'), ('challenge', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', 'mainly'), ('mainly', 'arises'), ('arises', 'due'), ('due', '5V'), ('5V', '’'), ('’', 'effects'), ('effects', 'dataset'), ('dataset', 'performance'), ('performance', '('), ('(', 'Qiu'), ('Qiu', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('The', 'challenge', 'big'), ('challenge', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', 'mainly'), ('analysis', 'mainly', 'arises'), ('mainly', 'arises', 'due'), ('arises', 'due', '5V'), ('due', '5V', '’'), ('5V', '’', 'effects'), ('’', 'effects', 'dataset'), ('effects', 'dataset', 'performance'), ('dataset', 'performance', '('), ('performance', '(', 'Qiu'), ('(', 'Qiu', 'et'), ('Qiu', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('challenge', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('mainly', 'RB'), ('arises', 'VBZ'), ('due', 'JJ'), ('5V', 'CD'), ('’', 'JJ'), ('effects', 'NNS'), ('dataset', 'VBN'), ('performance', 'NN'), ('(', '('), ('Qiu', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP The/DT challenge/NN)
  (NP big/JJ data/NNS analysis/NN)
  mainly/RB
  arises/VBZ
  due/JJ
  5V/CD
  (NP ’/JJ effects/NNS)
  dataset/VBN
  (NP performance/NN)
  (/(
  (NP Qiu/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['The challenge', 'big data analysis', '’ effects', 'performance', 'Qiu']

>> Named Entities are: 
 [('ORGANIZATION', 'Qiu')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('challenge', 'challeng'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('mainly', 'mainli'), ('arises', 'aris'), ('due', 'due'), ('5V', '5v'), ('’', '’'), ('effects', 'effect'), ('dataset', 'dataset'), ('performance', 'perform'), ('(', '('), ('Qiu', 'qiu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('challenge', 'challeng'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('mainly', 'main'), ('arises', 'aris'), ('due', 'due'), ('5V', '5v'), ('’', '’'), ('effects', 'effect'), ('dataset', 'dataset'), ('performance', 'perform'), ('(', '('), ('Qiu', 'qiu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('challenge', 'challenge'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('mainly', 'mainly'), ('arises', 'arises'), ('due', 'due'), ('5V', '5V'), ('’', '’'), ('effects', 'effect'), ('dataset', 'dataset'), ('performance', 'performance'), ('(', '('), ('Qiu', 'Qiu'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 513 =============================

One solution for the storage challenge is using Hadoop (Apache platform), which is an open-source   distributed data processing platform with the power to process extremely large amounts of data. 


>> Tokens are: 
 ['One', 'solution', 'storage', 'challenge', 'using', 'Hadoop', '(', 'Apache', 'platform', ')', ',', 'open-source', 'distributed', 'data', 'processing', 'platform', 'power', 'process', 'extremely', 'large', 'amounts', 'data', '.']

>> Bigrams are: 
 [('One', 'solution'), ('solution', 'storage'), ('storage', 'challenge'), ('challenge', 'using'), ('using', 'Hadoop'), ('Hadoop', '('), ('(', 'Apache'), ('Apache', 'platform'), ('platform', ')'), (')', ','), (',', 'open-source'), ('open-source', 'distributed'), ('distributed', 'data'), ('data', 'processing'), ('processing', 'platform'), ('platform', 'power'), ('power', 'process'), ('process', 'extremely'), ('extremely', 'large'), ('large', 'amounts'), ('amounts', 'data'), ('data', '.')]

>> Trigrams are: 
 [('One', 'solution', 'storage'), ('solution', 'storage', 'challenge'), ('storage', 'challenge', 'using'), ('challenge', 'using', 'Hadoop'), ('using', 'Hadoop', '('), ('Hadoop', '(', 'Apache'), ('(', 'Apache', 'platform'), ('Apache', 'platform', ')'), ('platform', ')', ','), (')', ',', 'open-source'), (',', 'open-source', 'distributed'), ('open-source', 'distributed', 'data'), ('distributed', 'data', 'processing'), ('data', 'processing', 'platform'), ('processing', 'platform', 'power'), ('platform', 'power', 'process'), ('power', 'process', 'extremely'), ('process', 'extremely', 'large'), ('extremely', 'large', 'amounts'), ('large', 'amounts', 'data'), ('amounts', 'data', '.')]

>> POS Tags are: 
 [('One', 'CD'), ('solution', 'NN'), ('storage', 'NN'), ('challenge', 'NN'), ('using', 'VBG'), ('Hadoop', 'NNP'), ('(', '('), ('Apache', 'NNP'), ('platform', 'NN'), (')', ')'), (',', ','), ('open-source', 'JJ'), ('distributed', 'VBN'), ('data', 'NNS'), ('processing', 'VBG'), ('platform', 'NN'), ('power', 'NN'), ('process', 'NN'), ('extremely', 'RB'), ('large', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('.', '.')]

 (S
  One/CD
  (NP solution/NN storage/NN challenge/NN)
  using/VBG
  (NP Hadoop/NNP)
  (/(
  (NP Apache/NNP platform/NN)
  )/)
  ,/,
  open-source/JJ
  distributed/VBN
  (NP data/NNS)
  processing/VBG
  (NP platform/NN power/NN process/NN)
  extremely/RB
  (NP large/JJ amounts/NNS data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['solution storage challenge', 'Hadoop', 'Apache platform', 'data', 'platform power process', 'large amounts data']

>> Named Entities are: 
 [('GPE', 'Hadoop'), ('ORGANIZATION', 'Apache')] 

>> Stemming using Porter Stemmer: 
 [('One', 'one'), ('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('using', 'use'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), (',', ','), ('open-source', 'open-sourc'), ('distributed', 'distribut'), ('data', 'data'), ('processing', 'process'), ('platform', 'platform'), ('power', 'power'), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('One', 'one'), ('solution', 'solut'), ('storage', 'storag'), ('challenge', 'challeng'), ('using', 'use'), ('Hadoop', 'hadoop'), ('(', '('), ('Apache', 'apach'), ('platform', 'platform'), (')', ')'), (',', ','), ('open-source', 'open-sourc'), ('distributed', 'distribut'), ('data', 'data'), ('processing', 'process'), ('platform', 'platform'), ('power', 'power'), ('process', 'process'), ('extremely', 'extrem'), ('large', 'larg'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('One', 'One'), ('solution', 'solution'), ('storage', 'storage'), ('challenge', 'challenge'), ('using', 'using'), ('Hadoop', 'Hadoop'), ('(', '('), ('Apache', 'Apache'), ('platform', 'platform'), (')', ')'), (',', ','), ('open-source', 'open-source'), ('distributed', 'distributed'), ('data', 'data'), ('processing', 'processing'), ('platform', 'platform'), ('power', 'power'), ('process', 'process'), ('extremely', 'extremely'), ('large', 'large'), ('amounts', 'amount'), ('data', 'data'), ('.', '.')]



============================ Sentence 514 =============================

It   does this by dividing the data into smaller parts then specifying some parts of the datasets to   separate servers (nodes) (Raghupathi, W. and Raghupathi, V., 2014)      9.4. 


>> Tokens are: 
 ['It', 'dividing', 'data', 'smaller', 'parts', 'specifying', 'parts', 'datasets', 'separate', 'servers', '(', 'nodes', ')', '(', 'Raghupathi', ',', 'W.', 'Raghupathi', ',', 'V.', ',', '2014', ')', '9.4', '.']

>> Bigrams are: 
 [('It', 'dividing'), ('dividing', 'data'), ('data', 'smaller'), ('smaller', 'parts'), ('parts', 'specifying'), ('specifying', 'parts'), ('parts', 'datasets'), ('datasets', 'separate'), ('separate', 'servers'), ('servers', '('), ('(', 'nodes'), ('nodes', ')'), (')', '('), ('(', 'Raghupathi'), ('Raghupathi', ','), (',', 'W.'), ('W.', 'Raghupathi'), ('Raghupathi', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', ')'), (')', '9.4'), ('9.4', '.')]

>> Trigrams are: 
 [('It', 'dividing', 'data'), ('dividing', 'data', 'smaller'), ('data', 'smaller', 'parts'), ('smaller', 'parts', 'specifying'), ('parts', 'specifying', 'parts'), ('specifying', 'parts', 'datasets'), ('parts', 'datasets', 'separate'), ('datasets', 'separate', 'servers'), ('separate', 'servers', '('), ('servers', '(', 'nodes'), ('(', 'nodes', ')'), ('nodes', ')', '('), (')', '(', 'Raghupathi'), ('(', 'Raghupathi', ','), ('Raghupathi', ',', 'W.'), (',', 'W.', 'Raghupathi'), ('W.', 'Raghupathi', ','), ('Raghupathi', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '9.4'), (')', '9.4', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('dividing', 'VBG'), ('data', 'NNS'), ('smaller', 'JJR'), ('parts', 'NNS'), ('specifying', 'VBG'), ('parts', 'NNS'), ('datasets', 'NNS'), ('separate', 'JJ'), ('servers', 'NNS'), ('(', '('), ('nodes', 'NNS'), (')', ')'), ('(', '('), ('Raghupathi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('9.4', 'CD'), ('.', '.')]

 (S
  It/PRP
  dividing/VBG
  (NP data/NNS)
  smaller/JJR
  (NP parts/NNS)
  specifying/VBG
  (NP parts/NNS datasets/NNS)
  (NP separate/JJ servers/NNS)
  (/(
  (NP nodes/NNS)
  )/)
  (/(
  (NP Raghupathi/NNP)
  ,/,
  (NP W./NNP Raghupathi/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  2014/CD
  )/)
  9.4/CD
  ./.) 


>> Noun Phrases are: 
 ['data', 'parts', 'parts datasets', 'separate servers', 'nodes', 'Raghupathi', 'W. Raghupathi', 'V.']

>> Named Entities are: 
 [('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('specifying', 'specifi'), ('parts', 'part'), ('datasets', 'dataset'), ('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')'), ('9.4', '9.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('dividing', 'divid'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('specifying', 'specifi'), ('parts', 'part'), ('datasets', 'dataset'), ('separate', 'separ'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('(', '('), ('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), (')', ')'), ('9.4', '9.4'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('dividing', 'dividing'), ('data', 'data'), ('smaller', 'smaller'), ('parts', 'part'), ('specifying', 'specifying'), ('parts', 'part'), ('datasets', 'datasets'), ('separate', 'separate'), ('servers', 'server'), ('(', '('), ('nodes', 'node'), (')', ')'), ('(', '('), ('Raghupathi', 'Raghupathi'), (',', ','), ('W.', 'W.'), ('Raghupathi', 'Raghupathi'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), (')', ')'), ('9.4', '9.4'), ('.', '.')]



============================ Sentence 515 =============================

Challenges in data analysis and visualisation   Data analysis challenges arise from data complexity, which in turn comes from the data’s complex   types and structures. 


>> Tokens are: 
 ['Challenges', 'data', 'analysis', 'visualisation', 'Data', 'analysis', 'challenges', 'arise', 'data', 'complexity', ',', 'turn', 'comes', 'data', '’', 'complex', 'types', 'structures', '.']

>> Bigrams are: 
 [('Challenges', 'data'), ('data', 'analysis'), ('analysis', 'visualisation'), ('visualisation', 'Data'), ('Data', 'analysis'), ('analysis', 'challenges'), ('challenges', 'arise'), ('arise', 'data'), ('data', 'complexity'), ('complexity', ','), (',', 'turn'), ('turn', 'comes'), ('comes', 'data'), ('data', '’'), ('’', 'complex'), ('complex', 'types'), ('types', 'structures'), ('structures', '.')]

>> Trigrams are: 
 [('Challenges', 'data', 'analysis'), ('data', 'analysis', 'visualisation'), ('analysis', 'visualisation', 'Data'), ('visualisation', 'Data', 'analysis'), ('Data', 'analysis', 'challenges'), ('analysis', 'challenges', 'arise'), ('challenges', 'arise', 'data'), ('arise', 'data', 'complexity'), ('data', 'complexity', ','), ('complexity', ',', 'turn'), (',', 'turn', 'comes'), ('turn', 'comes', 'data'), ('comes', 'data', '’'), ('data', '’', 'complex'), ('’', 'complex', 'types'), ('complex', 'types', 'structures'), ('types', 'structures', '.')]

>> POS Tags are: 
 [('Challenges', 'NNS'), ('data', 'NNS'), ('analysis', 'NN'), ('visualisation', 'NN'), ('Data', 'NNP'), ('analysis', 'NN'), ('challenges', 'NNS'), ('arise', 'VBP'), ('data', 'NN'), ('complexity', 'NN'), (',', ','), ('turn', 'VBP'), ('comes', 'VBZ'), ('data', 'NNS'), ('’', 'NN'), ('complex', 'JJ'), ('types', 'NNS'), ('structures', 'NNS'), ('.', '.')]

 (S
  (NP
    Challenges/NNS
    data/NNS
    analysis/NN
    visualisation/NN
    Data/NNP
    analysis/NN
    challenges/NNS)
  arise/VBP
  (NP data/NN complexity/NN)
  ,/,
  turn/VBP
  comes/VBZ
  (NP data/NNS ’/NN)
  (NP complex/JJ types/NNS structures/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Challenges data analysis visualisation Data analysis challenges', 'data complexity', 'data ’', 'complex types structures']

>> Named Entities are: 
 [('PERSON', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis'), ('Data', 'data'), ('analysis', 'analysi'), ('challenges', 'challeng'), ('arise', 'aris'), ('data', 'data'), ('complexity', 'complex'), (',', ','), ('turn', 'turn'), ('comes', 'come'), ('data', 'data'), ('’', '’'), ('complex', 'complex'), ('types', 'type'), ('structures', 'structur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng'), ('data', 'data'), ('analysis', 'analysi'), ('visualisation', 'visualis'), ('Data', 'data'), ('analysis', 'analysi'), ('challenges', 'challeng'), ('arise', 'aris'), ('data', 'data'), ('complexity', 'complex'), (',', ','), ('turn', 'turn'), ('comes', 'come'), ('data', 'data'), ('’', '’'), ('complex', 'complex'), ('types', 'type'), ('structures', 'structur'), ('.', '.')]

>> Lemmatization: 
 [('Challenges', 'Challenges'), ('data', 'data'), ('analysis', 'analysis'), ('visualisation', 'visualisation'), ('Data', 'Data'), ('analysis', 'analysis'), ('challenges', 'challenge'), ('arise', 'arise'), ('data', 'data'), ('complexity', 'complexity'), (',', ','), ('turn', 'turn'), ('comes', 'come'), ('data', 'data'), ('’', '’'), ('complex', 'complex'), ('types', 'type'), ('structures', 'structure'), ('.', '.')]



============================ Sentence 516 =============================

Standard data analysis techniques face difficulties in handling such big data   as it is more difficult to understand the distribution laws of big data (Wang et al., 2016). 


>> Tokens are: 
 ['Standard', 'data', 'analysis', 'techniques', 'face', 'difficulties', 'handling', 'big', 'data', 'difficult', 'understand', 'distribution', 'laws', 'big', 'data', '(', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Standard', 'data'), ('data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'face'), ('face', 'difficulties'), ('difficulties', 'handling'), ('handling', 'big'), ('big', 'data'), ('data', 'difficult'), ('difficult', 'understand'), ('understand', 'distribution'), ('distribution', 'laws'), ('laws', 'big'), ('big', 'data'), ('data', '('), ('(', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Standard', 'data', 'analysis'), ('data', 'analysis', 'techniques'), ('analysis', 'techniques', 'face'), ('techniques', 'face', 'difficulties'), ('face', 'difficulties', 'handling'), ('difficulties', 'handling', 'big'), ('handling', 'big', 'data'), ('big', 'data', 'difficult'), ('data', 'difficult', 'understand'), ('difficult', 'understand', 'distribution'), ('understand', 'distribution', 'laws'), ('distribution', 'laws', 'big'), ('laws', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Wang'), ('(', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Standard', 'NNP'), ('data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('face', 'VBP'), ('difficulties', 'NNS'), ('handling', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('difficult', 'JJ'), ('understand', 'JJ'), ('distribution', 'NN'), ('laws', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Wang', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Standard/NNP data/NNS analysis/NN techniques/NNS)
  face/VBP
  (NP difficulties/NNS)
  handling/VBG
  (NP big/JJ data/NNS)
  (NP difficult/JJ understand/JJ distribution/NN laws/NNS)
  (NP big/JJ data/NNS)
  (/(
  (NP Wang/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Standard data analysis techniques', 'difficulties', 'big data', 'difficult understand distribution laws', 'big data', 'Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Standard', 'standard'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('face', 'face'), ('difficulties', 'difficulti'), ('handling', 'handl'), ('big', 'big'), ('data', 'data'), ('difficult', 'difficult'), ('understand', 'understand'), ('distribution', 'distribut'), ('laws', 'law'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Standard', 'standard'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('face', 'face'), ('difficulties', 'difficulti'), ('handling', 'handl'), ('big', 'big'), ('data', 'data'), ('difficult', 'difficult'), ('understand', 'understand'), ('distribution', 'distribut'), ('laws', 'law'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Standard', 'Standard'), ('data', 'data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('face', 'face'), ('difficulties', 'difficulty'), ('handling', 'handling'), ('big', 'big'), ('data', 'data'), ('difficult', 'difficult'), ('understand', 'understand'), ('distribution', 'distribution'), ('laws', 'law'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 517 =============================

Big data visualisation challenges come from the data’s high dimensions and size. 


>> Tokens are: 
 ['Big', 'data', 'visualisation', 'challenges', 'come', 'data', '’', 'high', 'dimensions', 'size', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'visualisation'), ('visualisation', 'challenges'), ('challenges', 'come'), ('come', 'data'), ('data', '’'), ('’', 'high'), ('high', 'dimensions'), ('dimensions', 'size'), ('size', '.')]

>> Trigrams are: 
 [('Big', 'data', 'visualisation'), ('data', 'visualisation', 'challenges'), ('visualisation', 'challenges', 'come'), ('challenges', 'come', 'data'), ('come', 'data', '’'), ('data', '’', 'high'), ('’', 'high', 'dimensions'), ('high', 'dimensions', 'size'), ('dimensions', 'size', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('visualisation', 'NN'), ('challenges', 'VBZ'), ('come', 'VBN'), ('data', 'NNS'), ('’', 'RB'), ('high', 'JJ'), ('dimensions', 'NNS'), ('size', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS visualisation/NN)
  challenges/VBZ
  come/VBN
  (NP data/NNS)
  ’/RB
  (NP high/JJ dimensions/NNS size/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data visualisation', 'data', 'high dimensions size']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('visualisation', 'visualis'), ('challenges', 'challeng'), ('come', 'come'), ('data', 'data'), ('’', '’'), ('high', 'high'), ('dimensions', 'dimens'), ('size', 'size'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('visualisation', 'visualis'), ('challenges', 'challeng'), ('come', 'come'), ('data', 'data'), ('’', '’'), ('high', 'high'), ('dimensions', 'dimens'), ('size', 'size'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('visualisation', 'visualisation'), ('challenges', 'challenge'), ('come', 'come'), ('data', 'data'), ('’', '’'), ('high', 'high'), ('dimensions', 'dimension'), ('size', 'size'), ('.', '.')]



============================ Sentence 518 =============================

The main goal   of data visualisation is to explain knowledge effectively by using diagrams; in order to transfer   information easily to the user, hidden knowledge in the complex and large-scale data sets is   rendered visible. 


>> Tokens are: 
 ['The', 'main', 'goal', 'data', 'visualisation', 'explain', 'knowledge', 'effectively', 'using', 'diagrams', ';', 'order', 'transfer', 'information', 'easily', 'user', ',', 'hidden', 'knowledge', 'complex', 'large-scale', 'data', 'sets', 'rendered', 'visible', '.']

>> Bigrams are: 
 [('The', 'main'), ('main', 'goal'), ('goal', 'data'), ('data', 'visualisation'), ('visualisation', 'explain'), ('explain', 'knowledge'), ('knowledge', 'effectively'), ('effectively', 'using'), ('using', 'diagrams'), ('diagrams', ';'), (';', 'order'), ('order', 'transfer'), ('transfer', 'information'), ('information', 'easily'), ('easily', 'user'), ('user', ','), (',', 'hidden'), ('hidden', 'knowledge'), ('knowledge', 'complex'), ('complex', 'large-scale'), ('large-scale', 'data'), ('data', 'sets'), ('sets', 'rendered'), ('rendered', 'visible'), ('visible', '.')]

>> Trigrams are: 
 [('The', 'main', 'goal'), ('main', 'goal', 'data'), ('goal', 'data', 'visualisation'), ('data', 'visualisation', 'explain'), ('visualisation', 'explain', 'knowledge'), ('explain', 'knowledge', 'effectively'), ('knowledge', 'effectively', 'using'), ('effectively', 'using', 'diagrams'), ('using', 'diagrams', ';'), ('diagrams', ';', 'order'), (';', 'order', 'transfer'), ('order', 'transfer', 'information'), ('transfer', 'information', 'easily'), ('information', 'easily', 'user'), ('easily', 'user', ','), ('user', ',', 'hidden'), (',', 'hidden', 'knowledge'), ('hidden', 'knowledge', 'complex'), ('knowledge', 'complex', 'large-scale'), ('complex', 'large-scale', 'data'), ('large-scale', 'data', 'sets'), ('data', 'sets', 'rendered'), ('sets', 'rendered', 'visible'), ('rendered', 'visible', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('main', 'JJ'), ('goal', 'NN'), ('data', 'NNS'), ('visualisation', 'NN'), ('explain', 'VBP'), ('knowledge', 'NN'), ('effectively', 'RB'), ('using', 'VBG'), ('diagrams', 'NNS'), (';', ':'), ('order', 'NN'), ('transfer', 'NN'), ('information', 'NN'), ('easily', 'RB'), ('user', 'RB'), (',', ','), ('hidden', 'JJ'), ('knowledge', 'NN'), ('complex', 'JJ'), ('large-scale', 'JJ'), ('data', 'NNS'), ('sets', 'NNS'), ('rendered', 'VBD'), ('visible', 'JJ'), ('.', '.')]

 (S
  (NP The/DT main/JJ goal/NN data/NNS visualisation/NN)
  explain/VBP
  (NP knowledge/NN)
  effectively/RB
  using/VBG
  (NP diagrams/NNS)
  ;/:
  (NP order/NN transfer/NN information/NN)
  easily/RB
  user/RB
  ,/,
  (NP hidden/JJ knowledge/NN)
  (NP complex/JJ large-scale/JJ data/NNS sets/NNS)
  rendered/VBD
  visible/JJ
  ./.) 


>> Noun Phrases are: 
 ['The main goal data visualisation', 'knowledge', 'diagrams', 'order transfer information', 'hidden knowledge', 'complex large-scale data sets']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('main', 'main'), ('goal', 'goal'), ('data', 'data'), ('visualisation', 'visualis'), ('explain', 'explain'), ('knowledge', 'knowledg'), ('effectively', 'effect'), ('using', 'use'), ('diagrams', 'diagram'), (';', ';'), ('order', 'order'), ('transfer', 'transfer'), ('information', 'inform'), ('easily', 'easili'), ('user', 'user'), (',', ','), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('complex', 'complex'), ('large-scale', 'large-scal'), ('data', 'data'), ('sets', 'set'), ('rendered', 'render'), ('visible', 'visibl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('main', 'main'), ('goal', 'goal'), ('data', 'data'), ('visualisation', 'visualis'), ('explain', 'explain'), ('knowledge', 'knowledg'), ('effectively', 'effect'), ('using', 'use'), ('diagrams', 'diagram'), (';', ';'), ('order', 'order'), ('transfer', 'transfer'), ('information', 'inform'), ('easily', 'easili'), ('user', 'user'), (',', ','), ('hidden', 'hidden'), ('knowledge', 'knowledg'), ('complex', 'complex'), ('large-scale', 'large-scal'), ('data', 'data'), ('sets', 'set'), ('rendered', 'render'), ('visible', 'visibl'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('main', 'main'), ('goal', 'goal'), ('data', 'data'), ('visualisation', 'visualisation'), ('explain', 'explain'), ('knowledge', 'knowledge'), ('effectively', 'effectively'), ('using', 'using'), ('diagrams', 'diagram'), (';', ';'), ('order', 'order'), ('transfer', 'transfer'), ('information', 'information'), ('easily', 'easily'), ('user', 'user'), (',', ','), ('hidden', 'hidden'), ('knowledge', 'knowledge'), ('complex', 'complex'), ('large-scale', 'large-scale'), ('data', 'data'), ('sets', 'set'), ('rendered', 'rendered'), ('visible', 'visible'), ('.', '.')]



============================ Sentence 519 =============================

For more accurate data analysis, however, abstracting information in schematic   formats, including features or variables representing units of information is valuable. 


>> Tokens are: 
 ['For', 'accurate', 'data', 'analysis', ',', 'however', ',', 'abstracting', 'information', 'schematic', 'formats', ',', 'including', 'features', 'variables', 'representing', 'units', 'information', 'valuable', '.']

>> Bigrams are: 
 [('For', 'accurate'), ('accurate', 'data'), ('data', 'analysis'), ('analysis', ','), (',', 'however'), ('however', ','), (',', 'abstracting'), ('abstracting', 'information'), ('information', 'schematic'), ('schematic', 'formats'), ('formats', ','), (',', 'including'), ('including', 'features'), ('features', 'variables'), ('variables', 'representing'), ('representing', 'units'), ('units', 'information'), ('information', 'valuable'), ('valuable', '.')]

>> Trigrams are: 
 [('For', 'accurate', 'data'), ('accurate', 'data', 'analysis'), ('data', 'analysis', ','), ('analysis', ',', 'however'), (',', 'however', ','), ('however', ',', 'abstracting'), (',', 'abstracting', 'information'), ('abstracting', 'information', 'schematic'), ('information', 'schematic', 'formats'), ('schematic', 'formats', ','), ('formats', ',', 'including'), (',', 'including', 'features'), ('including', 'features', 'variables'), ('features', 'variables', 'representing'), ('variables', 'representing', 'units'), ('representing', 'units', 'information'), ('units', 'information', 'valuable'), ('information', 'valuable', '.')]

>> POS Tags are: 
 [('For', 'IN'), ('accurate', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('however', 'RB'), (',', ','), ('abstracting', 'VBG'), ('information', 'NN'), ('schematic', 'JJ'), ('formats', 'NNS'), (',', ','), ('including', 'VBG'), ('features', 'NNS'), ('variables', 'NNS'), ('representing', 'VBG'), ('units', 'NNS'), ('information', 'NN'), ('valuable', 'NN'), ('.', '.')]

 (S
  For/IN
  (NP accurate/JJ data/NNS analysis/NN)
  ,/,
  however/RB
  ,/,
  abstracting/VBG
  (NP information/NN)
  (NP schematic/JJ formats/NNS)
  ,/,
  including/VBG
  (NP features/NNS variables/NNS)
  representing/VBG
  (NP units/NNS information/NN valuable/NN)
  ./.) 


>> Noun Phrases are: 
 ['accurate data analysis', 'information', 'schematic formats', 'features variables', 'units information valuable']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('For', 'for'), ('accurate', 'accur'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('however', 'howev'), (',', ','), ('abstracting', 'abstract'), ('information', 'inform'), ('schematic', 'schemat'), ('formats', 'format'), (',', ','), ('including', 'includ'), ('features', 'featur'), ('variables', 'variabl'), ('representing', 'repres'), ('units', 'unit'), ('information', 'inform'), ('valuable', 'valuabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('For', 'for'), ('accurate', 'accur'), ('data', 'data'), ('analysis', 'analysi'), (',', ','), ('however', 'howev'), (',', ','), ('abstracting', 'abstract'), ('information', 'inform'), ('schematic', 'schemat'), ('formats', 'format'), (',', ','), ('including', 'includ'), ('features', 'featur'), ('variables', 'variabl'), ('representing', 'repres'), ('units', 'unit'), ('information', 'inform'), ('valuable', 'valuabl'), ('.', '.')]

>> Lemmatization: 
 [('For', 'For'), ('accurate', 'accurate'), ('data', 'data'), ('analysis', 'analysis'), (',', ','), ('however', 'however'), (',', ','), ('abstracting', 'abstracting'), ('information', 'information'), ('schematic', 'schematic'), ('formats', 'format'), (',', ','), ('including', 'including'), ('features', 'feature'), ('variables', 'variable'), ('representing', 'representing'), ('units', 'unit'), ('information', 'information'), ('valuable', 'valuable'), ('.', '.')]



============================ Sentence 520 =============================

Nevertheless,   because of the large size and high dimensions of big data, it can also be difficult to manage data   visualisation in big data applications (Chen C.P et al., 2014; Wang et al., 2016). 


>> Tokens are: 
 ['Nevertheless', ',', 'large', 'size', 'high', 'dimensions', 'big', 'data', ',', 'also', 'difficult', 'manage', 'data', 'visualisation', 'big', 'data', 'applications', '(', 'Chen', 'C.P', 'et', 'al.', ',', '2014', ';', 'Wang', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Nevertheless', ','), (',', 'large'), ('large', 'size'), ('size', 'high'), ('high', 'dimensions'), ('dimensions', 'big'), ('big', 'data'), ('data', ','), (',', 'also'), ('also', 'difficult'), ('difficult', 'manage'), ('manage', 'data'), ('data', 'visualisation'), ('visualisation', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', '('), ('(', 'Chen'), ('Chen', 'C.P'), ('C.P', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ';'), (';', 'Wang'), ('Wang', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Nevertheless', ',', 'large'), (',', 'large', 'size'), ('large', 'size', 'high'), ('size', 'high', 'dimensions'), ('high', 'dimensions', 'big'), ('dimensions', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'also'), (',', 'also', 'difficult'), ('also', 'difficult', 'manage'), ('difficult', 'manage', 'data'), ('manage', 'data', 'visualisation'), ('data', 'visualisation', 'big'), ('visualisation', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', '('), ('applications', '(', 'Chen'), ('(', 'Chen', 'C.P'), ('Chen', 'C.P', 'et'), ('C.P', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Wang'), (';', 'Wang', 'et'), ('Wang', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Nevertheless', 'RB'), (',', ','), ('large', 'JJ'), ('size', 'NN'), ('high', 'JJ'), ('dimensions', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('also', 'RB'), ('difficult', 'JJ'), ('manage', 'NN'), ('data', 'NNS'), ('visualisation', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), ('(', '('), ('Chen', 'NNP'), ('C.P', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (';', ':'), ('Wang', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  Nevertheless/RB
  ,/,
  (NP large/JJ size/NN)
  (NP high/JJ dimensions/NNS)
  (NP big/JJ data/NNS)
  ,/,
  also/RB
  (NP difficult/JJ manage/NN data/NNS visualisation/NN)
  (NP big/JJ data/NNS applications/NNS)
  (/(
  (NP Chen/NNP C.P/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2014/CD
  ;/:
  (NP Wang/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['large size', 'high dimensions', 'big data', 'difficult manage data visualisation', 'big data applications', 'Chen C.P', 'al.', 'Wang', 'al.']

>> Named Entities are: 
 [('PERSON', 'Chen'), ('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ','), ('large', 'larg'), ('size', 'size'), ('high', 'high'), ('dimensions', 'dimens'), ('big', 'big'), ('data', 'data'), (',', ','), ('also', 'also'), ('difficult', 'difficult'), ('manage', 'manag'), ('data', 'data'), ('visualisation', 'visualis'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('(', '('), ('Chen', 'chen'), ('C.P', 'c.p'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nevertheless', 'nevertheless'), (',', ','), ('large', 'larg'), ('size', 'size'), ('high', 'high'), ('dimensions', 'dimens'), ('big', 'big'), ('data', 'data'), (',', ','), ('also', 'also'), ('difficult', 'difficult'), ('manage', 'manag'), ('data', 'data'), ('visualisation', 'visualis'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('(', '('), ('Chen', 'chen'), ('C.P', 'c.p'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Wang', 'wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Nevertheless', 'Nevertheless'), (',', ','), ('large', 'large'), ('size', 'size'), ('high', 'high'), ('dimensions', 'dimension'), ('big', 'big'), ('data', 'data'), (',', ','), ('also', 'also'), ('difficult', 'difficult'), ('manage', 'manage'), ('data', 'data'), ('visualisation', 'visualisation'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('(', '('), ('Chen', 'Chen'), ('C.P', 'C.P'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (';', ';'), ('Wang', 'Wang'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 521 =============================

Oussous et al. 


>> Tokens are: 
 ['Oussous', 'et', 'al', '.']

>> Bigrams are: 
 [('Oussous', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Oussous', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Oussous', 'JJ'), ('et', 'NN'), ('al', 'NN'), ('.', '.')]

 (S (NP Oussous/JJ et/NN al/NN) ./.) 


>> Noun Phrases are: 
 ['Oussous et al']

>> Named Entities are: 
 [('GPE', 'Oussous')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 522 =============================

(2018) discussed the value of data mining methods in several domains. 


>> Tokens are: 
 ['(', '2018', ')', 'discussed', 'value', 'data', 'mining', 'methods', 'several', 'domains', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'discussed'), ('discussed', 'value'), ('value', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', 'several'), ('several', 'domains'), ('domains', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'discussed'), (')', 'discussed', 'value'), ('discussed', 'value', 'data'), ('value', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', 'several'), ('methods', 'several', 'domains'), ('several', 'domains', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('discussed', 'VBD'), ('value', 'NN'), ('data', 'NNS'), ('mining', 'NN'), ('methods', 'NNS'), ('several', 'JJ'), ('domains', 'NNS'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  discussed/VBD
  (NP value/NN data/NNS mining/NN methods/NNS)
  (NP several/JJ domains/NNS)
  ./.) 


>> Noun Phrases are: 
 ['value data mining methods', 'several domains']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('value', 'valu'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('several', 'sever'), ('domains', 'domain'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discuss'), ('value', 'valu'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('several', 'sever'), ('domains', 'domain'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('discussed', 'discussed'), ('value', 'value'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('several', 'several'), ('domains', 'domain'), ('.', '.')]



============================ Sentence 523 =============================

Data mining   methods are significant when used for discovering patterns and extracting value hidden across   massive datasets. 


>> Tokens are: 
 ['Data', 'mining', 'methods', 'significant', 'used', 'discovering', 'patterns', 'extracting', 'value', 'hidden', 'across', 'massive', 'datasets', '.']

>> Bigrams are: 
 [('Data', 'mining'), ('mining', 'methods'), ('methods', 'significant'), ('significant', 'used'), ('used', 'discovering'), ('discovering', 'patterns'), ('patterns', 'extracting'), ('extracting', 'value'), ('value', 'hidden'), ('hidden', 'across'), ('across', 'massive'), ('massive', 'datasets'), ('datasets', '.')]

>> Trigrams are: 
 [('Data', 'mining', 'methods'), ('mining', 'methods', 'significant'), ('methods', 'significant', 'used'), ('significant', 'used', 'discovering'), ('used', 'discovering', 'patterns'), ('discovering', 'patterns', 'extracting'), ('patterns', 'extracting', 'value'), ('extracting', 'value', 'hidden'), ('value', 'hidden', 'across'), ('hidden', 'across', 'massive'), ('across', 'massive', 'datasets'), ('massive', 'datasets', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('mining', 'NN'), ('methods', 'NNS'), ('significant', 'JJ'), ('used', 'VBD'), ('discovering', 'VBG'), ('patterns', 'NNS'), ('extracting', 'VBG'), ('value', 'NN'), ('hidden', 'VBN'), ('across', 'IN'), ('massive', 'JJ'), ('datasets', 'NNS'), ('.', '.')]

 (S
  (NP Data/NNP mining/NN methods/NNS)
  significant/JJ
  used/VBD
  discovering/VBG
  (NP patterns/NNS)
  extracting/VBG
  (NP value/NN)
  hidden/VBN
  across/IN
  (NP massive/JJ datasets/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Data mining methods', 'patterns', 'value', 'massive datasets']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('significant', 'signific'), ('used', 'use'), ('discovering', 'discov'), ('patterns', 'pattern'), ('extracting', 'extract'), ('value', 'valu'), ('hidden', 'hidden'), ('across', 'across'), ('massive', 'massiv'), ('datasets', 'dataset'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('significant', 'signific'), ('used', 'use'), ('discovering', 'discov'), ('patterns', 'pattern'), ('extracting', 'extract'), ('value', 'valu'), ('hidden', 'hidden'), ('across', 'across'), ('massive', 'massiv'), ('datasets', 'dataset'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('mining', 'mining'), ('methods', 'method'), ('significant', 'significant'), ('used', 'used'), ('discovering', 'discovering'), ('patterns', 'pattern'), ('extracting', 'extracting'), ('value', 'value'), ('hidden', 'hidden'), ('across', 'across'), ('massive', 'massive'), ('datasets', 'datasets'), ('.', '.')]



============================ Sentence 524 =============================

Applying traditional data mining techniques, such as association mining,   clustering, and classification, to big data is, however, inefficient and inaccurate. 


>> Tokens are: 
 ['Applying', 'traditional', 'data', 'mining', 'techniques', ',', 'association', 'mining', ',', 'clustering', ',', 'classification', ',', 'big', 'data', ',', 'however', ',', 'inefficient', 'inaccurate', '.']

>> Bigrams are: 
 [('Applying', 'traditional'), ('traditional', 'data'), ('data', 'mining'), ('mining', 'techniques'), ('techniques', ','), (',', 'association'), ('association', 'mining'), ('mining', ','), (',', 'clustering'), ('clustering', ','), (',', 'classification'), ('classification', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'however'), ('however', ','), (',', 'inefficient'), ('inefficient', 'inaccurate'), ('inaccurate', '.')]

>> Trigrams are: 
 [('Applying', 'traditional', 'data'), ('traditional', 'data', 'mining'), ('data', 'mining', 'techniques'), ('mining', 'techniques', ','), ('techniques', ',', 'association'), (',', 'association', 'mining'), ('association', 'mining', ','), ('mining', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'classification'), (',', 'classification', ','), ('classification', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'however'), (',', 'however', ','), ('however', ',', 'inefficient'), (',', 'inefficient', 'inaccurate'), ('inefficient', 'inaccurate', '.')]

>> POS Tags are: 
 [('Applying', 'VBG'), ('traditional', 'JJ'), ('data', 'NNS'), ('mining', 'NN'), ('techniques', 'NNS'), (',', ','), ('association', 'NN'), ('mining', 'NN'), (',', ','), ('clustering', 'NN'), (',', ','), ('classification', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('inefficient', 'JJ'), ('inaccurate', 'NN'), ('.', '.')]

 (S
  Applying/VBG
  (NP traditional/JJ data/NNS mining/NN techniques/NNS)
  ,/,
  (NP association/NN mining/NN)
  ,/,
  (NP clustering/NN)
  ,/,
  (NP classification/NN)
  ,/,
  (NP big/JJ data/NNS)
  ,/,
  however/RB
  ,/,
  (NP inefficient/JJ inaccurate/NN)
  ./.) 


>> Noun Phrases are: 
 ['traditional data mining techniques', 'association mining', 'clustering', 'classification', 'big data', 'inefficient inaccurate']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('techniques', 'techniqu'), (',', ','), ('association', 'associ'), ('mining', 'mine'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('inefficient', 'ineffici'), ('inaccurate', 'inaccur'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli'), ('traditional', 'tradit'), ('data', 'data'), ('mining', 'mine'), ('techniques', 'techniqu'), (',', ','), ('association', 'associ'), ('mining', 'mine'), (',', ','), ('clustering', 'cluster'), (',', ','), ('classification', 'classif'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'howev'), (',', ','), ('inefficient', 'ineffici'), ('inaccurate', 'inaccur'), ('.', '.')]

>> Lemmatization: 
 [('Applying', 'Applying'), ('traditional', 'traditional'), ('data', 'data'), ('mining', 'mining'), ('techniques', 'technique'), (',', ','), ('association', 'association'), ('mining', 'mining'), (',', ','), ('clustering', 'clustering'), (',', ','), ('classification', 'classification'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('however', 'however'), (',', ','), ('inefficient', 'inefficient'), ('inaccurate', 'inaccurate'), ('.', '.')]



============================ Sentence 525 =============================

The volume,   speed, and variability of such data makes it unsuitable for long-term storage and analysis. 


>> Tokens are: 
 ['The', 'volume', ',', 'speed', ',', 'variability', 'data', 'makes', 'unsuitable', 'long-term', 'storage', 'analysis', '.']

>> Bigrams are: 
 [('The', 'volume'), ('volume', ','), (',', 'speed'), ('speed', ','), (',', 'variability'), ('variability', 'data'), ('data', 'makes'), ('makes', 'unsuitable'), ('unsuitable', 'long-term'), ('long-term', 'storage'), ('storage', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('The', 'volume', ','), ('volume', ',', 'speed'), (',', 'speed', ','), ('speed', ',', 'variability'), (',', 'variability', 'data'), ('variability', 'data', 'makes'), ('data', 'makes', 'unsuitable'), ('makes', 'unsuitable', 'long-term'), ('unsuitable', 'long-term', 'storage'), ('long-term', 'storage', 'analysis'), ('storage', 'analysis', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('volume', 'NN'), (',', ','), ('speed', 'NN'), (',', ','), ('variability', 'NN'), ('data', 'NNS'), ('makes', 'VBZ'), ('unsuitable', 'JJ'), ('long-term', 'JJ'), ('storage', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP The/DT volume/NN)
  ,/,
  (NP speed/NN)
  ,/,
  (NP variability/NN data/NNS)
  makes/VBZ
  (NP unsuitable/JJ long-term/JJ storage/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['The volume', 'speed', 'variability data', 'unsuitable long-term storage analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('volume', 'volum'), (',', ','), ('speed', 'speed'), (',', ','), ('variability', 'variabl'), ('data', 'data'), ('makes', 'make'), ('unsuitable', 'unsuit'), ('long-term', 'long-term'), ('storage', 'storag'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('volume', 'volum'), (',', ','), ('speed', 'speed'), (',', ','), ('variability', 'variabl'), ('data', 'data'), ('makes', 'make'), ('unsuitable', 'unsuit'), ('long-term', 'long-term'), ('storage', 'storag'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('volume', 'volume'), (',', ','), ('speed', 'speed'), (',', ','), ('variability', 'variability'), ('data', 'data'), ('makes', 'make'), ('unsuitable', 'unsuitable'), ('long-term', 'long-term'), ('storage', 'storage'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 526 =============================

Several   data mining methods have thus been adapted to contain detecting techniques to take the data   environment into account. 


>> Tokens are: 
 ['Several', 'data', 'mining', 'methods', 'thus', 'adapted', 'contain', 'detecting', 'techniques', 'take', 'data', 'environment', 'account', '.']

>> Bigrams are: 
 [('Several', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', 'thus'), ('thus', 'adapted'), ('adapted', 'contain'), ('contain', 'detecting'), ('detecting', 'techniques'), ('techniques', 'take'), ('take', 'data'), ('data', 'environment'), ('environment', 'account'), ('account', '.')]

>> Trigrams are: 
 [('Several', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', 'thus'), ('methods', 'thus', 'adapted'), ('thus', 'adapted', 'contain'), ('adapted', 'contain', 'detecting'), ('contain', 'detecting', 'techniques'), ('detecting', 'techniques', 'take'), ('techniques', 'take', 'data'), ('take', 'data', 'environment'), ('data', 'environment', 'account'), ('environment', 'account', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('data', 'NNS'), ('mining', 'VBG'), ('methods', 'NNS'), ('thus', 'RB'), ('adapted', 'VBD'), ('contain', 'NN'), ('detecting', 'VBG'), ('techniques', 'NNS'), ('take', 'VB'), ('data', 'NNS'), ('environment', 'NN'), ('account', 'NN'), ('.', '.')]

 (S
  (NP Several/JJ data/NNS)
  mining/VBG
  (NP methods/NNS)
  thus/RB
  adapted/VBD
  (NP contain/NN)
  detecting/VBG
  (NP techniques/NNS)
  take/VB
  (NP data/NNS environment/NN account/NN)
  ./.) 


>> Noun Phrases are: 
 ['Several data', 'methods', 'contain', 'techniques', 'data environment account']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('thus', 'thu'), ('adapted', 'adapt'), ('contain', 'contain'), ('detecting', 'detect'), ('techniques', 'techniqu'), ('take', 'take'), ('data', 'data'), ('environment', 'environ'), ('account', 'account'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('data', 'data'), ('mining', 'mine'), ('methods', 'method'), ('thus', 'thus'), ('adapted', 'adapt'), ('contain', 'contain'), ('detecting', 'detect'), ('techniques', 'techniqu'), ('take', 'take'), ('data', 'data'), ('environment', 'environ'), ('account', 'account'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('data', 'data'), ('mining', 'mining'), ('methods', 'method'), ('thus', 'thus'), ('adapted', 'adapted'), ('contain', 'contain'), ('detecting', 'detecting'), ('techniques', 'technique'), ('take', 'take'), ('data', 'data'), ('environment', 'environment'), ('account', 'account'), ('.', '.')]



============================ Sentence 527 =============================

Günther et al. 


>> Tokens are: 
 ['Günther', 'et', 'al', '.']

>> Bigrams are: 
 [('Günther', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Günther', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Günther', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Günther/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Günther', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Günther', 'günther'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Günther', 'günther'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Günther', 'Günther'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 528 =============================

(2017) noted that some empirical studies and some old ideas have characterised   much big data value realisation; the study examined six debates identified in terms of “how   organisations realize social and economic value from big data that require attention from future   research”. 


>> Tokens are: 
 ['(', '2017', ')', 'noted', 'empirical', 'studies', 'old', 'ideas', 'characterised', 'much', 'big', 'data', 'value', 'realisation', ';', 'study', 'examined', 'six', 'debates', 'identified', 'terms', '“', 'organisations', 'realize', 'social', 'economic', 'value', 'big', 'data', 'require', 'attention', 'future', 'research', '”', '.']

>> Bigrams are: 
 [('(', '2017'), ('2017', ')'), (')', 'noted'), ('noted', 'empirical'), ('empirical', 'studies'), ('studies', 'old'), ('old', 'ideas'), ('ideas', 'characterised'), ('characterised', 'much'), ('much', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', ';'), (';', 'study'), ('study', 'examined'), ('examined', 'six'), ('six', 'debates'), ('debates', 'identified'), ('identified', 'terms'), ('terms', '“'), ('“', 'organisations'), ('organisations', 'realize'), ('realize', 'social'), ('social', 'economic'), ('economic', 'value'), ('value', 'big'), ('big', 'data'), ('data', 'require'), ('require', 'attention'), ('attention', 'future'), ('future', 'research'), ('research', '”'), ('”', '.')]

>> Trigrams are: 
 [('(', '2017', ')'), ('2017', ')', 'noted'), (')', 'noted', 'empirical'), ('noted', 'empirical', 'studies'), ('empirical', 'studies', 'old'), ('studies', 'old', 'ideas'), ('old', 'ideas', 'characterised'), ('ideas', 'characterised', 'much'), ('characterised', 'much', 'big'), ('much', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', ';'), ('realisation', ';', 'study'), (';', 'study', 'examined'), ('study', 'examined', 'six'), ('examined', 'six', 'debates'), ('six', 'debates', 'identified'), ('debates', 'identified', 'terms'), ('identified', 'terms', '“'), ('terms', '“', 'organisations'), ('“', 'organisations', 'realize'), ('organisations', 'realize', 'social'), ('realize', 'social', 'economic'), ('social', 'economic', 'value'), ('economic', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', 'require'), ('data', 'require', 'attention'), ('require', 'attention', 'future'), ('attention', 'future', 'research'), ('future', 'research', '”'), ('research', '”', '.')]

>> POS Tags are: 
 [('(', '('), ('2017', 'CD'), (')', ')'), ('noted', 'VBD'), ('empirical', 'JJ'), ('studies', 'NNS'), ('old', 'JJ'), ('ideas', 'NNS'), ('characterised', 'VBD'), ('much', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), (';', ':'), ('study', 'NN'), ('examined', 'VBD'), ('six', 'CD'), ('debates', 'NNS'), ('identified', 'VBN'), ('terms', 'NNS'), ('“', 'JJ'), ('organisations', 'NNS'), ('realize', 'VBP'), ('social', 'JJ'), ('economic', 'JJ'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('require', 'VBP'), ('attention', 'NN'), ('future', 'JJ'), ('research', 'NN'), ('”', 'NN'), ('.', '.')]

 (S
  (/(
  2017/CD
  )/)
  noted/VBD
  (NP empirical/JJ studies/NNS)
  (NP old/JJ ideas/NNS)
  characterised/VBD
  much/RB
  (NP big/JJ data/NNS value/NN realisation/NN)
  ;/:
  (NP study/NN)
  examined/VBD
  six/CD
  (NP debates/NNS)
  identified/VBN
  (NP terms/NNS)
  (NP “/JJ organisations/NNS)
  realize/VBP
  (NP social/JJ economic/JJ value/NN)
  (NP big/JJ data/NNS)
  require/VBP
  (NP attention/NN)
  (NP future/JJ research/NN ”/NN)
  ./.) 


>> Noun Phrases are: 
 ['empirical studies', 'old ideas', 'big data value realisation', 'study', 'debates', 'terms', '“ organisations', 'social economic value', 'big data', 'attention', 'future research ”']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('noted', 'note'), ('empirical', 'empir'), ('studies', 'studi'), ('old', 'old'), ('ideas', 'idea'), ('characterised', 'characteris'), ('much', 'much'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (';', ';'), ('study', 'studi'), ('examined', 'examin'), ('six', 'six'), ('debates', 'debat'), ('identified', 'identifi'), ('terms', 'term'), ('“', '“'), ('organisations', 'organis'), ('realize', 'realiz'), ('social', 'social'), ('economic', 'econom'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('attention', 'attent'), ('future', 'futur'), ('research', 'research'), ('”', '”'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('noted', 'note'), ('empirical', 'empir'), ('studies', 'studi'), ('old', 'old'), ('ideas', 'idea'), ('characterised', 'characteris'), ('much', 'much'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (';', ';'), ('study', 'studi'), ('examined', 'examin'), ('six', 'six'), ('debates', 'debat'), ('identified', 'identifi'), ('terms', 'term'), ('“', '“'), ('organisations', 'organis'), ('realize', 'realiz'), ('social', 'social'), ('economic', 'econom'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('require', 'requir'), ('attention', 'attent'), ('future', 'futur'), ('research', 'research'), ('”', '”'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2017', '2017'), (')', ')'), ('noted', 'noted'), ('empirical', 'empirical'), ('studies', 'study'), ('old', 'old'), ('ideas', 'idea'), ('characterised', 'characterised'), ('much', 'much'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), (';', ';'), ('study', 'study'), ('examined', 'examined'), ('six', 'six'), ('debates', 'debate'), ('identified', 'identified'), ('terms', 'term'), ('“', '“'), ('organisations', 'organisation'), ('realize', 'realize'), ('social', 'social'), ('economic', 'economic'), ('value', 'value'), ('big', 'big'), ('data', 'data'), ('require', 'require'), ('attention', 'attention'), ('future', 'future'), ('research', 'research'), ('”', '”'), ('.', '.')]



============================ Sentence 529 =============================

Two additional features of big data were also identified, portability and   interconnectivity, and those features were utilised to show the effect of big data value realisation   in organisations. 


>> Tokens are: 
 ['Two', 'additional', 'features', 'big', 'data', 'also', 'identified', ',', 'portability', 'interconnectivity', ',', 'features', 'utilised', 'show', 'effect', 'big', 'data', 'value', 'realisation', 'organisations', '.']

>> Bigrams are: 
 [('Two', 'additional'), ('additional', 'features'), ('features', 'big'), ('big', 'data'), ('data', 'also'), ('also', 'identified'), ('identified', ','), (',', 'portability'), ('portability', 'interconnectivity'), ('interconnectivity', ','), (',', 'features'), ('features', 'utilised'), ('utilised', 'show'), ('show', 'effect'), ('effect', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', 'organisations'), ('organisations', '.')]

>> Trigrams are: 
 [('Two', 'additional', 'features'), ('additional', 'features', 'big'), ('features', 'big', 'data'), ('big', 'data', 'also'), ('data', 'also', 'identified'), ('also', 'identified', ','), ('identified', ',', 'portability'), (',', 'portability', 'interconnectivity'), ('portability', 'interconnectivity', ','), ('interconnectivity', ',', 'features'), (',', 'features', 'utilised'), ('features', 'utilised', 'show'), ('utilised', 'show', 'effect'), ('show', 'effect', 'big'), ('effect', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', 'organisations'), ('realisation', 'organisations', '.')]

>> POS Tags are: 
 [('Two', 'CD'), ('additional', 'JJ'), ('features', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('also', 'RB'), ('identified', 'VBN'), (',', ','), ('portability', 'NN'), ('interconnectivity', 'NN'), (',', ','), ('features', 'NNS'), ('utilised', 'VBD'), ('show', 'NN'), ('effect', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), ('organisations', 'NNS'), ('.', '.')]

 (S
  Two/CD
  (NP additional/JJ features/NNS)
  (NP big/JJ data/NNS)
  also/RB
  identified/VBN
  ,/,
  (NP portability/NN interconnectivity/NN)
  ,/,
  (NP features/NNS)
  utilised/VBD
  (NP show/NN effect/NN)
  (NP big/JJ data/NNS value/NN realisation/NN organisations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['additional features', 'big data', 'portability interconnectivity', 'features', 'show effect', 'big data value realisation organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Two', 'two'), ('additional', 'addit'), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('identified', 'identifi'), (',', ','), ('portability', 'portabl'), ('interconnectivity', 'interconnect'), (',', ','), ('features', 'featur'), ('utilised', 'utilis'), ('show', 'show'), ('effect', 'effect'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), ('organisations', 'organis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Two', 'two'), ('additional', 'addit'), ('features', 'featur'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('identified', 'identifi'), (',', ','), ('portability', 'portabl'), ('interconnectivity', 'interconnect'), (',', ','), ('features', 'featur'), ('utilised', 'utilis'), ('show', 'show'), ('effect', 'effect'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), ('organisations', 'organis'), ('.', '.')]

>> Lemmatization: 
 [('Two', 'Two'), ('additional', 'additional'), ('features', 'feature'), ('big', 'big'), ('data', 'data'), ('also', 'also'), ('identified', 'identified'), (',', ','), ('portability', 'portability'), ('interconnectivity', 'interconnectivity'), (',', ','), ('features', 'feature'), ('utilised', 'utilised'), ('show', 'show'), ('effect', 'effect'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), ('organisations', 'organisation'), ('.', '.')]



============================ Sentence 530 =============================

At the end of the study, the authors argued that the continuous interactions   between work practices, organisational models, and stakeholder interests prompted calls for   empirical research on cross-level interactions and alignment results from realising big data value,   as shown in Figure 23. 


>> Tokens are: 
 ['At', 'end', 'study', ',', 'authors', 'argued', 'continuous', 'interactions', 'work', 'practices', ',', 'organisational', 'models', ',', 'stakeholder', 'interests', 'prompted', 'calls', 'empirical', 'research', 'cross-level', 'interactions', 'alignment', 'results', 'realising', 'big', 'data', 'value', ',', 'shown', 'Figure', '23', '.']

>> Bigrams are: 
 [('At', 'end'), ('end', 'study'), ('study', ','), (',', 'authors'), ('authors', 'argued'), ('argued', 'continuous'), ('continuous', 'interactions'), ('interactions', 'work'), ('work', 'practices'), ('practices', ','), (',', 'organisational'), ('organisational', 'models'), ('models', ','), (',', 'stakeholder'), ('stakeholder', 'interests'), ('interests', 'prompted'), ('prompted', 'calls'), ('calls', 'empirical'), ('empirical', 'research'), ('research', 'cross-level'), ('cross-level', 'interactions'), ('interactions', 'alignment'), ('alignment', 'results'), ('results', 'realising'), ('realising', 'big'), ('big', 'data'), ('data', 'value'), ('value', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '23'), ('23', '.')]

>> Trigrams are: 
 [('At', 'end', 'study'), ('end', 'study', ','), ('study', ',', 'authors'), (',', 'authors', 'argued'), ('authors', 'argued', 'continuous'), ('argued', 'continuous', 'interactions'), ('continuous', 'interactions', 'work'), ('interactions', 'work', 'practices'), ('work', 'practices', ','), ('practices', ',', 'organisational'), (',', 'organisational', 'models'), ('organisational', 'models', ','), ('models', ',', 'stakeholder'), (',', 'stakeholder', 'interests'), ('stakeholder', 'interests', 'prompted'), ('interests', 'prompted', 'calls'), ('prompted', 'calls', 'empirical'), ('calls', 'empirical', 'research'), ('empirical', 'research', 'cross-level'), ('research', 'cross-level', 'interactions'), ('cross-level', 'interactions', 'alignment'), ('interactions', 'alignment', 'results'), ('alignment', 'results', 'realising'), ('results', 'realising', 'big'), ('realising', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', ','), ('value', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '23'), ('Figure', '23', '.')]

>> POS Tags are: 
 [('At', 'IN'), ('end', 'NN'), ('study', 'NN'), (',', ','), ('authors', 'NNS'), ('argued', 'VBD'), ('continuous', 'JJ'), ('interactions', 'NNS'), ('work', 'NN'), ('practices', 'NNS'), (',', ','), ('organisational', 'JJ'), ('models', 'NNS'), (',', ','), ('stakeholder', 'NN'), ('interests', 'NNS'), ('prompted', 'VBD'), ('calls', 'NNS'), ('empirical', 'JJ'), ('research', 'NN'), ('cross-level', 'JJ'), ('interactions', 'NNS'), ('alignment', 'JJ'), ('results', 'NNS'), ('realising', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('23', 'CD'), ('.', '.')]

 (S
  At/IN
  (NP end/NN study/NN)
  ,/,
  (NP authors/NNS)
  argued/VBD
  (NP continuous/JJ interactions/NNS work/NN practices/NNS)
  ,/,
  (NP organisational/JJ models/NNS)
  ,/,
  (NP stakeholder/NN interests/NNS)
  prompted/VBD
  (NP calls/NNS)
  (NP empirical/JJ research/NN)
  (NP cross-level/JJ interactions/NNS)
  (NP alignment/JJ results/NNS)
  realising/VBG
  (NP big/JJ data/NNS value/NN)
  ,/,
  shown/VBN
  (NP Figure/NN)
  23/CD
  ./.) 


>> Noun Phrases are: 
 ['end study', 'authors', 'continuous interactions work practices', 'organisational models', 'stakeholder interests', 'calls', 'empirical research', 'cross-level interactions', 'alignment results', 'big data value', 'Figure']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('At', 'at'), ('end', 'end'), ('study', 'studi'), (',', ','), ('authors', 'author'), ('argued', 'argu'), ('continuous', 'continu'), ('interactions', 'interact'), ('work', 'work'), ('practices', 'practic'), (',', ','), ('organisational', 'organis'), ('models', 'model'), (',', ','), ('stakeholder', 'stakehold'), ('interests', 'interest'), ('prompted', 'prompt'), ('calls', 'call'), ('empirical', 'empir'), ('research', 'research'), ('cross-level', 'cross-level'), ('interactions', 'interact'), ('alignment', 'align'), ('results', 'result'), ('realising', 'realis'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('23', '23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('At', 'at'), ('end', 'end'), ('study', 'studi'), (',', ','), ('authors', 'author'), ('argued', 'argu'), ('continuous', 'continu'), ('interactions', 'interact'), ('work', 'work'), ('practices', 'practic'), (',', ','), ('organisational', 'organis'), ('models', 'model'), (',', ','), ('stakeholder', 'stakehold'), ('interests', 'interest'), ('prompted', 'prompt'), ('calls', 'call'), ('empirical', 'empir'), ('research', 'research'), ('cross-level', 'cross-level'), ('interactions', 'interact'), ('alignment', 'align'), ('results', 'result'), ('realising', 'realis'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('23', '23'), ('.', '.')]

>> Lemmatization: 
 [('At', 'At'), ('end', 'end'), ('study', 'study'), (',', ','), ('authors', 'author'), ('argued', 'argued'), ('continuous', 'continuous'), ('interactions', 'interaction'), ('work', 'work'), ('practices', 'practice'), (',', ','), ('organisational', 'organisational'), ('models', 'model'), (',', ','), ('stakeholder', 'stakeholder'), ('interests', 'interest'), ('prompted', 'prompted'), ('calls', 'call'), ('empirical', 'empirical'), ('research', 'research'), ('cross-level', 'cross-level'), ('interactions', 'interaction'), ('alignment', 'alignment'), ('results', 'result'), ('realising', 'realising'), ('big', 'big'), ('data', 'data'), ('value', 'value'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('23', '23'), ('.', '.')]



============================ Sentence 531 =============================

Several suggestions for further study were also presented:     Sarah Al-Shiakhli   41      • Work on improving big data business models and innovative approaches, such as the  development of a four-stage big data maturity model, allowing organisations to reach   functional excellence despite the ability to develop business model transformation   occurring only in the last stage;   • Relevant systems, such as Hadoop, which have the ability to work with both big data and  more traditional data being identified for various cases (Ekbia et al., 2015);   • Examining the dependency on size of organisations that can adopt big data (Ekbia et al.,  2015);   • Examining appropriate organisational models for creating and appropriating value from  big data (Karpovsky and Galliers, 2015; Ekbia et al., 2015);   • Further investigation of two key issues: 1) controlled and open big data access when data  analytics can be considered a competitive advantage, as organisations may be opposed to   exchanging data with perceived competitors (Jagadish et al., 2014); and 2) minimising and   countering the social risks of big data value realisation (Clarke, 2016). 


>> Tokens are: 
 ['Several', 'suggestions', 'study', 'also', 'presented', ':', 'Sarah', 'Al-Shiakhli', '41', '•', 'Work', 'improving', 'big', 'data', 'business', 'models', 'innovative', 'approaches', ',', 'development', 'four-stage', 'big', 'data', 'maturity', 'model', ',', 'allowing', 'organisations', 'reach', 'functional', 'excellence', 'despite', 'ability', 'develop', 'business', 'model', 'transformation', 'occurring', 'last', 'stage', ';', '•', 'Relevant', 'systems', ',', 'Hadoop', ',', 'ability', 'work', 'big', 'data', 'traditional', 'data', 'identified', 'various', 'cases', '(', 'Ekbia', 'et', 'al.', ',', '2015', ')', ';', '•', 'Examining', 'dependency', 'size', 'organisations', 'adopt', 'big', 'data', '(', 'Ekbia', 'et', 'al.', ',', '2015', ')', ';', '•', 'Examining', 'appropriate', 'organisational', 'models', 'creating', 'appropriating', 'value', 'big', 'data', '(', 'Karpovsky', 'Galliers', ',', '2015', ';', 'Ekbia', 'et', 'al.', ',', '2015', ')', ';', '•', 'Further', 'investigation', 'two', 'key', 'issues', ':', '1', ')', 'controlled', 'open', 'big', 'data', 'access', 'data', 'analytics', 'considered', 'competitive', 'advantage', ',', 'organisations', 'may', 'opposed', 'exchanging', 'data', 'perceived', 'competitors', '(', 'Jagadish', 'et', 'al.', ',', '2014', ')', ';', '2', ')', 'minimising', 'countering', 'social', 'risks', 'big', 'data', 'value', 'realisation', '(', 'Clarke', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Several', 'suggestions'), ('suggestions', 'study'), ('study', 'also'), ('also', 'presented'), ('presented', ':'), (':', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '41'), ('41', '•'), ('•', 'Work'), ('Work', 'improving'), ('improving', 'big'), ('big', 'data'), ('data', 'business'), ('business', 'models'), ('models', 'innovative'), ('innovative', 'approaches'), ('approaches', ','), (',', 'development'), ('development', 'four-stage'), ('four-stage', 'big'), ('big', 'data'), ('data', 'maturity'), ('maturity', 'model'), ('model', ','), (',', 'allowing'), ('allowing', 'organisations'), ('organisations', 'reach'), ('reach', 'functional'), ('functional', 'excellence'), ('excellence', 'despite'), ('despite', 'ability'), ('ability', 'develop'), ('develop', 'business'), ('business', 'model'), ('model', 'transformation'), ('transformation', 'occurring'), ('occurring', 'last'), ('last', 'stage'), ('stage', ';'), (';', '•'), ('•', 'Relevant'), ('Relevant', 'systems'), ('systems', ','), (',', 'Hadoop'), ('Hadoop', ','), (',', 'ability'), ('ability', 'work'), ('work', 'big'), ('big', 'data'), ('data', 'traditional'), ('traditional', 'data'), ('data', 'identified'), ('identified', 'various'), ('various', 'cases'), ('cases', '('), ('(', 'Ekbia'), ('Ekbia', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', ';'), (';', '•'), ('•', 'Examining'), ('Examining', 'dependency'), ('dependency', 'size'), ('size', 'organisations'), ('organisations', 'adopt'), ('adopt', 'big'), ('big', 'data'), ('data', '('), ('(', 'Ekbia'), ('Ekbia', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', ';'), (';', '•'), ('•', 'Examining'), ('Examining', 'appropriate'), ('appropriate', 'organisational'), ('organisational', 'models'), ('models', 'creating'), ('creating', 'appropriating'), ('appropriating', 'value'), ('value', 'big'), ('big', 'data'), ('data', '('), ('(', 'Karpovsky'), ('Karpovsky', 'Galliers'), ('Galliers', ','), (',', '2015'), ('2015', ';'), (';', 'Ekbia'), ('Ekbia', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', ';'), (';', '•'), ('•', 'Further'), ('Further', 'investigation'), ('investigation', 'two'), ('two', 'key'), ('key', 'issues'), ('issues', ':'), (':', '1'), ('1', ')'), (')', 'controlled'), ('controlled', 'open'), ('open', 'big'), ('big', 'data'), ('data', 'access'), ('access', 'data'), ('data', 'analytics'), ('analytics', 'considered'), ('considered', 'competitive'), ('competitive', 'advantage'), ('advantage', ','), (',', 'organisations'), ('organisations', 'may'), ('may', 'opposed'), ('opposed', 'exchanging'), ('exchanging', 'data'), ('data', 'perceived'), ('perceived', 'competitors'), ('competitors', '('), ('(', 'Jagadish'), ('Jagadish', 'et'), ('et', 'al.'), ('al.', ','), (',', '2014'), ('2014', ')'), (')', ';'), (';', '2'), ('2', ')'), (')', 'minimising'), ('minimising', 'countering'), ('countering', 'social'), ('social', 'risks'), ('risks', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', '('), ('(', 'Clarke'), ('Clarke', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Several', 'suggestions', 'study'), ('suggestions', 'study', 'also'), ('study', 'also', 'presented'), ('also', 'presented', ':'), ('presented', ':', 'Sarah'), (':', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '41'), ('Al-Shiakhli', '41', '•'), ('41', '•', 'Work'), ('•', 'Work', 'improving'), ('Work', 'improving', 'big'), ('improving', 'big', 'data'), ('big', 'data', 'business'), ('data', 'business', 'models'), ('business', 'models', 'innovative'), ('models', 'innovative', 'approaches'), ('innovative', 'approaches', ','), ('approaches', ',', 'development'), (',', 'development', 'four-stage'), ('development', 'four-stage', 'big'), ('four-stage', 'big', 'data'), ('big', 'data', 'maturity'), ('data', 'maturity', 'model'), ('maturity', 'model', ','), ('model', ',', 'allowing'), (',', 'allowing', 'organisations'), ('allowing', 'organisations', 'reach'), ('organisations', 'reach', 'functional'), ('reach', 'functional', 'excellence'), ('functional', 'excellence', 'despite'), ('excellence', 'despite', 'ability'), ('despite', 'ability', 'develop'), ('ability', 'develop', 'business'), ('develop', 'business', 'model'), ('business', 'model', 'transformation'), ('model', 'transformation', 'occurring'), ('transformation', 'occurring', 'last'), ('occurring', 'last', 'stage'), ('last', 'stage', ';'), ('stage', ';', '•'), (';', '•', 'Relevant'), ('•', 'Relevant', 'systems'), ('Relevant', 'systems', ','), ('systems', ',', 'Hadoop'), (',', 'Hadoop', ','), ('Hadoop', ',', 'ability'), (',', 'ability', 'work'), ('ability', 'work', 'big'), ('work', 'big', 'data'), ('big', 'data', 'traditional'), ('data', 'traditional', 'data'), ('traditional', 'data', 'identified'), ('data', 'identified', 'various'), ('identified', 'various', 'cases'), ('various', 'cases', '('), ('cases', '(', 'Ekbia'), ('(', 'Ekbia', 'et'), ('Ekbia', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';'), (')', ';', '•'), (';', '•', 'Examining'), ('•', 'Examining', 'dependency'), ('Examining', 'dependency', 'size'), ('dependency', 'size', 'organisations'), ('size', 'organisations', 'adopt'), ('organisations', 'adopt', 'big'), ('adopt', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Ekbia'), ('(', 'Ekbia', 'et'), ('Ekbia', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';'), (')', ';', '•'), (';', '•', 'Examining'), ('•', 'Examining', 'appropriate'), ('Examining', 'appropriate', 'organisational'), ('appropriate', 'organisational', 'models'), ('organisational', 'models', 'creating'), ('models', 'creating', 'appropriating'), ('creating', 'appropriating', 'value'), ('appropriating', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', '('), ('data', '(', 'Karpovsky'), ('(', 'Karpovsky', 'Galliers'), ('Karpovsky', 'Galliers', ','), ('Galliers', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Ekbia'), (';', 'Ekbia', 'et'), ('Ekbia', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', ';'), (')', ';', '•'), (';', '•', 'Further'), ('•', 'Further', 'investigation'), ('Further', 'investigation', 'two'), ('investigation', 'two', 'key'), ('two', 'key', 'issues'), ('key', 'issues', ':'), ('issues', ':', '1'), (':', '1', ')'), ('1', ')', 'controlled'), (')', 'controlled', 'open'), ('controlled', 'open', 'big'), ('open', 'big', 'data'), ('big', 'data', 'access'), ('data', 'access', 'data'), ('access', 'data', 'analytics'), ('data', 'analytics', 'considered'), ('analytics', 'considered', 'competitive'), ('considered', 'competitive', 'advantage'), ('competitive', 'advantage', ','), ('advantage', ',', 'organisations'), (',', 'organisations', 'may'), ('organisations', 'may', 'opposed'), ('may', 'opposed', 'exchanging'), ('opposed', 'exchanging', 'data'), ('exchanging', 'data', 'perceived'), ('data', 'perceived', 'competitors'), ('perceived', 'competitors', '('), ('competitors', '(', 'Jagadish'), ('(', 'Jagadish', 'et'), ('Jagadish', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ';'), (')', ';', '2'), (';', '2', ')'), ('2', ')', 'minimising'), (')', 'minimising', 'countering'), ('minimising', 'countering', 'social'), ('countering', 'social', 'risks'), ('social', 'risks', 'big'), ('risks', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', '('), ('realisation', '(', 'Clarke'), ('(', 'Clarke', ','), ('Clarke', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Several', 'JJ'), ('suggestions', 'NNS'), ('study', 'NN'), ('also', 'RB'), ('presented', 'VBD'), (':', ':'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('41', 'CD'), ('•', 'NNP'), ('Work', 'NNP'), ('improving', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('business', 'NN'), ('models', 'NNS'), ('innovative', 'JJ'), ('approaches', 'NNS'), (',', ','), ('development', 'NN'), ('four-stage', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('maturity', 'NN'), ('model', 'NN'), (',', ','), ('allowing', 'VBG'), ('organisations', 'NNS'), ('reach', 'VBP'), ('functional', 'JJ'), ('excellence', 'NN'), ('despite', 'IN'), ('ability', 'NN'), ('develop', 'NN'), ('business', 'NN'), ('model', 'NN'), ('transformation', 'NN'), ('occurring', 'VBG'), ('last', 'JJ'), ('stage', 'NN'), (';', ':'), ('•', 'CC'), ('Relevant', 'JJ'), ('systems', 'NNS'), (',', ','), ('Hadoop', 'NNP'), (',', ','), ('ability', 'NN'), ('work', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('identified', 'VBN'), ('various', 'JJ'), ('cases', 'NNS'), ('(', '('), ('Ekbia', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':'), ('•', 'CC'), ('Examining', 'NNP'), ('dependency', 'NN'), ('size', 'NN'), ('organisations', 'NNS'), ('adopt', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Ekbia', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':'), ('•', 'CC'), ('Examining', 'NNP'), ('appropriate', 'JJ'), ('organisational', 'JJ'), ('models', 'NNS'), ('creating', 'VBG'), ('appropriating', 'VBG'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('(', '('), ('Karpovsky', 'NNP'), ('Galliers', 'NNP'), (',', ','), ('2015', 'CD'), (';', ':'), ('Ekbia', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2015', 'CD'), (')', ')'), (';', ':'), ('•', 'CC'), ('Further', 'NNP'), ('investigation', 'NN'), ('two', 'CD'), ('key', 'JJ'), ('issues', 'NNS'), (':', ':'), ('1', 'CD'), (')', ')'), ('controlled', 'VBD'), ('open', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('access', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('considered', 'VBD'), ('competitive', 'JJ'), ('advantage', 'NN'), (',', ','), ('organisations', 'NNS'), ('may', 'MD'), ('opposed', 'VBN'), ('exchanging', 'VBG'), ('data', 'NNS'), ('perceived', 'VBN'), ('competitors', 'NNS'), ('(', '('), ('Jagadish', 'JJ'), ('et', 'NN'), ('al.', 'NN'), (',', ','), ('2014', 'CD'), (')', ')'), (';', ':'), ('2', 'CD'), (')', ')'), ('minimising', 'VBG'), ('countering', 'VBG'), ('social', 'JJ'), ('risks', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), ('(', '('), ('Clarke', 'NNP'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Several/JJ suggestions/NNS study/NN)
  also/RB
  presented/VBD
  :/:
  (NP Sarah/NNP Al-Shiakhli/NNP)
  41/CD
  (NP •/NNP Work/NNP)
  improving/VBG
  (NP big/JJ data/NNS business/NN models/NNS)
  (NP innovative/JJ approaches/NNS)
  ,/,
  (NP development/NN four-stage/NN)
  (NP big/JJ data/NNS maturity/NN model/NN)
  ,/,
  allowing/VBG
  (NP organisations/NNS)
  reach/VBP
  (NP functional/JJ excellence/NN)
  despite/IN
  (NP ability/NN develop/NN business/NN model/NN transformation/NN)
  occurring/VBG
  (NP last/JJ stage/NN)
  ;/:
  •/CC
  (NP Relevant/JJ systems/NNS)
  ,/,
  (NP Hadoop/NNP)
  ,/,
  (NP ability/NN work/NN)
  (NP big/JJ data/NNS)
  (NP traditional/JJ data/NNS)
  identified/VBN
  (NP various/JJ cases/NNS)
  (/(
  (NP Ekbia/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ;/:
  •/CC
  (NP Examining/NNP dependency/NN size/NN organisations/NNS)
  adopt/VBP
  (NP big/JJ data/NNS)
  (/(
  (NP Ekbia/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ;/:
  •/CC
  (NP Examining/NNP)
  (NP appropriate/JJ organisational/JJ models/NNS)
  creating/VBG
  appropriating/VBG
  (NP value/NN)
  (NP big/JJ data/NNS)
  (/(
  (NP Karpovsky/NNP Galliers/NNP)
  ,/,
  2015/CD
  ;/:
  (NP Ekbia/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2015/CD
  )/)
  ;/:
  •/CC
  (NP Further/NNP investigation/NN)
  two/CD
  (NP key/JJ issues/NNS)
  :/:
  1/CD
  )/)
  controlled/VBD
  (NP open/JJ big/JJ data/NNS access/NN data/NNS analytics/NNS)
  considered/VBD
  (NP competitive/JJ advantage/NN)
  ,/,
  (NP organisations/NNS)
  may/MD
  opposed/VBN
  exchanging/VBG
  (NP data/NNS)
  perceived/VBN
  (NP competitors/NNS)
  (/(
  (NP Jagadish/JJ et/NN al./NN)
  ,/,
  2014/CD
  )/)
  ;/:
  2/CD
  )/)
  minimising/VBG
  countering/VBG
  (NP social/JJ risks/NNS)
  (NP big/JJ data/NNS value/NN realisation/NN)
  (/(
  (NP Clarke/NNP)
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Several suggestions study', 'Sarah Al-Shiakhli', '• Work', 'big data business models', 'innovative approaches', 'development four-stage', 'big data maturity model', 'organisations', 'functional excellence', 'ability develop business model transformation', 'last stage', 'Relevant systems', 'Hadoop', 'ability work', 'big data', 'traditional data', 'various cases', 'Ekbia', 'Examining dependency size organisations', 'big data', 'Ekbia', 'Examining', 'appropriate organisational models', 'value', 'big data', 'Karpovsky Galliers', 'Ekbia', 'al.', 'Further investigation', 'key issues', 'open big data access data analytics', 'competitive advantage', 'organisations', 'data', 'competitors', 'Jagadish et al.', 'social risks', 'big data value realisation', 'Clarke']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('ORGANIZATION', 'Relevant'), ('GPE', 'Hadoop'), ('PERSON', 'Ekbia'), ('PERSON', 'Ekbia'), ('PERSON', 'Karpovsky Galliers'), ('GPE', 'Ekbia'), ('PERSON', 'Further'), ('GPE', 'Jagadish'), ('PERSON', 'Clarke')] 

>> Stemming using Porter Stemmer: 
 [('Several', 'sever'), ('suggestions', 'suggest'), ('study', 'studi'), ('also', 'also'), ('presented', 'present'), (':', ':'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('41', '41'), ('•', '•'), ('Work', 'work'), ('improving', 'improv'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('models', 'model'), ('innovative', 'innov'), ('approaches', 'approach'), (',', ','), ('development', 'develop'), ('four-stage', 'four-stag'), ('big', 'big'), ('data', 'data'), ('maturity', 'matur'), ('model', 'model'), (',', ','), ('allowing', 'allow'), ('organisations', 'organis'), ('reach', 'reach'), ('functional', 'function'), ('excellence', 'excel'), ('despite', 'despit'), ('ability', 'abil'), ('develop', 'develop'), ('business', 'busi'), ('model', 'model'), ('transformation', 'transform'), ('occurring', 'occur'), ('last', 'last'), ('stage', 'stage'), (';', ';'), ('•', '•'), ('Relevant', 'relev'), ('systems', 'system'), (',', ','), ('Hadoop', 'hadoop'), (',', ','), ('ability', 'abil'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('identified', 'identifi'), ('various', 'variou'), ('cases', 'case'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Examining', 'examin'), ('dependency', 'depend'), ('size', 'size'), ('organisations', 'organis'), ('adopt', 'adopt'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Examining', 'examin'), ('appropriate', 'appropri'), ('organisational', 'organis'), ('models', 'model'), ('creating', 'creat'), ('appropriating', 'appropri'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Karpovsky', 'karpovski'), ('Galliers', 'gallier'), (',', ','), ('2015', '2015'), (';', ';'), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Further', 'further'), ('investigation', 'investig'), ('two', 'two'), ('key', 'key'), ('issues', 'issu'), (':', ':'), ('1', '1'), (')', ')'), ('controlled', 'control'), ('open', 'open'), ('big', 'big'), ('data', 'data'), ('access', 'access'), ('data', 'data'), ('analytics', 'analyt'), ('considered', 'consid'), ('competitive', 'competit'), ('advantage', 'advantag'), (',', ','), ('organisations', 'organis'), ('may', 'may'), ('opposed', 'oppos'), ('exchanging', 'exchang'), ('data', 'data'), ('perceived', 'perceiv'), ('competitors', 'competitor'), ('(', '('), ('Jagadish', 'jagadish'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('2', '2'), (')', ')'), ('minimising', 'minimis'), ('countering', 'counter'), ('social', 'social'), ('risks', 'risk'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), ('(', '('), ('Clarke', 'clark'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Several', 'sever'), ('suggestions', 'suggest'), ('study', 'studi'), ('also', 'also'), ('presented', 'present'), (':', ':'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('41', '41'), ('•', '•'), ('Work', 'work'), ('improving', 'improv'), ('big', 'big'), ('data', 'data'), ('business', 'busi'), ('models', 'model'), ('innovative', 'innov'), ('approaches', 'approach'), (',', ','), ('development', 'develop'), ('four-stage', 'four-stag'), ('big', 'big'), ('data', 'data'), ('maturity', 'matur'), ('model', 'model'), (',', ','), ('allowing', 'allow'), ('organisations', 'organis'), ('reach', 'reach'), ('functional', 'function'), ('excellence', 'excel'), ('despite', 'despit'), ('ability', 'abil'), ('develop', 'develop'), ('business', 'busi'), ('model', 'model'), ('transformation', 'transform'), ('occurring', 'occur'), ('last', 'last'), ('stage', 'stage'), (';', ';'), ('•', '•'), ('Relevant', 'relev'), ('systems', 'system'), (',', ','), ('Hadoop', 'hadoop'), (',', ','), ('ability', 'abil'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('identified', 'identifi'), ('various', 'various'), ('cases', 'case'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Examining', 'examin'), ('dependency', 'depend'), ('size', 'size'), ('organisations', 'organis'), ('adopt', 'adopt'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Examining', 'examin'), ('appropriate', 'appropri'), ('organisational', 'organis'), ('models', 'model'), ('creating', 'creat'), ('appropriating', 'appropri'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Karpovsky', 'karpovski'), ('Galliers', 'gallier'), (',', ','), ('2015', '2015'), (';', ';'), ('Ekbia', 'ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Further', 'further'), ('investigation', 'investig'), ('two', 'two'), ('key', 'key'), ('issues', 'issu'), (':', ':'), ('1', '1'), (')', ')'), ('controlled', 'control'), ('open', 'open'), ('big', 'big'), ('data', 'data'), ('access', 'access'), ('data', 'data'), ('analytics', 'analyt'), ('considered', 'consid'), ('competitive', 'competit'), ('advantage', 'advantag'), (',', ','), ('organisations', 'organis'), ('may', 'may'), ('opposed', 'oppos'), ('exchanging', 'exchang'), ('data', 'data'), ('perceived', 'perceiv'), ('competitors', 'competitor'), ('(', '('), ('Jagadish', 'jagadish'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('2', '2'), (')', ')'), ('minimising', 'minimis'), ('countering', 'counter'), ('social', 'social'), ('risks', 'risk'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), ('(', '('), ('Clarke', 'clark'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Several', 'Several'), ('suggestions', 'suggestion'), ('study', 'study'), ('also', 'also'), ('presented', 'presented'), (':', ':'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('41', '41'), ('•', '•'), ('Work', 'Work'), ('improving', 'improving'), ('big', 'big'), ('data', 'data'), ('business', 'business'), ('models', 'model'), ('innovative', 'innovative'), ('approaches', 'approach'), (',', ','), ('development', 'development'), ('four-stage', 'four-stage'), ('big', 'big'), ('data', 'data'), ('maturity', 'maturity'), ('model', 'model'), (',', ','), ('allowing', 'allowing'), ('organisations', 'organisation'), ('reach', 'reach'), ('functional', 'functional'), ('excellence', 'excellence'), ('despite', 'despite'), ('ability', 'ability'), ('develop', 'develop'), ('business', 'business'), ('model', 'model'), ('transformation', 'transformation'), ('occurring', 'occurring'), ('last', 'last'), ('stage', 'stage'), (';', ';'), ('•', '•'), ('Relevant', 'Relevant'), ('systems', 'system'), (',', ','), ('Hadoop', 'Hadoop'), (',', ','), ('ability', 'ability'), ('work', 'work'), ('big', 'big'), ('data', 'data'), ('traditional', 'traditional'), ('data', 'data'), ('identified', 'identified'), ('various', 'various'), ('cases', 'case'), ('(', '('), ('Ekbia', 'Ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Examining', 'Examining'), ('dependency', 'dependency'), ('size', 'size'), ('organisations', 'organisation'), ('adopt', 'adopt'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Ekbia', 'Ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Examining', 'Examining'), ('appropriate', 'appropriate'), ('organisational', 'organisational'), ('models', 'model'), ('creating', 'creating'), ('appropriating', 'appropriating'), ('value', 'value'), ('big', 'big'), ('data', 'data'), ('(', '('), ('Karpovsky', 'Karpovsky'), ('Galliers', 'Galliers'), (',', ','), ('2015', '2015'), (';', ';'), ('Ekbia', 'Ekbia'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), (';', ';'), ('•', '•'), ('Further', 'Further'), ('investigation', 'investigation'), ('two', 'two'), ('key', 'key'), ('issues', 'issue'), (':', ':'), ('1', '1'), (')', ')'), ('controlled', 'controlled'), ('open', 'open'), ('big', 'big'), ('data', 'data'), ('access', 'access'), ('data', 'data'), ('analytics', 'analytics'), ('considered', 'considered'), ('competitive', 'competitive'), ('advantage', 'advantage'), (',', ','), ('organisations', 'organisation'), ('may', 'may'), ('opposed', 'opposed'), ('exchanging', 'exchanging'), ('data', 'data'), ('perceived', 'perceived'), ('competitors', 'competitor'), ('(', '('), ('Jagadish', 'Jagadish'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('2', '2'), (')', ')'), ('minimising', 'minimising'), ('countering', 'countering'), ('social', 'social'), ('risks', 'risk'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), ('(', '('), ('Clarke', 'Clarke'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 532 =============================

Figure 23: Summary of debates related to big data value realisation, adopted from (Günther et   al., 2017). 


>> Tokens are: 
 ['Figure', '23', ':', 'Summary', 'debates', 'related', 'big', 'data', 'value', 'realisation', ',', 'adopted', '(', 'Günther', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Figure', '23'), ('23', ':'), (':', 'Summary'), ('Summary', 'debates'), ('debates', 'related'), ('related', 'big'), ('big', 'data'), ('data', 'value'), ('value', 'realisation'), ('realisation', ','), (',', 'adopted'), ('adopted', '('), ('(', 'Günther'), ('Günther', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '23', ':'), ('23', ':', 'Summary'), (':', 'Summary', 'debates'), ('Summary', 'debates', 'related'), ('debates', 'related', 'big'), ('related', 'big', 'data'), ('big', 'data', 'value'), ('data', 'value', 'realisation'), ('value', 'realisation', ','), ('realisation', ',', 'adopted'), (',', 'adopted', '('), ('adopted', '(', 'Günther'), ('(', 'Günther', 'et'), ('Günther', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('23', 'CD'), (':', ':'), ('Summary', 'JJ'), ('debates', 'NNS'), ('related', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('value', 'NN'), ('realisation', 'NN'), (',', ','), ('adopted', 'VBN'), ('(', '('), ('Günther', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  23/CD
  :/:
  (NP Summary/JJ debates/NNS)
  related/VBN
  (NP big/JJ data/NNS value/NN realisation/NN)
  ,/,
  adopted/VBN
  (/(
  (NP Günther/NNP)
  et/RB
  al./RB
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Summary debates', 'big data value realisation', 'Günther']

>> Named Entities are: 
 [('PERSON', 'Günther')] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('23', '23'), (':', ':'), ('Summary', 'summari'), ('debates', 'debat'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Günther', 'günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('23', '23'), (':', ':'), ('Summary', 'summari'), ('debates', 'debat'), ('related', 'relat'), ('big', 'big'), ('data', 'data'), ('value', 'valu'), ('realisation', 'realis'), (',', ','), ('adopted', 'adopt'), ('(', '('), ('Günther', 'günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('23', '23'), (':', ':'), ('Summary', 'Summary'), ('debates', 'debate'), ('related', 'related'), ('big', 'big'), ('data', 'data'), ('value', 'value'), ('realisation', 'realisation'), (',', ','), ('adopted', 'adopted'), ('(', '('), ('Günther', 'Günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 533 =============================

Sarah Al-Shiakhli   42      10. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '42', '10', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '42'), ('42', '10'), ('10', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '42'), ('Al-Shiakhli', '42', '10'), ('42', '10', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('42', 'CD'), ('10', 'CD'), ('.', '.')]

 (S (NP Sarah/NNP Al-Shiakhli/NNP) 42/CD 10/CD ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('42', '42'), ('10', '10'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('42', '42'), ('10', '10'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('42', '42'), ('10', '10'), ('.', '.')]



============================ Sentence 534 =============================

Big data analytics applications   A recent survey (Nashua, 2017) highlighted the growth in the use of big data analytics in   companies. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'applications', 'A', 'recent', 'survey', '(', 'Nashua', ',', '2017', ')', 'highlighted', 'growth', 'use', 'big', 'data', 'analytics', 'companies', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', 'A'), ('A', 'recent'), ('recent', 'survey'), ('survey', '('), ('(', 'Nashua'), ('Nashua', ','), (',', '2017'), ('2017', ')'), (')', 'highlighted'), ('highlighted', 'growth'), ('growth', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'companies'), ('companies', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', 'A'), ('applications', 'A', 'recent'), ('A', 'recent', 'survey'), ('recent', 'survey', '('), ('survey', '(', 'Nashua'), ('(', 'Nashua', ','), ('Nashua', ',', '2017'), (',', '2017', ')'), ('2017', ')', 'highlighted'), (')', 'highlighted', 'growth'), ('highlighted', 'growth', 'use'), ('growth', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'companies'), ('analytics', 'companies', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('A', 'DT'), ('recent', 'JJ'), ('survey', 'NN'), ('(', '('), ('Nashua', 'NNP'), (',', ','), ('2017', 'CD'), (')', ')'), ('highlighted', 'VBD'), ('growth', 'NN'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('companies', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS applications/NNS)
  (NP A/DT recent/JJ survey/NN)
  (/(
  (NP Nashua/NNP)
  ,/,
  2017/CD
  )/)
  highlighted/VBD
  (NP growth/NN use/NN)
  (NP big/JJ data/NNS analytics/NNS companies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics applications', 'A recent survey', 'Nashua', 'growth use', 'big data analytics companies']

>> Named Entities are: 
 [('ORGANIZATION', 'Nashua')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('A', 'a'), ('recent', 'recent'), ('survey', 'survey'), ('(', '('), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (')', ')'), ('highlighted', 'highlight'), ('growth', 'growth'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('companies', 'compani'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('A', 'a'), ('recent', 'recent'), ('survey', 'survey'), ('(', '('), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (')', ')'), ('highlighted', 'highlight'), ('growth', 'growth'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('companies', 'compani'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('A', 'A'), ('recent', 'recent'), ('survey', 'survey'), ('(', '('), ('Nashua', 'Nashua'), (',', ','), ('2017', '2017'), (')', ')'), ('highlighted', 'highlighted'), ('growth', 'growth'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('companies', 'company'), ('.', '.')]



============================ Sentence 535 =============================

The study examined companies’ use of big data compared to the previous year in 2015,   2016, and 2017. 


>> Tokens are: 
 ['The', 'study', 'examined', 'companies', '’', 'use', 'big', 'data', 'compared', 'previous', 'year', '2015', ',', '2016', ',', '2017', '.']

>> Bigrams are: 
 [('The', 'study'), ('study', 'examined'), ('examined', 'companies'), ('companies', '’'), ('’', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'compared'), ('compared', 'previous'), ('previous', 'year'), ('year', '2015'), ('2015', ','), (',', '2016'), ('2016', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('The', 'study', 'examined'), ('study', 'examined', 'companies'), ('examined', 'companies', '’'), ('companies', '’', 'use'), ('’', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'compared'), ('data', 'compared', 'previous'), ('compared', 'previous', 'year'), ('previous', 'year', '2015'), ('year', '2015', ','), ('2015', ',', '2016'), (',', '2016', ','), ('2016', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('study', 'NN'), ('examined', 'VBD'), ('companies', 'NNS'), ('’', 'NNP'), ('use', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('compared', 'VBN'), ('previous', 'JJ'), ('year', 'NN'), ('2015', 'CD'), (',', ','), ('2016', 'CD'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP The/DT study/NN)
  examined/VBD
  (NP companies/NNS ’/NNP)
  use/VBP
  (NP big/JJ data/NNS)
  compared/VBN
  (NP previous/JJ year/NN)
  2015/CD
  ,/,
  2016/CD
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['The study', 'companies ’', 'big data', 'previous year']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('examined', 'examin'), ('companies', 'compani'), ('’', '’'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('compared', 'compar'), ('previous', 'previou'), ('year', 'year'), ('2015', '2015'), (',', ','), ('2016', '2016'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('study', 'studi'), ('examined', 'examin'), ('companies', 'compani'), ('’', '’'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('compared', 'compar'), ('previous', 'previous'), ('year', 'year'), ('2015', '2015'), (',', ','), ('2016', '2016'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('study', 'study'), ('examined', 'examined'), ('companies', 'company'), ('’', '’'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('compared', 'compared'), ('previous', 'previous'), ('year', 'year'), ('2015', '2015'), (',', ','), ('2016', '2016'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 536 =============================

The results indicated that over 50 percent of organisations were using big data by   2017 (Watson, 2019), as shown in Figure 24. 


>> Tokens are: 
 ['The', 'results', 'indicated', '50', 'percent', 'organisations', 'using', 'big', 'data', '2017', '(', 'Watson', ',', '2019', ')', ',', 'shown', 'Figure', '24', '.']

>> Bigrams are: 
 [('The', 'results'), ('results', 'indicated'), ('indicated', '50'), ('50', 'percent'), ('percent', 'organisations'), ('organisations', 'using'), ('using', 'big'), ('big', 'data'), ('data', '2017'), ('2017', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'shown'), ('shown', 'Figure'), ('Figure', '24'), ('24', '.')]

>> Trigrams are: 
 [('The', 'results', 'indicated'), ('results', 'indicated', '50'), ('indicated', '50', 'percent'), ('50', 'percent', 'organisations'), ('percent', 'organisations', 'using'), ('organisations', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', '2017'), ('data', '2017', '('), ('2017', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'shown'), (',', 'shown', 'Figure'), ('shown', 'Figure', '24'), ('Figure', '24', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('results', 'NNS'), ('indicated', 'VBD'), ('50', 'CD'), ('percent', 'NN'), ('organisations', 'NNS'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('2017', 'CD'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('shown', 'VBN'), ('Figure', 'NN'), ('24', 'CD'), ('.', '.')]

 (S
  (NP The/DT results/NNS)
  indicated/VBD
  50/CD
  (NP percent/NN organisations/NNS)
  using/VBG
  (NP big/JJ data/NNS)
  2017/CD
  (/(
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  ,/,
  shown/VBN
  (NP Figure/NN)
  24/CD
  ./.) 


>> Noun Phrases are: 
 ['The results', 'percent organisations', 'big data', 'Watson', 'Figure']

>> Named Entities are: 
 [('PERSON', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('results', 'result'), ('indicated', 'indic'), ('50', '50'), ('percent', 'percent'), ('organisations', 'organis'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('2017', '2017'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('results', 'result'), ('indicated', 'indic'), ('50', '50'), ('percent', 'percent'), ('organisations', 'organis'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('2017', '2017'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'figur'), ('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('results', 'result'), ('indicated', 'indicated'), ('50', '50'), ('percent', 'percent'), ('organisations', 'organisation'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('2017', '2017'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('shown', 'shown'), ('Figure', 'Figure'), ('24', '24'), ('.', '.')]



============================ Sentence 537 =============================

Figure 24: Adoption of Big Data from 2015 to 20173   The potential key resource of many organisations’ business models is thus big data where such   “business models are reflections of the realized strategy” (Casadesus-Masanell et al., 2010;   Günther et al., 2017). 


>> Tokens are: 
 ['Figure', '24', ':', 'Adoption', 'Big', 'Data', '2015', '20173', 'The', 'potential', 'key', 'resource', 'many', 'organisations', '’', 'business', 'models', 'thus', 'big', 'data', '“', 'business', 'models', 'reflections', 'realized', 'strategy', '”', '(', 'Casadesus-Masanell', 'et', 'al.', ',', '2010', ';', 'Günther', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Figure', '24'), ('24', ':'), (':', 'Adoption'), ('Adoption', 'Big'), ('Big', 'Data'), ('Data', '2015'), ('2015', '20173'), ('20173', 'The'), ('The', 'potential'), ('potential', 'key'), ('key', 'resource'), ('resource', 'many'), ('many', 'organisations'), ('organisations', '’'), ('’', 'business'), ('business', 'models'), ('models', 'thus'), ('thus', 'big'), ('big', 'data'), ('data', '“'), ('“', 'business'), ('business', 'models'), ('models', 'reflections'), ('reflections', 'realized'), ('realized', 'strategy'), ('strategy', '”'), ('”', '('), ('(', 'Casadesus-Masanell'), ('Casadesus-Masanell', 'et'), ('et', 'al.'), ('al.', ','), (',', '2010'), ('2010', ';'), (';', 'Günther'), ('Günther', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Figure', '24', ':'), ('24', ':', 'Adoption'), (':', 'Adoption', 'Big'), ('Adoption', 'Big', 'Data'), ('Big', 'Data', '2015'), ('Data', '2015', '20173'), ('2015', '20173', 'The'), ('20173', 'The', 'potential'), ('The', 'potential', 'key'), ('potential', 'key', 'resource'), ('key', 'resource', 'many'), ('resource', 'many', 'organisations'), ('many', 'organisations', '’'), ('organisations', '’', 'business'), ('’', 'business', 'models'), ('business', 'models', 'thus'), ('models', 'thus', 'big'), ('thus', 'big', 'data'), ('big', 'data', '“'), ('data', '“', 'business'), ('“', 'business', 'models'), ('business', 'models', 'reflections'), ('models', 'reflections', 'realized'), ('reflections', 'realized', 'strategy'), ('realized', 'strategy', '”'), ('strategy', '”', '('), ('”', '(', 'Casadesus-Masanell'), ('(', 'Casadesus-Masanell', 'et'), ('Casadesus-Masanell', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2010'), (',', '2010', ';'), ('2010', ';', 'Günther'), (';', 'Günther', 'et'), ('Günther', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Figure', 'NN'), ('24', 'CD'), (':', ':'), ('Adoption', 'NN'), ('Big', 'NNP'), ('Data', 'NNP'), ('2015', 'CD'), ('20173', 'CD'), ('The', 'DT'), ('potential', 'JJ'), ('key', 'NN'), ('resource', 'NN'), ('many', 'JJ'), ('organisations', 'NNS'), ('’', 'VBP'), ('business', 'NN'), ('models', 'NNS'), ('thus', 'RB'), ('big', 'JJ'), ('data', 'NNS'), ('“', 'NN'), ('business', 'NN'), ('models', 'NNS'), ('reflections', 'NNS'), ('realized', 'VBD'), ('strategy', 'NN'), ('”', 'NNP'), ('(', '('), ('Casadesus-Masanell', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2010', 'CD'), (';', ':'), ('Günther', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Figure/NN)
  24/CD
  :/:
  (NP Adoption/NN Big/NNP Data/NNP)
  2015/CD
  20173/CD
  (NP The/DT potential/JJ key/NN resource/NN)
  (NP many/JJ organisations/NNS)
  ’/VBP
  (NP business/NN models/NNS)
  thus/RB
  (NP big/JJ data/NNS “/NN business/NN models/NNS reflections/NNS)
  realized/VBD
  (NP strategy/NN ”/NNP)
  (/(
  (NP Casadesus-Masanell/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2010/CD
  ;/:
  (NP Günther/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Figure', 'Adoption Big Data', 'The potential key resource', 'many organisations', 'business models', 'big data “ business models reflections', 'strategy ”', 'Casadesus-Masanell', 'al.', 'Günther', 'al.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Figure', 'figur'), ('24', '24'), (':', ':'), ('Adoption', 'adopt'), ('Big', 'big'), ('Data', 'data'), ('2015', '2015'), ('20173', '20173'), ('The', 'the'), ('potential', 'potenti'), ('key', 'key'), ('resource', 'resourc'), ('many', 'mani'), ('organisations', 'organis'), ('’', '’'), ('business', 'busi'), ('models', 'model'), ('thus', 'thu'), ('big', 'big'), ('data', 'data'), ('“', '“'), ('business', 'busi'), ('models', 'model'), ('reflections', 'reflect'), ('realized', 'realiz'), ('strategy', 'strategi'), ('”', '”'), ('(', '('), ('Casadesus-Masanell', 'casadesus-masanel'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (';', ';'), ('Günther', 'günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Figure', 'figur'), ('24', '24'), (':', ':'), ('Adoption', 'adopt'), ('Big', 'big'), ('Data', 'data'), ('2015', '2015'), ('20173', '20173'), ('The', 'the'), ('potential', 'potenti'), ('key', 'key'), ('resource', 'resourc'), ('many', 'mani'), ('organisations', 'organis'), ('’', '’'), ('business', 'busi'), ('models', 'model'), ('thus', 'thus'), ('big', 'big'), ('data', 'data'), ('“', '“'), ('business', 'busi'), ('models', 'model'), ('reflections', 'reflect'), ('realized', 'realiz'), ('strategy', 'strategi'), ('”', '”'), ('(', '('), ('Casadesus-Masanell', 'casadesus-masanel'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (';', ';'), ('Günther', 'günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Figure', 'Figure'), ('24', '24'), (':', ':'), ('Adoption', 'Adoption'), ('Big', 'Big'), ('Data', 'Data'), ('2015', '2015'), ('20173', '20173'), ('The', 'The'), ('potential', 'potential'), ('key', 'key'), ('resource', 'resource'), ('many', 'many'), ('organisations', 'organisation'), ('’', '’'), ('business', 'business'), ('models', 'model'), ('thus', 'thus'), ('big', 'big'), ('data', 'data'), ('“', '“'), ('business', 'business'), ('models', 'model'), ('reflections', 'reflection'), ('realized', 'realized'), ('strategy', 'strategy'), ('”', '”'), ('(', '('), ('Casadesus-Masanell', 'Casadesus-Masanell'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (';', ';'), ('Günther', 'Günther'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 538 =============================

Business models represent the ability of the organisation to create and   appropriate value. 


>> Tokens are: 
 ['Business', 'models', 'represent', 'ability', 'organisation', 'create', 'appropriate', 'value', '.']

>> Bigrams are: 
 [('Business', 'models'), ('models', 'represent'), ('represent', 'ability'), ('ability', 'organisation'), ('organisation', 'create'), ('create', 'appropriate'), ('appropriate', 'value'), ('value', '.')]

>> Trigrams are: 
 [('Business', 'models', 'represent'), ('models', 'represent', 'ability'), ('represent', 'ability', 'organisation'), ('ability', 'organisation', 'create'), ('organisation', 'create', 'appropriate'), ('create', 'appropriate', 'value'), ('appropriate', 'value', '.')]

>> POS Tags are: 
 [('Business', 'NN'), ('models', 'NNS'), ('represent', 'VBP'), ('ability', 'NN'), ('organisation', 'NN'), ('create', 'NN'), ('appropriate', 'JJ'), ('value', 'NN'), ('.', '.')]

 (S
  (NP Business/NN models/NNS)
  represent/VBP
  (NP ability/NN organisation/NN create/NN)
  (NP appropriate/JJ value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Business models', 'ability organisation create', 'appropriate value']

>> Named Entities are: 
 [('GPE', 'Business')] 

>> Stemming using Porter Stemmer: 
 [('Business', 'busi'), ('models', 'model'), ('represent', 'repres'), ('ability', 'abil'), ('organisation', 'organis'), ('create', 'creat'), ('appropriate', 'appropri'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Business', 'busi'), ('models', 'model'), ('represent', 'repres'), ('ability', 'abil'), ('organisation', 'organis'), ('create', 'creat'), ('appropriate', 'appropri'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Business', 'Business'), ('models', 'model'), ('represent', 'represent'), ('ability', 'ability'), ('organisation', 'organisation'), ('create', 'create'), ('appropriate', 'appropriate'), ('value', 'value'), ('.', '.')]



============================ Sentence 539 =============================

Organisations must rethink their use of big data in relation to their business   models, using analytics to develop access to new data sources and techniques to improve efficiency   and effectiveness (Woerner et al., 2015). 


>> Tokens are: 
 ['Organisations', 'must', 'rethink', 'use', 'big', 'data', 'relation', 'business', 'models', ',', 'using', 'analytics', 'develop', 'access', 'new', 'data', 'sources', 'techniques', 'improve', 'efficiency', 'effectiveness', '(', 'Woerner', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('Organisations', 'must'), ('must', 'rethink'), ('rethink', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'relation'), ('relation', 'business'), ('business', 'models'), ('models', ','), (',', 'using'), ('using', 'analytics'), ('analytics', 'develop'), ('develop', 'access'), ('access', 'new'), ('new', 'data'), ('data', 'sources'), ('sources', 'techniques'), ('techniques', 'improve'), ('improve', 'efficiency'), ('efficiency', 'effectiveness'), ('effectiveness', '('), ('(', 'Woerner'), ('Woerner', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('Organisations', 'must', 'rethink'), ('must', 'rethink', 'use'), ('rethink', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'relation'), ('data', 'relation', 'business'), ('relation', 'business', 'models'), ('business', 'models', ','), ('models', ',', 'using'), (',', 'using', 'analytics'), ('using', 'analytics', 'develop'), ('analytics', 'develop', 'access'), ('develop', 'access', 'new'), ('access', 'new', 'data'), ('new', 'data', 'sources'), ('data', 'sources', 'techniques'), ('sources', 'techniques', 'improve'), ('techniques', 'improve', 'efficiency'), ('improve', 'efficiency', 'effectiveness'), ('efficiency', 'effectiveness', '('), ('effectiveness', '(', 'Woerner'), ('(', 'Woerner', 'et'), ('Woerner', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('must', 'MD'), ('rethink', 'VB'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('relation', 'NN'), ('business', 'NN'), ('models', 'NNS'), (',', ','), ('using', 'VBG'), ('analytics', 'NNS'), ('develop', 'VB'), ('access', 'NN'), ('new', 'JJ'), ('data', 'NNS'), ('sources', 'NNS'), ('techniques', 'NNS'), ('improve', 'VBP'), ('efficiency', 'NN'), ('effectiveness', 'NN'), ('(', '('), ('Woerner', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Organisations/NNS)
  must/MD
  rethink/VB
  (NP use/NN)
  (NP big/JJ data/NNS relation/NN business/NN models/NNS)
  ,/,
  using/VBG
  (NP analytics/NNS)
  develop/VB
  (NP access/NN)
  (NP new/JJ data/NNS sources/NNS techniques/NNS)
  improve/VBP
  (NP efficiency/NN effectiveness/NN)
  (/(
  (NP Woerner/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Organisations', 'use', 'big data relation business models', 'analytics', 'access', 'new data sources techniques', 'efficiency effectiveness', 'Woerner']

>> Named Entities are: 
 [('PERSON', 'Woerner')] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('must', 'must'), ('rethink', 'rethink'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('relation', 'relat'), ('business', 'busi'), ('models', 'model'), (',', ','), ('using', 'use'), ('analytics', 'analyt'), ('develop', 'develop'), ('access', 'access'), ('new', 'new'), ('data', 'data'), ('sources', 'sourc'), ('techniques', 'techniqu'), ('improve', 'improv'), ('efficiency', 'effici'), ('effectiveness', 'effect'), ('(', '('), ('Woerner', 'woerner'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('must', 'must'), ('rethink', 'rethink'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('relation', 'relat'), ('business', 'busi'), ('models', 'model'), (',', ','), ('using', 'use'), ('analytics', 'analyt'), ('develop', 'develop'), ('access', 'access'), ('new', 'new'), ('data', 'data'), ('sources', 'sourc'), ('techniques', 'techniqu'), ('improve', 'improv'), ('efficiency', 'effici'), ('effectiveness', 'effect'), ('(', '('), ('Woerner', 'woerner'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('must', 'must'), ('rethink', 'rethink'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('relation', 'relation'), ('business', 'business'), ('models', 'model'), (',', ','), ('using', 'using'), ('analytics', 'analytics'), ('develop', 'develop'), ('access', 'access'), ('new', 'new'), ('data', 'data'), ('sources', 'source'), ('techniques', 'technique'), ('improve', 'improve'), ('efficiency', 'efficiency'), ('effectiveness', 'effectiveness'), ('(', '('), ('Woerner', 'Woerner'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 540 =============================

Grover et al. 


>> Tokens are: 
 ['Grover', 'et', 'al', '.']

>> Bigrams are: 
 [('Grover', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Grover', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S (NP Grover/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Grover', 'al']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 541 =============================

(2018) argued that to achieve strategic business value from big data, significant   investment in both infrastructure and analytic technologies are required to enable skilled analysis   and strategic positioning. 


>> Tokens are: 
 ['(', '2018', ')', 'argued', 'achieve', 'strategic', 'business', 'value', 'big', 'data', ',', 'significant', 'investment', 'infrastructure', 'analytic', 'technologies', 'required', 'enable', 'skilled', 'analysis', 'strategic', 'positioning', '.']

>> Bigrams are: 
 [('(', '2018'), ('2018', ')'), (')', 'argued'), ('argued', 'achieve'), ('achieve', 'strategic'), ('strategic', 'business'), ('business', 'value'), ('value', 'big'), ('big', 'data'), ('data', ','), (',', 'significant'), ('significant', 'investment'), ('investment', 'infrastructure'), ('infrastructure', 'analytic'), ('analytic', 'technologies'), ('technologies', 'required'), ('required', 'enable'), ('enable', 'skilled'), ('skilled', 'analysis'), ('analysis', 'strategic'), ('strategic', 'positioning'), ('positioning', '.')]

>> Trigrams are: 
 [('(', '2018', ')'), ('2018', ')', 'argued'), (')', 'argued', 'achieve'), ('argued', 'achieve', 'strategic'), ('achieve', 'strategic', 'business'), ('strategic', 'business', 'value'), ('business', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'significant'), (',', 'significant', 'investment'), ('significant', 'investment', 'infrastructure'), ('investment', 'infrastructure', 'analytic'), ('infrastructure', 'analytic', 'technologies'), ('analytic', 'technologies', 'required'), ('technologies', 'required', 'enable'), ('required', 'enable', 'skilled'), ('enable', 'skilled', 'analysis'), ('skilled', 'analysis', 'strategic'), ('analysis', 'strategic', 'positioning'), ('strategic', 'positioning', '.')]

>> POS Tags are: 
 [('(', '('), ('2018', 'CD'), (')', ')'), ('argued', 'VBD'), ('achieve', 'JJ'), ('strategic', 'JJ'), ('business', 'NN'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('significant', 'JJ'), ('investment', 'NN'), ('infrastructure', 'NN'), ('analytic', 'JJ'), ('technologies', 'NNS'), ('required', 'VBN'), ('enable', 'JJ'), ('skilled', 'JJ'), ('analysis', 'NN'), ('strategic', 'JJ'), ('positioning', 'NN'), ('.', '.')]

 (S
  (/(
  2018/CD
  )/)
  argued/VBD
  (NP achieve/JJ strategic/JJ business/NN value/NN)
  (NP big/JJ data/NNS)
  ,/,
  (NP significant/JJ investment/NN infrastructure/NN)
  (NP analytic/JJ technologies/NNS)
  required/VBN
  (NP enable/JJ skilled/JJ analysis/NN)
  (NP strategic/JJ positioning/NN)
  ./.) 


>> Noun Phrases are: 
 ['achieve strategic business value', 'big data', 'significant investment infrastructure', 'analytic technologies', 'enable skilled analysis', 'strategic positioning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu'), ('achieve', 'achiev'), ('strategic', 'strateg'), ('business', 'busi'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), (',', ','), ('significant', 'signific'), ('investment', 'invest'), ('infrastructure', 'infrastructur'), ('analytic', 'analyt'), ('technologies', 'technolog'), ('required', 'requir'), ('enable', 'enabl'), ('skilled', 'skill'), ('analysis', 'analysi'), ('strategic', 'strateg'), ('positioning', 'posit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argu'), ('achieve', 'achiev'), ('strategic', 'strateg'), ('business', 'busi'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), (',', ','), ('significant', 'signific'), ('investment', 'invest'), ('infrastructure', 'infrastructur'), ('analytic', 'analyt'), ('technologies', 'technolog'), ('required', 'requir'), ('enable', 'enabl'), ('skilled', 'skill'), ('analysis', 'analysi'), ('strategic', 'strateg'), ('positioning', 'posit'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2018', '2018'), (')', ')'), ('argued', 'argued'), ('achieve', 'achieve'), ('strategic', 'strategic'), ('business', 'business'), ('value', 'value'), ('big', 'big'), ('data', 'data'), (',', ','), ('significant', 'significant'), ('investment', 'investment'), ('infrastructure', 'infrastructure'), ('analytic', 'analytic'), ('technologies', 'technology'), ('required', 'required'), ('enable', 'enable'), ('skilled', 'skilled'), ('analysis', 'analysis'), ('strategic', 'strategic'), ('positioning', 'positioning'), ('.', '.')]



============================ Sentence 542 =============================

Businesses thus need to access cutting edge tools and hire data-savvy   people who understand the relevant technologies. 


>> Tokens are: 
 ['Businesses', 'thus', 'need', 'access', 'cutting', 'edge', 'tools', 'hire', 'data-savvy', 'people', 'understand', 'relevant', 'technologies', '.']

>> Bigrams are: 
 [('Businesses', 'thus'), ('thus', 'need'), ('need', 'access'), ('access', 'cutting'), ('cutting', 'edge'), ('edge', 'tools'), ('tools', 'hire'), ('hire', 'data-savvy'), ('data-savvy', 'people'), ('people', 'understand'), ('understand', 'relevant'), ('relevant', 'technologies'), ('technologies', '.')]

>> Trigrams are: 
 [('Businesses', 'thus', 'need'), ('thus', 'need', 'access'), ('need', 'access', 'cutting'), ('access', 'cutting', 'edge'), ('cutting', 'edge', 'tools'), ('edge', 'tools', 'hire'), ('tools', 'hire', 'data-savvy'), ('hire', 'data-savvy', 'people'), ('data-savvy', 'people', 'understand'), ('people', 'understand', 'relevant'), ('understand', 'relevant', 'technologies'), ('relevant', 'technologies', '.')]

>> POS Tags are: 
 [('Businesses', 'NNS'), ('thus', 'RB'), ('need', 'VBP'), ('access', 'NN'), ('cutting', 'VBG'), ('edge', 'NN'), ('tools', 'NNS'), ('hire', 'VB'), ('data-savvy', 'JJ'), ('people', 'NNS'), ('understand', 'VBP'), ('relevant', 'JJ'), ('technologies', 'NNS'), ('.', '.')]

 (S
  (NP Businesses/NNS)
  thus/RB
  need/VBP
  (NP access/NN)
  cutting/VBG
  (NP edge/NN tools/NNS)
  hire/VB
  (NP data-savvy/JJ people/NNS)
  understand/VBP
  (NP relevant/JJ technologies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Businesses', 'access', 'edge tools', 'data-savvy people', 'relevant technologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Businesses', 'busi'), ('thus', 'thu'), ('need', 'need'), ('access', 'access'), ('cutting', 'cut'), ('edge', 'edg'), ('tools', 'tool'), ('hire', 'hire'), ('data-savvy', 'data-savvi'), ('people', 'peopl'), ('understand', 'understand'), ('relevant', 'relev'), ('technologies', 'technolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Businesses', 'busi'), ('thus', 'thus'), ('need', 'need'), ('access', 'access'), ('cutting', 'cut'), ('edge', 'edg'), ('tools', 'tool'), ('hire', 'hire'), ('data-savvy', 'data-savvi'), ('people', 'peopl'), ('understand', 'understand'), ('relevant', 'relev'), ('technologies', 'technolog'), ('.', '.')]

>> Lemmatization: 
 [('Businesses', 'Businesses'), ('thus', 'thus'), ('need', 'need'), ('access', 'access'), ('cutting', 'cutting'), ('edge', 'edge'), ('tools', 'tool'), ('hire', 'hire'), ('data-savvy', 'data-savvy'), ('people', 'people'), ('understand', 'understand'), ('relevant', 'relevant'), ('technologies', 'technology'), ('.', '.')]



============================ Sentence 543 =============================

Watson (2014) wrote a paper about big data analytics which was published by the association for   information systems (CAIS). 


>> Tokens are: 
 ['Watson', '(', '2014', ')', 'wrote', 'paper', 'big', 'data', 'analytics', 'published', 'association', 'information', 'systems', '(', 'CAIS', ')', '.']

>> Bigrams are: 
 [('Watson', '('), ('(', '2014'), ('2014', ')'), (')', 'wrote'), ('wrote', 'paper'), ('paper', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'published'), ('published', 'association'), ('association', 'information'), ('information', 'systems'), ('systems', '('), ('(', 'CAIS'), ('CAIS', ')'), (')', '.')]

>> Trigrams are: 
 [('Watson', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'wrote'), (')', 'wrote', 'paper'), ('wrote', 'paper', 'big'), ('paper', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'published'), ('analytics', 'published', 'association'), ('published', 'association', 'information'), ('association', 'information', 'systems'), ('information', 'systems', '('), ('systems', '(', 'CAIS'), ('(', 'CAIS', ')'), ('CAIS', ')', '.')]

>> POS Tags are: 
 [('Watson', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('wrote', 'VBD'), ('paper', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('published', 'VBN'), ('association', 'NN'), ('information', 'NN'), ('systems', 'NNS'), ('(', '('), ('CAIS', 'NNP'), (')', ')'), ('.', '.')]

 (S
  (NP Watson/NNP)
  (/(
  2014/CD
  )/)
  wrote/VBD
  (NP paper/NN)
  (NP big/JJ data/NNS analytics/NNS)
  published/VBN
  (NP association/NN information/NN systems/NNS)
  (/(
  (NP CAIS/NNP)
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Watson', 'paper', 'big data analytics', 'association information systems', 'CAIS']

>> Named Entities are: 
 [('GPE', 'Watson'), ('ORGANIZATION', 'CAIS')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2014', '2014'), (')', ')'), ('wrote', 'wrote'), ('paper', 'paper'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('published', 'publish'), ('association', 'associ'), ('information', 'inform'), ('systems', 'system'), ('(', '('), ('CAIS', 'cai'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), ('(', '('), ('2014', '2014'), (')', ')'), ('wrote', 'wrote'), ('paper', 'paper'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('published', 'publish'), ('association', 'associ'), ('information', 'inform'), ('systems', 'system'), ('(', '('), ('CAIS', 'cai'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Watson', 'Watson'), ('(', '('), ('2014', '2014'), (')', ')'), ('wrote', 'wrote'), ('paper', 'paper'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('published', 'published'), ('association', 'association'), ('information', 'information'), ('systems', 'system'), ('(', '('), ('CAIS', 'CAIS'), (')', ')'), ('.', '.')]



============================ Sentence 544 =============================

That paper showed the advances in technologies, applications, and   the impact of big data analytics at that time. 


>> Tokens are: 
 ['That', 'paper', 'showed', 'advances', 'technologies', ',', 'applications', ',', 'impact', 'big', 'data', 'analytics', 'time', '.']

>> Bigrams are: 
 [('That', 'paper'), ('paper', 'showed'), ('showed', 'advances'), ('advances', 'technologies'), ('technologies', ','), (',', 'applications'), ('applications', ','), (',', 'impact'), ('impact', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'time'), ('time', '.')]

>> Trigrams are: 
 [('That', 'paper', 'showed'), ('paper', 'showed', 'advances'), ('showed', 'advances', 'technologies'), ('advances', 'technologies', ','), ('technologies', ',', 'applications'), (',', 'applications', ','), ('applications', ',', 'impact'), (',', 'impact', 'big'), ('impact', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'time'), ('analytics', 'time', '.')]

>> POS Tags are: 
 [('That', 'DT'), ('paper', 'NN'), ('showed', 'VBD'), ('advances', 'NNS'), ('technologies', 'NNS'), (',', ','), ('applications', 'NNS'), (',', ','), ('impact', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('time', 'NN'), ('.', '.')]

 (S
  (NP That/DT paper/NN)
  showed/VBD
  (NP advances/NNS technologies/NNS)
  ,/,
  (NP applications/NNS)
  ,/,
  (NP impact/NN)
  (NP big/JJ data/NNS analytics/NNS time/NN)
  ./.) 


>> Noun Phrases are: 
 ['That paper', 'advances technologies', 'applications', 'impact', 'big data analytics time']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('That', 'that'), ('paper', 'paper'), ('showed', 'show'), ('advances', 'advanc'), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), (',', ','), ('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('time', 'time'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('That', 'that'), ('paper', 'paper'), ('showed', 'show'), ('advances', 'advanc'), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), (',', ','), ('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('time', 'time'), ('.', '.')]

>> Lemmatization: 
 [('That', 'That'), ('paper', 'paper'), ('showed', 'showed'), ('advances', 'advance'), ('technologies', 'technology'), (',', ','), ('applications', 'application'), (',', ','), ('impact', 'impact'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('time', 'time'), ('.', '.')]



============================ Sentence 545 =============================

In 2019, the same researcher (Watson, 2019)   highlighted several important recent developments in big data analytics including                                                      3 Adopted from (Dresner Advisory Services, 2017; Nashua, 2017; Watson, 2019     Sarah Al-Shiakhli   43      ➢ Continued adoption of the big data analytics,  ➢ Growth in the number of big data applications,  ➢ Development of the Hadoop ecosystem technology,  ➢ Data lakes,  ➢ Advanced analytics models, and  ➢ Algorithmic transparency principles. 


>> Tokens are: 
 ['In', '2019', ',', 'researcher', '(', 'Watson', ',', '2019', ')', 'highlighted', 'several', 'important', 'recent', 'developments', 'big', 'data', 'analytics', 'including', '3', 'Adopted', '(', 'Dresner', 'Advisory', 'Services', ',', '2017', ';', 'Nashua', ',', '2017', ';', 'Watson', ',', '2019', 'Sarah', 'Al-Shiakhli', '43', '➢', 'Continued', 'adoption', 'big', 'data', 'analytics', ',', '➢', 'Growth', 'number', 'big', 'data', 'applications', ',', '➢', 'Development', 'Hadoop', 'ecosystem', 'technology', ',', '➢', 'Data', 'lakes', ',', '➢', 'Advanced', 'analytics', 'models', ',', '➢', 'Algorithmic', 'transparency', 'principles', '.']

>> Bigrams are: 
 [('In', '2019'), ('2019', ','), (',', 'researcher'), ('researcher', '('), ('(', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', ')'), (')', 'highlighted'), ('highlighted', 'several'), ('several', 'important'), ('important', 'recent'), ('recent', 'developments'), ('developments', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'including'), ('including', '3'), ('3', 'Adopted'), ('Adopted', '('), ('(', 'Dresner'), ('Dresner', 'Advisory'), ('Advisory', 'Services'), ('Services', ','), (',', '2017'), ('2017', ';'), (';', 'Nashua'), ('Nashua', ','), (',', '2017'), ('2017', ';'), (';', 'Watson'), ('Watson', ','), (',', '2019'), ('2019', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '43'), ('43', '➢'), ('➢', 'Continued'), ('Continued', 'adoption'), ('adoption', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', '➢'), ('➢', 'Growth'), ('Growth', 'number'), ('number', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', ','), (',', '➢'), ('➢', 'Development'), ('Development', 'Hadoop'), ('Hadoop', 'ecosystem'), ('ecosystem', 'technology'), ('technology', ','), (',', '➢'), ('➢', 'Data'), ('Data', 'lakes'), ('lakes', ','), (',', '➢'), ('➢', 'Advanced'), ('Advanced', 'analytics'), ('analytics', 'models'), ('models', ','), (',', '➢'), ('➢', 'Algorithmic'), ('Algorithmic', 'transparency'), ('transparency', 'principles'), ('principles', '.')]

>> Trigrams are: 
 [('In', '2019', ','), ('2019', ',', 'researcher'), (',', 'researcher', '('), ('researcher', '(', 'Watson'), ('(', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', ')'), ('2019', ')', 'highlighted'), (')', 'highlighted', 'several'), ('highlighted', 'several', 'important'), ('several', 'important', 'recent'), ('important', 'recent', 'developments'), ('recent', 'developments', 'big'), ('developments', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'including'), ('analytics', 'including', '3'), ('including', '3', 'Adopted'), ('3', 'Adopted', '('), ('Adopted', '(', 'Dresner'), ('(', 'Dresner', 'Advisory'), ('Dresner', 'Advisory', 'Services'), ('Advisory', 'Services', ','), ('Services', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Nashua'), (';', 'Nashua', ','), ('Nashua', ',', '2017'), (',', '2017', ';'), ('2017', ';', 'Watson'), (';', 'Watson', ','), ('Watson', ',', '2019'), (',', '2019', 'Sarah'), ('2019', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '43'), ('Al-Shiakhli', '43', '➢'), ('43', '➢', 'Continued'), ('➢', 'Continued', 'adoption'), ('Continued', 'adoption', 'big'), ('adoption', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', '➢'), (',', '➢', 'Growth'), ('➢', 'Growth', 'number'), ('Growth', 'number', 'big'), ('number', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', ','), ('applications', ',', '➢'), (',', '➢', 'Development'), ('➢', 'Development', 'Hadoop'), ('Development', 'Hadoop', 'ecosystem'), ('Hadoop', 'ecosystem', 'technology'), ('ecosystem', 'technology', ','), ('technology', ',', '➢'), (',', '➢', 'Data'), ('➢', 'Data', 'lakes'), ('Data', 'lakes', ','), ('lakes', ',', '➢'), (',', '➢', 'Advanced'), ('➢', 'Advanced', 'analytics'), ('Advanced', 'analytics', 'models'), ('analytics', 'models', ','), ('models', ',', '➢'), (',', '➢', 'Algorithmic'), ('➢', 'Algorithmic', 'transparency'), ('Algorithmic', 'transparency', 'principles'), ('transparency', 'principles', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('2019', 'CD'), (',', ','), ('researcher', 'NN'), ('(', '('), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('highlighted', 'VBD'), ('several', 'JJ'), ('important', 'JJ'), ('recent', 'JJ'), ('developments', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('including', 'VBG'), ('3', 'CD'), ('Adopted', 'NNP'), ('(', '('), ('Dresner', 'NNP'), ('Advisory', 'NNP'), ('Services', 'NNPS'), (',', ','), ('2017', 'CD'), (';', ':'), ('Nashua', 'NNP'), (',', ','), ('2017', 'CD'), (';', ':'), ('Watson', 'NNP'), (',', ','), ('2019', 'CD'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('43', 'CD'), ('➢', 'NNP'), ('Continued', 'NNP'), ('adoption', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('➢', 'NNP'), ('Growth', 'NNP'), ('number', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), (',', ','), ('➢', 'NNP'), ('Development', 'NNP'), ('Hadoop', 'NNP'), ('ecosystem', 'NN'), ('technology', 'NN'), (',', ','), ('➢', 'NNP'), ('Data', 'NNP'), ('lakes', 'NNS'), (',', ','), ('➢', 'NNP'), ('Advanced', 'NNP'), ('analytics', 'NNS'), ('models', 'NNS'), (',', ','), ('➢', 'JJ'), ('Algorithmic', 'NNP'), ('transparency', 'NN'), ('principles', 'NNS'), ('.', '.')]

 (S
  In/IN
  2019/CD
  ,/,
  (NP researcher/NN)
  (/(
  (NP Watson/NNP)
  ,/,
  2019/CD
  )/)
  highlighted/VBD
  (NP several/JJ important/JJ recent/JJ developments/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  including/VBG
  3/CD
  (NP Adopted/NNP)
  (/(
  (NP Dresner/NNP Advisory/NNP)
  Services/NNPS
  ,/,
  2017/CD
  ;/:
  (NP Nashua/NNP)
  ,/,
  2017/CD
  ;/:
  (NP Watson/NNP)
  ,/,
  2019/CD
  (NP Sarah/NNP Al-Shiakhli/NNP)
  43/CD
  (NP ➢/NNP Continued/NNP adoption/NN)
  (NP big/JJ data/NN analytics/NNS)
  ,/,
  (NP ➢/NNP Growth/NNP number/NN)
  (NP big/JJ data/NNS applications/NNS)
  ,/,
  (NP ➢/NNP Development/NNP Hadoop/NNP ecosystem/NN technology/NN)
  ,/,
  (NP ➢/NNP Data/NNP lakes/NNS)
  ,/,
  (NP ➢/NNP Advanced/NNP analytics/NNS models/NNS)
  ,/,
  (NP ➢/JJ Algorithmic/NNP transparency/NN principles/NNS)
  ./.) 


>> Noun Phrases are: 
 ['researcher', 'Watson', 'several important recent developments', 'big data analytics', 'Adopted', 'Dresner Advisory', 'Nashua', 'Watson', 'Sarah Al-Shiakhli', '➢ Continued adoption', 'big data analytics', '➢ Growth number', 'big data applications', '➢ Development Hadoop ecosystem technology', '➢ Data lakes', '➢ Advanced analytics models', '➢ Algorithmic transparency principles']

>> Named Entities are: 
 [('PERSON', 'Watson'), ('GPE', 'Adopted'), ('ORGANIZATION', 'Dresner Advisory Services'), ('GPE', 'Nashua'), ('PERSON', 'Watson'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('2019', '2019'), (',', ','), ('researcher', 'research'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('highlighted', 'highlight'), ('several', 'sever'), ('important', 'import'), ('recent', 'recent'), ('developments', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('including', 'includ'), ('3', '3'), ('Adopted', 'adopt'), ('(', '('), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), (',', ','), ('2017', '2017'), (';', ';'), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('43', '43'), ('➢', '➢'), ('Continued', 'continu'), ('adoption', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('➢', '➢'), ('Growth', 'growth'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('➢', '➢'), ('Development', 'develop'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('technology', 'technolog'), (',', ','), ('➢', '➢'), ('Data', 'data'), ('lakes', 'lake'), (',', ','), ('➢', '➢'), ('Advanced', 'advanc'), ('analytics', 'analyt'), ('models', 'model'), (',', ','), ('➢', '➢'), ('Algorithmic', 'algorithm'), ('transparency', 'transpar'), ('principles', 'principl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('2019', '2019'), (',', ','), ('researcher', 'research'), ('(', '('), ('Watson', 'watson'), (',', ','), ('2019', '2019'), (')', ')'), ('highlighted', 'highlight'), ('several', 'sever'), ('important', 'import'), ('recent', 'recent'), ('developments', 'develop'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('including', 'includ'), ('3', '3'), ('Adopted', 'adopt'), ('(', '('), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), (',', ','), ('2017', '2017'), (';', ';'), ('Nashua', 'nashua'), (',', ','), ('2017', '2017'), (';', ';'), ('Watson', 'watson'), (',', ','), ('2019', '2019'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('43', '43'), ('➢', '➢'), ('Continued', 'continu'), ('adoption', 'adopt'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('➢', '➢'), ('Growth', 'growth'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), (',', ','), ('➢', '➢'), ('Development', 'develop'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('technology', 'technolog'), (',', ','), ('➢', '➢'), ('Data', 'data'), ('lakes', 'lake'), (',', ','), ('➢', '➢'), ('Advanced', 'advanc'), ('analytics', 'analyt'), ('models', 'model'), (',', ','), ('➢', '➢'), ('Algorithmic', 'algorithm'), ('transparency', 'transpar'), ('principles', 'principl'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('2019', '2019'), (',', ','), ('researcher', 'researcher'), ('(', '('), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), (')', ')'), ('highlighted', 'highlighted'), ('several', 'several'), ('important', 'important'), ('recent', 'recent'), ('developments', 'development'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('including', 'including'), ('3', '3'), ('Adopted', 'Adopted'), ('(', '('), ('Dresner', 'Dresner'), ('Advisory', 'Advisory'), ('Services', 'Services'), (',', ','), ('2017', '2017'), (';', ';'), ('Nashua', 'Nashua'), (',', ','), ('2017', '2017'), (';', ';'), ('Watson', 'Watson'), (',', ','), ('2019', '2019'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('43', '43'), ('➢', '➢'), ('Continued', 'Continued'), ('adoption', 'adoption'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('➢', '➢'), ('Growth', 'Growth'), ('number', 'number'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), (',', ','), ('➢', '➢'), ('Development', 'Development'), ('Hadoop', 'Hadoop'), ('ecosystem', 'ecosystem'), ('technology', 'technology'), (',', ','), ('➢', '➢'), ('Data', 'Data'), ('lakes', 'lake'), (',', ','), ('➢', '➢'), ('Advanced', 'Advanced'), ('analytics', 'analytics'), ('models', 'model'), (',', ','), ('➢', '➢'), ('Algorithmic', 'Algorithmic'), ('transparency', 'transparency'), ('principles', 'principle'), ('.', '.')]



============================ Sentence 546 =============================

Big data analytics has the potential to be applied to demand forecasting, analysing potential needs   based on previous work used to classify analytics techniques (Hofmann et al., 2018). 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'potential', 'applied', 'demand', 'forecasting', ',', 'analysing', 'potential', 'needs', 'based', 'previous', 'work', 'used', 'classify', 'analytics', 'techniques', '(', 'Hofmann', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'potential'), ('potential', 'applied'), ('applied', 'demand'), ('demand', 'forecasting'), ('forecasting', ','), (',', 'analysing'), ('analysing', 'potential'), ('potential', 'needs'), ('needs', 'based'), ('based', 'previous'), ('previous', 'work'), ('work', 'used'), ('used', 'classify'), ('classify', 'analytics'), ('analytics', 'techniques'), ('techniques', '('), ('(', 'Hofmann'), ('Hofmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'potential'), ('analytics', 'potential', 'applied'), ('potential', 'applied', 'demand'), ('applied', 'demand', 'forecasting'), ('demand', 'forecasting', ','), ('forecasting', ',', 'analysing'), (',', 'analysing', 'potential'), ('analysing', 'potential', 'needs'), ('potential', 'needs', 'based'), ('needs', 'based', 'previous'), ('based', 'previous', 'work'), ('previous', 'work', 'used'), ('work', 'used', 'classify'), ('used', 'classify', 'analytics'), ('classify', 'analytics', 'techniques'), ('analytics', 'techniques', '('), ('techniques', '(', 'Hofmann'), ('(', 'Hofmann', 'et'), ('Hofmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('potential', 'JJ'), ('applied', 'JJ'), ('demand', 'NN'), ('forecasting', 'NN'), (',', ','), ('analysing', 'VBG'), ('potential', 'JJ'), ('needs', 'NNS'), ('based', 'VBN'), ('previous', 'JJ'), ('work', 'NN'), ('used', 'VBN'), ('classify', 'VB'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('(', '('), ('Hofmann', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  (NP potential/JJ applied/JJ demand/NN forecasting/NN)
  ,/,
  analysing/VBG
  (NP potential/JJ needs/NNS)
  based/VBN
  (NP previous/JJ work/NN)
  used/VBN
  classify/VB
  (NP analytics/NNS techniques/NNS)
  (/(
  (NP Hofmann/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'potential applied demand forecasting', 'potential needs', 'previous work', 'analytics techniques', 'Hofmann']

>> Named Entities are: 
 [('PERSON', 'Hofmann')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('potential', 'potenti'), ('applied', 'appli'), ('demand', 'demand'), ('forecasting', 'forecast'), (',', ','), ('analysing', 'analys'), ('potential', 'potenti'), ('needs', 'need'), ('based', 'base'), ('previous', 'previou'), ('work', 'work'), ('used', 'use'), ('classify', 'classifi'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('potential', 'potenti'), ('applied', 'appli'), ('demand', 'demand'), ('forecasting', 'forecast'), (',', ','), ('analysing', 'analys'), ('potential', 'potenti'), ('needs', 'need'), ('based', 'base'), ('previous', 'previous'), ('work', 'work'), ('used', 'use'), ('classify', 'classifi'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('potential', 'potential'), ('applied', 'applied'), ('demand', 'demand'), ('forecasting', 'forecasting'), (',', ','), ('analysing', 'analysing'), ('potential', 'potential'), ('needs', 'need'), ('based', 'based'), ('previous', 'previous'), ('work', 'work'), ('used', 'used'), ('classify', 'classify'), ('analytics', 'analytics'), ('techniques', 'technique'), ('(', '('), ('Hofmann', 'Hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 547 =============================

Big data analytics have also been applied in many areas, serving different sectors. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'also', 'applied', 'many', 'areas', ',', 'serving', 'different', 'sectors', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'applied'), ('applied', 'many'), ('many', 'areas'), ('areas', ','), (',', 'serving'), ('serving', 'different'), ('different', 'sectors'), ('sectors', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'applied'), ('also', 'applied', 'many'), ('applied', 'many', 'areas'), ('many', 'areas', ','), ('areas', ',', 'serving'), (',', 'serving', 'different'), ('serving', 'different', 'sectors'), ('different', 'sectors', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('applied', 'VBD'), ('many', 'JJ'), ('areas', 'NNS'), (',', ','), ('serving', 'VBG'), ('different', 'JJ'), ('sectors', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  also/RB
  applied/VBD
  (NP many/JJ areas/NNS)
  ,/,
  serving/VBG
  (NP different/JJ sectors/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'many areas', 'different sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('applied', 'appli'), ('many', 'mani'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('applied', 'appli'), ('many', 'mani'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('applied', 'applied'), ('many', 'many'), ('areas', 'area'), (',', ','), ('serving', 'serving'), ('different', 'different'), ('sectors', 'sector'), ('.', '.')]



============================ Sentence 548 =============================

Some big data analytics applications:   10.1. 


>> Tokens are: 
 ['Some', 'big', 'data', 'analytics', 'applications', ':', '10.1', '.']

>> Bigrams are: 
 [('Some', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', ':'), (':', '10.1'), ('10.1', '.')]

>> Trigrams are: 
 [('Some', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', ':'), ('applications', ':', '10.1'), (':', '10.1', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), (':', ':'), ('10.1', 'CD'), ('.', '.')]

 (S
  (NP Some/DT big/JJ data/NNS analytics/NNS applications/NNS)
  :/:
  10.1/CD
  ./.) 


>> Noun Phrases are: 
 ['Some big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), (':', ':'), ('10.1', '10.1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), (':', ':'), ('10.1', '10.1'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), (':', ':'), ('10.1', '10.1'), ('.', '.')]



============================ Sentence 549 =============================

Healthcare    Research by Manyika (2011) showed that big data might help in reducing waste and improving   efficiency in clinical operations, research and development, and public health by means of   • statistical tools and algorithms;   • predictive modelling to produce new drugs and devices more quickly;   • analysing records of diseases to improve epidemiology (Elgendy, N. and Elragal, A.,  2014);   • allowing faster development of vaccines; and   • identifying the data relevant to provide services and prevent crises. 


>> Tokens are: 
 ['Healthcare', 'Research', 'Manyika', '(', '2011', ')', 'showed', 'big', 'data', 'might', 'help', 'reducing', 'waste', 'improving', 'efficiency', 'clinical', 'operations', ',', 'research', 'development', ',', 'public', 'health', 'means', '•', 'statistical', 'tools', 'algorithms', ';', '•', 'predictive', 'modelling', 'produce', 'new', 'drugs', 'devices', 'quickly', ';', '•', 'analysing', 'records', 'diseases', 'improve', 'epidemiology', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', ';', '•', 'allowing', 'faster', 'development', 'vaccines', ';', '•', 'identifying', 'data', 'relevant', 'provide', 'services', 'prevent', 'crises', '.']

>> Bigrams are: 
 [('Healthcare', 'Research'), ('Research', 'Manyika'), ('Manyika', '('), ('(', '2011'), ('2011', ')'), (')', 'showed'), ('showed', 'big'), ('big', 'data'), ('data', 'might'), ('might', 'help'), ('help', 'reducing'), ('reducing', 'waste'), ('waste', 'improving'), ('improving', 'efficiency'), ('efficiency', 'clinical'), ('clinical', 'operations'), ('operations', ','), (',', 'research'), ('research', 'development'), ('development', ','), (',', 'public'), ('public', 'health'), ('health', 'means'), ('means', '•'), ('•', 'statistical'), ('statistical', 'tools'), ('tools', 'algorithms'), ('algorithms', ';'), (';', '•'), ('•', 'predictive'), ('predictive', 'modelling'), ('modelling', 'produce'), ('produce', 'new'), ('new', 'drugs'), ('drugs', 'devices'), ('devices', 'quickly'), ('quickly', ';'), (';', '•'), ('•', 'analysing'), ('analysing', 'records'), ('records', 'diseases'), ('diseases', 'improve'), ('improve', 'epidemiology'), ('epidemiology', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', ';'), (';', '•'), ('•', 'allowing'), ('allowing', 'faster'), ('faster', 'development'), ('development', 'vaccines'), ('vaccines', ';'), (';', '•'), ('•', 'identifying'), ('identifying', 'data'), ('data', 'relevant'), ('relevant', 'provide'), ('provide', 'services'), ('services', 'prevent'), ('prevent', 'crises'), ('crises', '.')]

>> Trigrams are: 
 [('Healthcare', 'Research', 'Manyika'), ('Research', 'Manyika', '('), ('Manyika', '(', '2011'), ('(', '2011', ')'), ('2011', ')', 'showed'), (')', 'showed', 'big'), ('showed', 'big', 'data'), ('big', 'data', 'might'), ('data', 'might', 'help'), ('might', 'help', 'reducing'), ('help', 'reducing', 'waste'), ('reducing', 'waste', 'improving'), ('waste', 'improving', 'efficiency'), ('improving', 'efficiency', 'clinical'), ('efficiency', 'clinical', 'operations'), ('clinical', 'operations', ','), ('operations', ',', 'research'), (',', 'research', 'development'), ('research', 'development', ','), ('development', ',', 'public'), (',', 'public', 'health'), ('public', 'health', 'means'), ('health', 'means', '•'), ('means', '•', 'statistical'), ('•', 'statistical', 'tools'), ('statistical', 'tools', 'algorithms'), ('tools', 'algorithms', ';'), ('algorithms', ';', '•'), (';', '•', 'predictive'), ('•', 'predictive', 'modelling'), ('predictive', 'modelling', 'produce'), ('modelling', 'produce', 'new'), ('produce', 'new', 'drugs'), ('new', 'drugs', 'devices'), ('drugs', 'devices', 'quickly'), ('devices', 'quickly', ';'), ('quickly', ';', '•'), (';', '•', 'analysing'), ('•', 'analysing', 'records'), ('analysing', 'records', 'diseases'), ('records', 'diseases', 'improve'), ('diseases', 'improve', 'epidemiology'), ('improve', 'epidemiology', '('), ('epidemiology', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', ';'), (')', ';', '•'), (';', '•', 'allowing'), ('•', 'allowing', 'faster'), ('allowing', 'faster', 'development'), ('faster', 'development', 'vaccines'), ('development', 'vaccines', ';'), ('vaccines', ';', '•'), (';', '•', 'identifying'), ('•', 'identifying', 'data'), ('identifying', 'data', 'relevant'), ('data', 'relevant', 'provide'), ('relevant', 'provide', 'services'), ('provide', 'services', 'prevent'), ('services', 'prevent', 'crises'), ('prevent', 'crises', '.')]

>> POS Tags are: 
 [('Healthcare', 'NNP'), ('Research', 'NNP'), ('Manyika', 'NNP'), ('(', '('), ('2011', 'CD'), (')', ')'), ('showed', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('might', 'MD'), ('help', 'VB'), ('reducing', 'VBG'), ('waste', 'NN'), ('improving', 'VBG'), ('efficiency', 'NN'), ('clinical', 'JJ'), ('operations', 'NNS'), (',', ','), ('research', 'NN'), ('development', 'NN'), (',', ','), ('public', 'JJ'), ('health', 'NN'), ('means', 'NNS'), ('•', 'VBP'), ('statistical', 'JJ'), ('tools', 'NNS'), ('algorithms', 'VBP'), (';', ':'), ('•', 'NNP'), ('predictive', 'VBP'), ('modelling', 'VBG'), ('produce', 'VBP'), ('new', 'JJ'), ('drugs', 'NNS'), ('devices', 'NNS'), ('quickly', 'RB'), (';', ':'), ('•', 'CC'), ('analysing', 'VBG'), ('records', 'NNS'), ('diseases', 'NNS'), ('improve', 'VBP'), ('epidemiology', 'NN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), (';', ':'), ('•', 'CC'), ('allowing', 'VBG'), ('faster', 'RBR'), ('development', 'NN'), ('vaccines', 'NNS'), (';', ':'), ('•', 'CC'), ('identifying', 'VBG'), ('data', 'NNS'), ('relevant', 'NN'), ('provide', 'NN'), ('services', 'NNS'), ('prevent', 'NN'), ('crises', 'NNS'), ('.', '.')]

 (S
  (NP Healthcare/NNP Research/NNP Manyika/NNP)
  (/(
  2011/CD
  )/)
  showed/VBD
  (NP big/JJ data/NNS)
  might/MD
  help/VB
  reducing/VBG
  (NP waste/NN)
  improving/VBG
  (NP efficiency/NN)
  (NP clinical/JJ operations/NNS)
  ,/,
  (NP research/NN development/NN)
  ,/,
  (NP public/JJ health/NN means/NNS)
  •/VBP
  (NP statistical/JJ tools/NNS)
  algorithms/VBP
  ;/:
  (NP •/NNP)
  predictive/VBP
  modelling/VBG
  produce/VBP
  (NP new/JJ drugs/NNS devices/NNS)
  quickly/RB
  ;/:
  •/CC
  analysing/VBG
  (NP records/NNS diseases/NNS)
  improve/VBP
  (NP epidemiology/NN)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ;/:
  •/CC
  allowing/VBG
  faster/RBR
  (NP development/NN vaccines/NNS)
  ;/:
  •/CC
  identifying/VBG
  (NP
    data/NNS
    relevant/NN
    provide/NN
    services/NNS
    prevent/NN
    crises/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Healthcare Research Manyika', 'big data', 'waste', 'efficiency', 'clinical operations', 'research development', 'public health means', 'statistical tools', '•', 'new drugs devices', 'records diseases', 'epidemiology', 'Elgendy', 'N. Elragal', 'A.', 'development vaccines', 'data relevant provide services prevent crises']

>> Named Entities are: 
 [('PERSON', 'Healthcare'), ('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Healthcare', 'healthcar'), ('Research', 'research'), ('Manyika', 'manyika'), ('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('might', 'might'), ('help', 'help'), ('reducing', 'reduc'), ('waste', 'wast'), ('improving', 'improv'), ('efficiency', 'effici'), ('clinical', 'clinic'), ('operations', 'oper'), (',', ','), ('research', 'research'), ('development', 'develop'), (',', ','), ('public', 'public'), ('health', 'health'), ('means', 'mean'), ('•', '•'), ('statistical', 'statist'), ('tools', 'tool'), ('algorithms', 'algorithm'), (';', ';'), ('•', '•'), ('predictive', 'predict'), ('modelling', 'model'), ('produce', 'produc'), ('new', 'new'), ('drugs', 'drug'), ('devices', 'devic'), ('quickly', 'quickli'), (';', ';'), ('•', '•'), ('analysing', 'analys'), ('records', 'record'), ('diseases', 'diseas'), ('improve', 'improv'), ('epidemiology', 'epidemiolog'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('•', '•'), ('allowing', 'allow'), ('faster', 'faster'), ('development', 'develop'), ('vaccines', 'vaccin'), (';', ';'), ('•', '•'), ('identifying', 'identifi'), ('data', 'data'), ('relevant', 'relev'), ('provide', 'provid'), ('services', 'servic'), ('prevent', 'prevent'), ('crises', 'crise'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Healthcare', 'healthcar'), ('Research', 'research'), ('Manyika', 'manyika'), ('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('might', 'might'), ('help', 'help'), ('reducing', 'reduc'), ('waste', 'wast'), ('improving', 'improv'), ('efficiency', 'effici'), ('clinical', 'clinic'), ('operations', 'oper'), (',', ','), ('research', 'research'), ('development', 'develop'), (',', ','), ('public', 'public'), ('health', 'health'), ('means', 'mean'), ('•', '•'), ('statistical', 'statist'), ('tools', 'tool'), ('algorithms', 'algorithm'), (';', ';'), ('•', '•'), ('predictive', 'predict'), ('modelling', 'model'), ('produce', 'produc'), ('new', 'new'), ('drugs', 'drug'), ('devices', 'devic'), ('quickly', 'quick'), (';', ';'), ('•', '•'), ('analysing', 'analys'), ('records', 'record'), ('diseases', 'diseas'), ('improve', 'improv'), ('epidemiology', 'epidemiolog'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('•', '•'), ('allowing', 'allow'), ('faster', 'faster'), ('development', 'develop'), ('vaccines', 'vaccin'), (';', ';'), ('•', '•'), ('identifying', 'identifi'), ('data', 'data'), ('relevant', 'relev'), ('provide', 'provid'), ('services', 'servic'), ('prevent', 'prevent'), ('crises', 'crise'), ('.', '.')]

>> Lemmatization: 
 [('Healthcare', 'Healthcare'), ('Research', 'Research'), ('Manyika', 'Manyika'), ('(', '('), ('2011', '2011'), (')', ')'), ('showed', 'showed'), ('big', 'big'), ('data', 'data'), ('might', 'might'), ('help', 'help'), ('reducing', 'reducing'), ('waste', 'waste'), ('improving', 'improving'), ('efficiency', 'efficiency'), ('clinical', 'clinical'), ('operations', 'operation'), (',', ','), ('research', 'research'), ('development', 'development'), (',', ','), ('public', 'public'), ('health', 'health'), ('means', 'mean'), ('•', '•'), ('statistical', 'statistical'), ('tools', 'tool'), ('algorithms', 'algorithm'), (';', ';'), ('•', '•'), ('predictive', 'predictive'), ('modelling', 'modelling'), ('produce', 'produce'), ('new', 'new'), ('drugs', 'drug'), ('devices', 'device'), ('quickly', 'quickly'), (';', ';'), ('•', '•'), ('analysing', 'analysing'), ('records', 'record'), ('diseases', 'disease'), ('improve', 'improve'), ('epidemiology', 'epidemiology'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), (';', ';'), ('•', '•'), ('allowing', 'allowing'), ('faster', 'faster'), ('development', 'development'), ('vaccines', 'vaccine'), (';', ';'), ('•', '•'), ('identifying', 'identifying'), ('data', 'data'), ('relevant', 'relevant'), ('provide', 'provide'), ('services', 'service'), ('prevent', 'prevent'), ('crises', 'crisis'), ('.', '.')]



============================ Sentence 550 =============================

Raghupathi and Raghupathi (2014) described big data analytics in healthcare and identified several   remaining challenges; big data analytics has the power to develop care, save lives, and minimise   the costs, using the recent data explosion to extract insights in order to allow healthcare providers   to make better decisions. 


>> Tokens are: 
 ['Raghupathi', 'Raghupathi', '(', '2014', ')', 'described', 'big', 'data', 'analytics', 'healthcare', 'identified', 'several', 'remaining', 'challenges', ';', 'big', 'data', 'analytics', 'power', 'develop', 'care', ',', 'save', 'lives', ',', 'minimise', 'costs', ',', 'using', 'recent', 'data', 'explosion', 'extract', 'insights', 'order', 'allow', 'healthcare', 'providers', 'make', 'better', 'decisions', '.']

>> Bigrams are: 
 [('Raghupathi', 'Raghupathi'), ('Raghupathi', '('), ('(', '2014'), ('2014', ')'), (')', 'described'), ('described', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'healthcare'), ('healthcare', 'identified'), ('identified', 'several'), ('several', 'remaining'), ('remaining', 'challenges'), ('challenges', ';'), (';', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'power'), ('power', 'develop'), ('develop', 'care'), ('care', ','), (',', 'save'), ('save', 'lives'), ('lives', ','), (',', 'minimise'), ('minimise', 'costs'), ('costs', ','), (',', 'using'), ('using', 'recent'), ('recent', 'data'), ('data', 'explosion'), ('explosion', 'extract'), ('extract', 'insights'), ('insights', 'order'), ('order', 'allow'), ('allow', 'healthcare'), ('healthcare', 'providers'), ('providers', 'make'), ('make', 'better'), ('better', 'decisions'), ('decisions', '.')]

>> Trigrams are: 
 [('Raghupathi', 'Raghupathi', '('), ('Raghupathi', '(', '2014'), ('(', '2014', ')'), ('2014', ')', 'described'), (')', 'described', 'big'), ('described', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'healthcare'), ('analytics', 'healthcare', 'identified'), ('healthcare', 'identified', 'several'), ('identified', 'several', 'remaining'), ('several', 'remaining', 'challenges'), ('remaining', 'challenges', ';'), ('challenges', ';', 'big'), (';', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'power'), ('analytics', 'power', 'develop'), ('power', 'develop', 'care'), ('develop', 'care', ','), ('care', ',', 'save'), (',', 'save', 'lives'), ('save', 'lives', ','), ('lives', ',', 'minimise'), (',', 'minimise', 'costs'), ('minimise', 'costs', ','), ('costs', ',', 'using'), (',', 'using', 'recent'), ('using', 'recent', 'data'), ('recent', 'data', 'explosion'), ('data', 'explosion', 'extract'), ('explosion', 'extract', 'insights'), ('extract', 'insights', 'order'), ('insights', 'order', 'allow'), ('order', 'allow', 'healthcare'), ('allow', 'healthcare', 'providers'), ('healthcare', 'providers', 'make'), ('providers', 'make', 'better'), ('make', 'better', 'decisions'), ('better', 'decisions', '.')]

>> POS Tags are: 
 [('Raghupathi', 'NNP'), ('Raghupathi', 'NNP'), ('(', '('), ('2014', 'CD'), (')', ')'), ('described', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('healthcare', 'VBP'), ('identified', 'JJ'), ('several', 'JJ'), ('remaining', 'VBG'), ('challenges', 'NNS'), (';', ':'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('power', 'NN'), ('develop', 'NN'), ('care', 'NN'), (',', ','), ('save', 'VBP'), ('lives', 'NNS'), (',', ','), ('minimise', 'NN'), ('costs', 'NNS'), (',', ','), ('using', 'VBG'), ('recent', 'JJ'), ('data', 'NNS'), ('explosion', 'NN'), ('extract', 'NN'), ('insights', 'NNS'), ('order', 'NN'), ('allow', 'IN'), ('healthcare', 'NN'), ('providers', 'NNS'), ('make', 'VBP'), ('better', 'JJR'), ('decisions', 'NNS'), ('.', '.')]

 (S
  (NP Raghupathi/NNP Raghupathi/NNP)
  (/(
  2014/CD
  )/)
  described/VBD
  (NP big/JJ data/NNS analytics/NNS)
  healthcare/VBP
  identified/JJ
  several/JJ
  remaining/VBG
  (NP challenges/NNS)
  ;/:
  (NP big/JJ data/NNS analytics/NNS power/NN develop/NN care/NN)
  ,/,
  save/VBP
  (NP lives/NNS)
  ,/,
  (NP minimise/NN costs/NNS)
  ,/,
  using/VBG
  (NP
    recent/JJ
    data/NNS
    explosion/NN
    extract/NN
    insights/NNS
    order/NN)
  allow/IN
  (NP healthcare/NN providers/NNS)
  make/VBP
  better/JJR
  (NP decisions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Raghupathi Raghupathi', 'big data analytics', 'challenges', 'big data analytics power develop care', 'lives', 'minimise costs', 'recent data explosion extract insights order', 'healthcare providers', 'decisions']

>> Named Entities are: 
 [('PERSON', 'Raghupathi'), ('ORGANIZATION', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), ('(', '('), ('2014', '2014'), (')', ')'), ('described', 'describ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), ('identified', 'identifi'), ('several', 'sever'), ('remaining', 'remain'), ('challenges', 'challeng'), (';', ';'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('develop', 'develop'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('minimise', 'minimis'), ('costs', 'cost'), (',', ','), ('using', 'use'), ('recent', 'recent'), ('data', 'data'), ('explosion', 'explos'), ('extract', 'extract'), ('insights', 'insight'), ('order', 'order'), ('allow', 'allow'), ('healthcare', 'healthcar'), ('providers', 'provid'), ('make', 'make'), ('better', 'better'), ('decisions', 'decis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Raghupathi', 'raghupathi'), ('Raghupathi', 'raghupathi'), ('(', '('), ('2014', '2014'), (')', ')'), ('described', 'describ'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), ('identified', 'identifi'), ('several', 'sever'), ('remaining', 'remain'), ('challenges', 'challeng'), (';', ';'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('develop', 'develop'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('minimise', 'minimis'), ('costs', 'cost'), (',', ','), ('using', 'use'), ('recent', 'recent'), ('data', 'data'), ('explosion', 'explos'), ('extract', 'extract'), ('insights', 'insight'), ('order', 'order'), ('allow', 'allow'), ('healthcare', 'healthcar'), ('providers', 'provid'), ('make', 'make'), ('better', 'better'), ('decisions', 'decis'), ('.', '.')]

>> Lemmatization: 
 [('Raghupathi', 'Raghupathi'), ('Raghupathi', 'Raghupathi'), ('(', '('), ('2014', '2014'), (')', ')'), ('described', 'described'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('healthcare', 'healthcare'), ('identified', 'identified'), ('several', 'several'), ('remaining', 'remaining'), ('challenges', 'challenge'), (';', ';'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('power', 'power'), ('develop', 'develop'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'life'), (',', ','), ('minimise', 'minimise'), ('costs', 'cost'), (',', ','), ('using', 'using'), ('recent', 'recent'), ('data', 'data'), ('explosion', 'explosion'), ('extract', 'extract'), ('insights', 'insight'), ('order', 'order'), ('allow', 'allow'), ('healthcare', 'healthcare'), ('providers', 'provider'), ('make', 'make'), ('better', 'better'), ('decisions', 'decision'), ('.', '.')]



============================ Sentence 551 =============================

The potential benefits gained from using big data in healthcare include,   but are not limited to, discovering diseases quickly, thus making treatment easier and more   effective; identifying healthcare fraud quickly in order to manage specific individuals; and   improving population health. 


>> Tokens are: 
 ['The', 'potential', 'benefits', 'gained', 'using', 'big', 'data', 'healthcare', 'include', ',', 'limited', ',', 'discovering', 'diseases', 'quickly', ',', 'thus', 'making', 'treatment', 'easier', 'effective', ';', 'identifying', 'healthcare', 'fraud', 'quickly', 'order', 'manage', 'specific', 'individuals', ';', 'improving', 'population', 'health', '.']

>> Bigrams are: 
 [('The', 'potential'), ('potential', 'benefits'), ('benefits', 'gained'), ('gained', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'healthcare'), ('healthcare', 'include'), ('include', ','), (',', 'limited'), ('limited', ','), (',', 'discovering'), ('discovering', 'diseases'), ('diseases', 'quickly'), ('quickly', ','), (',', 'thus'), ('thus', 'making'), ('making', 'treatment'), ('treatment', 'easier'), ('easier', 'effective'), ('effective', ';'), (';', 'identifying'), ('identifying', 'healthcare'), ('healthcare', 'fraud'), ('fraud', 'quickly'), ('quickly', 'order'), ('order', 'manage'), ('manage', 'specific'), ('specific', 'individuals'), ('individuals', ';'), (';', 'improving'), ('improving', 'population'), ('population', 'health'), ('health', '.')]

>> Trigrams are: 
 [('The', 'potential', 'benefits'), ('potential', 'benefits', 'gained'), ('benefits', 'gained', 'using'), ('gained', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'healthcare'), ('data', 'healthcare', 'include'), ('healthcare', 'include', ','), ('include', ',', 'limited'), (',', 'limited', ','), ('limited', ',', 'discovering'), (',', 'discovering', 'diseases'), ('discovering', 'diseases', 'quickly'), ('diseases', 'quickly', ','), ('quickly', ',', 'thus'), (',', 'thus', 'making'), ('thus', 'making', 'treatment'), ('making', 'treatment', 'easier'), ('treatment', 'easier', 'effective'), ('easier', 'effective', ';'), ('effective', ';', 'identifying'), (';', 'identifying', 'healthcare'), ('identifying', 'healthcare', 'fraud'), ('healthcare', 'fraud', 'quickly'), ('fraud', 'quickly', 'order'), ('quickly', 'order', 'manage'), ('order', 'manage', 'specific'), ('manage', 'specific', 'individuals'), ('specific', 'individuals', ';'), ('individuals', ';', 'improving'), (';', 'improving', 'population'), ('improving', 'population', 'health'), ('population', 'health', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('potential', 'JJ'), ('benefits', 'NNS'), ('gained', 'VBN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('healthcare', 'NN'), ('include', 'VBP'), (',', ','), ('limited', 'JJ'), (',', ','), ('discovering', 'VBG'), ('diseases', 'NNS'), ('quickly', 'RB'), (',', ','), ('thus', 'RB'), ('making', 'VBG'), ('treatment', 'NN'), ('easier', 'RB'), ('effective', 'JJ'), (';', ':'), ('identifying', 'VBG'), ('healthcare', 'NN'), ('fraud', 'NN'), ('quickly', 'RB'), ('order', 'NN'), ('manage', 'NN'), ('specific', 'JJ'), ('individuals', 'NNS'), (';', ':'), ('improving', 'VBG'), ('population', 'NN'), ('health', 'NN'), ('.', '.')]

 (S
  (NP The/DT potential/JJ benefits/NNS)
  gained/VBN
  using/VBG
  (NP big/JJ data/NNS healthcare/NN)
  include/VBP
  ,/,
  limited/JJ
  ,/,
  discovering/VBG
  (NP diseases/NNS)
  quickly/RB
  ,/,
  thus/RB
  making/VBG
  (NP treatment/NN)
  easier/RB
  effective/JJ
  ;/:
  identifying/VBG
  (NP healthcare/NN fraud/NN)
  quickly/RB
  (NP order/NN manage/NN)
  (NP specific/JJ individuals/NNS)
  ;/:
  improving/VBG
  (NP population/NN health/NN)
  ./.) 


>> Noun Phrases are: 
 ['The potential benefits', 'big data healthcare', 'diseases', 'treatment', 'healthcare fraud', 'order manage', 'specific individuals', 'population health']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('benefits', 'benefit'), ('gained', 'gain'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('healthcare', 'healthcar'), ('include', 'includ'), (',', ','), ('limited', 'limit'), (',', ','), ('discovering', 'discov'), ('diseases', 'diseas'), ('quickly', 'quickli'), (',', ','), ('thus', 'thu'), ('making', 'make'), ('treatment', 'treatment'), ('easier', 'easier'), ('effective', 'effect'), (';', ';'), ('identifying', 'identifi'), ('healthcare', 'healthcar'), ('fraud', 'fraud'), ('quickly', 'quickli'), ('order', 'order'), ('manage', 'manag'), ('specific', 'specif'), ('individuals', 'individu'), (';', ';'), ('improving', 'improv'), ('population', 'popul'), ('health', 'health'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('potential', 'potenti'), ('benefits', 'benefit'), ('gained', 'gain'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('healthcare', 'healthcar'), ('include', 'includ'), (',', ','), ('limited', 'limit'), (',', ','), ('discovering', 'discov'), ('diseases', 'diseas'), ('quickly', 'quick'), (',', ','), ('thus', 'thus'), ('making', 'make'), ('treatment', 'treatment'), ('easier', 'easier'), ('effective', 'effect'), (';', ';'), ('identifying', 'identifi'), ('healthcare', 'healthcar'), ('fraud', 'fraud'), ('quickly', 'quick'), ('order', 'order'), ('manage', 'manag'), ('specific', 'specif'), ('individuals', 'individu'), (';', ';'), ('improving', 'improv'), ('population', 'popul'), ('health', 'health'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('potential', 'potential'), ('benefits', 'benefit'), ('gained', 'gained'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('healthcare', 'healthcare'), ('include', 'include'), (',', ','), ('limited', 'limited'), (',', ','), ('discovering', 'discovering'), ('diseases', 'disease'), ('quickly', 'quickly'), (',', ','), ('thus', 'thus'), ('making', 'making'), ('treatment', 'treatment'), ('easier', 'easier'), ('effective', 'effective'), (';', ';'), ('identifying', 'identifying'), ('healthcare', 'healthcare'), ('fraud', 'fraud'), ('quickly', 'quickly'), ('order', 'order'), ('manage', 'manage'), ('specific', 'specific'), ('individuals', 'individual'), (';', ';'), ('improving', 'improving'), ('population', 'population'), ('health', 'health'), ('.', '.')]



============================ Sentence 552 =============================

Furthermore, Zhong et al. 


>> Tokens are: 
 ['Furthermore', ',', 'Zhong', 'et', 'al', '.']

>> Bigrams are: 
 [('Furthermore', ','), (',', 'Zhong'), ('Zhong', 'et'), ('et', 'al'), ('al', '.')]

>> Trigrams are: 
 [('Furthermore', ',', 'Zhong'), (',', 'Zhong', 'et'), ('Zhong', 'et', 'al'), ('et', 'al', '.')]

>> POS Tags are: 
 [('Furthermore', 'RB'), (',', ','), ('Zhong', 'NNP'), ('et', 'CC'), ('al', 'NN'), ('.', '.')]

 (S Furthermore/RB ,/, (NP Zhong/NNP) et/CC (NP al/NN) ./.) 


>> Noun Phrases are: 
 ['Zhong', 'al']

>> Named Entities are: 
 [('GPE', 'Zhong')] 

>> Stemming using Porter Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('Zhong', 'zhong'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Furthermore', 'furthermor'), (',', ','), ('Zhong', 'zhong'), ('et', 'et'), ('al', 'al'), ('.', '.')]

>> Lemmatization: 
 [('Furthermore', 'Furthermore'), (',', ','), ('Zhong', 'Zhong'), ('et', 'et'), ('al', 'al'), ('.', '.')]



============================ Sentence 553 =============================

(2016) presented big data applications in healthcare and showed how   big data can be embedded into daily life to offer the ability to examine experiences of illness and   healthcare. 


>> Tokens are: 
 ['(', '2016', ')', 'presented', 'big', 'data', 'applications', 'healthcare', 'showed', 'big', 'data', 'embedded', 'daily', 'life', 'offer', 'ability', 'examine', 'experiences', 'illness', 'healthcare', '.']

>> Bigrams are: 
 [('(', '2016'), ('2016', ')'), (')', 'presented'), ('presented', 'big'), ('big', 'data'), ('data', 'applications'), ('applications', 'healthcare'), ('healthcare', 'showed'), ('showed', 'big'), ('big', 'data'), ('data', 'embedded'), ('embedded', 'daily'), ('daily', 'life'), ('life', 'offer'), ('offer', 'ability'), ('ability', 'examine'), ('examine', 'experiences'), ('experiences', 'illness'), ('illness', 'healthcare'), ('healthcare', '.')]

>> Trigrams are: 
 [('(', '2016', ')'), ('2016', ')', 'presented'), (')', 'presented', 'big'), ('presented', 'big', 'data'), ('big', 'data', 'applications'), ('data', 'applications', 'healthcare'), ('applications', 'healthcare', 'showed'), ('healthcare', 'showed', 'big'), ('showed', 'big', 'data'), ('big', 'data', 'embedded'), ('data', 'embedded', 'daily'), ('embedded', 'daily', 'life'), ('daily', 'life', 'offer'), ('life', 'offer', 'ability'), ('offer', 'ability', 'examine'), ('ability', 'examine', 'experiences'), ('examine', 'experiences', 'illness'), ('experiences', 'illness', 'healthcare'), ('illness', 'healthcare', '.')]

>> POS Tags are: 
 [('(', '('), ('2016', 'CD'), (')', ')'), ('presented', 'VBD'), ('big', 'JJ'), ('data', 'NNS'), ('applications', 'NNS'), ('healthcare', 'VBP'), ('showed', 'VBN'), ('big', 'JJ'), ('data', 'NNS'), ('embedded', 'VBD'), ('daily', 'JJ'), ('life', 'NN'), ('offer', 'NN'), ('ability', 'NN'), ('examine', 'NN'), ('experiences', 'NNS'), ('illness', 'NN'), ('healthcare', 'NN'), ('.', '.')]

 (S
  (/(
  2016/CD
  )/)
  presented/VBD
  (NP big/JJ data/NNS applications/NNS)
  healthcare/VBP
  showed/VBN
  (NP big/JJ data/NNS)
  embedded/VBD
  (NP
    daily/JJ
    life/NN
    offer/NN
    ability/NN
    examine/NN
    experiences/NNS
    illness/NN
    healthcare/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data applications', 'big data', 'daily life offer ability examine experiences illness healthcare']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('healthcare', 'healthcar'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('embedded', 'embed'), ('daily', 'daili'), ('life', 'life'), ('offer', 'offer'), ('ability', 'abil'), ('examine', 'examin'), ('experiences', 'experi'), ('illness', 'ill'), ('healthcare', 'healthcar'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'present'), ('big', 'big'), ('data', 'data'), ('applications', 'applic'), ('healthcare', 'healthcar'), ('showed', 'show'), ('big', 'big'), ('data', 'data'), ('embedded', 'embed'), ('daily', 'daili'), ('life', 'life'), ('offer', 'offer'), ('ability', 'abil'), ('examine', 'examin'), ('experiences', 'experi'), ('illness', 'ill'), ('healthcare', 'healthcar'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('2016', '2016'), (')', ')'), ('presented', 'presented'), ('big', 'big'), ('data', 'data'), ('applications', 'application'), ('healthcare', 'healthcare'), ('showed', 'showed'), ('big', 'big'), ('data', 'data'), ('embedded', 'embedded'), ('daily', 'daily'), ('life', 'life'), ('offer', 'offer'), ('ability', 'ability'), ('examine', 'examine'), ('experiences', 'experience'), ('illness', 'illness'), ('healthcare', 'healthcare'), ('.', '.')]



============================ Sentence 554 =============================

Big data analytics thus have a large impact on the healthcare sector, reducing   operational costs and improving patients’ quality of life (Elgendy and Elragal, 2014; Wamba et   al., 2017). 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'thus', 'large', 'impact', 'healthcare', 'sector', ',', 'reducing', 'operational', 'costs', 'improving', 'patients', '’', 'quality', 'life', '(', 'Elgendy', 'Elragal', ',', '2014', ';', 'Wamba', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'thus'), ('thus', 'large'), ('large', 'impact'), ('impact', 'healthcare'), ('healthcare', 'sector'), ('sector', ','), (',', 'reducing'), ('reducing', 'operational'), ('operational', 'costs'), ('costs', 'improving'), ('improving', 'patients'), ('patients', '’'), ('’', 'quality'), ('quality', 'life'), ('life', '('), ('(', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ';'), (';', 'Wamba'), ('Wamba', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'thus'), ('analytics', 'thus', 'large'), ('thus', 'large', 'impact'), ('large', 'impact', 'healthcare'), ('impact', 'healthcare', 'sector'), ('healthcare', 'sector', ','), ('sector', ',', 'reducing'), (',', 'reducing', 'operational'), ('reducing', 'operational', 'costs'), ('operational', 'costs', 'improving'), ('costs', 'improving', 'patients'), ('improving', 'patients', '’'), ('patients', '’', 'quality'), ('’', 'quality', 'life'), ('quality', 'life', '('), ('life', '(', 'Elgendy'), ('(', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ';'), ('2014', ';', 'Wamba'), (';', 'Wamba', 'et'), ('Wamba', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('thus', 'RB'), ('large', 'JJ'), ('impact', 'NN'), ('healthcare', 'NN'), ('sector', 'NN'), (',', ','), ('reducing', 'VBG'), ('operational', 'JJ'), ('costs', 'NNS'), ('improving', 'VBG'), ('patients', 'NNS'), ('’', 'JJ'), ('quality', 'JJ'), ('life', 'NN'), ('(', '('), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (';', ':'), ('Wamba', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  thus/RB
  (NP large/JJ impact/NN healthcare/NN sector/NN)
  ,/,
  reducing/VBG
  (NP operational/JJ costs/NNS)
  improving/VBG
  (NP patients/NNS)
  (NP ’/JJ quality/JJ life/NN)
  (/(
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  ;/:
  (NP Wamba/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'large impact healthcare sector', 'operational costs', 'patients', '’ quality life', 'Elgendy Elragal', 'Wamba', 'al.']

>> Named Entities are: 
 [('PERSON', 'Elgendy Elragal'), ('PERSON', 'Wamba')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thu'), ('large', 'larg'), ('impact', 'impact'), ('healthcare', 'healthcar'), ('sector', 'sector'), (',', ','), ('reducing', 'reduc'), ('operational', 'oper'), ('costs', 'cost'), ('improving', 'improv'), ('patients', 'patient'), ('’', '’'), ('quality', 'qualiti'), ('life', 'life'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Wamba', 'wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thus'), ('large', 'larg'), ('impact', 'impact'), ('healthcare', 'healthcar'), ('sector', 'sector'), (',', ','), ('reducing', 'reduc'), ('operational', 'oper'), ('costs', 'cost'), ('improving', 'improv'), ('patients', 'patient'), ('’', '’'), ('quality', 'qualiti'), ('life', 'life'), ('(', '('), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (';', ';'), ('Wamba', 'wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('thus', 'thus'), ('large', 'large'), ('impact', 'impact'), ('healthcare', 'healthcare'), ('sector', 'sector'), (',', ','), ('reducing', 'reducing'), ('operational', 'operational'), ('costs', 'cost'), ('improving', 'improving'), ('patients', 'patient'), ('’', '’'), ('quality', 'quality'), ('life', 'life'), ('(', '('), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (';', ';'), ('Wamba', 'Wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 555 =============================

10.2. 


>> Tokens are: 
 ['10.2', '.']

>> Bigrams are: 
 [('10.2', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.2', 'CD'), ('.', '.')]

 (S 10.2/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.2', '10.2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.2', '10.2'), ('.', '.')]

>> Lemmatization: 
 [('10.2', '10.2'), ('.', '.')]



============================ Sentence 556 =============================

Banking   Handling massive volumes of data of many different types is not easy. 


>> Tokens are: 
 ['Banking', 'Handling', 'massive', 'volumes', 'data', 'many', 'different', 'types', 'easy', '.']

>> Bigrams are: 
 [('Banking', 'Handling'), ('Handling', 'massive'), ('massive', 'volumes'), ('volumes', 'data'), ('data', 'many'), ('many', 'different'), ('different', 'types'), ('types', 'easy'), ('easy', '.')]

>> Trigrams are: 
 [('Banking', 'Handling', 'massive'), ('Handling', 'massive', 'volumes'), ('massive', 'volumes', 'data'), ('volumes', 'data', 'many'), ('data', 'many', 'different'), ('many', 'different', 'types'), ('different', 'types', 'easy'), ('types', 'easy', '.')]

>> POS Tags are: 
 [('Banking', 'VBG'), ('Handling', 'VBG'), ('massive', 'JJ'), ('volumes', 'NNS'), ('data', 'VBP'), ('many', 'JJ'), ('different', 'JJ'), ('types', 'NNS'), ('easy', 'JJ'), ('.', '.')]

 (S
  Banking/VBG
  Handling/VBG
  (NP massive/JJ volumes/NNS)
  data/VBP
  (NP many/JJ different/JJ types/NNS)
  easy/JJ
  ./.) 


>> Noun Phrases are: 
 ['massive volumes', 'many different types']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Banking', 'bank'), ('Handling', 'handl'), ('massive', 'massiv'), ('volumes', 'volum'), ('data', 'data'), ('many', 'mani'), ('different', 'differ'), ('types', 'type'), ('easy', 'easi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Banking', 'bank'), ('Handling', 'handl'), ('massive', 'massiv'), ('volumes', 'volum'), ('data', 'data'), ('many', 'mani'), ('different', 'differ'), ('types', 'type'), ('easy', 'easi'), ('.', '.')]

>> Lemmatization: 
 [('Banking', 'Banking'), ('Handling', 'Handling'), ('massive', 'massive'), ('volumes', 'volume'), ('data', 'data'), ('many', 'many'), ('different', 'different'), ('types', 'type'), ('easy', 'easy'), ('.', '.')]



============================ Sentence 557 =============================

Big data analytics offers   potential benefits to industries such as banking by allowing analysis of customer log files and the   handling of customer interactions. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'offers', 'potential', 'benefits', 'industries', 'banking', 'allowing', 'analysis', 'customer', 'log', 'files', 'handling', 'customer', 'interactions', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'offers'), ('offers', 'potential'), ('potential', 'benefits'), ('benefits', 'industries'), ('industries', 'banking'), ('banking', 'allowing'), ('allowing', 'analysis'), ('analysis', 'customer'), ('customer', 'log'), ('log', 'files'), ('files', 'handling'), ('handling', 'customer'), ('customer', 'interactions'), ('interactions', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'offers'), ('analytics', 'offers', 'potential'), ('offers', 'potential', 'benefits'), ('potential', 'benefits', 'industries'), ('benefits', 'industries', 'banking'), ('industries', 'banking', 'allowing'), ('banking', 'allowing', 'analysis'), ('allowing', 'analysis', 'customer'), ('analysis', 'customer', 'log'), ('customer', 'log', 'files'), ('log', 'files', 'handling'), ('files', 'handling', 'customer'), ('handling', 'customer', 'interactions'), ('customer', 'interactions', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('offers', 'VBZ'), ('potential', 'JJ'), ('benefits', 'NNS'), ('industries', 'NNS'), ('banking', 'VBG'), ('allowing', 'VBG'), ('analysis', 'NN'), ('customer', 'NN'), ('log', 'NN'), ('files', 'NNS'), ('handling', 'VBG'), ('customer', 'NN'), ('interactions', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  offers/VBZ
  (NP potential/JJ benefits/NNS industries/NNS)
  banking/VBG
  allowing/VBG
  (NP analysis/NN customer/NN log/NN files/NNS)
  handling/VBG
  (NP customer/NN interactions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'potential benefits industries', 'analysis customer log files', 'customer interactions']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('offers', 'offer'), ('potential', 'potenti'), ('benefits', 'benefit'), ('industries', 'industri'), ('banking', 'bank'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file'), ('handling', 'handl'), ('customer', 'custom'), ('interactions', 'interact'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('offers', 'offer'), ('potential', 'potenti'), ('benefits', 'benefit'), ('industries', 'industri'), ('banking', 'bank'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file'), ('handling', 'handl'), ('customer', 'custom'), ('interactions', 'interact'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('offers', 'offer'), ('potential', 'potential'), ('benefits', 'benefit'), ('industries', 'industry'), ('banking', 'banking'), ('allowing', 'allowing'), ('analysis', 'analysis'), ('customer', 'customer'), ('log', 'log'), ('files', 'file'), ('handling', 'handling'), ('customer', 'customer'), ('interactions', 'interaction'), ('.', '.')]



============================ Sentence 558 =============================

Combining structured and unstructured data types in this way   can give companies a better view of both their customers and operations (Davenport, T.H. 


>> Tokens are: 
 ['Combining', 'structured', 'unstructured', 'data', 'types', 'way', 'give', 'companies', 'better', 'view', 'customers', 'operations', '(', 'Davenport', ',', 'T.H', '.']

>> Bigrams are: 
 [('Combining', 'structured'), ('structured', 'unstructured'), ('unstructured', 'data'), ('data', 'types'), ('types', 'way'), ('way', 'give'), ('give', 'companies'), ('companies', 'better'), ('better', 'view'), ('view', 'customers'), ('customers', 'operations'), ('operations', '('), ('(', 'Davenport'), ('Davenport', ','), (',', 'T.H'), ('T.H', '.')]

>> Trigrams are: 
 [('Combining', 'structured', 'unstructured'), ('structured', 'unstructured', 'data'), ('unstructured', 'data', 'types'), ('data', 'types', 'way'), ('types', 'way', 'give'), ('way', 'give', 'companies'), ('give', 'companies', 'better'), ('companies', 'better', 'view'), ('better', 'view', 'customers'), ('view', 'customers', 'operations'), ('customers', 'operations', '('), ('operations', '(', 'Davenport'), ('(', 'Davenport', ','), ('Davenport', ',', 'T.H'), (',', 'T.H', '.')]

>> POS Tags are: 
 [('Combining', 'VBG'), ('structured', 'VBN'), ('unstructured', 'JJ'), ('data', 'NNS'), ('types', 'NNS'), ('way', 'NN'), ('give', 'VBP'), ('companies', 'NNS'), ('better', 'RBR'), ('view', 'NN'), ('customers', 'NNS'), ('operations', 'NNS'), ('(', '('), ('Davenport', 'NNP'), (',', ','), ('T.H', 'NNP'), ('.', '.')]

 (S
  Combining/VBG
  structured/VBN
  (NP unstructured/JJ data/NNS types/NNS way/NN)
  give/VBP
  (NP companies/NNS)
  better/RBR
  (NP view/NN customers/NNS operations/NNS)
  (/(
  (NP Davenport/NNP)
  ,/,
  (NP T.H/NNP)
  ./.) 


>> Noun Phrases are: 
 ['unstructured data types way', 'companies', 'view customers operations', 'Davenport', 'T.H']

>> Named Entities are: 
 [('ORGANIZATION', 'Davenport')] 

>> Stemming using Porter Stemmer: 
 [('Combining', 'combin'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('way', 'way'), ('give', 'give'), ('companies', 'compani'), ('better', 'better'), ('view', 'view'), ('customers', 'custom'), ('operations', 'oper'), ('(', '('), ('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Combining', 'combin'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('way', 'way'), ('give', 'give'), ('companies', 'compani'), ('better', 'better'), ('view', 'view'), ('customers', 'custom'), ('operations', 'oper'), ('(', '('), ('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Lemmatization: 
 [('Combining', 'Combining'), ('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('types', 'type'), ('way', 'way'), ('give', 'give'), ('companies', 'company'), ('better', 'better'), ('view', 'view'), ('customers', 'customer'), ('operations', 'operation'), ('(', '('), ('Davenport', 'Davenport'), (',', ','), ('T.H', 'T.H'), ('.', '.')]



============================ Sentence 559 =============================

and   Dyché, J., 2013). 


>> Tokens are: 
 ['Dyché', ',', 'J.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('Dyché', ','), (',', 'J.'), ('J.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Dyché', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Dyché', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

 (S (NP Dyché/NNP) ,/, (NP J./NNP) ,/, 2013/CD )/) ./.) 


>> Noun Phrases are: 
 ['Dyché', 'J.']

>> Named Entities are: 
 [('GPE', 'Dyché')] 

>> Stemming using Porter Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Dyché', 'Dyché'), (',', ','), ('J.', 'J.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



============================ Sentence 560 =============================

Sarah Al-Shiakhli   44      Analytics offers banks the ability to segment customers depending on their risk profiles, credit   usage, and similar markers, offering products tailored to their needs and ability to handle   money. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '44', 'Analytics', 'offers', 'banks', 'ability', 'segment', 'customers', 'depending', 'risk', 'profiles', ',', 'credit', 'usage', ',', 'similar', 'markers', ',', 'offering', 'products', 'tailored', 'needs', 'ability', 'handle', 'money', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '44'), ('44', 'Analytics'), ('Analytics', 'offers'), ('offers', 'banks'), ('banks', 'ability'), ('ability', 'segment'), ('segment', 'customers'), ('customers', 'depending'), ('depending', 'risk'), ('risk', 'profiles'), ('profiles', ','), (',', 'credit'), ('credit', 'usage'), ('usage', ','), (',', 'similar'), ('similar', 'markers'), ('markers', ','), (',', 'offering'), ('offering', 'products'), ('products', 'tailored'), ('tailored', 'needs'), ('needs', 'ability'), ('ability', 'handle'), ('handle', 'money'), ('money', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '44'), ('Al-Shiakhli', '44', 'Analytics'), ('44', 'Analytics', 'offers'), ('Analytics', 'offers', 'banks'), ('offers', 'banks', 'ability'), ('banks', 'ability', 'segment'), ('ability', 'segment', 'customers'), ('segment', 'customers', 'depending'), ('customers', 'depending', 'risk'), ('depending', 'risk', 'profiles'), ('risk', 'profiles', ','), ('profiles', ',', 'credit'), (',', 'credit', 'usage'), ('credit', 'usage', ','), ('usage', ',', 'similar'), (',', 'similar', 'markers'), ('similar', 'markers', ','), ('markers', ',', 'offering'), (',', 'offering', 'products'), ('offering', 'products', 'tailored'), ('products', 'tailored', 'needs'), ('tailored', 'needs', 'ability'), ('needs', 'ability', 'handle'), ('ability', 'handle', 'money'), ('handle', 'money', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('44', 'CD'), ('Analytics', 'NNPS'), ('offers', 'NNS'), ('banks', 'NNS'), ('ability', 'NN'), ('segment', 'NN'), ('customers', 'NNS'), ('depending', 'VBG'), ('risk', 'NN'), ('profiles', 'NNS'), (',', ','), ('credit', 'NN'), ('usage', 'NN'), (',', ','), ('similar', 'JJ'), ('markers', 'NNS'), (',', ','), ('offering', 'VBG'), ('products', 'NNS'), ('tailored', 'VBN'), ('needs', 'NNS'), ('ability', 'NN'), ('handle', 'VBP'), ('money', 'NN'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  44/CD
  Analytics/NNPS
  (NP offers/NNS banks/NNS ability/NN segment/NN customers/NNS)
  depending/VBG
  (NP risk/NN profiles/NNS)
  ,/,
  (NP credit/NN usage/NN)
  ,/,
  (NP similar/JJ markers/NNS)
  ,/,
  offering/VBG
  (NP products/NNS)
  tailored/VBN
  (NP needs/NNS ability/NN)
  handle/VBP
  (NP money/NN)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'offers banks ability segment customers', 'risk profiles', 'credit usage', 'similar markers', 'products', 'needs ability', 'money']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('44', '44'), ('Analytics', 'analyt'), ('offers', 'offer'), ('banks', 'bank'), ('ability', 'abil'), ('segment', 'segment'), ('customers', 'custom'), ('depending', 'depend'), ('risk', 'risk'), ('profiles', 'profil'), (',', ','), ('credit', 'credit'), ('usage', 'usag'), (',', ','), ('similar', 'similar'), ('markers', 'marker'), (',', ','), ('offering', 'offer'), ('products', 'product'), ('tailored', 'tailor'), ('needs', 'need'), ('ability', 'abil'), ('handle', 'handl'), ('money', 'money'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('44', '44'), ('Analytics', 'analyt'), ('offers', 'offer'), ('banks', 'bank'), ('ability', 'abil'), ('segment', 'segment'), ('customers', 'custom'), ('depending', 'depend'), ('risk', 'risk'), ('profiles', 'profil'), (',', ','), ('credit', 'credit'), ('usage', 'usag'), (',', ','), ('similar', 'similar'), ('markers', 'marker'), (',', ','), ('offering', 'offer'), ('products', 'product'), ('tailored', 'tailor'), ('needs', 'need'), ('ability', 'abil'), ('handle', 'handl'), ('money', 'money'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('44', '44'), ('Analytics', 'Analytics'), ('offers', 'offer'), ('banks', 'bank'), ('ability', 'ability'), ('segment', 'segment'), ('customers', 'customer'), ('depending', 'depending'), ('risk', 'risk'), ('profiles', 'profile'), (',', ','), ('credit', 'credit'), ('usage', 'usage'), (',', ','), ('similar', 'similar'), ('markers', 'marker'), (',', ','), ('offering', 'offering'), ('products', 'product'), ('tailored', 'tailored'), ('needs', 'need'), ('ability', 'ability'), ('handle', 'handle'), ('money', 'money'), ('.', '.')]



============================ Sentence 561 =============================

Analytics are utilized throughout the industry, such as in retail banking operations, where  every customer transaction is tracked and matched to the customer. 


>> Tokens are: 
 ['Analytics', 'utilized', 'throughout', 'industry', ',', 'retail', 'banking', 'operations', ',', 'every', 'customer', 'transaction', 'tracked', 'matched', 'customer', '.']

>> Bigrams are: 
 [('Analytics', 'utilized'), ('utilized', 'throughout'), ('throughout', 'industry'), ('industry', ','), (',', 'retail'), ('retail', 'banking'), ('banking', 'operations'), ('operations', ','), (',', 'every'), ('every', 'customer'), ('customer', 'transaction'), ('transaction', 'tracked'), ('tracked', 'matched'), ('matched', 'customer'), ('customer', '.')]

>> Trigrams are: 
 [('Analytics', 'utilized', 'throughout'), ('utilized', 'throughout', 'industry'), ('throughout', 'industry', ','), ('industry', ',', 'retail'), (',', 'retail', 'banking'), ('retail', 'banking', 'operations'), ('banking', 'operations', ','), ('operations', ',', 'every'), (',', 'every', 'customer'), ('every', 'customer', 'transaction'), ('customer', 'transaction', 'tracked'), ('transaction', 'tracked', 'matched'), ('tracked', 'matched', 'customer'), ('matched', 'customer', '.')]

>> POS Tags are: 
 [('Analytics', 'NNS'), ('utilized', 'JJ'), ('throughout', 'IN'), ('industry', 'NN'), (',', ','), ('retail', 'JJ'), ('banking', 'NN'), ('operations', 'NNS'), (',', ','), ('every', 'DT'), ('customer', 'NN'), ('transaction', 'NN'), ('tracked', 'VBD'), ('matched', 'JJ'), ('customer', 'NN'), ('.', '.')]

 (S
  (NP Analytics/NNS)
  utilized/JJ
  throughout/IN
  (NP industry/NN)
  ,/,
  (NP retail/JJ banking/NN operations/NNS)
  ,/,
  (NP every/DT customer/NN transaction/NN)
  tracked/VBD
  (NP matched/JJ customer/NN)
  ./.) 


>> Noun Phrases are: 
 ['Analytics', 'industry', 'retail banking operations', 'every customer transaction', 'matched customer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analytics', 'analyt'), ('utilized', 'util'), ('throughout', 'throughout'), ('industry', 'industri'), (',', ','), ('retail', 'retail'), ('banking', 'bank'), ('operations', 'oper'), (',', ','), ('every', 'everi'), ('customer', 'custom'), ('transaction', 'transact'), ('tracked', 'track'), ('matched', 'match'), ('customer', 'custom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analytics', 'analyt'), ('utilized', 'util'), ('throughout', 'throughout'), ('industry', 'industri'), (',', ','), ('retail', 'retail'), ('banking', 'bank'), ('operations', 'oper'), (',', ','), ('every', 'everi'), ('customer', 'custom'), ('transaction', 'transact'), ('tracked', 'track'), ('matched', 'match'), ('customer', 'custom'), ('.', '.')]

>> Lemmatization: 
 [('Analytics', 'Analytics'), ('utilized', 'utilized'), ('throughout', 'throughout'), ('industry', 'industry'), (',', ','), ('retail', 'retail'), ('banking', 'banking'), ('operations', 'operation'), (',', ','), ('every', 'every'), ('customer', 'customer'), ('transaction', 'transaction'), ('tracked', 'tracked'), ('matched', 'matched'), ('customer', 'customer'), ('.', '.')]



============================ Sentence 562 =============================

Banks have adopted new   requirements for data science (analytics) in a wise manner to avoid reduced performance, and data   science (analytics) offers them a resolution to next generation business problems (Banerjee et al.,   2013). 


>> Tokens are: 
 ['Banks', 'adopted', 'new', 'requirements', 'data', 'science', '(', 'analytics', ')', 'wise', 'manner', 'avoid', 'reduced', 'performance', ',', 'data', 'science', '(', 'analytics', ')', 'offers', 'resolution', 'next', 'generation', 'business', 'problems', '(', 'Banerjee', 'et', 'al.', ',', '2013', ')', '.']

>> Bigrams are: 
 [('Banks', 'adopted'), ('adopted', 'new'), ('new', 'requirements'), ('requirements', 'data'), ('data', 'science'), ('science', '('), ('(', 'analytics'), ('analytics', ')'), (')', 'wise'), ('wise', 'manner'), ('manner', 'avoid'), ('avoid', 'reduced'), ('reduced', 'performance'), ('performance', ','), (',', 'data'), ('data', 'science'), ('science', '('), ('(', 'analytics'), ('analytics', ')'), (')', 'offers'), ('offers', 'resolution'), ('resolution', 'next'), ('next', 'generation'), ('generation', 'business'), ('business', 'problems'), ('problems', '('), ('(', 'Banerjee'), ('Banerjee', 'et'), ('et', 'al.'), ('al.', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Banks', 'adopted', 'new'), ('adopted', 'new', 'requirements'), ('new', 'requirements', 'data'), ('requirements', 'data', 'science'), ('data', 'science', '('), ('science', '(', 'analytics'), ('(', 'analytics', ')'), ('analytics', ')', 'wise'), (')', 'wise', 'manner'), ('wise', 'manner', 'avoid'), ('manner', 'avoid', 'reduced'), ('avoid', 'reduced', 'performance'), ('reduced', 'performance', ','), ('performance', ',', 'data'), (',', 'data', 'science'), ('data', 'science', '('), ('science', '(', 'analytics'), ('(', 'analytics', ')'), ('analytics', ')', 'offers'), (')', 'offers', 'resolution'), ('offers', 'resolution', 'next'), ('resolution', 'next', 'generation'), ('next', 'generation', 'business'), ('generation', 'business', 'problems'), ('business', 'problems', '('), ('problems', '(', 'Banerjee'), ('(', 'Banerjee', 'et'), ('Banerjee', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Banks', 'NNS'), ('adopted', 'VBD'), ('new', 'JJ'), ('requirements', 'NNS'), ('data', 'NNS'), ('science', 'NN'), ('(', '('), ('analytics', 'NNS'), (')', ')'), ('wise', 'VBP'), ('manner', 'NN'), ('avoid', 'NN'), ('reduced', 'VBD'), ('performance', 'NN'), (',', ','), ('data', 'NNS'), ('science', 'NN'), ('(', '('), ('analytics', 'NNS'), (')', ')'), ('offers', 'VBZ'), ('resolution', 'NN'), ('next', 'JJ'), ('generation', 'NN'), ('business', 'NN'), ('problems', 'NNS'), ('(', '('), ('Banerjee', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Banks/NNS)
  adopted/VBD
  (NP new/JJ requirements/NNS data/NNS science/NN)
  (/(
  (NP analytics/NNS)
  )/)
  wise/VBP
  (NP manner/NN avoid/NN)
  reduced/VBD
  (NP performance/NN)
  ,/,
  (NP data/NNS science/NN)
  (/(
  (NP analytics/NNS)
  )/)
  offers/VBZ
  (NP resolution/NN)
  (NP next/JJ generation/NN business/NN problems/NNS)
  (/(
  (NP Banerjee/NNP)
  et/RB
  al./RB
  ,/,
  2013/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Banks', 'new requirements data science', 'analytics', 'manner avoid', 'performance', 'data science', 'analytics', 'resolution', 'next generation business problems', 'Banerjee']

>> Named Entities are: 
 [('ORGANIZATION', 'Banerjee')] 

>> Stemming using Porter Stemmer: 
 [('Banks', 'bank'), ('adopted', 'adopt'), ('new', 'new'), ('requirements', 'requir'), ('data', 'data'), ('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('wise', 'wise'), ('manner', 'manner'), ('avoid', 'avoid'), ('reduced', 'reduc'), ('performance', 'perform'), (',', ','), ('data', 'data'), ('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('offers', 'offer'), ('resolution', 'resolut'), ('next', 'next'), ('generation', 'gener'), ('business', 'busi'), ('problems', 'problem'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Banks', 'bank'), ('adopted', 'adopt'), ('new', 'new'), ('requirements', 'requir'), ('data', 'data'), ('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('wise', 'wise'), ('manner', 'manner'), ('avoid', 'avoid'), ('reduced', 'reduc'), ('performance', 'perform'), (',', ','), ('data', 'data'), ('science', 'scienc'), ('(', '('), ('analytics', 'analyt'), (')', ')'), ('offers', 'offer'), ('resolution', 'resolut'), ('next', 'next'), ('generation', 'generat'), ('business', 'busi'), ('problems', 'problem'), ('(', '('), ('Banerjee', 'banerje'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Banks', 'Banks'), ('adopted', 'adopted'), ('new', 'new'), ('requirements', 'requirement'), ('data', 'data'), ('science', 'science'), ('(', '('), ('analytics', 'analytics'), (')', ')'), ('wise', 'wise'), ('manner', 'manner'), ('avoid', 'avoid'), ('reduced', 'reduced'), ('performance', 'performance'), (',', ','), ('data', 'data'), ('science', 'science'), ('(', '('), ('analytics', 'analytics'), (')', ')'), ('offers', 'offer'), ('resolution', 'resolution'), ('next', 'next'), ('generation', 'generation'), ('business', 'business'), ('problems', 'problem'), ('(', '('), ('Banerjee', 'Banerjee'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



============================ Sentence 563 =============================

Due to the massive number of transactions and activities in financial institutions such as banks,   big data development is inevitable, and this directly impacts on the management of scarce   resources by individuals, groups, and organisations. 


>> Tokens are: 
 ['Due', 'massive', 'number', 'transactions', 'activities', 'financial', 'institutions', 'banks', ',', 'big', 'data', 'development', 'inevitable', ',', 'directly', 'impacts', 'management', 'scarce', 'resources', 'individuals', ',', 'groups', ',', 'organisations', '.']

>> Bigrams are: 
 [('Due', 'massive'), ('massive', 'number'), ('number', 'transactions'), ('transactions', 'activities'), ('activities', 'financial'), ('financial', 'institutions'), ('institutions', 'banks'), ('banks', ','), (',', 'big'), ('big', 'data'), ('data', 'development'), ('development', 'inevitable'), ('inevitable', ','), (',', 'directly'), ('directly', 'impacts'), ('impacts', 'management'), ('management', 'scarce'), ('scarce', 'resources'), ('resources', 'individuals'), ('individuals', ','), (',', 'groups'), ('groups', ','), (',', 'organisations'), ('organisations', '.')]

>> Trigrams are: 
 [('Due', 'massive', 'number'), ('massive', 'number', 'transactions'), ('number', 'transactions', 'activities'), ('transactions', 'activities', 'financial'), ('activities', 'financial', 'institutions'), ('financial', 'institutions', 'banks'), ('institutions', 'banks', ','), ('banks', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'development'), ('data', 'development', 'inevitable'), ('development', 'inevitable', ','), ('inevitable', ',', 'directly'), (',', 'directly', 'impacts'), ('directly', 'impacts', 'management'), ('impacts', 'management', 'scarce'), ('management', 'scarce', 'resources'), ('scarce', 'resources', 'individuals'), ('resources', 'individuals', ','), ('individuals', ',', 'groups'), (',', 'groups', ','), ('groups', ',', 'organisations'), (',', 'organisations', '.')]

>> POS Tags are: 
 [('Due', 'JJ'), ('massive', 'JJ'), ('number', 'NN'), ('transactions', 'NNS'), ('activities', 'NNS'), ('financial', 'JJ'), ('institutions', 'NNS'), ('banks', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('development', 'NN'), ('inevitable', 'JJ'), (',', ','), ('directly', 'RB'), ('impacts', 'VBZ'), ('management', 'NN'), ('scarce', 'JJ'), ('resources', 'NNS'), ('individuals', 'NNS'), (',', ','), ('groups', 'NNS'), (',', ','), ('organisations', 'NNS'), ('.', '.')]

 (S
  (NP Due/JJ massive/JJ number/NN transactions/NNS activities/NNS)
  (NP financial/JJ institutions/NNS banks/NNS)
  ,/,
  (NP big/JJ data/NN development/NN)
  inevitable/JJ
  ,/,
  directly/RB
  impacts/VBZ
  (NP management/NN)
  (NP scarce/JJ resources/NNS individuals/NNS)
  ,/,
  (NP groups/NNS)
  ,/,
  (NP organisations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Due massive number transactions activities', 'financial institutions banks', 'big data development', 'management', 'scarce resources individuals', 'groups', 'organisations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Due', 'due'), ('massive', 'massiv'), ('number', 'number'), ('transactions', 'transact'), ('activities', 'activ'), ('financial', 'financi'), ('institutions', 'institut'), ('banks', 'bank'), (',', ','), ('big', 'big'), ('data', 'data'), ('development', 'develop'), ('inevitable', 'inevit'), (',', ','), ('directly', 'directli'), ('impacts', 'impact'), ('management', 'manag'), ('scarce', 'scarc'), ('resources', 'resourc'), ('individuals', 'individu'), (',', ','), ('groups', 'group'), (',', ','), ('organisations', 'organis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Due', 'due'), ('massive', 'massiv'), ('number', 'number'), ('transactions', 'transact'), ('activities', 'activ'), ('financial', 'financi'), ('institutions', 'institut'), ('banks', 'bank'), (',', ','), ('big', 'big'), ('data', 'data'), ('development', 'develop'), ('inevitable', 'inevit'), (',', ','), ('directly', 'direct'), ('impacts', 'impact'), ('management', 'manag'), ('scarce', 'scarc'), ('resources', 'resourc'), ('individuals', 'individu'), (',', ','), ('groups', 'group'), (',', ','), ('organisations', 'organis'), ('.', '.')]

>> Lemmatization: 
 [('Due', 'Due'), ('massive', 'massive'), ('number', 'number'), ('transactions', 'transaction'), ('activities', 'activity'), ('financial', 'financial'), ('institutions', 'institution'), ('banks', 'bank'), (',', ','), ('big', 'big'), ('data', 'data'), ('development', 'development'), ('inevitable', 'inevitable'), (',', ','), ('directly', 'directly'), ('impacts', 'impact'), ('management', 'management'), ('scarce', 'scarce'), ('resources', 'resource'), ('individuals', 'individual'), (',', ','), ('groups', 'group'), (',', ','), ('organisations', 'organisation'), ('.', '.')]



============================ Sentence 564 =============================

Big data analytics is thus used by the financial   service sector to predict client behaviours and to gain advantages based on understanding   customers and employees (Zhong et al., 2016; Breed and Verster, 2019; Rana, 2019). 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'thus', 'used', 'financial', 'service', 'sector', 'predict', 'client', 'behaviours', 'gain', 'advantages', 'based', 'understanding', 'customers', 'employees', '(', 'Zhong', 'et', 'al.', ',', '2016', ';', 'Breed', 'Verster', ',', '2019', ';', 'Rana', ',', '2019', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'thus'), ('thus', 'used'), ('used', 'financial'), ('financial', 'service'), ('service', 'sector'), ('sector', 'predict'), ('predict', 'client'), ('client', 'behaviours'), ('behaviours', 'gain'), ('gain', 'advantages'), ('advantages', 'based'), ('based', 'understanding'), ('understanding', 'customers'), ('customers', 'employees'), ('employees', '('), ('(', 'Zhong'), ('Zhong', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ';'), (';', 'Breed'), ('Breed', 'Verster'), ('Verster', ','), (',', '2019'), ('2019', ';'), (';', 'Rana'), ('Rana', ','), (',', '2019'), ('2019', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'thus'), ('analytics', 'thus', 'used'), ('thus', 'used', 'financial'), ('used', 'financial', 'service'), ('financial', 'service', 'sector'), ('service', 'sector', 'predict'), ('sector', 'predict', 'client'), ('predict', 'client', 'behaviours'), ('client', 'behaviours', 'gain'), ('behaviours', 'gain', 'advantages'), ('gain', 'advantages', 'based'), ('advantages', 'based', 'understanding'), ('based', 'understanding', 'customers'), ('understanding', 'customers', 'employees'), ('customers', 'employees', '('), ('employees', '(', 'Zhong'), ('(', 'Zhong', 'et'), ('Zhong', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ';'), ('2016', ';', 'Breed'), (';', 'Breed', 'Verster'), ('Breed', 'Verster', ','), ('Verster', ',', '2019'), (',', '2019', ';'), ('2019', ';', 'Rana'), (';', 'Rana', ','), ('Rana', ',', '2019'), (',', '2019', ')'), ('2019', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('thus', 'RB'), ('used', 'VBN'), ('financial', 'JJ'), ('service', 'NN'), ('sector', 'NN'), ('predict', 'VBP'), ('client', 'NN'), ('behaviours', 'NNS'), ('gain', 'VBP'), ('advantages', 'NNS'), ('based', 'VBN'), ('understanding', 'VBG'), ('customers', 'NNS'), ('employees', 'NNS'), ('(', '('), ('Zhong', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (';', ':'), ('Breed', 'NNP'), ('Verster', 'NNP'), (',', ','), ('2019', 'CD'), (';', ':'), ('Rana', 'NNP'), (',', ','), ('2019', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  thus/RB
  used/VBN
  (NP financial/JJ service/NN sector/NN)
  predict/VBP
  (NP client/NN behaviours/NNS)
  gain/VBP
  (NP advantages/NNS)
  based/VBN
  understanding/VBG
  (NP customers/NNS employees/NNS)
  (/(
  (NP Zhong/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  ;/:
  (NP Breed/NNP Verster/NNP)
  ,/,
  2019/CD
  ;/:
  (NP Rana/NNP)
  ,/,
  2019/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'financial service sector', 'client behaviours', 'advantages', 'customers employees', 'Zhong', 'Breed Verster', 'Rana']

>> Named Entities are: 
 [('PERSON', 'Zhong'), ('PERSON', 'Breed Verster'), ('GPE', 'Rana')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thu'), ('used', 'use'), ('financial', 'financi'), ('service', 'servic'), ('sector', 'sector'), ('predict', 'predict'), ('client', 'client'), ('behaviours', 'behaviour'), ('gain', 'gain'), ('advantages', 'advantag'), ('based', 'base'), ('understanding', 'understand'), ('customers', 'custom'), ('employees', 'employe'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (';', ';'), ('Rana', 'rana'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('thus', 'thus'), ('used', 'use'), ('financial', 'financi'), ('service', 'servic'), ('sector', 'sector'), ('predict', 'predict'), ('client', 'client'), ('behaviours', 'behaviour'), ('gain', 'gain'), ('advantages', 'advantag'), ('based', 'base'), ('understanding', 'understand'), ('customers', 'custom'), ('employees', 'employe'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'breed'), ('Verster', 'verster'), (',', ','), ('2019', '2019'), (';', ';'), ('Rana', 'rana'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('thus', 'thus'), ('used', 'used'), ('financial', 'financial'), ('service', 'service'), ('sector', 'sector'), ('predict', 'predict'), ('client', 'client'), ('behaviours', 'behaviour'), ('gain', 'gain'), ('advantages', 'advantage'), ('based', 'based'), ('understanding', 'understanding'), ('customers', 'customer'), ('employees', 'employee'), ('(', '('), ('Zhong', 'Zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (';', ';'), ('Breed', 'Breed'), ('Verster', 'Verster'), (',', ','), ('2019', '2019'), (';', ';'), ('Rana', 'Rana'), (',', ','), ('2019', '2019'), (')', ')'), ('.', '.')]



============================ Sentence 565 =============================

Big data analytics is used widely in the field: McKinsey & Company, a global management   consulting company, uses big data analytics to develop its services and to improve service   performance. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'used', 'widely', 'field', ':', 'McKinsey', '&', 'Company', ',', 'global', 'management', 'consulting', 'company', ',', 'uses', 'big', 'data', 'analytics', 'develop', 'services', 'improve', 'service', 'performance', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'used'), ('used', 'widely'), ('widely', 'field'), ('field', ':'), (':', 'McKinsey'), ('McKinsey', '&'), ('&', 'Company'), ('Company', ','), (',', 'global'), ('global', 'management'), ('management', 'consulting'), ('consulting', 'company'), ('company', ','), (',', 'uses'), ('uses', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'develop'), ('develop', 'services'), ('services', 'improve'), ('improve', 'service'), ('service', 'performance'), ('performance', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'used'), ('analytics', 'used', 'widely'), ('used', 'widely', 'field'), ('widely', 'field', ':'), ('field', ':', 'McKinsey'), (':', 'McKinsey', '&'), ('McKinsey', '&', 'Company'), ('&', 'Company', ','), ('Company', ',', 'global'), (',', 'global', 'management'), ('global', 'management', 'consulting'), ('management', 'consulting', 'company'), ('consulting', 'company', ','), ('company', ',', 'uses'), (',', 'uses', 'big'), ('uses', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'develop'), ('analytics', 'develop', 'services'), ('develop', 'services', 'improve'), ('services', 'improve', 'service'), ('improve', 'service', 'performance'), ('service', 'performance', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('used', 'VBD'), ('widely', 'RB'), ('field', 'NN'), (':', ':'), ('McKinsey', 'NNP'), ('&', 'CC'), ('Company', 'NNP'), (',', ','), ('global', 'JJ'), ('management', 'NN'), ('consulting', 'NN'), ('company', 'NN'), (',', ','), ('uses', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('develop', 'VB'), ('services', 'NNS'), ('improve', 'VB'), ('service', 'NN'), ('performance', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  used/VBD
  widely/RB
  (NP field/NN)
  :/:
  (NP McKinsey/NNP)
  &/CC
  (NP Company/NNP)
  ,/,
  (NP global/JJ management/NN consulting/NN company/NN)
  ,/,
  uses/VBZ
  (NP big/JJ data/NNS analytics/NNS)
  develop/VB
  (NP services/NNS)
  improve/VB
  (NP service/NN performance/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'field', 'McKinsey', 'Company', 'global management consulting company', 'big data analytics', 'services', 'service performance']

>> Named Entities are: 
 [('ORGANIZATION', 'McKinsey'), ('ORGANIZATION', 'Company')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('widely', 'wide'), ('field', 'field'), (':', ':'), ('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani'), (',', ','), ('global', 'global'), ('management', 'manag'), ('consulting', 'consult'), ('company', 'compani'), (',', ','), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('develop', 'develop'), ('services', 'servic'), ('improve', 'improv'), ('service', 'servic'), ('performance', 'perform'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('widely', 'wide'), ('field', 'field'), (':', ':'), ('McKinsey', 'mckinsey'), ('&', '&'), ('Company', 'compani'), (',', ','), ('global', 'global'), ('management', 'manag'), ('consulting', 'consult'), ('company', 'compani'), (',', ','), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('develop', 'develop'), ('services', 'servic'), ('improve', 'improv'), ('service', 'servic'), ('performance', 'perform'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('used', 'used'), ('widely', 'widely'), ('field', 'field'), (':', ':'), ('McKinsey', 'McKinsey'), ('&', '&'), ('Company', 'Company'), (',', ','), ('global', 'global'), ('management', 'management'), ('consulting', 'consulting'), ('company', 'company'), (',', ','), ('uses', 'us'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('develop', 'develop'), ('services', 'service'), ('improve', 'improve'), ('service', 'service'), ('performance', 'performance'), ('.', '.')]



============================ Sentence 566 =============================

This company uses big data analytics to analyse consumer behaviours to upgrade   services and to forecast customer behaviours, to allow fraud detection, and to determine financial   risk assessments (Zhong et al., 2016). 


>> Tokens are: 
 ['This', 'company', 'uses', 'big', 'data', 'analytics', 'analyse', 'consumer', 'behaviours', 'upgrade', 'services', 'forecast', 'customer', 'behaviours', ',', 'allow', 'fraud', 'detection', ',', 'determine', 'financial', 'risk', 'assessments', '(', 'Zhong', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('This', 'company'), ('company', 'uses'), ('uses', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'analyse'), ('analyse', 'consumer'), ('consumer', 'behaviours'), ('behaviours', 'upgrade'), ('upgrade', 'services'), ('services', 'forecast'), ('forecast', 'customer'), ('customer', 'behaviours'), ('behaviours', ','), (',', 'allow'), ('allow', 'fraud'), ('fraud', 'detection'), ('detection', ','), (',', 'determine'), ('determine', 'financial'), ('financial', 'risk'), ('risk', 'assessments'), ('assessments', '('), ('(', 'Zhong'), ('Zhong', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('This', 'company', 'uses'), ('company', 'uses', 'big'), ('uses', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'analyse'), ('analytics', 'analyse', 'consumer'), ('analyse', 'consumer', 'behaviours'), ('consumer', 'behaviours', 'upgrade'), ('behaviours', 'upgrade', 'services'), ('upgrade', 'services', 'forecast'), ('services', 'forecast', 'customer'), ('forecast', 'customer', 'behaviours'), ('customer', 'behaviours', ','), ('behaviours', ',', 'allow'), (',', 'allow', 'fraud'), ('allow', 'fraud', 'detection'), ('fraud', 'detection', ','), ('detection', ',', 'determine'), (',', 'determine', 'financial'), ('determine', 'financial', 'risk'), ('financial', 'risk', 'assessments'), ('risk', 'assessments', '('), ('assessments', '(', 'Zhong'), ('(', 'Zhong', 'et'), ('Zhong', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('company', 'NN'), ('uses', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('analyse', 'JJ'), ('consumer', 'NN'), ('behaviours', 'NNS'), ('upgrade', 'JJ'), ('services', 'NNS'), ('forecast', 'VBP'), ('customer', 'NN'), ('behaviours', 'NN'), (',', ','), ('allow', 'VB'), ('fraud', 'NN'), ('detection', 'NN'), (',', ','), ('determine', 'VB'), ('financial', 'JJ'), ('risk', 'NN'), ('assessments', 'NNS'), ('(', '('), ('Zhong', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP This/DT company/NN)
  uses/VBZ
  (NP big/JJ data/NNS analytics/NNS)
  (NP analyse/JJ consumer/NN behaviours/NNS)
  (NP upgrade/JJ services/NNS)
  forecast/VBP
  (NP customer/NN behaviours/NN)
  ,/,
  allow/VB
  (NP fraud/NN detection/NN)
  ,/,
  determine/VB
  (NP financial/JJ risk/NN assessments/NNS)
  (/(
  (NP Zhong/NNP)
  et/RB
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['This company', 'big data analytics', 'analyse consumer behaviours', 'upgrade services', 'customer behaviours', 'fraud detection', 'financial risk assessments', 'Zhong']

>> Named Entities are: 
 [('PERSON', 'Zhong')] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('company', 'compani'), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('analyse', 'analys'), ('consumer', 'consum'), ('behaviours', 'behaviour'), ('upgrade', 'upgrad'), ('services', 'servic'), ('forecast', 'forecast'), ('customer', 'custom'), ('behaviours', 'behaviour'), (',', ','), ('allow', 'allow'), ('fraud', 'fraud'), ('detection', 'detect'), (',', ','), ('determine', 'determin'), ('financial', 'financi'), ('risk', 'risk'), ('assessments', 'assess'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('company', 'compani'), ('uses', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('analyse', 'analys'), ('consumer', 'consum'), ('behaviours', 'behaviour'), ('upgrade', 'upgrad'), ('services', 'servic'), ('forecast', 'forecast'), ('customer', 'custom'), ('behaviours', 'behaviour'), (',', ','), ('allow', 'allow'), ('fraud', 'fraud'), ('detection', 'detect'), (',', ','), ('determine', 'determin'), ('financial', 'financi'), ('risk', 'risk'), ('assessments', 'assess'), ('(', '('), ('Zhong', 'zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('company', 'company'), ('uses', 'us'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('analyse', 'analyse'), ('consumer', 'consumer'), ('behaviours', 'behaviour'), ('upgrade', 'upgrade'), ('services', 'service'), ('forecast', 'forecast'), ('customer', 'customer'), ('behaviours', 'behaviour'), (',', ','), ('allow', 'allow'), ('fraud', 'fraud'), ('detection', 'detection'), (',', ','), ('determine', 'determine'), ('financial', 'financial'), ('risk', 'risk'), ('assessments', 'assessment'), ('(', '('), ('Zhong', 'Zhong'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 567 =============================

10.3. 


>> Tokens are: 
 ['10.3', '.']

>> Bigrams are: 
 [('10.3', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('10.3', 'CD'), ('.', '.')]

 (S 10.3/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('10.3', '10.3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('10.3', '10.3'), ('.', '.')]

>> Lemmatization: 
 [('10.3', '10.3'), ('.', '.')]



============================ Sentence 568 =============================

Retail   Big data analytics has a massive impact on retail industries, improving the customer experience   and reducing fraud (Wamba et al., 2017). 


>> Tokens are: 
 ['Retail', 'Big', 'data', 'analytics', 'massive', 'impact', 'retail', 'industries', ',', 'improving', 'customer', 'experience', 'reducing', 'fraud', '(', 'Wamba', 'et', 'al.', ',', '2017', ')', '.']

>> Bigrams are: 
 [('Retail', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', 'massive'), ('massive', 'impact'), ('impact', 'retail'), ('retail', 'industries'), ('industries', ','), (',', 'improving'), ('improving', 'customer'), ('customer', 'experience'), ('experience', 'reducing'), ('reducing', 'fraud'), ('fraud', '('), ('(', 'Wamba'), ('Wamba', 'et'), ('et', 'al.'), ('al.', ','), (',', '2017'), ('2017', ')'), (')', '.')]

>> Trigrams are: 
 [('Retail', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', 'massive'), ('analytics', 'massive', 'impact'), ('massive', 'impact', 'retail'), ('impact', 'retail', 'industries'), ('retail', 'industries', ','), ('industries', ',', 'improving'), (',', 'improving', 'customer'), ('improving', 'customer', 'experience'), ('customer', 'experience', 'reducing'), ('experience', 'reducing', 'fraud'), ('reducing', 'fraud', '('), ('fraud', '(', 'Wamba'), ('(', 'Wamba', 'et'), ('Wamba', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2017'), (',', '2017', ')'), ('2017', ')', '.')]

>> POS Tags are: 
 [('Retail', 'JJ'), ('Big', 'NNP'), ('data', 'NN'), ('analytics', 'NNS'), ('massive', 'JJ'), ('impact', 'NN'), ('retail', 'JJ'), ('industries', 'NNS'), (',', ','), ('improving', 'VBG'), ('customer', 'NN'), ('experience', 'NN'), ('reducing', 'VBG'), ('fraud', 'NN'), ('(', '('), ('Wamba', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2017', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Retail/JJ Big/NNP data/NN analytics/NNS)
  (NP massive/JJ impact/NN)
  (NP retail/JJ industries/NNS)
  ,/,
  improving/VBG
  (NP customer/NN experience/NN)
  reducing/VBG
  (NP fraud/NN)
  (/(
  (NP Wamba/NNP)
  et/RB
  al./RB
  ,/,
  2017/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Retail Big data analytics', 'massive impact', 'retail industries', 'customer experience', 'fraud', 'Wamba']

>> Named Entities are: 
 [('PERSON', 'Retail'), ('PERSON', 'Wamba')] 

>> Stemming using Porter Stemmer: 
 [('Retail', 'retail'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('massive', 'massiv'), ('impact', 'impact'), ('retail', 'retail'), ('industries', 'industri'), (',', ','), ('improving', 'improv'), ('customer', 'custom'), ('experience', 'experi'), ('reducing', 'reduc'), ('fraud', 'fraud'), ('(', '('), ('Wamba', 'wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Retail', 'retail'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('massive', 'massiv'), ('impact', 'impact'), ('retail', 'retail'), ('industries', 'industri'), (',', ','), ('improving', 'improv'), ('customer', 'custom'), ('experience', 'experi'), ('reducing', 'reduc'), ('fraud', 'fraud'), ('(', '('), ('Wamba', 'wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Retail', 'Retail'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('massive', 'massive'), ('impact', 'impact'), ('retail', 'retail'), ('industries', 'industry'), (',', ','), ('improving', 'improving'), ('customer', 'customer'), ('experience', 'experience'), ('reducing', 'reducing'), ('fraud', 'fraud'), ('(', '('), ('Wamba', 'Wamba'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2017', '2017'), (')', ')'), ('.', '.')]



============================ Sentence 569 =============================

The retail sector is of major importance in modern society, as almost everyone nowadays musy   buy their basic needs. 


>> Tokens are: 
 ['The', 'retail', 'sector', 'major', 'importance', 'modern', 'society', ',', 'almost', 'everyone', 'nowadays', 'musy', 'buy', 'basic', 'needs', '.']

>> Bigrams are: 
 [('The', 'retail'), ('retail', 'sector'), ('sector', 'major'), ('major', 'importance'), ('importance', 'modern'), ('modern', 'society'), ('society', ','), (',', 'almost'), ('almost', 'everyone'), ('everyone', 'nowadays'), ('nowadays', 'musy'), ('musy', 'buy'), ('buy', 'basic'), ('basic', 'needs'), ('needs', '.')]

>> Trigrams are: 
 [('The', 'retail', 'sector'), ('retail', 'sector', 'major'), ('sector', 'major', 'importance'), ('major', 'importance', 'modern'), ('importance', 'modern', 'society'), ('modern', 'society', ','), ('society', ',', 'almost'), (',', 'almost', 'everyone'), ('almost', 'everyone', 'nowadays'), ('everyone', 'nowadays', 'musy'), ('nowadays', 'musy', 'buy'), ('musy', 'buy', 'basic'), ('buy', 'basic', 'needs'), ('basic', 'needs', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('retail', 'JJ'), ('sector', 'NN'), ('major', 'JJ'), ('importance', 'NN'), ('modern', 'JJ'), ('society', 'NN'), (',', ','), ('almost', 'RB'), ('everyone', 'NN'), ('nowadays', 'JJ'), ('musy', 'JJ'), ('buy', 'NN'), ('basic', 'JJ'), ('needs', 'VBZ'), ('.', '.')]

 (S
  (NP The/DT retail/JJ sector/NN)
  (NP major/JJ importance/NN)
  (NP modern/JJ society/NN)
  ,/,
  almost/RB
  (NP everyone/NN)
  (NP nowadays/JJ musy/JJ buy/NN)
  basic/JJ
  needs/VBZ
  ./.) 


>> Noun Phrases are: 
 ['The retail sector', 'major importance', 'modern society', 'everyone', 'nowadays musy buy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('major', 'major'), ('importance', 'import'), ('modern', 'modern'), ('society', 'societi'), (',', ','), ('almost', 'almost'), ('everyone', 'everyon'), ('nowadays', 'nowaday'), ('musy', 'musi'), ('buy', 'buy'), ('basic', 'basic'), ('needs', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('major', 'major'), ('importance', 'import'), ('modern', 'modern'), ('society', 'societi'), (',', ','), ('almost', 'almost'), ('everyone', 'everyon'), ('nowadays', 'nowaday'), ('musy', 'musi'), ('buy', 'buy'), ('basic', 'basic'), ('needs', 'need'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('retail', 'retail'), ('sector', 'sector'), ('major', 'major'), ('importance', 'importance'), ('modern', 'modern'), ('society', 'society'), (',', ','), ('almost', 'almost'), ('everyone', 'everyone'), ('nowadays', 'nowadays'), ('musy', 'musy'), ('buy', 'buy'), ('basic', 'basic'), ('needs', 'need'), ('.', '.')]



============================ Sentence 570 =============================

Predicting demand for items allows retailers to offer better services to   customers (Singh et al., 2015; Lekhwar et al., 2019), and retailers can use customers’ billing data   to gather information for business intelligence. 


>> Tokens are: 
 ['Predicting', 'demand', 'items', 'allows', 'retailers', 'offer', 'better', 'services', 'customers', '(', 'Singh', 'et', 'al.', ',', '2015', ';', 'Lekhwar', 'et', 'al.', ',', '2019', ')', ',', 'retailers', 'use', 'customers', '’', 'billing', 'data', 'gather', 'information', 'business', 'intelligence', '.']

>> Bigrams are: 
 [('Predicting', 'demand'), ('demand', 'items'), ('items', 'allows'), ('allows', 'retailers'), ('retailers', 'offer'), ('offer', 'better'), ('better', 'services'), ('services', 'customers'), ('customers', '('), ('(', 'Singh'), ('Singh', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ';'), (';', 'Lekhwar'), ('Lekhwar', 'et'), ('et', 'al.'), ('al.', ','), (',', '2019'), ('2019', ')'), (')', ','), (',', 'retailers'), ('retailers', 'use'), ('use', 'customers'), ('customers', '’'), ('’', 'billing'), ('billing', 'data'), ('data', 'gather'), ('gather', 'information'), ('information', 'business'), ('business', 'intelligence'), ('intelligence', '.')]

>> Trigrams are: 
 [('Predicting', 'demand', 'items'), ('demand', 'items', 'allows'), ('items', 'allows', 'retailers'), ('allows', 'retailers', 'offer'), ('retailers', 'offer', 'better'), ('offer', 'better', 'services'), ('better', 'services', 'customers'), ('services', 'customers', '('), ('customers', '(', 'Singh'), ('(', 'Singh', 'et'), ('Singh', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ';'), ('2015', ';', 'Lekhwar'), (';', 'Lekhwar', 'et'), ('Lekhwar', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2019'), (',', '2019', ')'), ('2019', ')', ','), (')', ',', 'retailers'), (',', 'retailers', 'use'), ('retailers', 'use', 'customers'), ('use', 'customers', '’'), ('customers', '’', 'billing'), ('’', 'billing', 'data'), ('billing', 'data', 'gather'), ('data', 'gather', 'information'), ('gather', 'information', 'business'), ('information', 'business', 'intelligence'), ('business', 'intelligence', '.')]

>> POS Tags are: 
 [('Predicting', 'VBG'), ('demand', 'NN'), ('items', 'NNS'), ('allows', 'VBZ'), ('retailers', 'NNS'), ('offer', 'VBP'), ('better', 'JJR'), ('services', 'NNS'), ('customers', 'NNS'), ('(', '('), ('Singh', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (';', ':'), ('Lekhwar', 'NNP'), ('et', 'FW'), ('al.', 'NN'), (',', ','), ('2019', 'CD'), (')', ')'), (',', ','), ('retailers', 'NNS'), ('use', 'VBP'), ('customers', 'NNS'), ('’', 'VBP'), ('billing', 'VBG'), ('data', 'NNS'), ('gather', 'CC'), ('information', 'NN'), ('business', 'NN'), ('intelligence', 'NN'), ('.', '.')]

 (S
  Predicting/VBG
  (NP demand/NN items/NNS)
  allows/VBZ
  (NP retailers/NNS)
  offer/VBP
  better/JJR
  (NP services/NNS customers/NNS)
  (/(
  (NP Singh/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  ;/:
  (NP Lekhwar/NNP)
  et/FW
  (NP al./NN)
  ,/,
  2019/CD
  )/)
  ,/,
  (NP retailers/NNS)
  use/VBP
  (NP customers/NNS)
  ’/VBP
  billing/VBG
  (NP data/NNS)
  gather/CC
  (NP information/NN business/NN intelligence/NN)
  ./.) 


>> Noun Phrases are: 
 ['demand items', 'retailers', 'services customers', 'Singh', 'Lekhwar', 'al.', 'retailers', 'customers', 'data', 'information business intelligence']

>> Named Entities are: 
 [('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('Predicting', 'predict'), ('demand', 'demand'), ('items', 'item'), ('allows', 'allow'), ('retailers', 'retail'), ('offer', 'offer'), ('better', 'better'), ('services', 'servic'), ('customers', 'custom'), ('(', '('), ('Singh', 'singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Lekhwar', 'lekhwar'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('retailers', 'retail'), ('use', 'use'), ('customers', 'custom'), ('’', '’'), ('billing', 'bill'), ('data', 'data'), ('gather', 'gather'), ('information', 'inform'), ('business', 'busi'), ('intelligence', 'intellig'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Predicting', 'predict'), ('demand', 'demand'), ('items', 'item'), ('allows', 'allow'), ('retailers', 'retail'), ('offer', 'offer'), ('better', 'better'), ('services', 'servic'), ('customers', 'custom'), ('(', '('), ('Singh', 'singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Lekhwar', 'lekhwar'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('retailers', 'retail'), ('use', 'use'), ('customers', 'custom'), ('’', '’'), ('billing', 'bill'), ('data', 'data'), ('gather', 'gather'), ('information', 'inform'), ('business', 'busi'), ('intelligence', 'intellig'), ('.', '.')]

>> Lemmatization: 
 [('Predicting', 'Predicting'), ('demand', 'demand'), ('items', 'item'), ('allows', 'allows'), ('retailers', 'retailer'), ('offer', 'offer'), ('better', 'better'), ('services', 'service'), ('customers', 'customer'), ('(', '('), ('Singh', 'Singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (';', ';'), ('Lekhwar', 'Lekhwar'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2019', '2019'), (')', ')'), (',', ','), ('retailers', 'retailer'), ('use', 'use'), ('customers', 'customer'), ('’', '’'), ('billing', 'billing'), ('data', 'data'), ('gather', 'gather'), ('information', 'information'), ('business', 'business'), ('intelligence', 'intelligence'), ('.', '.')]



============================ Sentence 571 =============================

A Hadoop distributed file system (HDFS) tool is   using to store, process, and analyse such data to allow the extraction of more information (Singh   et al., 2015). 


>> Tokens are: 
 ['A', 'Hadoop', 'distributed', 'file', 'system', '(', 'HDFS', ')', 'tool', 'using', 'store', ',', 'process', ',', 'analyse', 'data', 'allow', 'extraction', 'information', '(', 'Singh', 'et', 'al.', ',', '2015', ')', '.']

>> Bigrams are: 
 [('A', 'Hadoop'), ('Hadoop', 'distributed'), ('distributed', 'file'), ('file', 'system'), ('system', '('), ('(', 'HDFS'), ('HDFS', ')'), (')', 'tool'), ('tool', 'using'), ('using', 'store'), ('store', ','), (',', 'process'), ('process', ','), (',', 'analyse'), ('analyse', 'data'), ('data', 'allow'), ('allow', 'extraction'), ('extraction', 'information'), ('information', '('), ('(', 'Singh'), ('Singh', 'et'), ('et', 'al.'), ('al.', ','), (',', '2015'), ('2015', ')'), (')', '.')]

>> Trigrams are: 
 [('A', 'Hadoop', 'distributed'), ('Hadoop', 'distributed', 'file'), ('distributed', 'file', 'system'), ('file', 'system', '('), ('system', '(', 'HDFS'), ('(', 'HDFS', ')'), ('HDFS', ')', 'tool'), (')', 'tool', 'using'), ('tool', 'using', 'store'), ('using', 'store', ','), ('store', ',', 'process'), (',', 'process', ','), ('process', ',', 'analyse'), (',', 'analyse', 'data'), ('analyse', 'data', 'allow'), ('data', 'allow', 'extraction'), ('allow', 'extraction', 'information'), ('extraction', 'information', '('), ('information', '(', 'Singh'), ('(', 'Singh', 'et'), ('Singh', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2015'), (',', '2015', ')'), ('2015', ')', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('Hadoop', 'NNP'), ('distributed', 'VBN'), ('file', 'NN'), ('system', 'NN'), ('(', '('), ('HDFS', 'NNP'), (')', ')'), ('tool', 'NN'), ('using', 'VBG'), ('store', 'NN'), (',', ','), ('process', 'NN'), (',', ','), ('analyse', 'NN'), ('data', 'NNS'), ('allow', 'VBP'), ('extraction', 'NN'), ('information', 'NN'), ('(', '('), ('Singh', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2015', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP A/DT Hadoop/NNP)
  distributed/VBN
  (NP file/NN system/NN)
  (/(
  (NP HDFS/NNP)
  )/)
  (NP tool/NN)
  using/VBG
  (NP store/NN)
  ,/,
  (NP process/NN)
  ,/,
  (NP analyse/NN data/NNS)
  allow/VBP
  (NP extraction/NN information/NN)
  (/(
  (NP Singh/NNP)
  et/RB
  al./RB
  ,/,
  2015/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['A Hadoop', 'file system', 'HDFS', 'tool', 'store', 'process', 'analyse data', 'extraction information', 'Singh']

>> Named Entities are: 
 [('ORGANIZATION', 'HDFS'), ('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Hadoop', 'hadoop'), ('distributed', 'distribut'), ('file', 'file'), ('system', 'system'), ('(', '('), ('HDFS', 'hdf'), (')', ')'), ('tool', 'tool'), ('using', 'use'), ('store', 'store'), (',', ','), ('process', 'process'), (',', ','), ('analyse', 'analys'), ('data', 'data'), ('allow', 'allow'), ('extraction', 'extract'), ('information', 'inform'), ('(', '('), ('Singh', 'singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Hadoop', 'hadoop'), ('distributed', 'distribut'), ('file', 'file'), ('system', 'system'), ('(', '('), ('HDFS', 'hdfs'), (')', ')'), ('tool', 'tool'), ('using', 'use'), ('store', 'store'), (',', ','), ('process', 'process'), (',', ','), ('analyse', 'analys'), ('data', 'data'), ('allow', 'allow'), ('extraction', 'extract'), ('information', 'inform'), ('(', '('), ('Singh', 'singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('Hadoop', 'Hadoop'), ('distributed', 'distributed'), ('file', 'file'), ('system', 'system'), ('(', '('), ('HDFS', 'HDFS'), (')', ')'), ('tool', 'tool'), ('using', 'using'), ('store', 'store'), (',', ','), ('process', 'process'), (',', ','), ('analyse', 'analyse'), ('data', 'data'), ('allow', 'allow'), ('extraction', 'extraction'), ('information', 'information'), ('(', '('), ('Singh', 'Singh'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2015', '2015'), (')', ')'), ('.', '.')]



============================ Sentence 572 =============================

Big data analytics provides these organisations with more information on market decisions and   help in segmenting customer based on their characteristics. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'provides', 'organisations', 'information', 'market', 'decisions', 'help', 'segmenting', 'customer', 'based', 'characteristics', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'provides'), ('provides', 'organisations'), ('organisations', 'information'), ('information', 'market'), ('market', 'decisions'), ('decisions', 'help'), ('help', 'segmenting'), ('segmenting', 'customer'), ('customer', 'based'), ('based', 'characteristics'), ('characteristics', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'provides'), ('analytics', 'provides', 'organisations'), ('provides', 'organisations', 'information'), ('organisations', 'information', 'market'), ('information', 'market', 'decisions'), ('market', 'decisions', 'help'), ('decisions', 'help', 'segmenting'), ('help', 'segmenting', 'customer'), ('segmenting', 'customer', 'based'), ('customer', 'based', 'characteristics'), ('based', 'characteristics', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('provides', 'VBZ'), ('organisations', 'NNS'), ('information', 'NN'), ('market', 'NN'), ('decisions', 'NNS'), ('help', 'VBP'), ('segmenting', 'VBG'), ('customer', 'NN'), ('based', 'VBN'), ('characteristics', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  provides/VBZ
  (NP organisations/NNS information/NN market/NN decisions/NNS)
  help/VBP
  segmenting/VBG
  (NP customer/NN)
  based/VBN
  (NP characteristics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'organisations information market decisions', 'customer', 'characteristics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('provides', 'provid'), ('organisations', 'organis'), ('information', 'inform'), ('market', 'market'), ('decisions', 'decis'), ('help', 'help'), ('segmenting', 'segment'), ('customer', 'custom'), ('based', 'base'), ('characteristics', 'characterist'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('provides', 'provid'), ('organisations', 'organis'), ('information', 'inform'), ('market', 'market'), ('decisions', 'decis'), ('help', 'help'), ('segmenting', 'segment'), ('customer', 'custom'), ('based', 'base'), ('characteristics', 'characterist'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('provides', 'provides'), ('organisations', 'organisation'), ('information', 'information'), ('market', 'market'), ('decisions', 'decision'), ('help', 'help'), ('segmenting', 'segmenting'), ('customer', 'customer'), ('based', 'based'), ('characteristics', 'characteristic'), ('.', '.')]



============================ Sentence 573 =============================

Social media analytics can also be used   to inform companies about what their customers prefer. 


>> Tokens are: 
 ['Social', 'media', 'analytics', 'also', 'used', 'inform', 'companies', 'customers', 'prefer', '.']

>> Bigrams are: 
 [('Social', 'media'), ('media', 'analytics'), ('analytics', 'also'), ('also', 'used'), ('used', 'inform'), ('inform', 'companies'), ('companies', 'customers'), ('customers', 'prefer'), ('prefer', '.')]

>> Trigrams are: 
 [('Social', 'media', 'analytics'), ('media', 'analytics', 'also'), ('analytics', 'also', 'used'), ('also', 'used', 'inform'), ('used', 'inform', 'companies'), ('inform', 'companies', 'customers'), ('companies', 'customers', 'prefer'), ('customers', 'prefer', '.')]

>> POS Tags are: 
 [('Social', 'JJ'), ('media', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('inform', 'NN'), ('companies', 'NNS'), ('customers', 'NNS'), ('prefer', 'VBP'), ('.', '.')]

 (S
  (NP Social/JJ media/NNS analytics/NNS)
  also/RB
  used/VBD
  (NP inform/NN companies/NNS customers/NNS)
  prefer/VBP
  ./.) 


>> Noun Phrases are: 
 ['Social media analytics', 'inform companies customers']

>> Named Entities are: 
 [('GPE', 'Social')] 

>> Stemming using Porter Stemmer: 
 [('Social', 'social'), ('media', 'media'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use'), ('inform', 'inform'), ('companies', 'compani'), ('customers', 'custom'), ('prefer', 'prefer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Social', 'social'), ('media', 'media'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use'), ('inform', 'inform'), ('companies', 'compani'), ('customers', 'custom'), ('prefer', 'prefer'), ('.', '.')]

>> Lemmatization: 
 [('Social', 'Social'), ('media', 'medium'), ('analytics', 'analytics'), ('also', 'also'), ('used', 'used'), ('inform', 'inform'), ('companies', 'company'), ('customers', 'customer'), ('prefer', 'prefer'), ('.', '.')]



============================ Sentence 574 =============================

Applying sentiment analysis to such data   provides the organisation with early warnings when the customer turns to different products,   allowing action to be taken by the organisation (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 ['Applying', 'sentiment', 'analysis', 'data', 'provides', 'organisation', 'early', 'warnings', 'customer', 'turns', 'different', 'products', ',', 'allowing', 'action', 'taken', 'organisation', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Applying', 'sentiment'), ('sentiment', 'analysis'), ('analysis', 'data'), ('data', 'provides'), ('provides', 'organisation'), ('organisation', 'early'), ('early', 'warnings'), ('warnings', 'customer'), ('customer', 'turns'), ('turns', 'different'), ('different', 'products'), ('products', ','), (',', 'allowing'), ('allowing', 'action'), ('action', 'taken'), ('taken', 'organisation'), ('organisation', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Applying', 'sentiment', 'analysis'), ('sentiment', 'analysis', 'data'), ('analysis', 'data', 'provides'), ('data', 'provides', 'organisation'), ('provides', 'organisation', 'early'), ('organisation', 'early', 'warnings'), ('early', 'warnings', 'customer'), ('warnings', 'customer', 'turns'), ('customer', 'turns', 'different'), ('turns', 'different', 'products'), ('different', 'products', ','), ('products', ',', 'allowing'), (',', 'allowing', 'action'), ('allowing', 'action', 'taken'), ('action', 'taken', 'organisation'), ('taken', 'organisation', '('), ('organisation', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Applying', 'VBG'), ('sentiment', 'NN'), ('analysis', 'NN'), ('data', 'NNS'), ('provides', 'VBZ'), ('organisation', 'NN'), ('early', 'JJ'), ('warnings', 'NNS'), ('customer', 'NN'), ('turns', 'VBZ'), ('different', 'JJ'), ('products', 'NNS'), (',', ','), ('allowing', 'VBG'), ('action', 'NN'), ('taken', 'VBN'), ('organisation', 'NN'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  Applying/VBG
  (NP sentiment/NN analysis/NN data/NNS)
  provides/VBZ
  (NP organisation/NN)
  (NP early/JJ warnings/NNS customer/NN)
  turns/VBZ
  (NP different/JJ products/NNS)
  ,/,
  allowing/VBG
  (NP action/NN)
  taken/VBN
  (NP organisation/NN)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['sentiment analysis data', 'organisation', 'early warnings customer', 'different products', 'action', 'organisation', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Applying', 'appli'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('data', 'data'), ('provides', 'provid'), ('organisation', 'organis'), ('early', 'earli'), ('warnings', 'warn'), ('customer', 'custom'), ('turns', 'turn'), ('different', 'differ'), ('products', 'product'), (',', ','), ('allowing', 'allow'), ('action', 'action'), ('taken', 'taken'), ('organisation', 'organis'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Applying', 'appli'), ('sentiment', 'sentiment'), ('analysis', 'analysi'), ('data', 'data'), ('provides', 'provid'), ('organisation', 'organis'), ('early', 'earli'), ('warnings', 'warn'), ('customer', 'custom'), ('turns', 'turn'), ('different', 'differ'), ('products', 'product'), (',', ','), ('allowing', 'allow'), ('action', 'action'), ('taken', 'taken'), ('organisation', 'organis'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Applying', 'Applying'), ('sentiment', 'sentiment'), ('analysis', 'analysis'), ('data', 'data'), ('provides', 'provides'), ('organisation', 'organisation'), ('early', 'early'), ('warnings', 'warning'), ('customer', 'customer'), ('turns', 'turn'), ('different', 'different'), ('products', 'product'), (',', ','), ('allowing', 'allowing'), ('action', 'action'), ('taken', 'taken'), ('organisation', 'organisation'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 575 =============================

Organisations have used segmentation of customers for many years, but this is now assisted by   complex big data techniques such as real-time micro-segmentation which offers better-targeted   advertising (Manyika et al., 2011; Elgendy and Elragal, 2014). 


>> Tokens are: 
 ['Organisations', 'used', 'segmentation', 'customers', 'many', 'years', ',', 'assisted', 'complex', 'big', 'data', 'techniques', 'real-time', 'micro-segmentation', 'offers', 'better-targeted', 'advertising', '(', 'Manyika', 'et', 'al.', ',', '2011', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Organisations', 'used'), ('used', 'segmentation'), ('segmentation', 'customers'), ('customers', 'many'), ('many', 'years'), ('years', ','), (',', 'assisted'), ('assisted', 'complex'), ('complex', 'big'), ('big', 'data'), ('data', 'techniques'), ('techniques', 'real-time'), ('real-time', 'micro-segmentation'), ('micro-segmentation', 'offers'), ('offers', 'better-targeted'), ('better-targeted', 'advertising'), ('advertising', '('), ('(', 'Manyika'), ('Manyika', 'et'), ('et', 'al.'), ('al.', ','), (',', '2011'), ('2011', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Organisations', 'used', 'segmentation'), ('used', 'segmentation', 'customers'), ('segmentation', 'customers', 'many'), ('customers', 'many', 'years'), ('many', 'years', ','), ('years', ',', 'assisted'), (',', 'assisted', 'complex'), ('assisted', 'complex', 'big'), ('complex', 'big', 'data'), ('big', 'data', 'techniques'), ('data', 'techniques', 'real-time'), ('techniques', 'real-time', 'micro-segmentation'), ('real-time', 'micro-segmentation', 'offers'), ('micro-segmentation', 'offers', 'better-targeted'), ('offers', 'better-targeted', 'advertising'), ('better-targeted', 'advertising', '('), ('advertising', '(', 'Manyika'), ('(', 'Manyika', 'et'), ('Manyika', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('used', 'VBN'), ('segmentation', 'NN'), ('customers', 'NNS'), ('many', 'JJ'), ('years', 'NNS'), (',', ','), ('assisted', 'VBD'), ('complex', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('techniques', 'NNS'), ('real-time', 'JJ'), ('micro-segmentation', 'NN'), ('offers', 'NNS'), ('better-targeted', 'JJ'), ('advertising', 'NN'), ('(', '('), ('Manyika', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Organisations/NNS)
  used/VBN
  (NP segmentation/NN customers/NNS)
  (NP many/JJ years/NNS)
  ,/,
  assisted/VBD
  (NP complex/JJ big/JJ data/NNS techniques/NNS)
  (NP real-time/JJ micro-segmentation/NN offers/NNS)
  (NP better-targeted/JJ advertising/NN)
  (/(
  (NP Manyika/NNP)
  et/RB
  al./RB
  ,/,
  2011/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Organisations', 'segmentation customers', 'many years', 'complex big data techniques', 'real-time micro-segmentation offers', 'better-targeted advertising', 'Manyika', 'Elgendy Elragal']

>> Named Entities are: 
 [('PERSON', 'Manyika'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('used', 'use'), ('segmentation', 'segment'), ('customers', 'custom'), ('many', 'mani'), ('years', 'year'), (',', ','), ('assisted', 'assist'), ('complex', 'complex'), ('big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('real-time', 'real-tim'), ('micro-segmentation', 'micro-segment'), ('offers', 'offer'), ('better-targeted', 'better-target'), ('advertising', 'advertis'), ('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('used', 'use'), ('segmentation', 'segment'), ('customers', 'custom'), ('many', 'mani'), ('years', 'year'), (',', ','), ('assisted', 'assist'), ('complex', 'complex'), ('big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('real-time', 'real-tim'), ('micro-segmentation', 'micro-segment'), ('offers', 'offer'), ('better-targeted', 'better-target'), ('advertising', 'advertis'), ('(', '('), ('Manyika', 'manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('used', 'used'), ('segmentation', 'segmentation'), ('customers', 'customer'), ('many', 'many'), ('years', 'year'), (',', ','), ('assisted', 'assisted'), ('complex', 'complex'), ('big', 'big'), ('data', 'data'), ('techniques', 'technique'), ('real-time', 'real-time'), ('micro-segmentation', 'micro-segmentation'), ('offers', 'offer'), ('better-targeted', 'better-targeted'), ('advertising', 'advertising'), ('(', '('), ('Manyika', 'Manyika'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 576 =============================

Organisations can also gain better   targets for social marketing by understanding customer behaviors and predicting market sentiment   trends (Russom, 2011; Elgendy and Elragal, 2014). 


>> Tokens are: 
 ['Organisations', 'also', 'gain', 'better', 'targets', 'social', 'marketing', 'understanding', 'customer', 'behaviors', 'predicting', 'market', 'sentiment', 'trends', '(', 'Russom', ',', '2011', ';', 'Elgendy', 'Elragal', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Organisations', 'also'), ('also', 'gain'), ('gain', 'better'), ('better', 'targets'), ('targets', 'social'), ('social', 'marketing'), ('marketing', 'understanding'), ('understanding', 'customer'), ('customer', 'behaviors'), ('behaviors', 'predicting'), ('predicting', 'market'), ('market', 'sentiment'), ('sentiment', 'trends'), ('trends', '('), ('(', 'Russom'), ('Russom', ','), (',', '2011'), ('2011', ';'), (';', 'Elgendy'), ('Elgendy', 'Elragal'), ('Elragal', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Organisations', 'also', 'gain'), ('also', 'gain', 'better'), ('gain', 'better', 'targets'), ('better', 'targets', 'social'), ('targets', 'social', 'marketing'), ('social', 'marketing', 'understanding'), ('marketing', 'understanding', 'customer'), ('understanding', 'customer', 'behaviors'), ('customer', 'behaviors', 'predicting'), ('behaviors', 'predicting', 'market'), ('predicting', 'market', 'sentiment'), ('market', 'sentiment', 'trends'), ('sentiment', 'trends', '('), ('trends', '(', 'Russom'), ('(', 'Russom', ','), ('Russom', ',', '2011'), (',', '2011', ';'), ('2011', ';', 'Elgendy'), (';', 'Elgendy', 'Elragal'), ('Elgendy', 'Elragal', ','), ('Elragal', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Organisations', 'NNS'), ('also', 'RB'), ('gain', 'VBP'), ('better', 'JJR'), ('targets', 'NNS'), ('social', 'JJ'), ('marketing', 'NN'), ('understanding', 'VBG'), ('customer', 'NN'), ('behaviors', 'NNS'), ('predicting', 'VBG'), ('market', 'NN'), ('sentiment', 'NN'), ('trends', 'NNS'), ('(', '('), ('Russom', 'NNP'), (',', ','), ('2011', 'CD'), (';', ':'), ('Elgendy', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Organisations/NNS)
  also/RB
  gain/VBP
  better/JJR
  (NP targets/NNS)
  (NP social/JJ marketing/NN)
  understanding/VBG
  (NP customer/NN behaviors/NNS)
  predicting/VBG
  (NP market/NN sentiment/NN trends/NNS)
  (/(
  (NP Russom/NNP)
  ,/,
  2011/CD
  ;/:
  (NP Elgendy/NNP Elragal/NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Organisations', 'targets', 'social marketing', 'customer behaviors', 'market sentiment trends', 'Russom', 'Elgendy Elragal']

>> Named Entities are: 
 [('GPE', 'Russom'), ('PERSON', 'Elgendy Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Organisations', 'organis'), ('also', 'also'), ('gain', 'gain'), ('better', 'better'), ('targets', 'target'), ('social', 'social'), ('marketing', 'market'), ('understanding', 'understand'), ('customer', 'custom'), ('behaviors', 'behavior'), ('predicting', 'predict'), ('market', 'market'), ('sentiment', 'sentiment'), ('trends', 'trend'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Organisations', 'organis'), ('also', 'also'), ('gain', 'gain'), ('better', 'better'), ('targets', 'target'), ('social', 'social'), ('marketing', 'market'), ('understanding', 'understand'), ('customer', 'custom'), ('behaviors', 'behavior'), ('predicting', 'predict'), ('market', 'market'), ('sentiment', 'sentiment'), ('trends', 'trend'), ('(', '('), ('Russom', 'russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'elgendi'), ('Elragal', 'elrag'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Organisations', 'Organisations'), ('also', 'also'), ('gain', 'gain'), ('better', 'better'), ('targets', 'target'), ('social', 'social'), ('marketing', 'marketing'), ('understanding', 'understanding'), ('customer', 'customer'), ('behaviors', 'behavior'), ('predicting', 'predicting'), ('market', 'market'), ('sentiment', 'sentiment'), ('trends', 'trend'), ('(', '('), ('Russom', 'Russom'), (',', ','), ('2011', '2011'), (';', ';'), ('Elgendy', 'Elgendy'), ('Elragal', 'Elragal'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 577 =============================

Retailers are thus using data analytics in order to address new challenges and find opportunities   based on increases in market expectations, competition, and volatility. 


>> Tokens are: 
 ['Retailers', 'thus', 'using', 'data', 'analytics', 'order', 'address', 'new', 'challenges', 'find', 'opportunities', 'based', 'increases', 'market', 'expectations', ',', 'competition', ',', 'volatility', '.']

>> Bigrams are: 
 [('Retailers', 'thus'), ('thus', 'using'), ('using', 'data'), ('data', 'analytics'), ('analytics', 'order'), ('order', 'address'), ('address', 'new'), ('new', 'challenges'), ('challenges', 'find'), ('find', 'opportunities'), ('opportunities', 'based'), ('based', 'increases'), ('increases', 'market'), ('market', 'expectations'), ('expectations', ','), (',', 'competition'), ('competition', ','), (',', 'volatility'), ('volatility', '.')]

>> Trigrams are: 
 [('Retailers', 'thus', 'using'), ('thus', 'using', 'data'), ('using', 'data', 'analytics'), ('data', 'analytics', 'order'), ('analytics', 'order', 'address'), ('order', 'address', 'new'), ('address', 'new', 'challenges'), ('new', 'challenges', 'find'), ('challenges', 'find', 'opportunities'), ('find', 'opportunities', 'based'), ('opportunities', 'based', 'increases'), ('based', 'increases', 'market'), ('increases', 'market', 'expectations'), ('market', 'expectations', ','), ('expectations', ',', 'competition'), (',', 'competition', ','), ('competition', ',', 'volatility'), (',', 'volatility', '.')]

>> POS Tags are: 
 [('Retailers', 'NNS'), ('thus', 'RB'), ('using', 'VBG'), ('data', 'NNS'), ('analytics', 'NNS'), ('order', 'NN'), ('address', 'IN'), ('new', 'JJ'), ('challenges', 'NNS'), ('find', 'VBP'), ('opportunities', 'NNS'), ('based', 'VBN'), ('increases', 'NNS'), ('market', 'NN'), ('expectations', 'NNS'), (',', ','), ('competition', 'NN'), (',', ','), ('volatility', 'NN'), ('.', '.')]

 (S
  (NP Retailers/NNS)
  thus/RB
  using/VBG
  (NP data/NNS analytics/NNS order/NN)
  address/IN
  (NP new/JJ challenges/NNS)
  find/VBP
  (NP opportunities/NNS)
  based/VBN
  (NP increases/NNS market/NN expectations/NNS)
  ,/,
  (NP competition/NN)
  ,/,
  (NP volatility/NN)
  ./.) 


>> Noun Phrases are: 
 ['Retailers', 'data analytics order', 'new challenges', 'opportunities', 'increases market expectations', 'competition', 'volatility']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Retailers', 'retail'), ('thus', 'thu'), ('using', 'use'), ('data', 'data'), ('analytics', 'analyt'), ('order', 'order'), ('address', 'address'), ('new', 'new'), ('challenges', 'challeng'), ('find', 'find'), ('opportunities', 'opportun'), ('based', 'base'), ('increases', 'increas'), ('market', 'market'), ('expectations', 'expect'), (',', ','), ('competition', 'competit'), (',', ','), ('volatility', 'volatil'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Retailers', 'retail'), ('thus', 'thus'), ('using', 'use'), ('data', 'data'), ('analytics', 'analyt'), ('order', 'order'), ('address', 'address'), ('new', 'new'), ('challenges', 'challeng'), ('find', 'find'), ('opportunities', 'opportun'), ('based', 'base'), ('increases', 'increas'), ('market', 'market'), ('expectations', 'expect'), (',', ','), ('competition', 'competit'), (',', ','), ('volatility', 'volatil'), ('.', '.')]

>> Lemmatization: 
 [('Retailers', 'Retailers'), ('thus', 'thus'), ('using', 'using'), ('data', 'data'), ('analytics', 'analytics'), ('order', 'order'), ('address', 'address'), ('new', 'new'), ('challenges', 'challenge'), ('find', 'find'), ('opportunities', 'opportunity'), ('based', 'based'), ('increases', 'increase'), ('market', 'market'), ('expectations', 'expectation'), (',', ','), ('competition', 'competition'), (',', ','), ('volatility', 'volatility'), ('.', '.')]



============================ Sentence 578 =============================

In many companies,   additional accuracy, clarity, and insight can be provided by the adoption of data analytics   techniques, and such intelligence can be extended toward industry supply chains (Hofmann et al.,   2018). 


>> Tokens are: 
 ['In', 'many', 'companies', ',', 'additional', 'accuracy', ',', 'clarity', ',', 'insight', 'provided', 'adoption', 'data', 'analytics', 'techniques', ',', 'intelligence', 'extended', 'toward', 'industry', 'supply', 'chains', '(', 'Hofmann', 'et', 'al.', ',', '2018', ')', '.']

>> Bigrams are: 
 [('In', 'many'), ('many', 'companies'), ('companies', ','), (',', 'additional'), ('additional', 'accuracy'), ('accuracy', ','), (',', 'clarity'), ('clarity', ','), (',', 'insight'), ('insight', 'provided'), ('provided', 'adoption'), ('adoption', 'data'), ('data', 'analytics'), ('analytics', 'techniques'), ('techniques', ','), (',', 'intelligence'), ('intelligence', 'extended'), ('extended', 'toward'), ('toward', 'industry'), ('industry', 'supply'), ('supply', 'chains'), ('chains', '('), ('(', 'Hofmann'), ('Hofmann', 'et'), ('et', 'al.'), ('al.', ','), (',', '2018'), ('2018', ')'), (')', '.')]

>> Trigrams are: 
 [('In', 'many', 'companies'), ('many', 'companies', ','), ('companies', ',', 'additional'), (',', 'additional', 'accuracy'), ('additional', 'accuracy', ','), ('accuracy', ',', 'clarity'), (',', 'clarity', ','), ('clarity', ',', 'insight'), (',', 'insight', 'provided'), ('insight', 'provided', 'adoption'), ('provided', 'adoption', 'data'), ('adoption', 'data', 'analytics'), ('data', 'analytics', 'techniques'), ('analytics', 'techniques', ','), ('techniques', ',', 'intelligence'), (',', 'intelligence', 'extended'), ('intelligence', 'extended', 'toward'), ('extended', 'toward', 'industry'), ('toward', 'industry', 'supply'), ('industry', 'supply', 'chains'), ('supply', 'chains', '('), ('chains', '(', 'Hofmann'), ('(', 'Hofmann', 'et'), ('Hofmann', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2018'), (',', '2018', ')'), ('2018', ')', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('many', 'JJ'), ('companies', 'NNS'), (',', ','), ('additional', 'JJ'), ('accuracy', 'NN'), (',', ','), ('clarity', 'NN'), (',', ','), ('insight', 'NN'), ('provided', 'VBD'), ('adoption', 'NN'), ('data', 'NNS'), ('analytics', 'NNS'), ('techniques', 'NNS'), (',', ','), ('intelligence', 'NN'), ('extended', 'VBD'), ('toward', 'IN'), ('industry', 'NN'), ('supply', 'NN'), ('chains', 'NNS'), ('(', '('), ('Hofmann', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2018', 'CD'), (')', ')'), ('.', '.')]

 (S
  In/IN
  (NP many/JJ companies/NNS)
  ,/,
  (NP additional/JJ accuracy/NN)
  ,/,
  (NP clarity/NN)
  ,/,
  (NP insight/NN)
  provided/VBD
  (NP adoption/NN data/NNS analytics/NNS techniques/NNS)
  ,/,
  (NP intelligence/NN)
  extended/VBD
  toward/IN
  (NP industry/NN supply/NN chains/NNS)
  (/(
  (NP Hofmann/NNP)
  et/RB
  al./RB
  ,/,
  2018/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['many companies', 'additional accuracy', 'clarity', 'insight', 'adoption data analytics techniques', 'intelligence', 'industry supply chains', 'Hofmann']

>> Named Entities are: 
 [('PERSON', 'Hofmann')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('many', 'mani'), ('companies', 'compani'), (',', ','), ('additional', 'addit'), ('accuracy', 'accuraci'), (',', ','), ('clarity', 'clariti'), (',', ','), ('insight', 'insight'), ('provided', 'provid'), ('adoption', 'adopt'), ('data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), (',', ','), ('intelligence', 'intellig'), ('extended', 'extend'), ('toward', 'toward'), ('industry', 'industri'), ('supply', 'suppli'), ('chains', 'chain'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('many', 'mani'), ('companies', 'compani'), (',', ','), ('additional', 'addit'), ('accuracy', 'accuraci'), (',', ','), ('clarity', 'clariti'), (',', ','), ('insight', 'insight'), ('provided', 'provid'), ('adoption', 'adopt'), ('data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), (',', ','), ('intelligence', 'intellig'), ('extended', 'extend'), ('toward', 'toward'), ('industry', 'industri'), ('supply', 'suppli'), ('chains', 'chain'), ('(', '('), ('Hofmann', 'hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('many', 'many'), ('companies', 'company'), (',', ','), ('additional', 'additional'), ('accuracy', 'accuracy'), (',', ','), ('clarity', 'clarity'), (',', ','), ('insight', 'insight'), ('provided', 'provided'), ('adoption', 'adoption'), ('data', 'data'), ('analytics', 'analytics'), ('techniques', 'technique'), (',', ','), ('intelligence', 'intelligence'), ('extended', 'extended'), ('toward', 'toward'), ('industry', 'industry'), ('supply', 'supply'), ('chains', 'chain'), ('(', '('), ('Hofmann', 'Hofmann'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2018', '2018'), (')', ')'), ('.', '.')]



============================ Sentence 579 =============================

Sarah Al-Shiakhli   45         10.4. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '45', '10.4', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '45'), ('45', '10.4'), ('10.4', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '45'), ('Al-Shiakhli', '45', '10.4'), ('45', '10.4', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('45', 'CD'), ('10.4', 'CD'), ('.', '.')]

 (S (NP Sarah/NNP Al-Shiakhli/NNP) 45/CD 10.4/CD ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('45', '45'), ('10.4', '10.4'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('45', '45'), ('10.4', '10.4'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('45', '45'), ('10.4', '10.4'), ('.', '.')]



============================ Sentence 580 =============================

Telecommunications   Big data analytics can improve the quality of management in telecommunications by making use   of real-time data analyses and monitoring machine logs. 


>> Tokens are: 
 ['Telecommunications', 'Big', 'data', 'analytics', 'improve', 'quality', 'management', 'telecommunications', 'making', 'use', 'real-time', 'data', 'analyses', 'monitoring', 'machine', 'logs', '.']

>> Bigrams are: 
 [('Telecommunications', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', 'improve'), ('improve', 'quality'), ('quality', 'management'), ('management', 'telecommunications'), ('telecommunications', 'making'), ('making', 'use'), ('use', 'real-time'), ('real-time', 'data'), ('data', 'analyses'), ('analyses', 'monitoring'), ('monitoring', 'machine'), ('machine', 'logs'), ('logs', '.')]

>> Trigrams are: 
 [('Telecommunications', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', 'improve'), ('analytics', 'improve', 'quality'), ('improve', 'quality', 'management'), ('quality', 'management', 'telecommunications'), ('management', 'telecommunications', 'making'), ('telecommunications', 'making', 'use'), ('making', 'use', 'real-time'), ('use', 'real-time', 'data'), ('real-time', 'data', 'analyses'), ('data', 'analyses', 'monitoring'), ('analyses', 'monitoring', 'machine'), ('monitoring', 'machine', 'logs'), ('machine', 'logs', '.')]

>> POS Tags are: 
 [('Telecommunications', 'NNS'), ('Big', 'NNP'), ('data', 'NN'), ('analytics', 'NNS'), ('improve', 'VBP'), ('quality', 'NN'), ('management', 'NN'), ('telecommunications', 'NNS'), ('making', 'VBG'), ('use', 'JJ'), ('real-time', 'JJ'), ('data', 'NNS'), ('analyses', 'NNS'), ('monitoring', 'VBG'), ('machine', 'NN'), ('logs', 'NNS'), ('.', '.')]

 (S
  (NP Telecommunications/NNS Big/NNP data/NN analytics/NNS)
  improve/VBP
  (NP quality/NN management/NN telecommunications/NNS)
  making/VBG
  (NP use/JJ real-time/JJ data/NNS analyses/NNS)
  monitoring/VBG
  (NP machine/NN logs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Telecommunications Big data analytics', 'quality management telecommunications', 'use real-time data analyses', 'machine logs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Telecommunications', 'telecommun'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('quality', 'qualiti'), ('management', 'manag'), ('telecommunications', 'telecommun'), ('making', 'make'), ('use', 'use'), ('real-time', 'real-tim'), ('data', 'data'), ('analyses', 'analys'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Telecommunications', 'telecommun'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('improve', 'improv'), ('quality', 'qualiti'), ('management', 'manag'), ('telecommunications', 'telecommun'), ('making', 'make'), ('use', 'use'), ('real-time', 'real-tim'), ('data', 'data'), ('analyses', 'analys'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('.', '.')]

>> Lemmatization: 
 [('Telecommunications', 'Telecommunications'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('improve', 'improve'), ('quality', 'quality'), ('management', 'management'), ('telecommunications', 'telecommunication'), ('making', 'making'), ('use', 'use'), ('real-time', 'real-time'), ('data', 'data'), ('analyses', 'analysis'), ('monitoring', 'monitoring'), ('machine', 'machine'), ('logs', 'log'), ('.', '.')]



============================ Sentence 581 =============================

Predictive analytics can also be used to   minimise performance variability and to prevent quality issues by providing early warning alerts   (Elgendy, N. and Elragal, A., 2014). 


>> Tokens are: 
 ['Predictive', 'analytics', 'also', 'used', 'minimise', 'performance', 'variability', 'prevent', 'quality', 'issues', 'providing', 'early', 'warning', 'alerts', '(', 'Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', ')', '.']

>> Bigrams are: 
 [('Predictive', 'analytics'), ('analytics', 'also'), ('also', 'used'), ('used', 'minimise'), ('minimise', 'performance'), ('performance', 'variability'), ('variability', 'prevent'), ('prevent', 'quality'), ('quality', 'issues'), ('issues', 'providing'), ('providing', 'early'), ('early', 'warning'), ('warning', 'alerts'), ('alerts', '('), ('(', 'Elgendy'), ('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', ')'), (')', '.')]

>> Trigrams are: 
 [('Predictive', 'analytics', 'also'), ('analytics', 'also', 'used'), ('also', 'used', 'minimise'), ('used', 'minimise', 'performance'), ('minimise', 'performance', 'variability'), ('performance', 'variability', 'prevent'), ('variability', 'prevent', 'quality'), ('prevent', 'quality', 'issues'), ('quality', 'issues', 'providing'), ('issues', 'providing', 'early'), ('providing', 'early', 'warning'), ('early', 'warning', 'alerts'), ('warning', 'alerts', '('), ('alerts', '(', 'Elgendy'), ('(', 'Elgendy', ','), ('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', ')'), ('2014', ')', '.')]

>> POS Tags are: 
 [('Predictive', 'JJ'), ('analytics', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('minimise', 'NN'), ('performance', 'NN'), ('variability', 'NN'), ('prevent', 'VBP'), ('quality', 'NN'), ('issues', 'NNS'), ('providing', 'VBG'), ('early', 'JJ'), ('warning', 'NN'), ('alerts', 'NNS'), ('(', '('), ('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Predictive/JJ analytics/NNS)
  also/RB
  used/VBD
  (NP minimise/NN performance/NN variability/NN)
  prevent/VBP
  (NP quality/NN issues/NNS)
  providing/VBG
  (NP early/JJ warning/NN alerts/NNS)
  (/(
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Predictive analytics', 'minimise performance variability', 'quality issues', 'early warning alerts', 'Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('PERSON', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use'), ('minimise', 'minimis'), ('performance', 'perform'), ('variability', 'variabl'), ('prevent', 'prevent'), ('quality', 'qualiti'), ('issues', 'issu'), ('providing', 'provid'), ('early', 'earli'), ('warning', 'warn'), ('alerts', 'alert'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Predictive', 'predict'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use'), ('minimise', 'minimis'), ('performance', 'perform'), ('variability', 'variabl'), ('prevent', 'prevent'), ('quality', 'qualiti'), ('issues', 'issu'), ('providing', 'provid'), ('early', 'earli'), ('warning', 'warn'), ('alerts', 'alert'), ('(', '('), ('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Predictive', 'Predictive'), ('analytics', 'analytics'), ('also', 'also'), ('used', 'used'), ('minimise', 'minimise'), ('performance', 'performance'), ('variability', 'variability'), ('prevent', 'prevent'), ('quality', 'quality'), ('issues', 'issue'), ('providing', 'providing'), ('early', 'early'), ('warning', 'warning'), ('alerts', 'alert'), ('(', '('), ('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), (')', ')'), ('.', '.')]



============================ Sentence 582 =============================

Big data analytics platforms used in the telecommunication field face the major challenge of how   to store and process big data; traditional analysis techniques are too expensive in many cases. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'platforms', 'used', 'telecommunication', 'field', 'face', 'major', 'challenge', 'store', 'process', 'big', 'data', ';', 'traditional', 'analysis', 'techniques', 'expensive', 'many', 'cases', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'platforms'), ('platforms', 'used'), ('used', 'telecommunication'), ('telecommunication', 'field'), ('field', 'face'), ('face', 'major'), ('major', 'challenge'), ('challenge', 'store'), ('store', 'process'), ('process', 'big'), ('big', 'data'), ('data', ';'), (';', 'traditional'), ('traditional', 'analysis'), ('analysis', 'techniques'), ('techniques', 'expensive'), ('expensive', 'many'), ('many', 'cases'), ('cases', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'platforms'), ('analytics', 'platforms', 'used'), ('platforms', 'used', 'telecommunication'), ('used', 'telecommunication', 'field'), ('telecommunication', 'field', 'face'), ('field', 'face', 'major'), ('face', 'major', 'challenge'), ('major', 'challenge', 'store'), ('challenge', 'store', 'process'), ('store', 'process', 'big'), ('process', 'big', 'data'), ('big', 'data', ';'), ('data', ';', 'traditional'), (';', 'traditional', 'analysis'), ('traditional', 'analysis', 'techniques'), ('analysis', 'techniques', 'expensive'), ('techniques', 'expensive', 'many'), ('expensive', 'many', 'cases'), ('many', 'cases', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('platforms', 'NNS'), ('used', 'VBN'), ('telecommunication', 'NN'), ('field', 'NN'), ('face', 'NN'), ('major', 'JJ'), ('challenge', 'NN'), ('store', 'NN'), ('process', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (';', ':'), ('traditional', 'JJ'), ('analysis', 'NN'), ('techniques', 'NNS'), ('expensive', 'VBP'), ('many', 'JJ'), ('cases', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS platforms/NNS)
  used/VBN
  (NP telecommunication/NN field/NN face/NN)
  (NP major/JJ challenge/NN store/NN process/NN)
  (NP big/JJ data/NNS)
  ;/:
  (NP traditional/JJ analysis/NN techniques/NNS)
  expensive/VBP
  (NP many/JJ cases/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics platforms', 'telecommunication field face', 'major challenge store process', 'big data', 'traditional analysis techniques', 'many cases']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platforms', 'platform'), ('used', 'use'), ('telecommunication', 'telecommun'), ('field', 'field'), ('face', 'face'), ('major', 'major'), ('challenge', 'challeng'), ('store', 'store'), ('process', 'process'), ('big', 'big'), ('data', 'data'), (';', ';'), ('traditional', 'tradit'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('expensive', 'expens'), ('many', 'mani'), ('cases', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('platforms', 'platform'), ('used', 'use'), ('telecommunication', 'telecommun'), ('field', 'field'), ('face', 'face'), ('major', 'major'), ('challenge', 'challeng'), ('store', 'store'), ('process', 'process'), ('big', 'big'), ('data', 'data'), (';', ';'), ('traditional', 'tradit'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('expensive', 'expens'), ('many', 'mani'), ('cases', 'case'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('platforms', 'platform'), ('used', 'used'), ('telecommunication', 'telecommunication'), ('field', 'field'), ('face', 'face'), ('major', 'major'), ('challenge', 'challenge'), ('store', 'store'), ('process', 'process'), ('big', 'big'), ('data', 'data'), (';', ';'), ('traditional', 'traditional'), ('analysis', 'analysis'), ('techniques', 'technique'), ('expensive', 'expensive'), ('many', 'many'), ('cases', 'case'), ('.', '.')]



============================ Sentence 583 =============================

Big   data techniques such as Hadoop can help in reducing the storage costs, particularly where storage   modules such as the Hadoop Distributed File System (HDFS) and computation modules such   as MapReduce are included (Çelebi, 2013). 


>> Tokens are: 
 ['Big', 'data', 'techniques', 'Hadoop', 'help', 'reducing', 'storage', 'costs', ',', 'particularly', 'storage', 'modules', 'Hadoop', 'Distributed', 'File', 'System', '(', 'HDFS', ')', 'computation', 'modules', 'MapReduce', 'included', '(', 'Çelebi', ',', '2013', ')', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'techniques'), ('techniques', 'Hadoop'), ('Hadoop', 'help'), ('help', 'reducing'), ('reducing', 'storage'), ('storage', 'costs'), ('costs', ','), (',', 'particularly'), ('particularly', 'storage'), ('storage', 'modules'), ('modules', 'Hadoop'), ('Hadoop', 'Distributed'), ('Distributed', 'File'), ('File', 'System'), ('System', '('), ('(', 'HDFS'), ('HDFS', ')'), (')', 'computation'), ('computation', 'modules'), ('modules', 'MapReduce'), ('MapReduce', 'included'), ('included', '('), ('(', 'Çelebi'), ('Çelebi', ','), (',', '2013'), ('2013', ')'), (')', '.')]

>> Trigrams are: 
 [('Big', 'data', 'techniques'), ('data', 'techniques', 'Hadoop'), ('techniques', 'Hadoop', 'help'), ('Hadoop', 'help', 'reducing'), ('help', 'reducing', 'storage'), ('reducing', 'storage', 'costs'), ('storage', 'costs', ','), ('costs', ',', 'particularly'), (',', 'particularly', 'storage'), ('particularly', 'storage', 'modules'), ('storage', 'modules', 'Hadoop'), ('modules', 'Hadoop', 'Distributed'), ('Hadoop', 'Distributed', 'File'), ('Distributed', 'File', 'System'), ('File', 'System', '('), ('System', '(', 'HDFS'), ('(', 'HDFS', ')'), ('HDFS', ')', 'computation'), (')', 'computation', 'modules'), ('computation', 'modules', 'MapReduce'), ('modules', 'MapReduce', 'included'), ('MapReduce', 'included', '('), ('included', '(', 'Çelebi'), ('(', 'Çelebi', ','), ('Çelebi', ',', '2013'), (',', '2013', ')'), ('2013', ')', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('techniques', 'NNS'), ('Hadoop', 'NNP'), ('help', 'NN'), ('reducing', 'VBG'), ('storage', 'NN'), ('costs', 'NNS'), (',', ','), ('particularly', 'RB'), ('storage', 'NN'), ('modules', 'NNS'), ('Hadoop', 'NNP'), ('Distributed', 'NNP'), ('File', 'NNP'), ('System', 'NNP'), ('(', '('), ('HDFS', 'NNP'), (')', ')'), ('computation', 'NN'), ('modules', 'NNS'), ('MapReduce', 'NNP'), ('included', 'VBD'), ('(', '('), ('Çelebi', 'CD'), (',', ','), ('2013', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS techniques/NNS Hadoop/NNP help/NN)
  reducing/VBG
  (NP storage/NN costs/NNS)
  ,/,
  particularly/RB
  (NP
    storage/NN
    modules/NNS
    Hadoop/NNP
    Distributed/NNP
    File/NNP
    System/NNP)
  (/(
  (NP HDFS/NNP)
  )/)
  (NP computation/NN modules/NNS MapReduce/NNP)
  included/VBD
  (/(
  Çelebi/CD
  ,/,
  2013/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Big data techniques Hadoop help', 'storage costs', 'storage modules Hadoop Distributed File System', 'HDFS', 'computation modules MapReduce']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Hadoop Distributed File System'), ('ORGANIZATION', 'HDFS'), ('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('Hadoop', 'hadoop'), ('help', 'help'), ('reducing', 'reduc'), ('storage', 'storag'), ('costs', 'cost'), (',', ','), ('particularly', 'particularli'), ('storage', 'storag'), ('modules', 'modul'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdf'), (')', ')'), ('computation', 'comput'), ('modules', 'modul'), ('MapReduce', 'mapreduc'), ('included', 'includ'), ('(', '('), ('Çelebi', 'çelebi'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('techniques', 'techniqu'), ('Hadoop', 'hadoop'), ('help', 'help'), ('reducing', 'reduc'), ('storage', 'storag'), ('costs', 'cost'), (',', ','), ('particularly', 'particular'), ('storage', 'storag'), ('modules', 'modul'), ('Hadoop', 'hadoop'), ('Distributed', 'distribut'), ('File', 'file'), ('System', 'system'), ('(', '('), ('HDFS', 'hdfs'), (')', ')'), ('computation', 'comput'), ('modules', 'modul'), ('MapReduce', 'mapreduc'), ('included', 'includ'), ('(', '('), ('Çelebi', 'çelebi'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('techniques', 'technique'), ('Hadoop', 'Hadoop'), ('help', 'help'), ('reducing', 'reducing'), ('storage', 'storage'), ('costs', 'cost'), (',', ','), ('particularly', 'particularly'), ('storage', 'storage'), ('modules', 'module'), ('Hadoop', 'Hadoop'), ('Distributed', 'Distributed'), ('File', 'File'), ('System', 'System'), ('(', '('), ('HDFS', 'HDFS'), (')', ')'), ('computation', 'computation'), ('modules', 'module'), ('MapReduce', 'MapReduce'), ('included', 'included'), ('(', '('), ('Çelebi', 'Çelebi'), (',', ','), ('2013', '2013'), (')', ')'), ('.', '.')]



============================ Sentence 584 =============================

Big data analytics has the power to extract more information than traditional data analytics, which   can help in improving mobile cellular networks. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'power', 'extract', 'information', 'traditional', 'data', 'analytics', ',', 'help', 'improving', 'mobile', 'cellular', 'networks', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'power'), ('power', 'extract'), ('extract', 'information'), ('information', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 'help'), ('help', 'improving'), ('improving', 'mobile'), ('mobile', 'cellular'), ('cellular', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'power'), ('analytics', 'power', 'extract'), ('power', 'extract', 'information'), ('extract', 'information', 'traditional'), ('information', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 'help'), (',', 'help', 'improving'), ('help', 'improving', 'mobile'), ('improving', 'mobile', 'cellular'), ('mobile', 'cellular', 'networks'), ('cellular', 'networks', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('power', 'NN'), ('extract', 'JJ'), ('information', 'NN'), ('traditional', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), (',', ','), ('help', 'NN'), ('improving', 'VBG'), ('mobile', 'JJ'), ('cellular', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS power/NN)
  (NP extract/JJ information/NN)
  (NP traditional/JJ data/NN analytics/NNS)
  ,/,
  (NP help/NN)
  improving/VBG
  (NP mobile/JJ cellular/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics power', 'extract information', 'traditional data analytics', 'help', 'mobile cellular networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('extract', 'extract'), ('information', 'inform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('help', 'help'), ('improving', 'improv'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('power', 'power'), ('extract', 'extract'), ('information', 'inform'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('help', 'help'), ('improving', 'improv'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('power', 'power'), ('extract', 'extract'), ('information', 'information'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('help', 'help'), ('improving', 'improving'), ('mobile', 'mobile'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]



============================ Sentence 585 =============================

Such mobile cellular networks generate and carry   massive amounts of data such as calls and mobile application activities that consist of both   structured and unstructured data types. 


>> Tokens are: 
 ['Such', 'mobile', 'cellular', 'networks', 'generate', 'carry', 'massive', 'amounts', 'data', 'calls', 'mobile', 'application', 'activities', 'consist', 'structured', 'unstructured', 'data', 'types', '.']

>> Bigrams are: 
 [('Such', 'mobile'), ('mobile', 'cellular'), ('cellular', 'networks'), ('networks', 'generate'), ('generate', 'carry'), ('carry', 'massive'), ('massive', 'amounts'), ('amounts', 'data'), ('data', 'calls'), ('calls', 'mobile'), ('mobile', 'application'), ('application', 'activities'), ('activities', 'consist'), ('consist', 'structured'), ('structured', 'unstructured'), ('unstructured', 'data'), ('data', 'types'), ('types', '.')]

>> Trigrams are: 
 [('Such', 'mobile', 'cellular'), ('mobile', 'cellular', 'networks'), ('cellular', 'networks', 'generate'), ('networks', 'generate', 'carry'), ('generate', 'carry', 'massive'), ('carry', 'massive', 'amounts'), ('massive', 'amounts', 'data'), ('amounts', 'data', 'calls'), ('data', 'calls', 'mobile'), ('calls', 'mobile', 'application'), ('mobile', 'application', 'activities'), ('application', 'activities', 'consist'), ('activities', 'consist', 'structured'), ('consist', 'structured', 'unstructured'), ('structured', 'unstructured', 'data'), ('unstructured', 'data', 'types'), ('data', 'types', '.')]

>> POS Tags are: 
 [('Such', 'JJ'), ('mobile', 'JJ'), ('cellular', 'JJ'), ('networks', 'NNS'), ('generate', 'VBP'), ('carry', 'JJ'), ('massive', 'JJ'), ('amounts', 'NNS'), ('data', 'NNS'), ('calls', 'NNS'), ('mobile', 'JJ'), ('application', 'NN'), ('activities', 'NNS'), ('consist', 'VBP'), ('structured', 'VBN'), ('unstructured', 'JJ'), ('data', 'NNS'), ('types', 'NNS'), ('.', '.')]

 (S
  (NP Such/JJ mobile/JJ cellular/JJ networks/NNS)
  generate/VBP
  (NP carry/JJ massive/JJ amounts/NNS data/NNS calls/NNS)
  (NP mobile/JJ application/NN activities/NNS)
  consist/VBP
  structured/VBN
  (NP unstructured/JJ data/NNS types/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Such mobile cellular networks', 'carry massive amounts data calls', 'mobile application activities', 'unstructured data types']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Such', 'such'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('generate', 'gener'), ('carry', 'carri'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('calls', 'call'), ('mobile', 'mobil'), ('application', 'applic'), ('activities', 'activ'), ('consist', 'consist'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Such', 'such'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('generate', 'generat'), ('carry', 'carri'), ('massive', 'massiv'), ('amounts', 'amount'), ('data', 'data'), ('calls', 'call'), ('mobile', 'mobil'), ('application', 'applic'), ('activities', 'activ'), ('consist', 'consist'), ('structured', 'structur'), ('unstructured', 'unstructur'), ('data', 'data'), ('types', 'type'), ('.', '.')]

>> Lemmatization: 
 [('Such', 'Such'), ('mobile', 'mobile'), ('cellular', 'cellular'), ('networks', 'network'), ('generate', 'generate'), ('carry', 'carry'), ('massive', 'massive'), ('amounts', 'amount'), ('data', 'data'), ('calls', 'call'), ('mobile', 'mobile'), ('application', 'application'), ('activities', 'activity'), ('consist', 'consist'), ('structured', 'structured'), ('unstructured', 'unstructured'), ('data', 'data'), ('types', 'type'), ('.', '.')]



============================ Sentence 586 =============================

Traditional data analytics deals only with structured data,   and thus it is almost impossible to handle that data with traditional data analytics (He et al., 2016). 


>> Tokens are: 
 ['Traditional', 'data', 'analytics', 'deals', 'structured', 'data', ',', 'thus', 'almost', 'impossible', 'handle', 'data', 'traditional', 'data', 'analytics', '(', 'He', 'et', 'al.', ',', '2016', ')', '.']

>> Bigrams are: 
 [('Traditional', 'data'), ('data', 'analytics'), ('analytics', 'deals'), ('deals', 'structured'), ('structured', 'data'), ('data', ','), (',', 'thus'), ('thus', 'almost'), ('almost', 'impossible'), ('impossible', 'handle'), ('handle', 'data'), ('data', 'traditional'), ('traditional', 'data'), ('data', 'analytics'), ('analytics', '('), ('(', 'He'), ('He', 'et'), ('et', 'al.'), ('al.', ','), (',', '2016'), ('2016', ')'), (')', '.')]

>> Trigrams are: 
 [('Traditional', 'data', 'analytics'), ('data', 'analytics', 'deals'), ('analytics', 'deals', 'structured'), ('deals', 'structured', 'data'), ('structured', 'data', ','), ('data', ',', 'thus'), (',', 'thus', 'almost'), ('thus', 'almost', 'impossible'), ('almost', 'impossible', 'handle'), ('impossible', 'handle', 'data'), ('handle', 'data', 'traditional'), ('data', 'traditional', 'data'), ('traditional', 'data', 'analytics'), ('data', 'analytics', '('), ('analytics', '(', 'He'), ('(', 'He', 'et'), ('He', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2016'), (',', '2016', ')'), ('2016', ')', '.')]

>> POS Tags are: 
 [('Traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('deals', 'NNS'), ('structured', 'VBD'), ('data', 'NNS'), (',', ','), ('thus', 'RB'), ('almost', 'RB'), ('impossible', 'JJ'), ('handle', 'JJ'), ('data', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('(', '('), ('He', 'PRP'), ('et', 'VBZ'), ('al.', 'RB'), (',', ','), ('2016', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Traditional/JJ data/NNS analytics/NNS deals/NNS)
  structured/VBD
  (NP data/NNS)
  ,/,
  thus/RB
  almost/RB
  (NP impossible/JJ handle/JJ data/NNS)
  (NP traditional/JJ data/NNS analytics/NNS)
  (/(
  He/PRP
  et/VBZ
  al./RB
  ,/,
  2016/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Traditional data analytics deals', 'data', 'impossible handle data', 'traditional data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('deals', 'deal'), ('structured', 'structur'), ('data', 'data'), (',', ','), ('thus', 'thu'), ('almost', 'almost'), ('impossible', 'imposs'), ('handle', 'handl'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('He', 'he'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('deals', 'deal'), ('structured', 'structur'), ('data', 'data'), (',', ','), ('thus', 'thus'), ('almost', 'almost'), ('impossible', 'imposs'), ('handle', 'handl'), ('data', 'data'), ('traditional', 'tradit'), ('data', 'data'), ('analytics', 'analyt'), ('(', '('), ('He', 'he'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Traditional', 'Traditional'), ('data', 'data'), ('analytics', 'analytics'), ('deals', 'deal'), ('structured', 'structured'), ('data', 'data'), (',', ','), ('thus', 'thus'), ('almost', 'almost'), ('impossible', 'impossible'), ('handle', 'handle'), ('data', 'data'), ('traditional', 'traditional'), ('data', 'data'), ('analytics', 'analytics'), ('(', '('), ('He', 'He'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2016', '2016'), (')', ')'), ('.', '.')]



============================ Sentence 587 =============================

11. 


>> Tokens are: 
 ['11', '.']

>> Bigrams are: 
 [('11', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('11', 'CD'), ('.', '.')]

 (S 11/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('11', '11'), ('.', '.')]



============================ Sentence 588 =============================

Implications of research    Big data has the power to change research and education. 


>> Tokens are: 
 ['Implications', 'research', 'Big', 'data', 'power', 'change', 'research', 'education', '.']

>> Bigrams are: 
 [('Implications', 'research'), ('research', 'Big'), ('Big', 'data'), ('data', 'power'), ('power', 'change'), ('change', 'research'), ('research', 'education'), ('education', '.')]

>> Trigrams are: 
 [('Implications', 'research', 'Big'), ('research', 'Big', 'data'), ('Big', 'data', 'power'), ('data', 'power', 'change'), ('power', 'change', 'research'), ('change', 'research', 'education'), ('research', 'education', '.')]

>> POS Tags are: 
 [('Implications', 'NNS'), ('research', 'NN'), ('Big', 'NNP'), ('data', 'NN'), ('power', 'NN'), ('change', 'NN'), ('research', 'NN'), ('education', 'NN'), ('.', '.')]

 (S
  (NP
    Implications/NNS
    research/NN
    Big/NNP
    data/NN
    power/NN
    change/NN
    research/NN
    education/NN)
  ./.) 


>> Noun Phrases are: 
 ['Implications research Big data power change research education']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Implications', 'implic'), ('research', 'research'), ('Big', 'big'), ('data', 'data'), ('power', 'power'), ('change', 'chang'), ('research', 'research'), ('education', 'educ'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Implications', 'implic'), ('research', 'research'), ('Big', 'big'), ('data', 'data'), ('power', 'power'), ('change', 'chang'), ('research', 'research'), ('education', 'educ'), ('.', '.')]

>> Lemmatization: 
 [('Implications', 'Implications'), ('research', 'research'), ('Big', 'Big'), ('data', 'data'), ('power', 'power'), ('change', 'change'), ('research', 'research'), ('education', 'education'), ('.', '.')]



============================ Sentence 589 =============================

Improving the students’ results by   refining the student’s performance during courses and understanding their behaviours can be done   using big data analytics. 


>> Tokens are: 
 ['Improving', 'students', '’', 'results', 'refining', 'student', '’', 'performance', 'courses', 'understanding', 'behaviours', 'done', 'using', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Improving', 'students'), ('students', '’'), ('’', 'results'), ('results', 'refining'), ('refining', 'student'), ('student', '’'), ('’', 'performance'), ('performance', 'courses'), ('courses', 'understanding'), ('understanding', 'behaviours'), ('behaviours', 'done'), ('done', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Improving', 'students', '’'), ('students', '’', 'results'), ('’', 'results', 'refining'), ('results', 'refining', 'student'), ('refining', 'student', '’'), ('student', '’', 'performance'), ('’', 'performance', 'courses'), ('performance', 'courses', 'understanding'), ('courses', 'understanding', 'behaviours'), ('understanding', 'behaviours', 'done'), ('behaviours', 'done', 'using'), ('done', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Improving', 'VBG'), ('students', 'NNS'), ('’', 'JJ'), ('results', 'NNS'), ('refining', 'VBG'), ('student', 'NN'), ('’', 'NN'), ('performance', 'NN'), ('courses', 'NNS'), ('understanding', 'JJ'), ('behaviours', 'NNS'), ('done', 'VBN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

 (S
  Improving/VBG
  (NP students/NNS)
  (NP ’/JJ results/NNS)
  refining/VBG
  (NP student/NN ’/NN performance/NN courses/NNS)
  (NP understanding/JJ behaviours/NNS)
  done/VBN
  using/VBG
  (NP big/JJ data/NNS analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['students', '’ results', 'student ’ performance courses', 'understanding behaviours', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Improving', 'improv'), ('students', 'student'), ('’', '’'), ('results', 'result'), ('refining', 'refin'), ('student', 'student'), ('’', '’'), ('performance', 'perform'), ('courses', 'cours'), ('understanding', 'understand'), ('behaviours', 'behaviour'), ('done', 'done'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Improving', 'improv'), ('students', 'student'), ('’', '’'), ('results', 'result'), ('refining', 'refin'), ('student', 'student'), ('’', '’'), ('performance', 'perform'), ('courses', 'cours'), ('understanding', 'understand'), ('behaviours', 'behaviour'), ('done', 'done'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Improving', 'Improving'), ('students', 'student'), ('’', '’'), ('results', 'result'), ('refining', 'refining'), ('student', 'student'), ('’', '’'), ('performance', 'performance'), ('courses', 'course'), ('understanding', 'understanding'), ('behaviours', 'behaviour'), ('done', 'done'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 590 =============================

Also, big data analytics gives students the ability to matching their   interests to the available programs; thus, can choose the best school or educational program. 


>> Tokens are: 
 ['Also', ',', 'big', 'data', 'analytics', 'gives', 'students', 'ability', 'matching', 'interests', 'available', 'programs', ';', 'thus', ',', 'choose', 'best', 'school', 'educational', 'program', '.']

>> Bigrams are: 
 [('Also', ','), (',', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'gives'), ('gives', 'students'), ('students', 'ability'), ('ability', 'matching'), ('matching', 'interests'), ('interests', 'available'), ('available', 'programs'), ('programs', ';'), (';', 'thus'), ('thus', ','), (',', 'choose'), ('choose', 'best'), ('best', 'school'), ('school', 'educational'), ('educational', 'program'), ('program', '.')]

>> Trigrams are: 
 [('Also', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'gives'), ('analytics', 'gives', 'students'), ('gives', 'students', 'ability'), ('students', 'ability', 'matching'), ('ability', 'matching', 'interests'), ('matching', 'interests', 'available'), ('interests', 'available', 'programs'), ('available', 'programs', ';'), ('programs', ';', 'thus'), (';', 'thus', ','), ('thus', ',', 'choose'), (',', 'choose', 'best'), ('choose', 'best', 'school'), ('best', 'school', 'educational'), ('school', 'educational', 'program'), ('educational', 'program', '.')]

>> POS Tags are: 
 [('Also', 'RB'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('gives', 'VBZ'), ('students', 'NNS'), ('ability', 'NN'), ('matching', 'VBG'), ('interests', 'NNS'), ('available', 'JJ'), ('programs', 'NNS'), (';', ':'), ('thus', 'RB'), (',', ','), ('choose', 'JJ'), ('best', 'JJS'), ('school', 'NN'), ('educational', 'JJ'), ('program', 'NN'), ('.', '.')]

 (S
  Also/RB
  ,/,
  (NP big/JJ data/NNS analytics/NNS)
  gives/VBZ
  (NP students/NNS ability/NN)
  matching/VBG
  (NP interests/NNS)
  (NP available/JJ programs/NNS)
  ;/:
  thus/RB
  ,/,
  choose/JJ
  best/JJS
  (NP school/NN)
  (NP educational/JJ program/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data analytics', 'students ability', 'interests', 'available programs', 'school', 'educational program']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Also', 'also'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('gives', 'give'), ('students', 'student'), ('ability', 'abil'), ('matching', 'match'), ('interests', 'interest'), ('available', 'avail'), ('programs', 'program'), (';', ';'), ('thus', 'thu'), (',', ','), ('choose', 'choos'), ('best', 'best'), ('school', 'school'), ('educational', 'educ'), ('program', 'program'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Also', 'also'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('gives', 'give'), ('students', 'student'), ('ability', 'abil'), ('matching', 'match'), ('interests', 'interest'), ('available', 'avail'), ('programs', 'program'), (';', ';'), ('thus', 'thus'), (',', ','), ('choose', 'choos'), ('best', 'best'), ('school', 'school'), ('educational', 'educ'), ('program', 'program'), ('.', '.')]

>> Lemmatization: 
 [('Also', 'Also'), (',', ','), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('gives', 'give'), ('students', 'student'), ('ability', 'ability'), ('matching', 'matching'), ('interests', 'interest'), ('available', 'available'), ('programs', 'program'), (';', ';'), ('thus', 'thus'), (',', ','), ('choose', 'choose'), ('best', 'best'), ('school', 'school'), ('educational', 'educational'), ('program', 'program'), ('.', '.')]



============================ Sentence 591 =============================

On   the other hand, big data helps teachers to understand the knowledge level of each student and tune   the teaching technique with the most valuable effect on an individual basis. 


>> Tokens are: 
 ['On', 'hand', ',', 'big', 'data', 'helps', 'teachers', 'understand', 'knowledge', 'level', 'student', 'tune', 'teaching', 'technique', 'valuable', 'effect', 'individual', 'basis', '.']

>> Bigrams are: 
 [('On', 'hand'), ('hand', ','), (',', 'big'), ('big', 'data'), ('data', 'helps'), ('helps', 'teachers'), ('teachers', 'understand'), ('understand', 'knowledge'), ('knowledge', 'level'), ('level', 'student'), ('student', 'tune'), ('tune', 'teaching'), ('teaching', 'technique'), ('technique', 'valuable'), ('valuable', 'effect'), ('effect', 'individual'), ('individual', 'basis'), ('basis', '.')]

>> Trigrams are: 
 [('On', 'hand', ','), ('hand', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'helps'), ('data', 'helps', 'teachers'), ('helps', 'teachers', 'understand'), ('teachers', 'understand', 'knowledge'), ('understand', 'knowledge', 'level'), ('knowledge', 'level', 'student'), ('level', 'student', 'tune'), ('student', 'tune', 'teaching'), ('tune', 'teaching', 'technique'), ('teaching', 'technique', 'valuable'), ('technique', 'valuable', 'effect'), ('valuable', 'effect', 'individual'), ('effect', 'individual', 'basis'), ('individual', 'basis', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('hand', 'NN'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('helps', 'VBZ'), ('teachers', 'NNS'), ('understand', 'VBP'), ('knowledge', 'NN'), ('level', 'NN'), ('student', 'NN'), ('tune', 'NN'), ('teaching', 'VBG'), ('technique', 'NN'), ('valuable', 'JJ'), ('effect', 'NN'), ('individual', 'JJ'), ('basis', 'NN'), ('.', '.')]

 (S
  On/IN
  (NP hand/NN)
  ,/,
  (NP big/JJ data/NN)
  helps/VBZ
  (NP teachers/NNS)
  understand/VBP
  (NP knowledge/NN level/NN student/NN tune/NN)
  teaching/VBG
  (NP technique/NN)
  (NP valuable/JJ effect/NN)
  (NP individual/JJ basis/NN)
  ./.) 


>> Noun Phrases are: 
 ['hand', 'big data', 'teachers', 'knowledge level student tune', 'technique', 'valuable effect', 'individual basis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('hand', 'hand'), (',', ','), ('big', 'big'), ('data', 'data'), ('helps', 'help'), ('teachers', 'teacher'), ('understand', 'understand'), ('knowledge', 'knowledg'), ('level', 'level'), ('student', 'student'), ('tune', 'tune'), ('teaching', 'teach'), ('technique', 'techniqu'), ('valuable', 'valuabl'), ('effect', 'effect'), ('individual', 'individu'), ('basis', 'basi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('hand', 'hand'), (',', ','), ('big', 'big'), ('data', 'data'), ('helps', 'help'), ('teachers', 'teacher'), ('understand', 'understand'), ('knowledge', 'knowledg'), ('level', 'level'), ('student', 'student'), ('tune', 'tune'), ('teaching', 'teach'), ('technique', 'techniqu'), ('valuable', 'valuabl'), ('effect', 'effect'), ('individual', 'individu'), ('basis', 'basi'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('hand', 'hand'), (',', ','), ('big', 'big'), ('data', 'data'), ('helps', 'help'), ('teachers', 'teacher'), ('understand', 'understand'), ('knowledge', 'knowledge'), ('level', 'level'), ('student', 'student'), ('tune', 'tune'), ('teaching', 'teaching'), ('technique', 'technique'), ('valuable', 'valuable'), ('effect', 'effect'), ('individual', 'individual'), ('basis', 'basis'), ('.', '.')]



============================ Sentence 592 =============================

Consequently, using   big data for guiding instructions in academia has a significant role in enhancing the educational   services by allowing students to access online instructors and communities at low-cost content. 


>> Tokens are: 
 ['Consequently', ',', 'using', 'big', 'data', 'guiding', 'instructions', 'academia', 'significant', 'role', 'enhancing', 'educational', 'services', 'allowing', 'students', 'access', 'online', 'instructors', 'communities', 'low-cost', 'content', '.']

>> Bigrams are: 
 [('Consequently', ','), (',', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'guiding'), ('guiding', 'instructions'), ('instructions', 'academia'), ('academia', 'significant'), ('significant', 'role'), ('role', 'enhancing'), ('enhancing', 'educational'), ('educational', 'services'), ('services', 'allowing'), ('allowing', 'students'), ('students', 'access'), ('access', 'online'), ('online', 'instructors'), ('instructors', 'communities'), ('communities', 'low-cost'), ('low-cost', 'content'), ('content', '.')]

>> Trigrams are: 
 [('Consequently', ',', 'using'), (',', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'guiding'), ('data', 'guiding', 'instructions'), ('guiding', 'instructions', 'academia'), ('instructions', 'academia', 'significant'), ('academia', 'significant', 'role'), ('significant', 'role', 'enhancing'), ('role', 'enhancing', 'educational'), ('enhancing', 'educational', 'services'), ('educational', 'services', 'allowing'), ('services', 'allowing', 'students'), ('allowing', 'students', 'access'), ('students', 'access', 'online'), ('access', 'online', 'instructors'), ('online', 'instructors', 'communities'), ('instructors', 'communities', 'low-cost'), ('communities', 'low-cost', 'content'), ('low-cost', 'content', '.')]

>> POS Tags are: 
 [('Consequently', 'RB'), (',', ','), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('guiding', 'VBG'), ('instructions', 'NNS'), ('academia', 'VBP'), ('significant', 'JJ'), ('role', 'NN'), ('enhancing', 'VBG'), ('educational', 'JJ'), ('services', 'NNS'), ('allowing', 'VBG'), ('students', 'NNS'), ('access', 'NN'), ('online', 'JJ'), ('instructors', 'NNS'), ('communities', 'NNS'), ('low-cost', 'JJ'), ('content', 'NN'), ('.', '.')]

 (S
  Consequently/RB
  ,/,
  using/VBG
  (NP big/JJ data/NNS)
  guiding/VBG
  (NP instructions/NNS)
  academia/VBP
  (NP significant/JJ role/NN)
  enhancing/VBG
  (NP educational/JJ services/NNS)
  allowing/VBG
  (NP students/NNS access/NN)
  (NP online/JJ instructors/NNS communities/NNS)
  (NP low-cost/JJ content/NN)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'instructions', 'significant role', 'educational services', 'students access', 'online instructors communities', 'low-cost content']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Consequently', 'consequ'), (',', ','), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('guiding', 'guid'), ('instructions', 'instruct'), ('academia', 'academia'), ('significant', 'signific'), ('role', 'role'), ('enhancing', 'enhanc'), ('educational', 'educ'), ('services', 'servic'), ('allowing', 'allow'), ('students', 'student'), ('access', 'access'), ('online', 'onlin'), ('instructors', 'instructor'), ('communities', 'commun'), ('low-cost', 'low-cost'), ('content', 'content'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Consequently', 'consequ'), (',', ','), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('guiding', 'guid'), ('instructions', 'instruct'), ('academia', 'academia'), ('significant', 'signific'), ('role', 'role'), ('enhancing', 'enhanc'), ('educational', 'educ'), ('services', 'servic'), ('allowing', 'allow'), ('students', 'student'), ('access', 'access'), ('online', 'onlin'), ('instructors', 'instructor'), ('communities', 'communiti'), ('low-cost', 'low-cost'), ('content', 'content'), ('.', '.')]

>> Lemmatization: 
 [('Consequently', 'Consequently'), (',', ','), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('guiding', 'guiding'), ('instructions', 'instruction'), ('academia', 'academia'), ('significant', 'significant'), ('role', 'role'), ('enhancing', 'enhancing'), ('educational', 'educational'), ('services', 'service'), ('allowing', 'allowing'), ('students', 'student'), ('access', 'access'), ('online', 'online'), ('instructors', 'instructor'), ('communities', 'community'), ('low-cost', 'low-cost'), ('content', 'content'), ('.', '.')]



============================ Sentence 593 =============================

Technologies for controlling and analysing data are broadly available. 


>> Tokens are: 
 ['Technologies', 'controlling', 'analysing', 'data', 'broadly', 'available', '.']

>> Bigrams are: 
 [('Technologies', 'controlling'), ('controlling', 'analysing'), ('analysing', 'data'), ('data', 'broadly'), ('broadly', 'available'), ('available', '.')]

>> Trigrams are: 
 [('Technologies', 'controlling', 'analysing'), ('controlling', 'analysing', 'data'), ('analysing', 'data', 'broadly'), ('data', 'broadly', 'available'), ('broadly', 'available', '.')]

>> POS Tags are: 
 [('Technologies', 'NNS'), ('controlling', 'VBG'), ('analysing', 'VBG'), ('data', 'NNS'), ('broadly', 'RB'), ('available', 'JJ'), ('.', '.')]

 (S
  (NP Technologies/NNS)
  controlling/VBG
  analysing/VBG
  (NP data/NNS)
  broadly/RB
  available/JJ
  ./.) 


>> Noun Phrases are: 
 ['Technologies', 'data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Technologies', 'technolog'), ('controlling', 'control'), ('analysing', 'analys'), ('data', 'data'), ('broadly', 'broadli'), ('available', 'avail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technologies', 'technolog'), ('controlling', 'control'), ('analysing', 'analys'), ('data', 'data'), ('broadly', 'broad'), ('available', 'avail'), ('.', '.')]

>> Lemmatization: 
 [('Technologies', 'Technologies'), ('controlling', 'controlling'), ('analysing', 'analysing'), ('data', 'data'), ('broadly', 'broadly'), ('available', 'available'), ('.', '.')]



============================ Sentence 594 =============================

Companies take advantage   of capturing the data to support accurate and stable business experimentation that direct decision   makers. 


>> Tokens are: 
 ['Companies', 'take', 'advantage', 'capturing', 'data', 'support', 'accurate', 'stable', 'business', 'experimentation', 'direct', 'decision', 'makers', '.']

>> Bigrams are: 
 [('Companies', 'take'), ('take', 'advantage'), ('advantage', 'capturing'), ('capturing', 'data'), ('data', 'support'), ('support', 'accurate'), ('accurate', 'stable'), ('stable', 'business'), ('business', 'experimentation'), ('experimentation', 'direct'), ('direct', 'decision'), ('decision', 'makers'), ('makers', '.')]

>> Trigrams are: 
 [('Companies', 'take', 'advantage'), ('take', 'advantage', 'capturing'), ('advantage', 'capturing', 'data'), ('capturing', 'data', 'support'), ('data', 'support', 'accurate'), ('support', 'accurate', 'stable'), ('accurate', 'stable', 'business'), ('stable', 'business', 'experimentation'), ('business', 'experimentation', 'direct'), ('experimentation', 'direct', 'decision'), ('direct', 'decision', 'makers'), ('decision', 'makers', '.')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('take', 'VBP'), ('advantage', 'NN'), ('capturing', 'VBG'), ('data', 'NNS'), ('support', 'NN'), ('accurate', 'NN'), ('stable', 'JJ'), ('business', 'NN'), ('experimentation', 'NN'), ('direct', 'JJ'), ('decision', 'NN'), ('makers', 'NNS'), ('.', '.')]

 (S
  (NP Companies/NNS)
  take/VBP
  (NP advantage/NN)
  capturing/VBG
  (NP data/NNS support/NN accurate/NN)
  (NP stable/JJ business/NN experimentation/NN)
  (NP direct/JJ decision/NN makers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Companies', 'advantage', 'data support accurate', 'stable business experimentation', 'direct decision makers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('take', 'take'), ('advantage', 'advantag'), ('capturing', 'captur'), ('data', 'data'), ('support', 'support'), ('accurate', 'accur'), ('stable', 'stabl'), ('business', 'busi'), ('experimentation', 'experiment'), ('direct', 'direct'), ('decision', 'decis'), ('makers', 'maker'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('take', 'take'), ('advantage', 'advantag'), ('capturing', 'captur'), ('data', 'data'), ('support', 'support'), ('accurate', 'accur'), ('stable', 'stabl'), ('business', 'busi'), ('experimentation', 'experiment'), ('direct', 'direct'), ('decision', 'decis'), ('makers', 'maker'), ('.', '.')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('take', 'take'), ('advantage', 'advantage'), ('capturing', 'capturing'), ('data', 'data'), ('support', 'support'), ('accurate', 'accurate'), ('stable', 'stable'), ('business', 'business'), ('experimentation', 'experimentation'), ('direct', 'direct'), ('decision', 'decision'), ('makers', 'maker'), ('.', '.')]



============================ Sentence 595 =============================

It might also evaluate outputs, business models, and restoration in customer experience. 


>> Tokens are: 
 ['It', 'might', 'also', 'evaluate', 'outputs', ',', 'business', 'models', ',', 'restoration', 'customer', 'experience', '.']

>> Bigrams are: 
 [('It', 'might'), ('might', 'also'), ('also', 'evaluate'), ('evaluate', 'outputs'), ('outputs', ','), (',', 'business'), ('business', 'models'), ('models', ','), (',', 'restoration'), ('restoration', 'customer'), ('customer', 'experience'), ('experience', '.')]

>> Trigrams are: 
 [('It', 'might', 'also'), ('might', 'also', 'evaluate'), ('also', 'evaluate', 'outputs'), ('evaluate', 'outputs', ','), ('outputs', ',', 'business'), (',', 'business', 'models'), ('business', 'models', ','), ('models', ',', 'restoration'), (',', 'restoration', 'customer'), ('restoration', 'customer', 'experience'), ('customer', 'experience', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('might', 'MD'), ('also', 'RB'), ('evaluate', 'VB'), ('outputs', 'NNS'), (',', ','), ('business', 'NN'), ('models', 'NNS'), (',', ','), ('restoration', 'NN'), ('customer', 'NN'), ('experience', 'NN'), ('.', '.')]

 (S
  It/PRP
  might/MD
  also/RB
  evaluate/VB
  (NP outputs/NNS)
  ,/,
  (NP business/NN models/NNS)
  ,/,
  (NP restoration/NN customer/NN experience/NN)
  ./.) 


>> Noun Phrases are: 
 ['outputs', 'business models', 'restoration customer experience']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('might', 'might'), ('also', 'also'), ('evaluate', 'evalu'), ('outputs', 'output'), (',', ','), ('business', 'busi'), ('models', 'model'), (',', ','), ('restoration', 'restor'), ('customer', 'custom'), ('experience', 'experi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('might', 'might'), ('also', 'also'), ('evaluate', 'evalu'), ('outputs', 'output'), (',', ','), ('business', 'busi'), ('models', 'model'), (',', ','), ('restoration', 'restor'), ('customer', 'custom'), ('experience', 'experi'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('might', 'might'), ('also', 'also'), ('evaluate', 'evaluate'), ('outputs', 'output'), (',', ','), ('business', 'business'), ('models', 'model'), (',', ','), ('restoration', 'restoration'), ('customer', 'customer'), ('experience', 'experience'), ('.', '.')]



============================ Sentence 596 =============================

Trends allow directing a revolutionary transformation in research, invention, and business   marketing. 


>> Tokens are: 
 ['Trends', 'allow', 'directing', 'revolutionary', 'transformation', 'research', ',', 'invention', ',', 'business', 'marketing', '.']

>> Bigrams are: 
 [('Trends', 'allow'), ('allow', 'directing'), ('directing', 'revolutionary'), ('revolutionary', 'transformation'), ('transformation', 'research'), ('research', ','), (',', 'invention'), ('invention', ','), (',', 'business'), ('business', 'marketing'), ('marketing', '.')]

>> Trigrams are: 
 [('Trends', 'allow', 'directing'), ('allow', 'directing', 'revolutionary'), ('directing', 'revolutionary', 'transformation'), ('revolutionary', 'transformation', 'research'), ('transformation', 'research', ','), ('research', ',', 'invention'), (',', 'invention', ','), ('invention', ',', 'business'), (',', 'business', 'marketing'), ('business', 'marketing', '.')]

>> POS Tags are: 
 [('Trends', 'NNS'), ('allow', 'VBP'), ('directing', 'VBG'), ('revolutionary', 'JJ'), ('transformation', 'NN'), ('research', 'NN'), (',', ','), ('invention', 'NN'), (',', ','), ('business', 'NN'), ('marketing', 'NN'), ('.', '.')]

 (S
  (NP Trends/NNS)
  allow/VBP
  directing/VBG
  (NP revolutionary/JJ transformation/NN research/NN)
  ,/,
  (NP invention/NN)
  ,/,
  (NP business/NN marketing/NN)
  ./.) 


>> Noun Phrases are: 
 ['Trends', 'revolutionary transformation research', 'invention', 'business marketing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Trends', 'trend'), ('allow', 'allow'), ('directing', 'direct'), ('revolutionary', 'revolutionari'), ('transformation', 'transform'), ('research', 'research'), (',', ','), ('invention', 'invent'), (',', ','), ('business', 'busi'), ('marketing', 'market'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Trends', 'trend'), ('allow', 'allow'), ('directing', 'direct'), ('revolutionary', 'revolutionari'), ('transformation', 'transform'), ('research', 'research'), (',', ','), ('invention', 'invent'), (',', ','), ('business', 'busi'), ('marketing', 'market'), ('.', '.')]

>> Lemmatization: 
 [('Trends', 'Trends'), ('allow', 'allow'), ('directing', 'directing'), ('revolutionary', 'revolutionary'), ('transformation', 'transformation'), ('research', 'research'), (',', ','), ('invention', 'invention'), (',', ','), ('business', 'business'), ('marketing', 'marketing'), ('.', '.')]



============================ Sentence 597 =============================

Some firms like Amazon, Google, and eBay analyse elements that control performance   to determine factors that raise sales income and track the activity of users (Bughin et al., 2010). 


>> Tokens are: 
 ['Some', 'firms', 'like', 'Amazon', ',', 'Google', ',', 'eBay', 'analyse', 'elements', 'control', 'performance', 'determine', 'factors', 'raise', 'sales', 'income', 'track', 'activity', 'users', '(', 'Bughin', 'et', 'al.', ',', '2010', ')', '.']

>> Bigrams are: 
 [('Some', 'firms'), ('firms', 'like'), ('like', 'Amazon'), ('Amazon', ','), (',', 'Google'), ('Google', ','), (',', 'eBay'), ('eBay', 'analyse'), ('analyse', 'elements'), ('elements', 'control'), ('control', 'performance'), ('performance', 'determine'), ('determine', 'factors'), ('factors', 'raise'), ('raise', 'sales'), ('sales', 'income'), ('income', 'track'), ('track', 'activity'), ('activity', 'users'), ('users', '('), ('(', 'Bughin'), ('Bughin', 'et'), ('et', 'al.'), ('al.', ','), (',', '2010'), ('2010', ')'), (')', '.')]

>> Trigrams are: 
 [('Some', 'firms', 'like'), ('firms', 'like', 'Amazon'), ('like', 'Amazon', ','), ('Amazon', ',', 'Google'), (',', 'Google', ','), ('Google', ',', 'eBay'), (',', 'eBay', 'analyse'), ('eBay', 'analyse', 'elements'), ('analyse', 'elements', 'control'), ('elements', 'control', 'performance'), ('control', 'performance', 'determine'), ('performance', 'determine', 'factors'), ('determine', 'factors', 'raise'), ('factors', 'raise', 'sales'), ('raise', 'sales', 'income'), ('sales', 'income', 'track'), ('income', 'track', 'activity'), ('track', 'activity', 'users'), ('activity', 'users', '('), ('users', '(', 'Bughin'), ('(', 'Bughin', 'et'), ('Bughin', 'et', 'al.'), ('et', 'al.', ','), ('al.', ',', '2010'), (',', '2010', ')'), ('2010', ')', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('firms', 'NNS'), ('like', 'IN'), ('Amazon', 'NNP'), (',', ','), ('Google', 'NNP'), (',', ','), ('eBay', 'NN'), ('analyse', 'JJ'), ('elements', 'NNS'), ('control', 'NN'), ('performance', 'NN'), ('determine', 'NN'), ('factors', 'NNS'), ('raise', 'VBP'), ('sales', 'NNS'), ('income', 'NN'), ('track', 'NN'), ('activity', 'NN'), ('users', 'NNS'), ('(', '('), ('Bughin', 'NNP'), ('et', 'RB'), ('al.', 'RB'), (',', ','), ('2010', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Some/DT firms/NNS)
  like/IN
  (NP Amazon/NNP)
  ,/,
  (NP Google/NNP)
  ,/,
  (NP eBay/NN)
  (NP
    analyse/JJ
    elements/NNS
    control/NN
    performance/NN
    determine/NN
    factors/NNS)
  raise/VBP
  (NP sales/NNS income/NN track/NN activity/NN users/NNS)
  (/(
  (NP Bughin/NNP)
  et/RB
  al./RB
  ,/,
  2010/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Some firms', 'Amazon', 'Google', 'eBay', 'analyse elements control performance determine factors', 'sales income track activity users', 'Bughin']

>> Named Entities are: 
 [('PERSON', 'Amazon'), ('GPE', 'Google'), ('ORGANIZATION', 'eBay'), ('PERSON', 'Bughin')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('firms', 'firm'), ('like', 'like'), ('Amazon', 'amazon'), (',', ','), ('Google', 'googl'), (',', ','), ('eBay', 'ebay'), ('analyse', 'analys'), ('elements', 'element'), ('control', 'control'), ('performance', 'perform'), ('determine', 'determin'), ('factors', 'factor'), ('raise', 'rais'), ('sales', 'sale'), ('income', 'incom'), ('track', 'track'), ('activity', 'activ'), ('users', 'user'), ('(', '('), ('Bughin', 'bughin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('firms', 'firm'), ('like', 'like'), ('Amazon', 'amazon'), (',', ','), ('Google', 'googl'), (',', ','), ('eBay', 'ebay'), ('analyse', 'analys'), ('elements', 'element'), ('control', 'control'), ('performance', 'perform'), ('determine', 'determin'), ('factors', 'factor'), ('raise', 'rais'), ('sales', 'sale'), ('income', 'incom'), ('track', 'track'), ('activity', 'activ'), ('users', 'user'), ('(', '('), ('Bughin', 'bughin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('firms', 'firm'), ('like', 'like'), ('Amazon', 'Amazon'), (',', ','), ('Google', 'Google'), (',', ','), ('eBay', 'eBay'), ('analyse', 'analyse'), ('elements', 'element'), ('control', 'control'), ('performance', 'performance'), ('determine', 'determine'), ('factors', 'factor'), ('raise', 'raise'), ('sales', 'sale'), ('income', 'income'), ('track', 'track'), ('activity', 'activity'), ('users', 'user'), ('(', '('), ('Bughin', 'Bughin'), ('et', 'et'), ('al.', 'al.'), (',', ','), ('2010', '2010'), (')', ')'), ('.', '.')]



============================ Sentence 598 =============================

Big data has an essential impact on financial institutions as they keep modifying their methods for   segment credit card customers. 


>> Tokens are: 
 ['Big', 'data', 'essential', 'impact', 'financial', 'institutions', 'keep', 'modifying', 'methods', 'segment', 'credit', 'card', 'customers', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'essential'), ('essential', 'impact'), ('impact', 'financial'), ('financial', 'institutions'), ('institutions', 'keep'), ('keep', 'modifying'), ('modifying', 'methods'), ('methods', 'segment'), ('segment', 'credit'), ('credit', 'card'), ('card', 'customers'), ('customers', '.')]

>> Trigrams are: 
 [('Big', 'data', 'essential'), ('data', 'essential', 'impact'), ('essential', 'impact', 'financial'), ('impact', 'financial', 'institutions'), ('financial', 'institutions', 'keep'), ('institutions', 'keep', 'modifying'), ('keep', 'modifying', 'methods'), ('modifying', 'methods', 'segment'), ('methods', 'segment', 'credit'), ('segment', 'credit', 'card'), ('credit', 'card', 'customers'), ('card', 'customers', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('essential', 'JJ'), ('impact', 'NN'), ('financial', 'JJ'), ('institutions', 'NNS'), ('keep', 'VB'), ('modifying', 'VBG'), ('methods', 'NNS'), ('segment', 'NN'), ('credit', 'NN'), ('card', 'NN'), ('customers', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  (NP essential/JJ impact/NN)
  (NP financial/JJ institutions/NNS)
  keep/VB
  modifying/VBG
  (NP methods/NNS segment/NN credit/NN card/NN customers/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'essential impact', 'financial institutions', 'methods segment credit card customers']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('essential', 'essenti'), ('impact', 'impact'), ('financial', 'financi'), ('institutions', 'institut'), ('keep', 'keep'), ('modifying', 'modifi'), ('methods', 'method'), ('segment', 'segment'), ('credit', 'credit'), ('card', 'card'), ('customers', 'custom'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('essential', 'essenti'), ('impact', 'impact'), ('financial', 'financi'), ('institutions', 'institut'), ('keep', 'keep'), ('modifying', 'modifi'), ('methods', 'method'), ('segment', 'segment'), ('credit', 'credit'), ('card', 'card'), ('customers', 'custom'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('essential', 'essential'), ('impact', 'impact'), ('financial', 'financial'), ('institutions', 'institution'), ('keep', 'keep'), ('modifying', 'modifying'), ('methods', 'method'), ('segment', 'segment'), ('credit', 'credit'), ('card', 'card'), ('customers', 'customer'), ('.', '.')]



============================ Sentence 599 =============================

Companies such as Brick and Mortar are utilizing big data to test   the ability to guide customer data by collecting transactional information from millions of   customers, then use the collected information in analysing new opportunities such as optimizing   the most effective promotions. 


>> Tokens are: 
 ['Companies', 'Brick', 'Mortar', 'utilizing', 'big', 'data', 'test', 'ability', 'guide', 'customer', 'data', 'collecting', 'transactional', 'information', 'millions', 'customers', ',', 'use', 'collected', 'information', 'analysing', 'new', 'opportunities', 'optimizing', 'effective', 'promotions', '.']

>> Bigrams are: 
 [('Companies', 'Brick'), ('Brick', 'Mortar'), ('Mortar', 'utilizing'), ('utilizing', 'big'), ('big', 'data'), ('data', 'test'), ('test', 'ability'), ('ability', 'guide'), ('guide', 'customer'), ('customer', 'data'), ('data', 'collecting'), ('collecting', 'transactional'), ('transactional', 'information'), ('information', 'millions'), ('millions', 'customers'), ('customers', ','), (',', 'use'), ('use', 'collected'), ('collected', 'information'), ('information', 'analysing'), ('analysing', 'new'), ('new', 'opportunities'), ('opportunities', 'optimizing'), ('optimizing', 'effective'), ('effective', 'promotions'), ('promotions', '.')]

>> Trigrams are: 
 [('Companies', 'Brick', 'Mortar'), ('Brick', 'Mortar', 'utilizing'), ('Mortar', 'utilizing', 'big'), ('utilizing', 'big', 'data'), ('big', 'data', 'test'), ('data', 'test', 'ability'), ('test', 'ability', 'guide'), ('ability', 'guide', 'customer'), ('guide', 'customer', 'data'), ('customer', 'data', 'collecting'), ('data', 'collecting', 'transactional'), ('collecting', 'transactional', 'information'), ('transactional', 'information', 'millions'), ('information', 'millions', 'customers'), ('millions', 'customers', ','), ('customers', ',', 'use'), (',', 'use', 'collected'), ('use', 'collected', 'information'), ('collected', 'information', 'analysing'), ('information', 'analysing', 'new'), ('analysing', 'new', 'opportunities'), ('new', 'opportunities', 'optimizing'), ('opportunities', 'optimizing', 'effective'), ('optimizing', 'effective', 'promotions'), ('effective', 'promotions', '.')]

>> POS Tags are: 
 [('Companies', 'NNS'), ('Brick', 'NNP'), ('Mortar', 'NNP'), ('utilizing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('test', 'NN'), ('ability', 'NN'), ('guide', 'VBP'), ('customer', 'NN'), ('data', 'NNS'), ('collecting', 'VBG'), ('transactional', 'JJ'), ('information', 'NN'), ('millions', 'NNS'), ('customers', 'NNS'), (',', ','), ('use', 'RB'), ('collected', 'VBN'), ('information', 'NN'), ('analysing', 'VBG'), ('new', 'JJ'), ('opportunities', 'NNS'), ('optimizing', 'VBG'), ('effective', 'JJ'), ('promotions', 'NNS'), ('.', '.')]

 (S
  (NP Companies/NNS Brick/NNP Mortar/NNP)
  utilizing/VBG
  (NP big/JJ data/NNS test/NN ability/NN)
  guide/VBP
  (NP customer/NN data/NNS)
  collecting/VBG
  (NP transactional/JJ information/NN millions/NNS customers/NNS)
  ,/,
  use/RB
  collected/VBN
  (NP information/NN)
  analysing/VBG
  (NP new/JJ opportunities/NNS)
  optimizing/VBG
  (NP effective/JJ promotions/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Companies Brick Mortar', 'big data test ability', 'customer data', 'transactional information millions customers', 'information', 'new opportunities', 'effective promotions']

>> Named Entities are: 
 [('PERSON', 'Brick Mortar')] 

>> Stemming using Porter Stemmer: 
 [('Companies', 'compani'), ('Brick', 'brick'), ('Mortar', 'mortar'), ('utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('test', 'test'), ('ability', 'abil'), ('guide', 'guid'), ('customer', 'custom'), ('data', 'data'), ('collecting', 'collect'), ('transactional', 'transact'), ('information', 'inform'), ('millions', 'million'), ('customers', 'custom'), (',', ','), ('use', 'use'), ('collected', 'collect'), ('information', 'inform'), ('analysing', 'analys'), ('new', 'new'), ('opportunities', 'opportun'), ('optimizing', 'optim'), ('effective', 'effect'), ('promotions', 'promot'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Companies', 'compani'), ('Brick', 'brick'), ('Mortar', 'mortar'), ('utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('test', 'test'), ('ability', 'abil'), ('guide', 'guid'), ('customer', 'custom'), ('data', 'data'), ('collecting', 'collect'), ('transactional', 'transact'), ('information', 'inform'), ('millions', 'million'), ('customers', 'custom'), (',', ','), ('use', 'use'), ('collected', 'collect'), ('information', 'inform'), ('analysing', 'analys'), ('new', 'new'), ('opportunities', 'opportun'), ('optimizing', 'optim'), ('effective', 'effect'), ('promotions', 'promot'), ('.', '.')]

>> Lemmatization: 
 [('Companies', 'Companies'), ('Brick', 'Brick'), ('Mortar', 'Mortar'), ('utilizing', 'utilizing'), ('big', 'big'), ('data', 'data'), ('test', 'test'), ('ability', 'ability'), ('guide', 'guide'), ('customer', 'customer'), ('data', 'data'), ('collecting', 'collecting'), ('transactional', 'transactional'), ('information', 'information'), ('millions', 'million'), ('customers', 'customer'), (',', ','), ('use', 'use'), ('collected', 'collected'), ('information', 'information'), ('analysing', 'analysing'), ('new', 'new'), ('opportunities', 'opportunity'), ('optimizing', 'optimizing'), ('effective', 'effective'), ('promotions', 'promotion'), ('.', '.')]



============================ Sentence 600 =============================

Other companies use data mining to gather information from social   media. 


>> Tokens are: 
 ['Other', 'companies', 'use', 'data', 'mining', 'gather', 'information', 'social', 'media', '.']

>> Bigrams are: 
 [('Other', 'companies'), ('companies', 'use'), ('use', 'data'), ('data', 'mining'), ('mining', 'gather'), ('gather', 'information'), ('information', 'social'), ('social', 'media'), ('media', '.')]

>> Trigrams are: 
 [('Other', 'companies', 'use'), ('companies', 'use', 'data'), ('use', 'data', 'mining'), ('data', 'mining', 'gather'), ('mining', 'gather', 'information'), ('gather', 'information', 'social'), ('information', 'social', 'media'), ('social', 'media', '.')]

>> POS Tags are: 
 [('Other', 'JJ'), ('companies', 'NNS'), ('use', 'VBP'), ('data', 'NNS'), ('mining', 'NN'), ('gather', 'NN'), ('information', 'NN'), ('social', 'JJ'), ('media', 'NNS'), ('.', '.')]

 (S
  (NP Other/JJ companies/NNS)
  use/VBP
  (NP data/NNS mining/NN gather/NN information/NN)
  (NP social/JJ media/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Other companies', 'data mining gather information', 'social media']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Other', 'other'), ('companies', 'compani'), ('use', 'use'), ('data', 'data'), ('mining', 'mine'), ('gather', 'gather'), ('information', 'inform'), ('social', 'social'), ('media', 'media'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Other', 'other'), ('companies', 'compani'), ('use', 'use'), ('data', 'data'), ('mining', 'mine'), ('gather', 'gather'), ('information', 'inform'), ('social', 'social'), ('media', 'media'), ('.', '.')]

>> Lemmatization: 
 [('Other', 'Other'), ('companies', 'company'), ('use', 'use'), ('data', 'data'), ('mining', 'mining'), ('gather', 'gather'), ('information', 'information'), ('social', 'social'), ('media', 'medium'), ('.', '.')]



============================ Sentence 601 =============================

Southwest Airlines, Ford motor, and Pepsico analyse consumer posts on social media like   Facebook and Twitter to standard the immediate influence on a movement and track the consumer   opinions about their products. 


>> Tokens are: 
 ['Southwest', 'Airlines', ',', 'Ford', 'motor', ',', 'Pepsico', 'analyse', 'consumer', 'posts', 'social', 'media', 'like', 'Facebook', 'Twitter', 'standard', 'immediate', 'influence', 'movement', 'track', 'consumer', 'opinions', 'products', '.']

>> Bigrams are: 
 [('Southwest', 'Airlines'), ('Airlines', ','), (',', 'Ford'), ('Ford', 'motor'), ('motor', ','), (',', 'Pepsico'), ('Pepsico', 'analyse'), ('analyse', 'consumer'), ('consumer', 'posts'), ('posts', 'social'), ('social', 'media'), ('media', 'like'), ('like', 'Facebook'), ('Facebook', 'Twitter'), ('Twitter', 'standard'), ('standard', 'immediate'), ('immediate', 'influence'), ('influence', 'movement'), ('movement', 'track'), ('track', 'consumer'), ('consumer', 'opinions'), ('opinions', 'products'), ('products', '.')]

>> Trigrams are: 
 [('Southwest', 'Airlines', ','), ('Airlines', ',', 'Ford'), (',', 'Ford', 'motor'), ('Ford', 'motor', ','), ('motor', ',', 'Pepsico'), (',', 'Pepsico', 'analyse'), ('Pepsico', 'analyse', 'consumer'), ('analyse', 'consumer', 'posts'), ('consumer', 'posts', 'social'), ('posts', 'social', 'media'), ('social', 'media', 'like'), ('media', 'like', 'Facebook'), ('like', 'Facebook', 'Twitter'), ('Facebook', 'Twitter', 'standard'), ('Twitter', 'standard', 'immediate'), ('standard', 'immediate', 'influence'), ('immediate', 'influence', 'movement'), ('influence', 'movement', 'track'), ('movement', 'track', 'consumer'), ('track', 'consumer', 'opinions'), ('consumer', 'opinions', 'products'), ('opinions', 'products', '.')]

>> POS Tags are: 
 [('Southwest', 'NNP'), ('Airlines', 'NNPS'), (',', ','), ('Ford', 'NNP'), ('motor', 'NN'), (',', ','), ('Pepsico', 'NNP'), ('analyse', 'VBZ'), ('consumer', 'NN'), ('posts', 'NNS'), ('social', 'JJ'), ('media', 'NNS'), ('like', 'IN'), ('Facebook', 'NNP'), ('Twitter', 'NNP'), ('standard', 'NN'), ('immediate', 'JJ'), ('influence', 'NN'), ('movement', 'NN'), ('track', 'NN'), ('consumer', 'NN'), ('opinions', 'NNS'), ('products', 'NNS'), ('.', '.')]

 (S
  (NP Southwest/NNP)
  Airlines/NNPS
  ,/,
  (NP Ford/NNP motor/NN)
  ,/,
  (NP Pepsico/NNP)
  analyse/VBZ
  (NP consumer/NN posts/NNS)
  (NP social/JJ media/NNS)
  like/IN
  (NP Facebook/NNP Twitter/NNP standard/NN)
  (NP
    immediate/JJ
    influence/NN
    movement/NN
    track/NN
    consumer/NN
    opinions/NNS
    products/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Southwest', 'Ford motor', 'Pepsico', 'consumer posts', 'social media', 'Facebook Twitter standard', 'immediate influence movement track consumer opinions products']

>> Named Entities are: 
 [('GPE', 'Southwest'), ('ORGANIZATION', 'Airlines'), ('ORGANIZATION', 'Ford'), ('PERSON', 'Pepsico'), ('PERSON', 'Facebook Twitter')] 

>> Stemming using Porter Stemmer: 
 [('Southwest', 'southwest'), ('Airlines', 'airlin'), (',', ','), ('Ford', 'ford'), ('motor', 'motor'), (',', ','), ('Pepsico', 'pepsico'), ('analyse', 'analys'), ('consumer', 'consum'), ('posts', 'post'), ('social', 'social'), ('media', 'media'), ('like', 'like'), ('Facebook', 'facebook'), ('Twitter', 'twitter'), ('standard', 'standard'), ('immediate', 'immedi'), ('influence', 'influenc'), ('movement', 'movement'), ('track', 'track'), ('consumer', 'consum'), ('opinions', 'opinion'), ('products', 'product'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Southwest', 'southwest'), ('Airlines', 'airlin'), (',', ','), ('Ford', 'ford'), ('motor', 'motor'), (',', ','), ('Pepsico', 'pepsico'), ('analyse', 'analys'), ('consumer', 'consum'), ('posts', 'post'), ('social', 'social'), ('media', 'media'), ('like', 'like'), ('Facebook', 'facebook'), ('Twitter', 'twitter'), ('standard', 'standard'), ('immediate', 'immedi'), ('influence', 'influenc'), ('movement', 'movement'), ('track', 'track'), ('consumer', 'consum'), ('opinions', 'opinion'), ('products', 'product'), ('.', '.')]

>> Lemmatization: 
 [('Southwest', 'Southwest'), ('Airlines', 'Airlines'), (',', ','), ('Ford', 'Ford'), ('motor', 'motor'), (',', ','), ('Pepsico', 'Pepsico'), ('analyse', 'analyse'), ('consumer', 'consumer'), ('posts', 'post'), ('social', 'social'), ('media', 'medium'), ('like', 'like'), ('Facebook', 'Facebook'), ('Twitter', 'Twitter'), ('standard', 'standard'), ('immediate', 'immediate'), ('influence', 'influence'), ('movement', 'movement'), ('track', 'track'), ('consumer', 'consumer'), ('opinions', 'opinion'), ('products', 'product'), ('.', '.')]



============================ Sentence 602 =============================

Sarah Al-Shiakhli   46      Big data has an impact on many aspects of society resulting in societal benefits. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '46', 'Big', 'data', 'impact', 'many', 'aspects', 'society', 'resulting', 'societal', 'benefits', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '46'), ('46', 'Big'), ('Big', 'data'), ('data', 'impact'), ('impact', 'many'), ('many', 'aspects'), ('aspects', 'society'), ('society', 'resulting'), ('resulting', 'societal'), ('societal', 'benefits'), ('benefits', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '46'), ('Al-Shiakhli', '46', 'Big'), ('46', 'Big', 'data'), ('Big', 'data', 'impact'), ('data', 'impact', 'many'), ('impact', 'many', 'aspects'), ('many', 'aspects', 'society'), ('aspects', 'society', 'resulting'), ('society', 'resulting', 'societal'), ('resulting', 'societal', 'benefits'), ('societal', 'benefits', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('46', 'CD'), ('Big', 'NNP'), ('data', 'NNS'), ('impact', 'NN'), ('many', 'JJ'), ('aspects', 'NNS'), ('society', 'NN'), ('resulting', 'VBG'), ('societal', 'JJ'), ('benefits', 'NNS'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  46/CD
  (NP Big/NNP data/NNS impact/NN)
  (NP many/JJ aspects/NNS society/NN)
  resulting/VBG
  (NP societal/JJ benefits/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Big data impact', 'many aspects society', 'societal benefits']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('46', '46'), ('Big', 'big'), ('data', 'data'), ('impact', 'impact'), ('many', 'mani'), ('aspects', 'aspect'), ('society', 'societi'), ('resulting', 'result'), ('societal', 'societ'), ('benefits', 'benefit'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('46', '46'), ('Big', 'big'), ('data', 'data'), ('impact', 'impact'), ('many', 'mani'), ('aspects', 'aspect'), ('society', 'societi'), ('resulting', 'result'), ('societal', 'societ'), ('benefits', 'benefit'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('46', '46'), ('Big', 'Big'), ('data', 'data'), ('impact', 'impact'), ('many', 'many'), ('aspects', 'aspect'), ('society', 'society'), ('resulting', 'resulting'), ('societal', 'societal'), ('benefits', 'benefit'), ('.', '.')]



============================ Sentence 603 =============================

On the medical   system, for example, it gives benefits of saving lives, as using big data enables the doctors to decide   which medication is the best to a patient. 


>> Tokens are: 
 ['On', 'medical', 'system', ',', 'example', ',', 'gives', 'benefits', 'saving', 'lives', ',', 'using', 'big', 'data', 'enables', 'doctors', 'decide', 'medication', 'best', 'patient', '.']

>> Bigrams are: 
 [('On', 'medical'), ('medical', 'system'), ('system', ','), (',', 'example'), ('example', ','), (',', 'gives'), ('gives', 'benefits'), ('benefits', 'saving'), ('saving', 'lives'), ('lives', ','), (',', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'enables'), ('enables', 'doctors'), ('doctors', 'decide'), ('decide', 'medication'), ('medication', 'best'), ('best', 'patient'), ('patient', '.')]

>> Trigrams are: 
 [('On', 'medical', 'system'), ('medical', 'system', ','), ('system', ',', 'example'), (',', 'example', ','), ('example', ',', 'gives'), (',', 'gives', 'benefits'), ('gives', 'benefits', 'saving'), ('benefits', 'saving', 'lives'), ('saving', 'lives', ','), ('lives', ',', 'using'), (',', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'enables'), ('data', 'enables', 'doctors'), ('enables', 'doctors', 'decide'), ('doctors', 'decide', 'medication'), ('decide', 'medication', 'best'), ('medication', 'best', 'patient'), ('best', 'patient', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('medical', 'JJ'), ('system', 'NN'), (',', ','), ('example', 'NN'), (',', ','), ('gives', 'VBZ'), ('benefits', 'NNS'), ('saving', 'VBG'), ('lives', 'NNS'), (',', ','), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('enables', 'NNS'), ('doctors', 'NNS'), ('decide', 'VBP'), ('medication', 'NN'), ('best', 'RBS'), ('patient', 'NN'), ('.', '.')]

 (S
  On/IN
  (NP medical/JJ system/NN)
  ,/,
  (NP example/NN)
  ,/,
  gives/VBZ
  (NP benefits/NNS)
  saving/VBG
  (NP lives/NNS)
  ,/,
  using/VBG
  (NP big/JJ data/NNS enables/NNS doctors/NNS)
  decide/VBP
  (NP medication/NN)
  best/RBS
  (NP patient/NN)
  ./.) 


>> Noun Phrases are: 
 ['medical system', 'example', 'benefits', 'lives', 'big data enables doctors', 'medication', 'patient']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('medical', 'medic'), ('system', 'system'), (',', ','), ('example', 'exampl'), (',', ','), ('gives', 'give'), ('benefits', 'benefit'), ('saving', 'save'), ('lives', 'live'), (',', ','), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('enables', 'enabl'), ('doctors', 'doctor'), ('decide', 'decid'), ('medication', 'medic'), ('best', 'best'), ('patient', 'patient'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('medical', 'medic'), ('system', 'system'), (',', ','), ('example', 'exampl'), (',', ','), ('gives', 'give'), ('benefits', 'benefit'), ('saving', 'save'), ('lives', 'live'), (',', ','), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('enables', 'enabl'), ('doctors', 'doctor'), ('decide', 'decid'), ('medication', 'medic'), ('best', 'best'), ('patient', 'patient'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('medical', 'medical'), ('system', 'system'), (',', ','), ('example', 'example'), (',', ','), ('gives', 'give'), ('benefits', 'benefit'), ('saving', 'saving'), ('lives', 'life'), (',', ','), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('enables', 'enables'), ('doctors', 'doctor'), ('decide', 'decide'), ('medication', 'medication'), ('best', 'best'), ('patient', 'patient'), ('.', '.')]



============================ Sentence 604 =============================

The patient does not need to wait long times, get severe   reactions, or dying from using medicines that do not fit with their case. 


>> Tokens are: 
 ['The', 'patient', 'need', 'wait', 'long', 'times', ',', 'get', 'severe', 'reactions', ',', 'dying', 'using', 'medicines', 'fit', 'case', '.']

>> Bigrams are: 
 [('The', 'patient'), ('patient', 'need'), ('need', 'wait'), ('wait', 'long'), ('long', 'times'), ('times', ','), (',', 'get'), ('get', 'severe'), ('severe', 'reactions'), ('reactions', ','), (',', 'dying'), ('dying', 'using'), ('using', 'medicines'), ('medicines', 'fit'), ('fit', 'case'), ('case', '.')]

>> Trigrams are: 
 [('The', 'patient', 'need'), ('patient', 'need', 'wait'), ('need', 'wait', 'long'), ('wait', 'long', 'times'), ('long', 'times', ','), ('times', ',', 'get'), (',', 'get', 'severe'), ('get', 'severe', 'reactions'), ('severe', 'reactions', ','), ('reactions', ',', 'dying'), (',', 'dying', 'using'), ('dying', 'using', 'medicines'), ('using', 'medicines', 'fit'), ('medicines', 'fit', 'case'), ('fit', 'case', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('patient', 'NN'), ('need', 'MD'), ('wait', 'VB'), ('long', 'JJ'), ('times', 'NNS'), (',', ','), ('get', 'VB'), ('severe', 'JJ'), ('reactions', 'NNS'), (',', ','), ('dying', 'VBG'), ('using', 'VBG'), ('medicines', 'NNS'), ('fit', 'JJ'), ('case', 'NN'), ('.', '.')]

 (S
  (NP The/DT patient/NN)
  need/MD
  wait/VB
  (NP long/JJ times/NNS)
  ,/,
  get/VB
  (NP severe/JJ reactions/NNS)
  ,/,
  dying/VBG
  using/VBG
  (NP medicines/NNS)
  (NP fit/JJ case/NN)
  ./.) 


>> Noun Phrases are: 
 ['The patient', 'long times', 'severe reactions', 'medicines', 'fit case']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('patient', 'patient'), ('need', 'need'), ('wait', 'wait'), ('long', 'long'), ('times', 'time'), (',', ','), ('get', 'get'), ('severe', 'sever'), ('reactions', 'reaction'), (',', ','), ('dying', 'die'), ('using', 'use'), ('medicines', 'medicin'), ('fit', 'fit'), ('case', 'case'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('patient', 'patient'), ('need', 'need'), ('wait', 'wait'), ('long', 'long'), ('times', 'time'), (',', ','), ('get', 'get'), ('severe', 'sever'), ('reactions', 'reaction'), (',', ','), ('dying', 'die'), ('using', 'use'), ('medicines', 'medicin'), ('fit', 'fit'), ('case', 'case'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('patient', 'patient'), ('need', 'need'), ('wait', 'wait'), ('long', 'long'), ('times', 'time'), (',', ','), ('get', 'get'), ('severe', 'severe'), ('reactions', 'reaction'), (',', ','), ('dying', 'dying'), ('using', 'using'), ('medicines', 'medicine'), ('fit', 'fit'), ('case', 'case'), ('.', '.')]



============================ Sentence 605 =============================

12. 


>> Tokens are: 
 ['12', '.']

>> Bigrams are: 
 [('12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('12', 'CD'), ('.', '.')]

 (S 12/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('12', '12'), ('.', '.')]



============================ Sentence 606 =============================

Conclusion and Future Research   The purpose of this study was to offer a literature review on the topic of big data analytics. 


>> Tokens are: 
 ['Conclusion', 'Future', 'Research', 'The', 'purpose', 'study', 'offer', 'literature', 'review', 'topic', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Conclusion', 'Future'), ('Future', 'Research'), ('Research', 'The'), ('The', 'purpose'), ('purpose', 'study'), ('study', 'offer'), ('offer', 'literature'), ('literature', 'review'), ('review', 'topic'), ('topic', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Conclusion', 'Future', 'Research'), ('Future', 'Research', 'The'), ('Research', 'The', 'purpose'), ('The', 'purpose', 'study'), ('purpose', 'study', 'offer'), ('study', 'offer', 'literature'), ('offer', 'literature', 'review'), ('literature', 'review', 'topic'), ('review', 'topic', 'big'), ('topic', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Conclusion', 'NNP'), ('Future', 'NNP'), ('Research', 'NNP'), ('The', 'DT'), ('purpose', 'NN'), ('study', 'NN'), ('offer', 'VBP'), ('literature', 'NN'), ('review', 'NN'), ('topic', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Conclusion/NNP Future/NNP Research/NNP)
  (NP The/DT purpose/NN study/NN)
  offer/VBP
  (NP literature/NN review/NN topic/NN)
  (NP big/JJ data/NNS analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Conclusion Future Research', 'The purpose study', 'literature review topic', 'big data analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research'), ('The', 'the'), ('purpose', 'purpos'), ('study', 'studi'), ('offer', 'offer'), ('literature', 'literatur'), ('review', 'review'), ('topic', 'topic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Conclusion', 'conclus'), ('Future', 'futur'), ('Research', 'research'), ('The', 'the'), ('purpose', 'purpos'), ('study', 'studi'), ('offer', 'offer'), ('literature', 'literatur'), ('review', 'review'), ('topic', 'topic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Conclusion', 'Conclusion'), ('Future', 'Future'), ('Research', 'Research'), ('The', 'The'), ('purpose', 'purpose'), ('study', 'study'), ('offer', 'offer'), ('literature', 'literature'), ('review', 'review'), ('topic', 'topic'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 607 =============================

This   began with the presentation of a general background to the topic, including big data definitions   and characteristics, followed by a review of big data analytics tools and methods. 


>> Tokens are: 
 ['This', 'began', 'presentation', 'general', 'background', 'topic', ',', 'including', 'big', 'data', 'definitions', 'characteristics', ',', 'followed', 'review', 'big', 'data', 'analytics', 'tools', 'methods', '.']

>> Bigrams are: 
 [('This', 'began'), ('began', 'presentation'), ('presentation', 'general'), ('general', 'background'), ('background', 'topic'), ('topic', ','), (',', 'including'), ('including', 'big'), ('big', 'data'), ('data', 'definitions'), ('definitions', 'characteristics'), ('characteristics', ','), (',', 'followed'), ('followed', 'review'), ('review', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'tools'), ('tools', 'methods'), ('methods', '.')]

>> Trigrams are: 
 [('This', 'began', 'presentation'), ('began', 'presentation', 'general'), ('presentation', 'general', 'background'), ('general', 'background', 'topic'), ('background', 'topic', ','), ('topic', ',', 'including'), (',', 'including', 'big'), ('including', 'big', 'data'), ('big', 'data', 'definitions'), ('data', 'definitions', 'characteristics'), ('definitions', 'characteristics', ','), ('characteristics', ',', 'followed'), (',', 'followed', 'review'), ('followed', 'review', 'big'), ('review', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'tools'), ('analytics', 'tools', 'methods'), ('tools', 'methods', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('began', 'VBD'), ('presentation', 'JJ'), ('general', 'JJ'), ('background', 'NN'), ('topic', 'NN'), (',', ','), ('including', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('definitions', 'NNS'), ('characteristics', 'NNS'), (',', ','), ('followed', 'VBD'), ('review', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('tools', 'NNS'), ('methods', 'NNS'), ('.', '.')]

 (S
  This/DT
  began/VBD
  (NP presentation/JJ general/JJ background/NN topic/NN)
  ,/,
  including/VBG
  (NP big/JJ data/NNS definitions/NNS characteristics/NNS)
  ,/,
  followed/VBD
  (NP review/NN)
  (NP big/JJ data/NNS analytics/NNS tools/NNS methods/NNS)
  ./.) 


>> Noun Phrases are: 
 ['presentation general background topic', 'big data definitions characteristics', 'review', 'big data analytics tools methods']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('began', 'began'), ('presentation', 'present'), ('general', 'gener'), ('background', 'background'), ('topic', 'topic'), (',', ','), ('including', 'includ'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('characteristics', 'characterist'), (',', ','), ('followed', 'follow'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('began', 'began'), ('presentation', 'present'), ('general', 'general'), ('background', 'background'), ('topic', 'topic'), (',', ','), ('including', 'includ'), ('big', 'big'), ('data', 'data'), ('definitions', 'definit'), ('characteristics', 'characterist'), (',', ','), ('followed', 'follow'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('tools', 'tool'), ('methods', 'method'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('began', 'began'), ('presentation', 'presentation'), ('general', 'general'), ('background', 'background'), ('topic', 'topic'), (',', ','), ('including', 'including'), ('big', 'big'), ('data', 'data'), ('definitions', 'definition'), ('characteristics', 'characteristic'), (',', ','), ('followed', 'followed'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('tools', 'tool'), ('methods', 'method'), ('.', '.')]



============================ Sentence 608 =============================

This thesis presented data analysis techniques characterised in four sections: supervised,   unsupervised, semi-supervised, and reinforcement learning. 


>> Tokens are: 
 ['This', 'thesis', 'presented', 'data', 'analysis', 'techniques', 'characterised', 'four', 'sections', ':', 'supervised', ',', 'unsupervised', ',', 'semi-supervised', ',', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('This', 'thesis'), ('thesis', 'presented'), ('presented', 'data'), ('data', 'analysis'), ('analysis', 'techniques'), ('techniques', 'characterised'), ('characterised', 'four'), ('four', 'sections'), ('sections', ':'), (':', 'supervised'), ('supervised', ','), (',', 'unsupervised'), ('unsupervised', ','), (',', 'semi-supervised'), ('semi-supervised', ','), (',', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('This', 'thesis', 'presented'), ('thesis', 'presented', 'data'), ('presented', 'data', 'analysis'), ('data', 'analysis', 'techniques'), ('analysis', 'techniques', 'characterised'), ('techniques', 'characterised', 'four'), ('characterised', 'four', 'sections'), ('four', 'sections', ':'), ('sections', ':', 'supervised'), (':', 'supervised', ','), ('supervised', ',', 'unsupervised'), (',', 'unsupervised', ','), ('unsupervised', ',', 'semi-supervised'), (',', 'semi-supervised', ','), ('semi-supervised', ',', 'reinforcement'), (',', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('This', 'DT'), ('thesis', 'NN'), ('presented', 'VBD'), ('data', 'NNS'), ('analysis', 'NN'), ('techniques', 'NNS'), ('characterised', 'VBD'), ('four', 'CD'), ('sections', 'NNS'), (':', ':'), ('supervised', 'VBN'), (',', ','), ('unsupervised', 'JJ'), (',', ','), ('semi-supervised', 'JJ'), (',', ','), ('reinforcement', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP This/DT thesis/NN)
  presented/VBD
  (NP data/NNS analysis/NN techniques/NNS)
  characterised/VBD
  four/CD
  (NP sections/NNS)
  :/:
  supervised/VBN
  ,/,
  unsupervised/JJ
  ,/,
  semi-supervised/JJ
  ,/,
  (NP reinforcement/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['This thesis', 'data analysis techniques', 'sections', 'reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('This', 'thi'), ('thesis', 'thesi'), ('presented', 'present'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('sections', 'section'), (':', ':'), ('supervised', 'supervis'), (',', ','), ('unsupervised', 'unsupervis'), (',', ','), ('semi-supervised', 'semi-supervis'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('This', 'this'), ('thesis', 'thesi'), ('presented', 'present'), ('data', 'data'), ('analysis', 'analysi'), ('techniques', 'techniqu'), ('characterised', 'characteris'), ('four', 'four'), ('sections', 'section'), (':', ':'), ('supervised', 'supervis'), (',', ','), ('unsupervised', 'unsupervis'), (',', ','), ('semi-supervised', 'semi-supervis'), (',', ','), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('This', 'This'), ('thesis', 'thesis'), ('presented', 'presented'), ('data', 'data'), ('analysis', 'analysis'), ('techniques', 'technique'), ('characterised', 'characterised'), ('four', 'four'), ('sections', 'section'), (':', ':'), ('supervised', 'supervised'), (',', ','), ('unsupervised', 'unsupervised'), (',', ','), ('semi-supervised', 'semi-supervised'), (',', ','), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 609 =============================

Some analytics techniques were also   presented, such as clustering, correlation, regression, and factor analytics, and some big data tools   and platforms such as Hadoop, Apache Mahout, and R were explained in relation to these. 


>> Tokens are: 
 ['Some', 'analytics', 'techniques', 'also', 'presented', ',', 'clustering', ',', 'correlation', ',', 'regression', ',', 'factor', 'analytics', ',', 'big', 'data', 'tools', 'platforms', 'Hadoop', ',', 'Apache', 'Mahout', ',', 'R', 'explained', 'relation', '.']

>> Bigrams are: 
 [('Some', 'analytics'), ('analytics', 'techniques'), ('techniques', 'also'), ('also', 'presented'), ('presented', ','), (',', 'clustering'), ('clustering', ','), (',', 'correlation'), ('correlation', ','), (',', 'regression'), ('regression', ','), (',', 'factor'), ('factor', 'analytics'), ('analytics', ','), (',', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', 'platforms'), ('platforms', 'Hadoop'), ('Hadoop', ','), (',', 'Apache'), ('Apache', 'Mahout'), ('Mahout', ','), (',', 'R'), ('R', 'explained'), ('explained', 'relation'), ('relation', '.')]

>> Trigrams are: 
 [('Some', 'analytics', 'techniques'), ('analytics', 'techniques', 'also'), ('techniques', 'also', 'presented'), ('also', 'presented', ','), ('presented', ',', 'clustering'), (',', 'clustering', ','), ('clustering', ',', 'correlation'), (',', 'correlation', ','), ('correlation', ',', 'regression'), (',', 'regression', ','), ('regression', ',', 'factor'), (',', 'factor', 'analytics'), ('factor', 'analytics', ','), ('analytics', ',', 'big'), (',', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', 'platforms'), ('tools', 'platforms', 'Hadoop'), ('platforms', 'Hadoop', ','), ('Hadoop', ',', 'Apache'), (',', 'Apache', 'Mahout'), ('Apache', 'Mahout', ','), ('Mahout', ',', 'R'), (',', 'R', 'explained'), ('R', 'explained', 'relation'), ('explained', 'relation', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('also', 'RB'), ('presented', 'VBD'), (',', ','), ('clustering', 'VBG'), (',', ','), ('correlation', 'NN'), (',', ','), ('regression', 'NN'), (',', ','), ('factor', 'NN'), ('analytics', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), ('platforms', 'NNS'), ('Hadoop', 'NNP'), (',', ','), ('Apache', 'NNP'), ('Mahout', 'NNP'), (',', ','), ('R', 'NNP'), ('explained', 'VBD'), ('relation', 'NN'), ('.', '.')]

 (S
  (NP Some/DT analytics/NNS techniques/NNS)
  also/RB
  presented/VBD
  ,/,
  clustering/VBG
  ,/,
  (NP correlation/NN)
  ,/,
  (NP regression/NN)
  ,/,
  (NP factor/NN analytics/NNS)
  ,/,
  (NP big/JJ data/NN tools/NNS platforms/NNS Hadoop/NNP)
  ,/,
  (NP Apache/NNP Mahout/NNP)
  ,/,
  (NP R/NNP)
  explained/VBD
  (NP relation/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some analytics techniques', 'correlation', 'regression', 'factor analytics', 'big data tools platforms Hadoop', 'Apache Mahout', 'R', 'relation']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('PERSON', 'Apache Mahout'), ('PERSON', 'R')] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('also', 'also'), ('presented', 'present'), (',', ','), ('clustering', 'cluster'), (',', ','), ('correlation', 'correl'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('Apache', 'apach'), ('Mahout', 'mahout'), (',', ','), ('R', 'r'), ('explained', 'explain'), ('relation', 'relat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('also', 'also'), ('presented', 'present'), (',', ','), ('clustering', 'cluster'), (',', ','), ('correlation', 'correl'), (',', ','), ('regression', 'regress'), (',', ','), ('factor', 'factor'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform'), ('Hadoop', 'hadoop'), (',', ','), ('Apache', 'apach'), ('Mahout', 'mahout'), (',', ','), ('R', 'r'), ('explained', 'explain'), ('relation', 'relat'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('analytics', 'analytics'), ('techniques', 'technique'), ('also', 'also'), ('presented', 'presented'), (',', ','), ('clustering', 'clustering'), (',', ','), ('correlation', 'correlation'), (',', ','), ('regression', 'regression'), (',', ','), ('factor', 'factor'), ('analytics', 'analytics'), (',', ','), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), ('platforms', 'platform'), ('Hadoop', 'Hadoop'), (',', ','), ('Apache', 'Apache'), ('Mahout', 'Mahout'), (',', ','), ('R', 'R'), ('explained', 'explained'), ('relation', 'relation'), ('.', '.')]



============================ Sentence 610 =============================

Big   data storage, management, and analytics processing were also discussed, and some emergent   advanced data analytics techniques further examined. 


>> Tokens are: 
 ['Big', 'data', 'storage', ',', 'management', ',', 'analytics', 'processing', 'also', 'discussed', ',', 'emergent', 'advanced', 'data', 'analytics', 'techniques', 'examined', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'storage'), ('storage', ','), (',', 'management'), ('management', ','), (',', 'analytics'), ('analytics', 'processing'), ('processing', 'also'), ('also', 'discussed'), ('discussed', ','), (',', 'emergent'), ('emergent', 'advanced'), ('advanced', 'data'), ('data', 'analytics'), ('analytics', 'techniques'), ('techniques', 'examined'), ('examined', '.')]

>> Trigrams are: 
 [('Big', 'data', 'storage'), ('data', 'storage', ','), ('storage', ',', 'management'), (',', 'management', ','), ('management', ',', 'analytics'), (',', 'analytics', 'processing'), ('analytics', 'processing', 'also'), ('processing', 'also', 'discussed'), ('also', 'discussed', ','), ('discussed', ',', 'emergent'), (',', 'emergent', 'advanced'), ('emergent', 'advanced', 'data'), ('advanced', 'data', 'analytics'), ('data', 'analytics', 'techniques'), ('analytics', 'techniques', 'examined'), ('techniques', 'examined', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('storage', 'NN'), (',', ','), ('management', 'NN'), (',', ','), ('analytics', 'NNS'), ('processing', 'NN'), ('also', 'RB'), ('discussed', 'VBD'), (',', ','), ('emergent', 'NN'), ('advanced', 'VBD'), ('data', 'NNS'), ('analytics', 'NNS'), ('techniques', 'NNS'), ('examined', 'VBN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS storage/NN)
  ,/,
  (NP management/NN)
  ,/,
  (NP analytics/NNS processing/NN)
  also/RB
  discussed/VBD
  ,/,
  (NP emergent/NN)
  advanced/VBD
  (NP data/NNS analytics/NNS techniques/NNS)
  examined/VBN
  ./.) 


>> Noun Phrases are: 
 ['Big data storage', 'management', 'analytics processing', 'emergent', 'data analytics techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('analytics', 'analyt'), ('processing', 'process'), ('also', 'also'), ('discussed', 'discuss'), (',', ','), ('emergent', 'emerg'), ('advanced', 'advanc'), ('data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('examined', 'examin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('analytics', 'analyt'), ('processing', 'process'), ('also', 'also'), ('discussed', 'discuss'), (',', ','), ('emergent', 'emerg'), ('advanced', 'advanc'), ('data', 'data'), ('analytics', 'analyt'), ('techniques', 'techniqu'), ('examined', 'examin'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('storage', 'storage'), (',', ','), ('management', 'management'), (',', ','), ('analytics', 'analytics'), ('processing', 'processing'), ('also', 'also'), ('discussed', 'discussed'), (',', ','), ('emergent', 'emergent'), ('advanced', 'advanced'), ('data', 'data'), ('analytics', 'analytics'), ('techniques', 'technique'), ('examined', 'examined'), ('.', '.')]



============================ Sentence 611 =============================

Various big data tools, methods, and technologies have been discussed in this research, offering   readers examples of the necessary technologies, and prompting developers to come up with ideas   about how to provide additional big data analytics solutions to help in decision making. 


>> Tokens are: 
 ['Various', 'big', 'data', 'tools', ',', 'methods', ',', 'technologies', 'discussed', 'research', ',', 'offering', 'readers', 'examples', 'necessary', 'technologies', ',', 'prompting', 'developers', 'come', 'ideas', 'provide', 'additional', 'big', 'data', 'analytics', 'solutions', 'help', 'decision', 'making', '.']

>> Bigrams are: 
 [('Various', 'big'), ('big', 'data'), ('data', 'tools'), ('tools', ','), (',', 'methods'), ('methods', ','), (',', 'technologies'), ('technologies', 'discussed'), ('discussed', 'research'), ('research', ','), (',', 'offering'), ('offering', 'readers'), ('readers', 'examples'), ('examples', 'necessary'), ('necessary', 'technologies'), ('technologies', ','), (',', 'prompting'), ('prompting', 'developers'), ('developers', 'come'), ('come', 'ideas'), ('ideas', 'provide'), ('provide', 'additional'), ('additional', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'solutions'), ('solutions', 'help'), ('help', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('Various', 'big', 'data'), ('big', 'data', 'tools'), ('data', 'tools', ','), ('tools', ',', 'methods'), (',', 'methods', ','), ('methods', ',', 'technologies'), (',', 'technologies', 'discussed'), ('technologies', 'discussed', 'research'), ('discussed', 'research', ','), ('research', ',', 'offering'), (',', 'offering', 'readers'), ('offering', 'readers', 'examples'), ('readers', 'examples', 'necessary'), ('examples', 'necessary', 'technologies'), ('necessary', 'technologies', ','), ('technologies', ',', 'prompting'), (',', 'prompting', 'developers'), ('prompting', 'developers', 'come'), ('developers', 'come', 'ideas'), ('come', 'ideas', 'provide'), ('ideas', 'provide', 'additional'), ('provide', 'additional', 'big'), ('additional', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'solutions'), ('analytics', 'solutions', 'help'), ('solutions', 'help', 'decision'), ('help', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('Various', 'JJ'), ('big', 'JJ'), ('data', 'NN'), ('tools', 'NNS'), (',', ','), ('methods', 'NNS'), (',', ','), ('technologies', 'NNS'), ('discussed', 'VBD'), ('research', 'NN'), (',', ','), ('offering', 'VBG'), ('readers', 'NNS'), ('examples', 'NNS'), ('necessary', 'JJ'), ('technologies', 'NNS'), (',', ','), ('prompting', 'VBG'), ('developers', 'NNS'), ('come', 'VBP'), ('ideas', 'NNS'), ('provide', 'VBP'), ('additional', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('solutions', 'NNS'), ('help', 'VBP'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

 (S
  (NP Various/JJ big/JJ data/NN tools/NNS)
  ,/,
  (NP methods/NNS)
  ,/,
  (NP technologies/NNS)
  discussed/VBD
  (NP research/NN)
  ,/,
  offering/VBG
  (NP readers/NNS examples/NNS)
  (NP necessary/JJ technologies/NNS)
  ,/,
  prompting/VBG
  (NP developers/NNS)
  come/VBP
  (NP ideas/NNS)
  provide/VBP
  (NP additional/JJ big/JJ data/NNS analytics/NNS solutions/NNS)
  help/VBP
  (NP decision/NN making/NN)
  ./.) 


>> Noun Phrases are: 
 ['Various big data tools', 'methods', 'technologies', 'research', 'readers examples', 'necessary technologies', 'developers', 'ideas', 'additional big data analytics solutions', 'decision making']

>> Named Entities are: 
 [('GPE', 'Various')] 

>> Stemming using Porter Stemmer: 
 [('Various', 'variou'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('technologies', 'technolog'), ('discussed', 'discuss'), ('research', 'research'), (',', ','), ('offering', 'offer'), ('readers', 'reader'), ('examples', 'exampl'), ('necessary', 'necessari'), ('technologies', 'technolog'), (',', ','), ('prompting', 'prompt'), ('developers', 'develop'), ('come', 'come'), ('ideas', 'idea'), ('provide', 'provid'), ('additional', 'addit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('solutions', 'solut'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Various', 'various'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('technologies', 'technolog'), ('discussed', 'discuss'), ('research', 'research'), (',', ','), ('offering', 'offer'), ('readers', 'reader'), ('examples', 'exampl'), ('necessary', 'necessari'), ('technologies', 'technolog'), (',', ','), ('prompting', 'prompt'), ('developers', 'develop'), ('come', 'come'), ('ideas', 'idea'), ('provide', 'provid'), ('additional', 'addit'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('solutions', 'solut'), ('help', 'help'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('Various', 'Various'), ('big', 'big'), ('data', 'data'), ('tools', 'tool'), (',', ','), ('methods', 'method'), (',', ','), ('technologies', 'technology'), ('discussed', 'discussed'), ('research', 'research'), (',', ','), ('offering', 'offering'), ('readers', 'reader'), ('examples', 'example'), ('necessary', 'necessary'), ('technologies', 'technology'), (',', ','), ('prompting', 'prompting'), ('developers', 'developer'), ('come', 'come'), ('ideas', 'idea'), ('provide', 'provide'), ('additional', 'additional'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('solutions', 'solution'), ('help', 'help'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



============================ Sentence 612 =============================

Big data analytics has been applied in various areas, serving many different sectors. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'applied', 'various', 'areas', ',', 'serving', 'many', 'different', 'sectors', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'applied'), ('applied', 'various'), ('various', 'areas'), ('areas', ','), (',', 'serving'), ('serving', 'many'), ('many', 'different'), ('different', 'sectors'), ('sectors', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'applied'), ('analytics', 'applied', 'various'), ('applied', 'various', 'areas'), ('various', 'areas', ','), ('areas', ',', 'serving'), (',', 'serving', 'many'), ('serving', 'many', 'different'), ('many', 'different', 'sectors'), ('different', 'sectors', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('applied', 'VBD'), ('various', 'JJ'), ('areas', 'NNS'), (',', ','), ('serving', 'VBG'), ('many', 'JJ'), ('different', 'JJ'), ('sectors', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  applied/VBD
  (NP various/JJ areas/NNS)
  ,/,
  serving/VBG
  (NP many/JJ different/JJ sectors/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'various areas', 'many different sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applied', 'appli'), ('various', 'variou'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('many', 'mani'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applied', 'appli'), ('various', 'various'), ('areas', 'area'), (',', ','), ('serving', 'serv'), ('many', 'mani'), ('different', 'differ'), ('sectors', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('applied', 'applied'), ('various', 'various'), ('areas', 'area'), (',', ','), ('serving', 'serving'), ('many', 'many'), ('different', 'different'), ('sectors', 'sector'), ('.', '.')]



============================ Sentence 613 =============================

Big data   analytics has the potential to improve care, save lives, and reduce costs in the healthcare sector. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'potential', 'improve', 'care', ',', 'save', 'lives', ',', 'reduce', 'costs', 'healthcare', 'sector', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'potential'), ('potential', 'improve'), ('improve', 'care'), ('care', ','), (',', 'save'), ('save', 'lives'), ('lives', ','), (',', 'reduce'), ('reduce', 'costs'), ('costs', 'healthcare'), ('healthcare', 'sector'), ('sector', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'potential'), ('analytics', 'potential', 'improve'), ('potential', 'improve', 'care'), ('improve', 'care', ','), ('care', ',', 'save'), (',', 'save', 'lives'), ('save', 'lives', ','), ('lives', ',', 'reduce'), (',', 'reduce', 'costs'), ('reduce', 'costs', 'healthcare'), ('costs', 'healthcare', 'sector'), ('healthcare', 'sector', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('potential', 'JJ'), ('improve', 'NN'), ('care', 'NN'), (',', ','), ('save', 'VBP'), ('lives', 'NNS'), (',', ','), ('reduce', 'VB'), ('costs', 'NNS'), ('healthcare', 'NN'), ('sector', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  (NP potential/JJ improve/NN care/NN)
  ,/,
  save/VBP
  (NP lives/NNS)
  ,/,
  reduce/VB
  (NP costs/NNS healthcare/NN sector/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'potential improve care', 'lives', 'costs healthcare sector']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('potential', 'potenti'), ('improve', 'improv'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('reduce', 'reduc'), ('costs', 'cost'), ('healthcare', 'healthcar'), ('sector', 'sector'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('potential', 'potenti'), ('improve', 'improv'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'live'), (',', ','), ('reduce', 'reduc'), ('costs', 'cost'), ('healthcare', 'healthcar'), ('sector', 'sector'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('potential', 'potential'), ('improve', 'improve'), ('care', 'care'), (',', ','), ('save', 'save'), ('lives', 'life'), (',', ','), ('reduce', 'reduce'), ('costs', 'cost'), ('healthcare', 'healthcare'), ('sector', 'sector'), ('.', '.')]



============================ Sentence 614 =============================

It   also benefits industries such as financial institutions by allowing analysis of customer log files to   help develop a better understanding of customer needs. 


>> Tokens are: 
 ['It', 'also', 'benefits', 'industries', 'financial', 'institutions', 'allowing', 'analysis', 'customer', 'log', 'files', 'help', 'develop', 'better', 'understanding', 'customer', 'needs', '.']

>> Bigrams are: 
 [('It', 'also'), ('also', 'benefits'), ('benefits', 'industries'), ('industries', 'financial'), ('financial', 'institutions'), ('institutions', 'allowing'), ('allowing', 'analysis'), ('analysis', 'customer'), ('customer', 'log'), ('log', 'files'), ('files', 'help'), ('help', 'develop'), ('develop', 'better'), ('better', 'understanding'), ('understanding', 'customer'), ('customer', 'needs'), ('needs', '.')]

>> Trigrams are: 
 [('It', 'also', 'benefits'), ('also', 'benefits', 'industries'), ('benefits', 'industries', 'financial'), ('industries', 'financial', 'institutions'), ('financial', 'institutions', 'allowing'), ('institutions', 'allowing', 'analysis'), ('allowing', 'analysis', 'customer'), ('analysis', 'customer', 'log'), ('customer', 'log', 'files'), ('log', 'files', 'help'), ('files', 'help', 'develop'), ('help', 'develop', 'better'), ('develop', 'better', 'understanding'), ('better', 'understanding', 'customer'), ('understanding', 'customer', 'needs'), ('customer', 'needs', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('also', 'RB'), ('benefits', 'NNS'), ('industries', 'NNS'), ('financial', 'JJ'), ('institutions', 'NNS'), ('allowing', 'VBG'), ('analysis', 'NN'), ('customer', 'NN'), ('log', 'NN'), ('files', 'NNS'), ('help', 'VBP'), ('develop', 'VB'), ('better', 'RBR'), ('understanding', 'VBG'), ('customer', 'NN'), ('needs', 'NNS'), ('.', '.')]

 (S
  It/PRP
  also/RB
  (NP benefits/NNS industries/NNS)
  (NP financial/JJ institutions/NNS)
  allowing/VBG
  (NP analysis/NN customer/NN log/NN files/NNS)
  help/VBP
  develop/VB
  better/RBR
  understanding/VBG
  (NP customer/NN needs/NNS)
  ./.) 


>> Noun Phrases are: 
 ['benefits industries', 'financial institutions', 'analysis customer log files', 'customer needs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('also', 'also'), ('benefits', 'benefit'), ('industries', 'industri'), ('financial', 'financi'), ('institutions', 'institut'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file'), ('help', 'help'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('customer', 'custom'), ('needs', 'need'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('also', 'also'), ('benefits', 'benefit'), ('industries', 'industri'), ('financial', 'financi'), ('institutions', 'institut'), ('allowing', 'allow'), ('analysis', 'analysi'), ('customer', 'custom'), ('log', 'log'), ('files', 'file'), ('help', 'help'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understand'), ('customer', 'custom'), ('needs', 'need'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('also', 'also'), ('benefits', 'benefit'), ('industries', 'industry'), ('financial', 'financial'), ('institutions', 'institution'), ('allowing', 'allowing'), ('analysis', 'analysis'), ('customer', 'customer'), ('log', 'log'), ('files', 'file'), ('help', 'help'), ('develop', 'develop'), ('better', 'better'), ('understanding', 'understanding'), ('customer', 'customer'), ('needs', 'need'), ('.', '.')]



============================ Sentence 615 =============================

The retail sector has a significant impact   on society and using big data analytics in this sector can again help managers to better understand   people’s needs, thus prompting the development of better services. 


>> Tokens are: 
 ['The', 'retail', 'sector', 'significant', 'impact', 'society', 'using', 'big', 'data', 'analytics', 'sector', 'help', 'managers', 'better', 'understand', 'people', '’', 'needs', ',', 'thus', 'prompting', 'development', 'better', 'services', '.']

>> Bigrams are: 
 [('The', 'retail'), ('retail', 'sector'), ('sector', 'significant'), ('significant', 'impact'), ('impact', 'society'), ('society', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'sector'), ('sector', 'help'), ('help', 'managers'), ('managers', 'better'), ('better', 'understand'), ('understand', 'people'), ('people', '’'), ('’', 'needs'), ('needs', ','), (',', 'thus'), ('thus', 'prompting'), ('prompting', 'development'), ('development', 'better'), ('better', 'services'), ('services', '.')]

>> Trigrams are: 
 [('The', 'retail', 'sector'), ('retail', 'sector', 'significant'), ('sector', 'significant', 'impact'), ('significant', 'impact', 'society'), ('impact', 'society', 'using'), ('society', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'sector'), ('analytics', 'sector', 'help'), ('sector', 'help', 'managers'), ('help', 'managers', 'better'), ('managers', 'better', 'understand'), ('better', 'understand', 'people'), ('understand', 'people', '’'), ('people', '’', 'needs'), ('’', 'needs', ','), ('needs', ',', 'thus'), (',', 'thus', 'prompting'), ('thus', 'prompting', 'development'), ('prompting', 'development', 'better'), ('development', 'better', 'services'), ('better', 'services', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('retail', 'JJ'), ('sector', 'NN'), ('significant', 'JJ'), ('impact', 'JJ'), ('society', 'NN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('sector', 'NN'), ('help', 'NN'), ('managers', 'NNS'), ('better', 'RBR'), ('understand', 'VBP'), ('people', 'NNS'), ('’', 'NNP'), ('needs', 'VBZ'), (',', ','), ('thus', 'RB'), ('prompting', 'VBG'), ('development', 'NN'), ('better', 'NN'), ('services', 'NNS'), ('.', '.')]

 (S
  (NP The/DT retail/JJ sector/NN)
  (NP significant/JJ impact/JJ society/NN)
  using/VBG
  (NP big/JJ data/NNS analytics/NNS sector/NN help/NN managers/NNS)
  better/RBR
  understand/VBP
  (NP people/NNS ’/NNP)
  needs/VBZ
  ,/,
  thus/RB
  prompting/VBG
  (NP development/NN better/NN services/NNS)
  ./.) 


>> Noun Phrases are: 
 ['The retail sector', 'significant impact society', 'big data analytics sector help managers', 'people ’', 'development better services']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('significant', 'signific'), ('impact', 'impact'), ('society', 'societi'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('sector', 'sector'), ('help', 'help'), ('managers', 'manag'), ('better', 'better'), ('understand', 'understand'), ('people', 'peopl'), ('’', '’'), ('needs', 'need'), (',', ','), ('thus', 'thu'), ('prompting', 'prompt'), ('development', 'develop'), ('better', 'better'), ('services', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('retail', 'retail'), ('sector', 'sector'), ('significant', 'signific'), ('impact', 'impact'), ('society', 'societi'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('sector', 'sector'), ('help', 'help'), ('managers', 'manag'), ('better', 'better'), ('understand', 'understand'), ('people', 'peopl'), ('’', '’'), ('needs', 'need'), (',', ','), ('thus', 'thus'), ('prompting', 'prompt'), ('development', 'develop'), ('better', 'better'), ('services', 'servic'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('retail', 'retail'), ('sector', 'sector'), ('significant', 'significant'), ('impact', 'impact'), ('society', 'society'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('sector', 'sector'), ('help', 'help'), ('managers', 'manager'), ('better', 'better'), ('understand', 'understand'), ('people', 'people'), ('’', '’'), ('needs', 'need'), (',', ','), ('thus', 'thus'), ('prompting', 'prompting'), ('development', 'development'), ('better', 'better'), ('services', 'service'), ('.', '.')]



============================ Sentence 616 =============================

Big data analytics are also used   in the telecommunications sector, where they help in monitoring machine logs and addressing   quality issues. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'also', 'used', 'telecommunications', 'sector', ',', 'help', 'monitoring', 'machine', 'logs', 'addressing', 'quality', 'issues', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'also'), ('also', 'used'), ('used', 'telecommunications'), ('telecommunications', 'sector'), ('sector', ','), (',', 'help'), ('help', 'monitoring'), ('monitoring', 'machine'), ('machine', 'logs'), ('logs', 'addressing'), ('addressing', 'quality'), ('quality', 'issues'), ('issues', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'also'), ('analytics', 'also', 'used'), ('also', 'used', 'telecommunications'), ('used', 'telecommunications', 'sector'), ('telecommunications', 'sector', ','), ('sector', ',', 'help'), (',', 'help', 'monitoring'), ('help', 'monitoring', 'machine'), ('monitoring', 'machine', 'logs'), ('machine', 'logs', 'addressing'), ('logs', 'addressing', 'quality'), ('addressing', 'quality', 'issues'), ('quality', 'issues', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('also', 'RB'), ('used', 'VBD'), ('telecommunications', 'NNS'), ('sector', 'NN'), (',', ','), ('help', 'VB'), ('monitoring', 'NN'), ('machine', 'NN'), ('logs', 'NNS'), ('addressing', 'VBG'), ('quality', 'NN'), ('issues', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  also/RB
  used/VBD
  (NP telecommunications/NNS sector/NN)
  ,/,
  help/VB
  (NP monitoring/NN machine/NN logs/NNS)
  addressing/VBG
  (NP quality/NN issues/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'telecommunications sector', 'monitoring machine logs', 'quality issues']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use'), ('telecommunications', 'telecommun'), ('sector', 'sector'), (',', ','), ('help', 'help'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('addressing', 'address'), ('quality', 'qualiti'), ('issues', 'issu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('also', 'also'), ('used', 'use'), ('telecommunications', 'telecommun'), ('sector', 'sector'), (',', ','), ('help', 'help'), ('monitoring', 'monitor'), ('machine', 'machin'), ('logs', 'log'), ('addressing', 'address'), ('quality', 'qualiti'), ('issues', 'issu'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('also', 'also'), ('used', 'used'), ('telecommunications', 'telecommunication'), ('sector', 'sector'), (',', ','), ('help', 'help'), ('monitoring', 'monitoring'), ('machine', 'machine'), ('logs', 'log'), ('addressing', 'addressing'), ('quality', 'quality'), ('issues', 'issue'), ('.', '.')]



============================ Sentence 617 =============================

Some big data analytics challenges were discussed in this work, particularly with regard to security   and privacy. 


>> Tokens are: 
 ['Some', 'big', 'data', 'analytics', 'challenges', 'discussed', 'work', ',', 'particularly', 'regard', 'security', 'privacy', '.']

>> Bigrams are: 
 [('Some', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'discussed'), ('discussed', 'work'), ('work', ','), (',', 'particularly'), ('particularly', 'regard'), ('regard', 'security'), ('security', 'privacy'), ('privacy', '.')]

>> Trigrams are: 
 [('Some', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'discussed'), ('challenges', 'discussed', 'work'), ('discussed', 'work', ','), ('work', ',', 'particularly'), (',', 'particularly', 'regard'), ('particularly', 'regard', 'security'), ('regard', 'security', 'privacy'), ('security', 'privacy', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('discussed', 'VBN'), ('work', 'NN'), (',', ','), ('particularly', 'RB'), ('regard', 'JJ'), ('security', 'NN'), ('privacy', 'NN'), ('.', '.')]

 (S
  (NP Some/DT big/JJ data/NNS analytics/NNS challenges/NNS)
  discussed/VBN
  (NP work/NN)
  ,/,
  particularly/RB
  (NP regard/JJ security/NN privacy/NN)
  ./.) 


>> Noun Phrases are: 
 ['Some big data analytics challenges', 'work', 'regard security privacy']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('discussed', 'discuss'), ('work', 'work'), (',', ','), ('particularly', 'particularli'), ('regard', 'regard'), ('security', 'secur'), ('privacy', 'privaci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('discussed', 'discuss'), ('work', 'work'), (',', ','), ('particularly', 'particular'), ('regard', 'regard'), ('security', 'secur'), ('privacy', 'privaci'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('discussed', 'discussed'), ('work', 'work'), (',', ','), ('particularly', 'particularly'), ('regard', 'regard'), ('security', 'security'), ('privacy', 'privacy'), ('.', '.')]



============================ Sentence 618 =============================

Some examples of how big data analytics can be used to handle issues such as   intrusion detection and big data characteristics such as size, velocity, variety, value and external   sources were also given. 


>> Tokens are: 
 ['Some', 'examples', 'big', 'data', 'analytics', 'used', 'handle', 'issues', 'intrusion', 'detection', 'big', 'data', 'characteristics', 'size', ',', 'velocity', ',', 'variety', ',', 'value', 'external', 'sources', 'also', 'given', '.']

>> Bigrams are: 
 [('Some', 'examples'), ('examples', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'used'), ('used', 'handle'), ('handle', 'issues'), ('issues', 'intrusion'), ('intrusion', 'detection'), ('detection', 'big'), ('big', 'data'), ('data', 'characteristics'), ('characteristics', 'size'), ('size', ','), (',', 'velocity'), ('velocity', ','), (',', 'variety'), ('variety', ','), (',', 'value'), ('value', 'external'), ('external', 'sources'), ('sources', 'also'), ('also', 'given'), ('given', '.')]

>> Trigrams are: 
 [('Some', 'examples', 'big'), ('examples', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'used'), ('analytics', 'used', 'handle'), ('used', 'handle', 'issues'), ('handle', 'issues', 'intrusion'), ('issues', 'intrusion', 'detection'), ('intrusion', 'detection', 'big'), ('detection', 'big', 'data'), ('big', 'data', 'characteristics'), ('data', 'characteristics', 'size'), ('characteristics', 'size', ','), ('size', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'variety'), (',', 'variety', ','), ('variety', ',', 'value'), (',', 'value', 'external'), ('value', 'external', 'sources'), ('external', 'sources', 'also'), ('sources', 'also', 'given'), ('also', 'given', '.')]

>> POS Tags are: 
 [('Some', 'DT'), ('examples', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('used', 'VBD'), ('handle', 'JJ'), ('issues', 'NNS'), ('intrusion', 'NN'), ('detection', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('characteristics', 'NNS'), ('size', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('variety', 'NN'), (',', ','), ('value', 'NN'), ('external', 'JJ'), ('sources', 'NNS'), ('also', 'RB'), ('given', 'VBN'), ('.', '.')]

 (S
  (NP Some/DT examples/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  used/VBD
  (NP handle/JJ issues/NNS intrusion/NN detection/NN)
  (NP big/JJ data/NNS characteristics/NNS size/NN)
  ,/,
  (NP velocity/NN)
  ,/,
  (NP variety/NN)
  ,/,
  (NP value/NN)
  (NP external/JJ sources/NNS)
  also/RB
  given/VBN
  ./.) 


>> Noun Phrases are: 
 ['Some examples', 'big data analytics', 'handle issues intrusion detection', 'big data characteristics size', 'velocity', 'variety', 'value', 'external sources']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Some', 'some'), ('examples', 'exampl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('handle', 'handl'), ('issues', 'issu'), ('intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('size', 'size'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (',', ','), ('value', 'valu'), ('external', 'extern'), ('sources', 'sourc'), ('also', 'also'), ('given', 'given'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Some', 'some'), ('examples', 'exampl'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('used', 'use'), ('handle', 'handl'), ('issues', 'issu'), ('intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characterist'), ('size', 'size'), (',', ','), ('velocity', 'veloc'), (',', ','), ('variety', 'varieti'), (',', ','), ('value', 'valu'), ('external', 'extern'), ('sources', 'sourc'), ('also', 'also'), ('given', 'given'), ('.', '.')]

>> Lemmatization: 
 [('Some', 'Some'), ('examples', 'example'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('used', 'used'), ('handle', 'handle'), ('issues', 'issue'), ('intrusion', 'intrusion'), ('detection', 'detection'), ('big', 'big'), ('data', 'data'), ('characteristics', 'characteristic'), ('size', 'size'), (',', ','), ('velocity', 'velocity'), (',', ','), ('variety', 'variety'), (',', ','), ('value', 'value'), ('external', 'external'), ('sources', 'source'), ('also', 'also'), ('given', 'given'), ('.', '.')]



============================ Sentence 619 =============================

Finally, some real-world big data analytics applications were introduced. 


>> Tokens are: 
 ['Finally', ',', 'real-world', 'big', 'data', 'analytics', 'applications', 'introduced', '.']

>> Bigrams are: 
 [('Finally', ','), (',', 'real-world'), ('real-world', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'applications'), ('applications', 'introduced'), ('introduced', '.')]

>> Trigrams are: 
 [('Finally', ',', 'real-world'), (',', 'real-world', 'big'), ('real-world', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'applications'), ('analytics', 'applications', 'introduced'), ('applications', 'introduced', '.')]

>> POS Tags are: 
 [('Finally', 'RB'), (',', ','), ('real-world', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('applications', 'NNS'), ('introduced', 'VBD'), ('.', '.')]

 (S
  Finally/RB
  ,/,
  (NP real-world/JJ big/JJ data/NNS analytics/NNS applications/NNS)
  introduced/VBD
  ./.) 


>> Noun Phrases are: 
 ['real-world big data analytics applications']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Finally', 'final'), (',', ','), ('real-world', 'real-world'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('introduced', 'introduc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Finally', 'final'), (',', ','), ('real-world', 'real-world'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('applications', 'applic'), ('introduced', 'introduc'), ('.', '.')]

>> Lemmatization: 
 [('Finally', 'Finally'), (',', ','), ('real-world', 'real-world'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('applications', 'application'), ('introduced', 'introduced'), ('.', '.')]



============================ Sentence 620 =============================

Big data is a significant area which offers many potential benefits and innovations. 


>> Tokens are: 
 ['Big', 'data', 'significant', 'area', 'offers', 'many', 'potential', 'benefits', 'innovations', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'significant'), ('significant', 'area'), ('area', 'offers'), ('offers', 'many'), ('many', 'potential'), ('potential', 'benefits'), ('benefits', 'innovations'), ('innovations', '.')]

>> Trigrams are: 
 [('Big', 'data', 'significant'), ('data', 'significant', 'area'), ('significant', 'area', 'offers'), ('area', 'offers', 'many'), ('offers', 'many', 'potential'), ('many', 'potential', 'benefits'), ('potential', 'benefits', 'innovations'), ('benefits', 'innovations', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('significant', 'JJ'), ('area', 'NN'), ('offers', 'NNS'), ('many', 'JJ'), ('potential', 'JJ'), ('benefits', 'NNS'), ('innovations', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  (NP significant/JJ area/NN offers/NNS)
  (NP many/JJ potential/JJ benefits/NNS innovations/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'significant area offers', 'many potential benefits innovations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('significant', 'signific'), ('area', 'area'), ('offers', 'offer'), ('many', 'mani'), ('potential', 'potenti'), ('benefits', 'benefit'), ('innovations', 'innov'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('significant', 'signific'), ('area', 'area'), ('offers', 'offer'), ('many', 'mani'), ('potential', 'potenti'), ('benefits', 'benefit'), ('innovations', 'innov'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('significant', 'significant'), ('area', 'area'), ('offers', 'offer'), ('many', 'many'), ('potential', 'potential'), ('benefits', 'benefit'), ('innovations', 'innovation'), ('.', '.')]



============================ Sentence 621 =============================

It is a   remarkable domain with a promising future, if approached correctly. 


>> Tokens are: 
 ['It', 'remarkable', 'domain', 'promising', 'future', ',', 'approached', 'correctly', '.']

>> Bigrams are: 
 [('It', 'remarkable'), ('remarkable', 'domain'), ('domain', 'promising'), ('promising', 'future'), ('future', ','), (',', 'approached'), ('approached', 'correctly'), ('correctly', '.')]

>> Trigrams are: 
 [('It', 'remarkable', 'domain'), ('remarkable', 'domain', 'promising'), ('domain', 'promising', 'future'), ('promising', 'future', ','), ('future', ',', 'approached'), (',', 'approached', 'correctly'), ('approached', 'correctly', '.')]

>> POS Tags are: 
 [('It', 'PRP'), ('remarkable', 'JJ'), ('domain', 'NN'), ('promising', 'JJ'), ('future', 'NN'), (',', ','), ('approached', 'VBN'), ('correctly', 'RB'), ('.', '.')]

 (S
  It/PRP
  (NP remarkable/JJ domain/NN)
  (NP promising/JJ future/NN)
  ,/,
  approached/VBN
  correctly/RB
  ./.) 


>> Noun Phrases are: 
 ['remarkable domain', 'promising future']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('It', 'it'), ('remarkable', 'remark'), ('domain', 'domain'), ('promising', 'promis'), ('future', 'futur'), (',', ','), ('approached', 'approach'), ('correctly', 'correctli'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('It', 'it'), ('remarkable', 'remark'), ('domain', 'domain'), ('promising', 'promis'), ('future', 'futur'), (',', ','), ('approached', 'approach'), ('correctly', 'correct'), ('.', '.')]

>> Lemmatization: 
 [('It', 'It'), ('remarkable', 'remarkable'), ('domain', 'domain'), ('promising', 'promising'), ('future', 'future'), (',', ','), ('approached', 'approached'), ('correctly', 'correctly'), ('.', '.')]



============================ Sentence 622 =============================

The difficulty with big data   comes mainly from its size, which requires proper storage, management, integration, cleansing,   processing, and analysis. 


>> Tokens are: 
 ['The', 'difficulty', 'big', 'data', 'comes', 'mainly', 'size', ',', 'requires', 'proper', 'storage', ',', 'management', ',', 'integration', ',', 'cleansing', ',', 'processing', ',', 'analysis', '.']

>> Bigrams are: 
 [('The', 'difficulty'), ('difficulty', 'big'), ('big', 'data'), ('data', 'comes'), ('comes', 'mainly'), ('mainly', 'size'), ('size', ','), (',', 'requires'), ('requires', 'proper'), ('proper', 'storage'), ('storage', ','), (',', 'management'), ('management', ','), (',', 'integration'), ('integration', ','), (',', 'cleansing'), ('cleansing', ','), (',', 'processing'), ('processing', ','), (',', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('The', 'difficulty', 'big'), ('difficulty', 'big', 'data'), ('big', 'data', 'comes'), ('data', 'comes', 'mainly'), ('comes', 'mainly', 'size'), ('mainly', 'size', ','), ('size', ',', 'requires'), (',', 'requires', 'proper'), ('requires', 'proper', 'storage'), ('proper', 'storage', ','), ('storage', ',', 'management'), (',', 'management', ','), ('management', ',', 'integration'), (',', 'integration', ','), ('integration', ',', 'cleansing'), (',', 'cleansing', ','), ('cleansing', ',', 'processing'), (',', 'processing', ','), ('processing', ',', 'analysis'), (',', 'analysis', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('difficulty', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('comes', 'VBZ'), ('mainly', 'RB'), ('size', 'NN'), (',', ','), ('requires', 'VBZ'), ('proper', 'JJ'), ('storage', 'NN'), (',', ','), ('management', 'NN'), (',', ','), ('integration', 'NN'), (',', ','), ('cleansing', 'VBG'), (',', ','), ('processing', 'NN'), (',', ','), ('analysis', 'NN'), ('.', '.')]

 (S
  (NP The/DT difficulty/NN)
  (NP big/JJ data/NNS)
  comes/VBZ
  mainly/RB
  (NP size/NN)
  ,/,
  requires/VBZ
  (NP proper/JJ storage/NN)
  ,/,
  (NP management/NN)
  ,/,
  (NP integration/NN)
  ,/,
  cleansing/VBG
  ,/,
  (NP processing/NN)
  ,/,
  (NP analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['The difficulty', 'big data', 'size', 'proper storage', 'management', 'integration', 'processing', 'analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('difficulty', 'difficulti'), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('mainly', 'mainli'), ('size', 'size'), (',', ','), ('requires', 'requir'), ('proper', 'proper'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('integration', 'integr'), (',', ','), ('cleansing', 'cleans'), (',', ','), ('processing', 'process'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('difficulty', 'difficulti'), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('mainly', 'main'), ('size', 'size'), (',', ','), ('requires', 'requir'), ('proper', 'proper'), ('storage', 'storag'), (',', ','), ('management', 'manag'), (',', ','), ('integration', 'integr'), (',', ','), ('cleansing', 'cleans'), (',', ','), ('processing', 'process'), (',', ','), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('difficulty', 'difficulty'), ('big', 'big'), ('data', 'data'), ('comes', 'come'), ('mainly', 'mainly'), ('size', 'size'), (',', ','), ('requires', 'requires'), ('proper', 'proper'), ('storage', 'storage'), (',', ','), ('management', 'management'), (',', ','), ('integration', 'integration'), (',', ','), ('cleansing', 'cleansing'), (',', ','), ('processing', 'processing'), (',', ','), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 623 =============================

The sheer volume, velocity, speed, and variety of data increases the   difficulty of dealing with it in terms of traditional data management, creating a need to study and   explore new analytics methods which might help in overcoming such difficulties to promote the   positive role of big data analytics to as many sectors as possible. 


>> Tokens are: 
 ['The', 'sheer', 'volume', ',', 'velocity', ',', 'speed', ',', 'variety', 'data', 'increases', 'difficulty', 'dealing', 'terms', 'traditional', 'data', 'management', ',', 'creating', 'need', 'study', 'explore', 'new', 'analytics', 'methods', 'might', 'help', 'overcoming', 'difficulties', 'promote', 'positive', 'role', 'big', 'data', 'analytics', 'many', 'sectors', 'possible', '.']

>> Bigrams are: 
 [('The', 'sheer'), ('sheer', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', ','), (',', 'speed'), ('speed', ','), (',', 'variety'), ('variety', 'data'), ('data', 'increases'), ('increases', 'difficulty'), ('difficulty', 'dealing'), ('dealing', 'terms'), ('terms', 'traditional'), ('traditional', 'data'), ('data', 'management'), ('management', ','), (',', 'creating'), ('creating', 'need'), ('need', 'study'), ('study', 'explore'), ('explore', 'new'), ('new', 'analytics'), ('analytics', 'methods'), ('methods', 'might'), ('might', 'help'), ('help', 'overcoming'), ('overcoming', 'difficulties'), ('difficulties', 'promote'), ('promote', 'positive'), ('positive', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'many'), ('many', 'sectors'), ('sectors', 'possible'), ('possible', '.')]

>> Trigrams are: 
 [('The', 'sheer', 'volume'), ('sheer', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', ','), ('velocity', ',', 'speed'), (',', 'speed', ','), ('speed', ',', 'variety'), (',', 'variety', 'data'), ('variety', 'data', 'increases'), ('data', 'increases', 'difficulty'), ('increases', 'difficulty', 'dealing'), ('difficulty', 'dealing', 'terms'), ('dealing', 'terms', 'traditional'), ('terms', 'traditional', 'data'), ('traditional', 'data', 'management'), ('data', 'management', ','), ('management', ',', 'creating'), (',', 'creating', 'need'), ('creating', 'need', 'study'), ('need', 'study', 'explore'), ('study', 'explore', 'new'), ('explore', 'new', 'analytics'), ('new', 'analytics', 'methods'), ('analytics', 'methods', 'might'), ('methods', 'might', 'help'), ('might', 'help', 'overcoming'), ('help', 'overcoming', 'difficulties'), ('overcoming', 'difficulties', 'promote'), ('difficulties', 'promote', 'positive'), ('promote', 'positive', 'role'), ('positive', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'many'), ('analytics', 'many', 'sectors'), ('many', 'sectors', 'possible'), ('sectors', 'possible', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('sheer', 'NN'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), (',', ','), ('speed', 'NN'), (',', ','), ('variety', 'NN'), ('data', 'NNS'), ('increases', 'VBZ'), ('difficulty', 'NN'), ('dealing', 'VBG'), ('terms', 'NNS'), ('traditional', 'JJ'), ('data', 'NNS'), ('management', 'NN'), (',', ','), ('creating', 'VBG'), ('need', 'NN'), ('study', 'NN'), ('explore', 'VBD'), ('new', 'JJ'), ('analytics', 'NNS'), ('methods', 'NNS'), ('might', 'MD'), ('help', 'VB'), ('overcoming', 'VBG'), ('difficulties', 'NNS'), ('promote', 'VBP'), ('positive', 'JJ'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('many', 'JJ'), ('sectors', 'NNS'), ('possible', 'JJ'), ('.', '.')]

 (S
  (NP The/DT sheer/NN volume/NN)
  ,/,
  (NP velocity/NN)
  ,/,
  (NP speed/NN)
  ,/,
  (NP variety/NN data/NNS)
  increases/VBZ
  (NP difficulty/NN)
  dealing/VBG
  (NP terms/NNS)
  (NP traditional/JJ data/NNS management/NN)
  ,/,
  creating/VBG
  (NP need/NN study/NN)
  explore/VBD
  (NP new/JJ analytics/NNS methods/NNS)
  might/MD
  help/VB
  overcoming/VBG
  (NP difficulties/NNS)
  promote/VBP
  (NP positive/JJ role/NN)
  (NP big/JJ data/NNS analytics/NNS)
  (NP many/JJ sectors/NNS)
  possible/JJ
  ./.) 


>> Noun Phrases are: 
 ['The sheer volume', 'velocity', 'speed', 'variety data', 'difficulty', 'terms', 'traditional data management', 'need study', 'new analytics methods', 'difficulties', 'positive role', 'big data analytics', 'many sectors']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('sheer', 'sheer'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('speed', 'speed'), (',', ','), ('variety', 'varieti'), ('data', 'data'), ('increases', 'increas'), ('difficulty', 'difficulti'), ('dealing', 'deal'), ('terms', 'term'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), (',', ','), ('creating', 'creat'), ('need', 'need'), ('study', 'studi'), ('explore', 'explor'), ('new', 'new'), ('analytics', 'analyt'), ('methods', 'method'), ('might', 'might'), ('help', 'help'), ('overcoming', 'overcom'), ('difficulties', 'difficulti'), ('promote', 'promot'), ('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('possible', 'possibl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('sheer', 'sheer'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), (',', ','), ('speed', 'speed'), (',', ','), ('variety', 'varieti'), ('data', 'data'), ('increases', 'increas'), ('difficulty', 'difficulti'), ('dealing', 'deal'), ('terms', 'term'), ('traditional', 'tradit'), ('data', 'data'), ('management', 'manag'), (',', ','), ('creating', 'creat'), ('need', 'need'), ('study', 'studi'), ('explore', 'explor'), ('new', 'new'), ('analytics', 'analyt'), ('methods', 'method'), ('might', 'might'), ('help', 'help'), ('overcoming', 'overcom'), ('difficulties', 'difficulti'), ('promote', 'promot'), ('positive', 'posit'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('many', 'mani'), ('sectors', 'sector'), ('possible', 'possibl'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('sheer', 'sheer'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), (',', ','), ('speed', 'speed'), (',', ','), ('variety', 'variety'), ('data', 'data'), ('increases', 'increase'), ('difficulty', 'difficulty'), ('dealing', 'dealing'), ('terms', 'term'), ('traditional', 'traditional'), ('data', 'data'), ('management', 'management'), (',', ','), ('creating', 'creating'), ('need', 'need'), ('study', 'study'), ('explore', 'explore'), ('new', 'new'), ('analytics', 'analytics'), ('methods', 'method'), ('might', 'might'), ('help', 'help'), ('overcoming', 'overcoming'), ('difficulties', 'difficulty'), ('promote', 'promote'), ('positive', 'positive'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('many', 'many'), ('sectors', 'sector'), ('possible', 'possible'), ('.', '.')]



============================ Sentence 624 =============================

Future research could thus   usefully focus on big data analytics challenges with regard to security and privacy issues, based     Sarah Al-Shiakhli   47      on big data’s weakness in coming from many different sources; a focus on cloud providers and   security breaches which affect multiple companies would also be advised. 


>> Tokens are: 
 ['Future', 'research', 'could', 'thus', 'usefully', 'focus', 'big', 'data', 'analytics', 'challenges', 'regard', 'security', 'privacy', 'issues', ',', 'based', 'Sarah', 'Al-Shiakhli', '47', 'big', 'data', '’', 'weakness', 'coming', 'many', 'different', 'sources', ';', 'focus', 'cloud', 'providers', 'security', 'breaches', 'affect', 'multiple', 'companies', 'would', 'also', 'advised', '.']

>> Bigrams are: 
 [('Future', 'research'), ('research', 'could'), ('could', 'thus'), ('thus', 'usefully'), ('usefully', 'focus'), ('focus', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'challenges'), ('challenges', 'regard'), ('regard', 'security'), ('security', 'privacy'), ('privacy', 'issues'), ('issues', ','), (',', 'based'), ('based', 'Sarah'), ('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '47'), ('47', 'big'), ('big', 'data'), ('data', '’'), ('’', 'weakness'), ('weakness', 'coming'), ('coming', 'many'), ('many', 'different'), ('different', 'sources'), ('sources', ';'), (';', 'focus'), ('focus', 'cloud'), ('cloud', 'providers'), ('providers', 'security'), ('security', 'breaches'), ('breaches', 'affect'), ('affect', 'multiple'), ('multiple', 'companies'), ('companies', 'would'), ('would', 'also'), ('also', 'advised'), ('advised', '.')]

>> Trigrams are: 
 [('Future', 'research', 'could'), ('research', 'could', 'thus'), ('could', 'thus', 'usefully'), ('thus', 'usefully', 'focus'), ('usefully', 'focus', 'big'), ('focus', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'challenges'), ('analytics', 'challenges', 'regard'), ('challenges', 'regard', 'security'), ('regard', 'security', 'privacy'), ('security', 'privacy', 'issues'), ('privacy', 'issues', ','), ('issues', ',', 'based'), (',', 'based', 'Sarah'), ('based', 'Sarah', 'Al-Shiakhli'), ('Sarah', 'Al-Shiakhli', '47'), ('Al-Shiakhli', '47', 'big'), ('47', 'big', 'data'), ('big', 'data', '’'), ('data', '’', 'weakness'), ('’', 'weakness', 'coming'), ('weakness', 'coming', 'many'), ('coming', 'many', 'different'), ('many', 'different', 'sources'), ('different', 'sources', ';'), ('sources', ';', 'focus'), (';', 'focus', 'cloud'), ('focus', 'cloud', 'providers'), ('cloud', 'providers', 'security'), ('providers', 'security', 'breaches'), ('security', 'breaches', 'affect'), ('breaches', 'affect', 'multiple'), ('affect', 'multiple', 'companies'), ('multiple', 'companies', 'would'), ('companies', 'would', 'also'), ('would', 'also', 'advised'), ('also', 'advised', '.')]

>> POS Tags are: 
 [('Future', 'NNP'), ('research', 'NN'), ('could', 'MD'), ('thus', 'RB'), ('usefully', 'RB'), ('focus', 'VBP'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('challenges', 'NNS'), ('regard', 'VBP'), ('security', 'NN'), ('privacy', 'NN'), ('issues', 'NNS'), (',', ','), ('based', 'VBN'), ('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('47', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('’', 'NNS'), ('weakness', 'NN'), ('coming', 'VBG'), ('many', 'JJ'), ('different', 'JJ'), ('sources', 'NNS'), (';', ':'), ('focus', 'VB'), ('cloud', 'JJ'), ('providers', 'NNS'), ('security', 'NN'), ('breaches', 'NNS'), ('affect', 'VBP'), ('multiple', 'JJ'), ('companies', 'NNS'), ('would', 'MD'), ('also', 'RB'), ('advised', 'VBN'), ('.', '.')]

 (S
  (NP Future/NNP research/NN)
  could/MD
  thus/RB
  usefully/RB
  focus/VBP
  (NP big/JJ data/NNS analytics/NNS challenges/NNS)
  regard/VBP
  (NP security/NN privacy/NN issues/NNS)
  ,/,
  based/VBN
  (NP Sarah/NNP Al-Shiakhli/NNP)
  47/CD
  (NP big/JJ data/NNS ’/NNS weakness/NN)
  coming/VBG
  (NP many/JJ different/JJ sources/NNS)
  ;/:
  focus/VB
  (NP cloud/JJ providers/NNS security/NN breaches/NNS)
  affect/VBP
  (NP multiple/JJ companies/NNS)
  would/MD
  also/RB
  advised/VBN
  ./.) 


>> Noun Phrases are: 
 ['Future research', 'big data analytics challenges', 'security privacy issues', 'Sarah Al-Shiakhli', 'big data ’ weakness', 'many different sources', 'cloud providers security breaches', 'multiple companies']

>> Named Entities are: 
 [('GPE', 'Future'), ('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Future', 'futur'), ('research', 'research'), ('could', 'could'), ('thus', 'thu'), ('usefully', 'use'), ('focus', 'focu'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('regard', 'regard'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('based', 'base'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('47', '47'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('weakness', 'weak'), ('coming', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (';', ';'), ('focus', 'focu'), ('cloud', 'cloud'), ('providers', 'provid'), ('security', 'secur'), ('breaches', 'breach'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani'), ('would', 'would'), ('also', 'also'), ('advised', 'advis'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Future', 'futur'), ('research', 'research'), ('could', 'could'), ('thus', 'thus'), ('usefully', 'use'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('challenges', 'challeng'), ('regard', 'regard'), ('security', 'secur'), ('privacy', 'privaci'), ('issues', 'issu'), (',', ','), ('based', 'base'), ('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('47', '47'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('weakness', 'weak'), ('coming', 'come'), ('many', 'mani'), ('different', 'differ'), ('sources', 'sourc'), (';', ';'), ('focus', 'focus'), ('cloud', 'cloud'), ('providers', 'provid'), ('security', 'secur'), ('breaches', 'breach'), ('affect', 'affect'), ('multiple', 'multipl'), ('companies', 'compani'), ('would', 'would'), ('also', 'also'), ('advised', 'advis'), ('.', '.')]

>> Lemmatization: 
 [('Future', 'Future'), ('research', 'research'), ('could', 'could'), ('thus', 'thus'), ('usefully', 'usefully'), ('focus', 'focus'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('challenges', 'challenge'), ('regard', 'regard'), ('security', 'security'), ('privacy', 'privacy'), ('issues', 'issue'), (',', ','), ('based', 'based'), ('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('47', '47'), ('big', 'big'), ('data', 'data'), ('’', '’'), ('weakness', 'weakness'), ('coming', 'coming'), ('many', 'many'), ('different', 'different'), ('sources', 'source'), (';', ';'), ('focus', 'focus'), ('cloud', 'cloud'), ('providers', 'provider'), ('security', 'security'), ('breaches', 'breach'), ('affect', 'affect'), ('multiple', 'multiple'), ('companies', 'company'), ('would', 'would'), ('also', 'also'), ('advised', 'advised'), ('.', '.')]



============================ Sentence 625 =============================

13. 


>> Tokens are: 
 ['13', '.']

>> Bigrams are: 
 [('13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('13', 'CD'), ('.', '.')]

 (S 13/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('13', '13'), ('.', '.')]



============================ Sentence 626 =============================

References   Acharjya, D.P. 


>> Tokens are: 
 ['References', 'Acharjya', ',', 'D.P', '.']

>> Bigrams are: 
 [('References', 'Acharjya'), ('Acharjya', ','), (',', 'D.P'), ('D.P', '.')]

>> Trigrams are: 
 [('References', 'Acharjya', ','), ('Acharjya', ',', 'D.P'), (',', 'D.P', '.')]

>> POS Tags are: 
 [('References', 'NNS'), ('Acharjya', 'NNP'), (',', ','), ('D.P', 'NNP'), ('.', '.')]

 (S (NP References/NNS Acharjya/NNP) ,/, (NP D.P/NNP) ./.) 


>> Noun Phrases are: 
 ['References Acharjya', 'D.P']

>> Named Entities are: 
 [('PERSON', 'Acharjya')] 

>> Stemming using Porter Stemmer: 
 [('References', 'refer'), ('Acharjya', 'acharjya'), (',', ','), ('D.P', 'd.p'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('References', 'refer'), ('Acharjya', 'acharjya'), (',', ','), ('D.P', 'd.p'), ('.', '.')]

>> Lemmatization: 
 [('References', 'References'), ('Acharjya', 'Acharjya'), (',', ','), ('D.P', 'D.P'), ('.', '.')]



============================ Sentence 627 =============================

and Ahmed, K., 2016. 


>> Tokens are: 
 ['Ahmed', ',', 'K.', ',', '2016', '.']

>> Bigrams are: 
 [('Ahmed', ','), (',', 'K.'), ('K.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Ahmed', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Ahmed', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S (NP Ahmed/NNP) ,/, (NP K./NNP) ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 ['Ahmed', 'K.']

>> Named Entities are: 
 [('GPE', 'Ahmed')] 

>> Stemming using Porter Stemmer: 
 [('Ahmed', 'ahm'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ahmed', 'ahm'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Ahmed', 'Ahmed'), (',', ','), ('K.', 'K.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 628 =============================

A survey on big data analytics: challenges, open research   issues and tools. 


>> Tokens are: 
 ['A', 'survey', 'big', 'data', 'analytics', ':', 'challenges', ',', 'open', 'research', 'issues', 'tools', '.']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'challenges'), ('challenges', ','), (',', 'open'), ('open', 'research'), ('research', 'issues'), ('issues', 'tools'), ('tools', '.')]

>> Trigrams are: 
 [('A', 'survey', 'big'), ('survey', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'challenges'), (':', 'challenges', ','), ('challenges', ',', 'open'), (',', 'open', 'research'), ('open', 'research', 'issues'), ('research', 'issues', 'tools'), ('issues', 'tools', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('challenges', 'NNS'), (',', ','), ('open', 'JJ'), ('research', 'NN'), ('issues', 'NNS'), ('tools', 'NNS'), ('.', '.')]

 (S
  (NP A/DT survey/NN)
  (NP big/JJ data/NNS analytics/NNS)
  :/:
  (NP challenges/NNS)
  ,/,
  (NP open/JJ research/NN issues/NNS tools/NNS)
  ./.) 


>> Noun Phrases are: 
 ['A survey', 'big data analytics', 'challenges', 'open research issues tools']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('open', 'open'), ('research', 'research'), ('issues', 'issu'), ('tools', 'tool'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('open', 'open'), ('research', 'research'), ('issues', 'issu'), ('tools', 'tool'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('challenges', 'challenge'), (',', ','), ('open', 'open'), ('research', 'research'), ('issues', 'issue'), ('tools', 'tool'), ('.', '.')]



============================ Sentence 629 =============================

International Journal of Advanced Computer Science and Applications, pp. 


>> Tokens are: 
 ['International', 'Journal', 'Advanced', 'Computer', 'Science', 'Applications', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Advanced'), ('Advanced', 'Computer'), ('Computer', 'Science'), ('Science', 'Applications'), ('Applications', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Advanced'), ('Journal', 'Advanced', 'Computer'), ('Advanced', 'Computer', 'Science'), ('Computer', 'Science', 'Applications'), ('Science', 'Applications', ','), ('Applications', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Advanced', 'NNP'), ('Computer', 'NNP'), ('Science', 'NNP'), ('Applications', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    International/NNP
    Journal/NNP
    Advanced/NNP
    Computer/NNP
    Science/NNP
    Applications/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['International Journal Advanced Computer Science Applications', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Advanced Computer Science Applications')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Advanced', 'advanc'), ('Computer', 'comput'), ('Science', 'scienc'), ('Applications', 'applic'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Advanced', 'advanc'), ('Computer', 'comput'), ('Science', 'scienc'), ('Applications', 'applic'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Advanced', 'Advanced'), ('Computer', 'Computer'), ('Science', 'Science'), ('Applications', 'Applications'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 630 =============================

511-  518. 


>> Tokens are: 
 ['511-', '518', '.']

>> Bigrams are: 
 [('511-', '518'), ('518', '.')]

>> Trigrams are: 
 [('511-', '518', '.')]

>> POS Tags are: 
 [('511-', 'JJ'), ('518', 'CD'), ('.', '.')]

 (S 511-/JJ 518/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('511-', '511-'), ('518', '518'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('511-', '511-'), ('518', '518'), ('.', '.')]

>> Lemmatization: 
 [('511-', '511-'), ('518', '518'), ('.', '.')]



============================ Sentence 631 =============================

Addo-Tenkorang, R. and Helo, P.T., 2016. 


>> Tokens are: 
 ['Addo-Tenkorang', ',', 'R.', 'Helo', ',', 'P.T.', ',', '2016', '.']

>> Bigrams are: 
 [('Addo-Tenkorang', ','), (',', 'R.'), ('R.', 'Helo'), ('Helo', ','), (',', 'P.T.'), ('P.T.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Addo-Tenkorang', ',', 'R.'), (',', 'R.', 'Helo'), ('R.', 'Helo', ','), ('Helo', ',', 'P.T.'), (',', 'P.T.', ','), ('P.T.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Addo-Tenkorang', 'NNP'), (',', ','), ('R.', 'NNP'), ('Helo', 'NNP'), (',', ','), ('P.T.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Addo-Tenkorang/NNP)
  ,/,
  (NP R./NNP Helo/NNP)
  ,/,
  (NP P.T./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Addo-Tenkorang', 'R. Helo', 'P.T.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Addo-Tenkorang', 'addo-tenkorang'), (',', ','), ('R.', 'r.'), ('Helo', 'helo'), (',', ','), ('P.T.', 'p.t.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Addo-Tenkorang', 'addo-tenkorang'), (',', ','), ('R.', 'r.'), ('Helo', 'helo'), (',', ','), ('P.T.', 'p.t.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Addo-Tenkorang', 'Addo-Tenkorang'), (',', ','), ('R.', 'R.'), ('Helo', 'Helo'), (',', ','), ('P.T.', 'P.T.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 632 =============================

Big data applications in operations/supply-chain   management: A literature review. 


>> Tokens are: 
 ['Big', 'data', 'applications', 'operations/supply-chain', 'management', ':', 'A', 'literature', 'review', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'applications'), ('applications', 'operations/supply-chain'), ('operations/supply-chain', 'management'), ('management', ':'), (':', 'A'), ('A', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Big', 'data', 'applications'), ('data', 'applications', 'operations/supply-chain'), ('applications', 'operations/supply-chain', 'management'), ('operations/supply-chain', 'management', ':'), ('management', ':', 'A'), (':', 'A', 'literature'), ('A', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('applications', 'NNS'), ('operations/supply-chain', 'JJ'), ('management', 'NN'), (':', ':'), ('A', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS applications/NNS)
  (NP operations/supply-chain/JJ management/NN)
  :/:
  (NP A/DT literature/NN review/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data applications', 'operations/supply-chain management', 'A literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('applications', 'applic'), ('operations/supply-chain', 'operations/supply-chain'), ('management', 'manag'), (':', ':'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('applications', 'applic'), ('operations/supply-chain', 'operations/supply-chain'), ('management', 'manag'), (':', ':'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('applications', 'application'), ('operations/supply-chain', 'operations/supply-chain'), ('management', 'management'), (':', ':'), ('A', 'A'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]



============================ Sentence 633 =============================

Computers & Industrial Engineering journal, Volume 101, pp. 


>> Tokens are: 
 ['Computers', '&', 'Industrial', 'Engineering', 'journal', ',', 'Volume', '101', ',', 'pp', '.']

>> Bigrams are: 
 [('Computers', '&'), ('&', 'Industrial'), ('Industrial', 'Engineering'), ('Engineering', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '101'), ('101', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Computers', '&', 'Industrial'), ('&', 'Industrial', 'Engineering'), ('Industrial', 'Engineering', 'journal'), ('Engineering', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '101'), ('Volume', '101', ','), ('101', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Computers', 'NNP'), ('&', 'CC'), ('Industrial', 'NNP'), ('Engineering', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('101', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Computers/NNP)
  &/CC
  (NP Industrial/NNP Engineering/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  101/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Computers', 'Industrial Engineering journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Computers'), ('ORGANIZATION', 'Industrial'), ('ORGANIZATION', 'Volume 101')] 

>> Stemming using Porter Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('101', '101'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('101', '101'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Computers', 'Computers'), ('&', '&'), ('Industrial', 'Industrial'), ('Engineering', 'Engineering'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('101', '101'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 634 =============================

528-543. 


>> Tokens are: 
 ['528-543', '.']

>> Bigrams are: 
 [('528-543', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('528-543', 'JJ'), ('.', '.')]

 (S 528-543/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('528-543', '528-543'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('528-543', '528-543'), ('.', '.')]

>> Lemmatization: 
 [('528-543', '528-543'), ('.', '.')]



============================ Sentence 635 =============================

Agarwal, R. and Dhar, V., 2014. 


>> Tokens are: 
 ['Agarwal', ',', 'R.', 'Dhar', ',', 'V.', ',', '2014', '.']

>> Bigrams are: 
 [('Agarwal', ','), (',', 'R.'), ('R.', 'Dhar'), ('Dhar', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Agarwal', ',', 'R.'), (',', 'R.', 'Dhar'), ('R.', 'Dhar', ','), ('Dhar', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Agarwal', 'NNP'), (',', ','), ('R.', 'NNP'), ('Dhar', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Agarwal/NNP)
  ,/,
  (NP R./NNP Dhar/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Agarwal', 'R. Dhar', 'V.']

>> Named Entities are: 
 [('GPE', 'Agarwal')] 

>> Stemming using Porter Stemmer: 
 [('Agarwal', 'agarw'), (',', ','), ('R.', 'r.'), ('Dhar', 'dhar'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Agarwal', 'agarw'), (',', ','), ('R.', 'r.'), ('Dhar', 'dhar'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Agarwal', 'Agarwal'), (',', ','), ('R.', 'R.'), ('Dhar', 'Dhar'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 636 =============================

Big data, data science, and analytics: The opportunity and   challenge for IS research. 


>> Tokens are: 
 ['Big', 'data', ',', 'data', 'science', ',', 'analytics', ':', 'The', 'opportunity', 'challenge', 'IS', 'research', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'data'), ('data', 'science'), ('science', ','), (',', 'analytics'), ('analytics', ':'), (':', 'The'), ('The', 'opportunity'), ('opportunity', 'challenge'), ('challenge', 'IS'), ('IS', 'research'), ('research', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'data'), (',', 'data', 'science'), ('data', 'science', ','), ('science', ',', 'analytics'), (',', 'analytics', ':'), ('analytics', ':', 'The'), (':', 'The', 'opportunity'), ('The', 'opportunity', 'challenge'), ('opportunity', 'challenge', 'IS'), ('challenge', 'IS', 'research'), ('IS', 'research', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('data', 'NNS'), ('science', 'NN'), (',', ','), ('analytics', 'NNS'), (':', ':'), ('The', 'DT'), ('opportunity', 'NN'), ('challenge', 'NN'), ('IS', 'NNP'), ('research', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  ,/,
  (NP data/NNS science/NN)
  ,/,
  (NP analytics/NNS)
  :/:
  (NP The/DT opportunity/NN challenge/NN IS/NNP research/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'data science', 'analytics', 'The opportunity challenge IS research']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (':', ':'), ('The', 'the'), ('opportunity', 'opportun'), ('challenge', 'challeng'), ('IS', 'is'), ('research', 'research'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('data', 'data'), ('science', 'scienc'), (',', ','), ('analytics', 'analyt'), (':', ':'), ('The', 'the'), ('opportunity', 'opportun'), ('challenge', 'challeng'), ('IS', 'is'), ('research', 'research'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('data', 'data'), ('science', 'science'), (',', ','), ('analytics', 'analytics'), (':', ':'), ('The', 'The'), ('opportunity', 'opportunity'), ('challenge', 'challenge'), ('IS', 'IS'), ('research', 'research'), ('.', '.')]



============================ Sentence 637 =============================

IS research Journal. 


>> Tokens are: 
 ['IS', 'research', 'Journal', '.']

>> Bigrams are: 
 [('IS', 'research'), ('research', 'Journal'), ('Journal', '.')]

>> Trigrams are: 
 [('IS', 'research', 'Journal'), ('research', 'Journal', '.')]

>> POS Tags are: 
 [('IS', 'VBZ'), ('research', 'NN'), ('Journal', 'NNP'), ('.', '.')]

 (S IS/VBZ (NP research/NN Journal/NNP) ./.) 


>> Noun Phrases are: 
 ['research Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('IS', 'is'), ('research', 'research'), ('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IS', 'is'), ('research', 'research'), ('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('IS', 'IS'), ('research', 'research'), ('Journal', 'Journal'), ('.', '.')]



============================ Sentence 638 =============================

Akter, S., Wamba, S.F., Gunasekaran, A., Dubey, R. and Childe, S.J., 2016. 


>> Tokens are: 
 ['Akter', ',', 'S.', ',', 'Wamba', ',', 'S.F.', ',', 'Gunasekaran', ',', 'A.', ',', 'Dubey', ',', 'R.', 'Childe', ',', 'S.J.', ',', '2016', '.']

>> Bigrams are: 
 [('Akter', ','), (',', 'S.'), ('S.', ','), (',', 'Wamba'), ('Wamba', ','), (',', 'S.F.'), ('S.F.', ','), (',', 'Gunasekaran'), ('Gunasekaran', ','), (',', 'A.'), ('A.', ','), (',', 'Dubey'), ('Dubey', ','), (',', 'R.'), ('R.', 'Childe'), ('Childe', ','), (',', 'S.J.'), ('S.J.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Akter', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Wamba'), (',', 'Wamba', ','), ('Wamba', ',', 'S.F.'), (',', 'S.F.', ','), ('S.F.', ',', 'Gunasekaran'), (',', 'Gunasekaran', ','), ('Gunasekaran', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Dubey'), (',', 'Dubey', ','), ('Dubey', ',', 'R.'), (',', 'R.', 'Childe'), ('R.', 'Childe', ','), ('Childe', ',', 'S.J.'), (',', 'S.J.', ','), ('S.J.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Akter', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Wamba', 'NNP'), (',', ','), ('S.F.', 'NNP'), (',', ','), ('Gunasekaran', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Dubey', 'NNP'), (',', ','), ('R.', 'NNP'), ('Childe', 'NNP'), (',', ','), ('S.J.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Akter/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Wamba/NNP)
  ,/,
  (NP S.F./NNP)
  ,/,
  (NP Gunasekaran/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Dubey/NNP)
  ,/,
  (NP R./NNP Childe/NNP)
  ,/,
  (NP S.J./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Akter', 'S.', 'Wamba', 'S.F.', 'Gunasekaran', 'A.', 'Dubey', 'R. Childe', 'S.J.']

>> Named Entities are: 
 [('PERSON', 'Akter'), ('PERSON', 'Wamba'), ('GPE', 'Gunasekaran'), ('PERSON', 'Dubey')] 

>> Stemming using Porter Stemmer: 
 [('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Akter', 'Akter'), (',', ','), ('S.', 'S.'), (',', ','), ('Wamba', 'Wamba'), (',', ','), ('S.F.', 'S.F.'), (',', ','), ('Gunasekaran', 'Gunasekaran'), (',', ','), ('A.', 'A.'), (',', ','), ('Dubey', 'Dubey'), (',', ','), ('R.', 'R.'), ('Childe', 'Childe'), (',', ','), ('S.J.', 'S.J.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 639 =============================

How to improve firm   performance using big data analytics capability and business strategy alignment?. 


>> Tokens are: 
 ['How', 'improve', 'firm', 'performance', 'using', 'big', 'data', 'analytics', 'capability', 'business', 'strategy', 'alignment', '?', '.']

>> Bigrams are: 
 [('How', 'improve'), ('improve', 'firm'), ('firm', 'performance'), ('performance', 'using'), ('using', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'capability'), ('capability', 'business'), ('business', 'strategy'), ('strategy', 'alignment'), ('alignment', '?'), ('?', '.')]

>> Trigrams are: 
 [('How', 'improve', 'firm'), ('improve', 'firm', 'performance'), ('firm', 'performance', 'using'), ('performance', 'using', 'big'), ('using', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'capability'), ('analytics', 'capability', 'business'), ('capability', 'business', 'strategy'), ('business', 'strategy', 'alignment'), ('strategy', 'alignment', '?'), ('alignment', '?', '.')]

>> POS Tags are: 
 [('How', 'WRB'), ('improve', 'JJ'), ('firm', 'NN'), ('performance', 'NN'), ('using', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('capability', 'NN'), ('business', 'NN'), ('strategy', 'NN'), ('alignment', 'NN'), ('?', '.'), ('.', '.')]

 (S
  How/WRB
  (NP improve/JJ firm/NN performance/NN)
  using/VBG
  (NP
    big/JJ
    data/NNS
    analytics/NNS
    capability/NN
    business/NN
    strategy/NN
    alignment/NN)
  ?/.
  ./.) 


>> Noun Phrases are: 
 ['improve firm performance', 'big data analytics capability business strategy alignment']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('How', 'how'), ('improve', 'improv'), ('firm', 'firm'), ('performance', 'perform'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('business', 'busi'), ('strategy', 'strategi'), ('alignment', 'align'), ('?', '?'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('How', 'how'), ('improve', 'improv'), ('firm', 'firm'), ('performance', 'perform'), ('using', 'use'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capability', 'capabl'), ('business', 'busi'), ('strategy', 'strategi'), ('alignment', 'align'), ('?', '?'), ('.', '.')]

>> Lemmatization: 
 [('How', 'How'), ('improve', 'improve'), ('firm', 'firm'), ('performance', 'performance'), ('using', 'using'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('capability', 'capability'), ('business', 'business'), ('strategy', 'strategy'), ('alignment', 'alignment'), ('?', '?'), ('.', '.')]



============================ Sentence 640 =============================

International   Journal of Production Economics, pp. 


>> Tokens are: 
 ['International', 'Journal', 'Production', 'Economics', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Production'), ('Production', 'Economics'), ('Economics', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Production'), ('Journal', 'Production', 'Economics'), ('Production', 'Economics', ','), ('Economics', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Production', 'NNP'), ('Economics', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP International/NNP Journal/NNP Production/NNP Economics/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['International Journal Production Economics', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Production Economics')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Production', 'product'), ('Economics', 'econom'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Production', 'product'), ('Economics', 'econom'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Production', 'Production'), ('Economics', 'Economics'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 641 =============================

113-131. 


>> Tokens are: 
 ['113-131', '.']

>> Bigrams are: 
 [('113-131', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('113-131', 'JJ'), ('.', '.')]

 (S 113-131/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('113-131', '113-131'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('113-131', '113-131'), ('.', '.')]

>> Lemmatization: 
 [('113-131', '113-131'), ('.', '.')]



============================ Sentence 642 =============================

Al-Barashdi, H. and Al-Karousi, R., 2019. 


>> Tokens are: 
 ['Al-Barashdi', ',', 'H.', 'Al-Karousi', ',', 'R.', ',', '2019', '.']

>> Bigrams are: 
 [('Al-Barashdi', ','), (',', 'H.'), ('H.', 'Al-Karousi'), ('Al-Karousi', ','), (',', 'R.'), ('R.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Al-Barashdi', ',', 'H.'), (',', 'H.', 'Al-Karousi'), ('H.', 'Al-Karousi', ','), ('Al-Karousi', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Al-Barashdi', 'NNP'), (',', ','), ('H.', 'NNP'), ('Al-Karousi', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Al-Barashdi/NNP)
  ,/,
  (NP H./NNP Al-Karousi/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Al-Barashdi', 'H. Al-Karousi', 'R.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Al-Barashdi', 'al-barashdi'), (',', ','), ('H.', 'h.'), ('Al-Karousi', 'al-karousi'), (',', ','), ('R.', 'r.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Al-Barashdi', 'al-barashdi'), (',', ','), ('H.', 'h.'), ('Al-Karousi', 'al-karousi'), (',', ','), ('R.', 'r.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Al-Barashdi', 'Al-Barashdi'), (',', ','), ('H.', 'H.'), ('Al-Karousi', 'Al-Karousi'), (',', ','), ('R.', 'R.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 643 =============================

Big Data in academic libraries: literature review and   future research directions.. Journal of Information Studies and Technology, p. 13. 


>> Tokens are: 
 ['Big', 'Data', 'academic', 'libraries', ':', 'literature', 'review', 'future', 'research', 'directions', '..', 'Journal', 'Information', 'Studies', 'Technology', ',', 'p.', '13', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'academic'), ('academic', 'libraries'), ('libraries', ':'), (':', 'literature'), ('literature', 'review'), ('review', 'future'), ('future', 'research'), ('research', 'directions'), ('directions', '..'), ('..', 'Journal'), ('Journal', 'Information'), ('Information', 'Studies'), ('Studies', 'Technology'), ('Technology', ','), (',', 'p.'), ('p.', '13'), ('13', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'academic'), ('Data', 'academic', 'libraries'), ('academic', 'libraries', ':'), ('libraries', ':', 'literature'), (':', 'literature', 'review'), ('literature', 'review', 'future'), ('review', 'future', 'research'), ('future', 'research', 'directions'), ('research', 'directions', '..'), ('directions', '..', 'Journal'), ('..', 'Journal', 'Information'), ('Journal', 'Information', 'Studies'), ('Information', 'Studies', 'Technology'), ('Studies', 'Technology', ','), ('Technology', ',', 'p.'), (',', 'p.', '13'), ('p.', '13', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('academic', 'JJ'), ('libraries', 'NNS'), (':', ':'), ('literature', 'NN'), ('review', 'NN'), ('future', 'JJ'), ('research', 'NN'), ('directions', 'NNS'), ('..', 'VBP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Studies', 'NNP'), ('Technology', 'NNP'), (',', ','), ('p.', 'VBD'), ('13', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP)
  (NP academic/JJ libraries/NNS)
  :/:
  (NP literature/NN review/NN)
  (NP future/JJ research/NN directions/NNS)
  ../VBP
  (NP Journal/NNP Information/NNP Studies/NNP Technology/NNP)
  ,/,
  p./VBD
  13/CD
  ./.) 


>> Noun Phrases are: 
 ['Big Data', 'academic libraries', 'literature review', 'future research directions', 'Journal Information Studies Technology']

>> Named Entities are: 
 [('PERSON', 'Journal Information Studies Technology')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('academic', 'academ'), ('libraries', 'librari'), (':', ':'), ('literature', 'literatur'), ('review', 'review'), ('future', 'futur'), ('research', 'research'), ('directions', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Studies', 'studi'), ('Technology', 'technolog'), (',', ','), ('p.', 'p.'), ('13', '13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('academic', 'academ'), ('libraries', 'librari'), (':', ':'), ('literature', 'literatur'), ('review', 'review'), ('future', 'futur'), ('research', 'research'), ('directions', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Studies', 'studi'), ('Technology', 'technolog'), (',', ','), ('p.', 'p.'), ('13', '13'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('academic', 'academic'), ('libraries', 'library'), (':', ':'), ('literature', 'literature'), ('review', 'review'), ('future', 'future'), ('research', 'research'), ('directions', 'direction'), ('..', '..'), ('Journal', 'Journal'), ('Information', 'Information'), ('Studies', 'Studies'), ('Technology', 'Technology'), (',', ','), ('p.', 'p.'), ('13', '13'), ('.', '.')]



============================ Sentence 644 =============================

Ali, A., Qadir, J., ur Rasool, R., Sathiaseelan, A., Zwitter, A. and Crowcroft, J., 2016. 


>> Tokens are: 
 ['Ali', ',', 'A.', ',', 'Qadir', ',', 'J.', ',', 'ur', 'Rasool', ',', 'R.', ',', 'Sathiaseelan', ',', 'A.', ',', 'Zwitter', ',', 'A.', 'Crowcroft', ',', 'J.', ',', '2016', '.']

>> Bigrams are: 
 [('Ali', ','), (',', 'A.'), ('A.', ','), (',', 'Qadir'), ('Qadir', ','), (',', 'J.'), ('J.', ','), (',', 'ur'), ('ur', 'Rasool'), ('Rasool', ','), (',', 'R.'), ('R.', ','), (',', 'Sathiaseelan'), ('Sathiaseelan', ','), (',', 'A.'), ('A.', ','), (',', 'Zwitter'), ('Zwitter', ','), (',', 'A.'), ('A.', 'Crowcroft'), ('Crowcroft', ','), (',', 'J.'), ('J.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Ali', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Qadir'), (',', 'Qadir', ','), ('Qadir', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'ur'), (',', 'ur', 'Rasool'), ('ur', 'Rasool', ','), ('Rasool', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Sathiaseelan'), (',', 'Sathiaseelan', ','), ('Sathiaseelan', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Zwitter'), (',', 'Zwitter', ','), ('Zwitter', ',', 'A.'), (',', 'A.', 'Crowcroft'), ('A.', 'Crowcroft', ','), ('Crowcroft', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Ali', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Qadir', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('ur', 'JJ'), ('Rasool', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Sathiaseelan', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Zwitter', 'NNP'), (',', ','), ('A.', 'NNP'), ('Crowcroft', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Ali/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Qadir/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP ur/JJ Rasool/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Sathiaseelan/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Zwitter/NNP)
  ,/,
  (NP A./NNP Crowcroft/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Ali', 'A.', 'Qadir', 'J.', 'ur Rasool', 'R.', 'Sathiaseelan', 'A.', 'Zwitter', 'A. Crowcroft', 'J.']

>> Named Entities are: 
 [('GPE', 'Ali'), ('PERSON', 'Qadir'), ('GPE', 'Rasool'), ('GPE', 'Sathiaseelan'), ('PERSON', 'Zwitter')] 

>> Stemming using Porter Stemmer: 
 [('Ali', 'ali'), (',', ','), ('A.', 'a.'), (',', ','), ('Qadir', 'qadir'), (',', ','), ('J.', 'j.'), (',', ','), ('ur', 'ur'), ('Rasool', 'rasool'), (',', ','), ('R.', 'r.'), (',', ','), ('Sathiaseelan', 'sathiaseelan'), (',', ','), ('A.', 'a.'), (',', ','), ('Zwitter', 'zwitter'), (',', ','), ('A.', 'a.'), ('Crowcroft', 'crowcroft'), (',', ','), ('J.', 'j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ali', 'ali'), (',', ','), ('A.', 'a.'), (',', ','), ('Qadir', 'qadir'), (',', ','), ('J.', 'j.'), (',', ','), ('ur', 'ur'), ('Rasool', 'rasool'), (',', ','), ('R.', 'r.'), (',', ','), ('Sathiaseelan', 'sathiaseelan'), (',', ','), ('A.', 'a.'), (',', ','), ('Zwitter', 'zwitter'), (',', ','), ('A.', 'a.'), ('Crowcroft', 'crowcroft'), (',', ','), ('J.', 'j.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Ali', 'Ali'), (',', ','), ('A.', 'A.'), (',', ','), ('Qadir', 'Qadir'), (',', ','), ('J.', 'J.'), (',', ','), ('ur', 'ur'), ('Rasool', 'Rasool'), (',', ','), ('R.', 'R.'), (',', ','), ('Sathiaseelan', 'Sathiaseelan'), (',', ','), ('A.', 'A.'), (',', ','), ('Zwitter', 'Zwitter'), (',', ','), ('A.', 'A.'), ('Crowcroft', 'Crowcroft'), (',', ','), ('J.', 'J.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 645 =============================

Big data for   development: applications and techniques.. Big Data Analytics journal, Volume 1, p. 2. 


>> Tokens are: 
 ['Big', 'data', 'development', ':', 'applications', 'techniques', '..', 'Big', 'Data', 'Analytics', 'journal', ',', 'Volume', '1', ',', 'p.', '2', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'development'), ('development', ':'), (':', 'applications'), ('applications', 'techniques'), ('techniques', '..'), ('..', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '1'), ('1', ','), (',', 'p.'), ('p.', '2'), ('2', '.')]

>> Trigrams are: 
 [('Big', 'data', 'development'), ('data', 'development', ':'), ('development', ':', 'applications'), (':', 'applications', 'techniques'), ('applications', 'techniques', '..'), ('techniques', '..', 'Big'), ('..', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'journal'), ('Analytics', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '1'), ('Volume', '1', ','), ('1', ',', 'p.'), (',', 'p.', '2'), ('p.', '2', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NN'), ('development', 'NN'), (':', ':'), ('applications', 'NNS'), ('techniques', 'NNS'), ('..', 'VBP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('1', 'CD'), (',', ','), ('p.', 'RB'), ('2', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NN development/NN)
  :/:
  (NP applications/NNS techniques/NNS)
  ../VBP
  (NP Big/NNP Data/NNP Analytics/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  1/CD
  ,/,
  p./RB
  2/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data development', 'applications techniques', 'Big Data Analytics journal', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('development', 'develop'), (':', ':'), ('applications', 'applic'), ('techniques', 'techniqu'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('p.', 'p.'), ('2', '2'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('development', 'develop'), (':', ':'), ('applications', 'applic'), ('techniques', 'techniqu'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('p.', 'p.'), ('2', '2'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('development', 'development'), (':', ':'), ('applications', 'application'), ('techniques', 'technique'), ('..', '..'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('1', '1'), (',', ','), ('p.', 'p.'), ('2', '2'), ('.', '.')]



============================ Sentence 646 =============================

Arunachalam, D., Kumar, N. and Kawalek, J.P., 2018. 


>> Tokens are: 
 ['Arunachalam', ',', 'D.', ',', 'Kumar', ',', 'N.', 'Kawalek', ',', 'J.P.', ',', '2018', '.']

>> Bigrams are: 
 [('Arunachalam', ','), (',', 'D.'), ('D.', ','), (',', 'Kumar'), ('Kumar', ','), (',', 'N.'), ('N.', 'Kawalek'), ('Kawalek', ','), (',', 'J.P.'), ('J.P.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Arunachalam', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Kumar'), (',', 'Kumar', ','), ('Kumar', ',', 'N.'), (',', 'N.', 'Kawalek'), ('N.', 'Kawalek', ','), ('Kawalek', ',', 'J.P.'), (',', 'J.P.', ','), ('J.P.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Arunachalam', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Kumar', 'NNP'), (',', ','), ('N.', 'NNP'), ('Kawalek', 'NNP'), (',', ','), ('J.P.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Arunachalam/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  (NP Kumar/NNP)
  ,/,
  (NP N./NNP Kawalek/NNP)
  ,/,
  (NP J.P./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Arunachalam', 'D.', 'Kumar', 'N. Kawalek', 'J.P.']

>> Named Entities are: 
 [('GPE', 'Arunachalam'), ('PERSON', 'Kumar')] 

>> Stemming using Porter Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N.', 'n.'), ('Kawalek', 'kawalek'), (',', ','), ('J.P.', 'j.p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N.', 'n.'), ('Kawalek', 'kawalek'), (',', ','), ('J.P.', 'j.p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Arunachalam', 'Arunachalam'), (',', ','), ('D.', 'D.'), (',', ','), ('Kumar', 'Kumar'), (',', ','), ('N.', 'N.'), ('Kawalek', 'Kawalek'), (',', ','), ('J.P.', 'J.P.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 647 =============================

Arunachalam, D., Kumar, N.   anUnderstanding big data analytics capabilities in supply chain management: Unravelling the   issues, challenges and implications for practice.. Transportation Research Part E: Logistics and   Transportation Review journal, Volume 114, pp. 


>> Tokens are: 
 ['Arunachalam', ',', 'D.', ',', 'Kumar', ',', 'N.', 'anUnderstanding', 'big', 'data', 'analytics', 'capabilities', 'supply', 'chain', 'management', ':', 'Unravelling', 'issues', ',', 'challenges', 'implications', 'practice', '..', 'Transportation', 'Research', 'Part', 'E', ':', 'Logistics', 'Transportation', 'Review', 'journal', ',', 'Volume', '114', ',', 'pp', '.']

>> Bigrams are: 
 [('Arunachalam', ','), (',', 'D.'), ('D.', ','), (',', 'Kumar'), ('Kumar', ','), (',', 'N.'), ('N.', 'anUnderstanding'), ('anUnderstanding', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'capabilities'), ('capabilities', 'supply'), ('supply', 'chain'), ('chain', 'management'), ('management', ':'), (':', 'Unravelling'), ('Unravelling', 'issues'), ('issues', ','), (',', 'challenges'), ('challenges', 'implications'), ('implications', 'practice'), ('practice', '..'), ('..', 'Transportation'), ('Transportation', 'Research'), ('Research', 'Part'), ('Part', 'E'), ('E', ':'), (':', 'Logistics'), ('Logistics', 'Transportation'), ('Transportation', 'Review'), ('Review', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '114'), ('114', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Arunachalam', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Kumar'), (',', 'Kumar', ','), ('Kumar', ',', 'N.'), (',', 'N.', 'anUnderstanding'), ('N.', 'anUnderstanding', 'big'), ('anUnderstanding', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'capabilities'), ('analytics', 'capabilities', 'supply'), ('capabilities', 'supply', 'chain'), ('supply', 'chain', 'management'), ('chain', 'management', ':'), ('management', ':', 'Unravelling'), (':', 'Unravelling', 'issues'), ('Unravelling', 'issues', ','), ('issues', ',', 'challenges'), (',', 'challenges', 'implications'), ('challenges', 'implications', 'practice'), ('implications', 'practice', '..'), ('practice', '..', 'Transportation'), ('..', 'Transportation', 'Research'), ('Transportation', 'Research', 'Part'), ('Research', 'Part', 'E'), ('Part', 'E', ':'), ('E', ':', 'Logistics'), (':', 'Logistics', 'Transportation'), ('Logistics', 'Transportation', 'Review'), ('Transportation', 'Review', 'journal'), ('Review', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '114'), ('Volume', '114', ','), ('114', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Arunachalam', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Kumar', 'NNP'), (',', ','), ('N.', 'NNP'), ('anUnderstanding', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('capabilities', 'NNS'), ('supply', 'VBP'), ('chain', 'NN'), ('management', 'NN'), (':', ':'), ('Unravelling', 'NN'), ('issues', 'NNS'), (',', ','), ('challenges', 'NNS'), ('implications', 'NNS'), ('practice', 'NN'), ('..', 'CD'), ('Transportation', 'NNP'), ('Research', 'NNP'), ('Part', 'NNP'), ('E', 'NNP'), (':', ':'), ('Logistics', 'NNS'), ('Transportation', 'NNP'), ('Review', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('114', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Arunachalam/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  (NP Kumar/NNP)
  ,/,
  (NP N./NNP)
  anUnderstanding/VBG
  (NP big/JJ data/NNS analytics/NNS capabilities/NNS)
  supply/VBP
  (NP chain/NN management/NN)
  :/:
  (NP Unravelling/NN issues/NNS)
  ,/,
  (NP challenges/NNS implications/NNS practice/NN)
  ../CD
  (NP Transportation/NNP Research/NNP Part/NNP E/NNP)
  :/:
  (NP Logistics/NNS Transportation/NNP Review/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  114/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Arunachalam', 'D.', 'Kumar', 'N.', 'big data analytics capabilities', 'chain management', 'Unravelling issues', 'challenges implications practice', 'Transportation Research Part E', 'Logistics Transportation Review journal', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Arunachalam'), ('PERSON', 'Kumar'), ('ORGANIZATION', 'Transportation Research Part'), ('ORGANIZATION', 'Transportation Review'), ('ORGANIZATION', 'Volume 114')] 

>> Stemming using Porter Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N.', 'n.'), ('anUnderstanding', 'anunderstand'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), ('supply', 'suppli'), ('chain', 'chain'), ('management', 'manag'), (':', ':'), ('Unravelling', 'unravel'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('implications', 'implic'), ('practice', 'practic'), ('..', '..'), ('Transportation', 'transport'), ('Research', 'research'), ('Part', 'part'), ('E', 'e'), (':', ':'), ('Logistics', 'logist'), ('Transportation', 'transport'), ('Review', 'review'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('114', '114'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Arunachalam', 'arunachalam'), (',', ','), ('D.', 'd.'), (',', ','), ('Kumar', 'kumar'), (',', ','), ('N.', 'n.'), ('anUnderstanding', 'anunderstand'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), ('supply', 'suppli'), ('chain', 'chain'), ('management', 'manag'), (':', ':'), ('Unravelling', 'unravel'), ('issues', 'issu'), (',', ','), ('challenges', 'challeng'), ('implications', 'implic'), ('practice', 'practic'), ('..', '..'), ('Transportation', 'transport'), ('Research', 'research'), ('Part', 'part'), ('E', 'e'), (':', ':'), ('Logistics', 'logist'), ('Transportation', 'transport'), ('Review', 'review'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('114', '114'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Arunachalam', 'Arunachalam'), (',', ','), ('D.', 'D.'), (',', ','), ('Kumar', 'Kumar'), (',', ','), ('N.', 'N.'), ('anUnderstanding', 'anUnderstanding'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('capabilities', 'capability'), ('supply', 'supply'), ('chain', 'chain'), ('management', 'management'), (':', ':'), ('Unravelling', 'Unravelling'), ('issues', 'issue'), (',', ','), ('challenges', 'challenge'), ('implications', 'implication'), ('practice', 'practice'), ('..', '..'), ('Transportation', 'Transportation'), ('Research', 'Research'), ('Part', 'Part'), ('E', 'E'), (':', ':'), ('Logistics', 'Logistics'), ('Transportation', 'Transportation'), ('Review', 'Review'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('114', '114'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 648 =============================

416--436. 


>> Tokens are: 
 ['416', '--', '436', '.']

>> Bigrams are: 
 [('416', '--'), ('--', '436'), ('436', '.')]

>> Trigrams are: 
 [('416', '--', '436'), ('--', '436', '.')]

>> POS Tags are: 
 [('416', 'CD'), ('--', ':'), ('436', 'CD'), ('.', '.')]

 (S 416/CD --/: 436/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('416', '416'), ('--', '--'), ('436', '436'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('416', '416'), ('--', '--'), ('436', '436'), ('.', '.')]

>> Lemmatization: 
 [('416', '416'), ('--', '--'), ('436', '436'), ('.', '.')]



============================ Sentence 649 =============================

Bakshi, K., 2012. 


>> Tokens are: 
 ['Bakshi', ',', 'K.', ',', '2012', '.']

>> Bigrams are: 
 [('Bakshi', ','), (',', 'K.'), ('K.', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Bakshi', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('Bakshi', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S (NP Bakshi/NNP) ,/, (NP K./NNP) ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 ['Bakshi', 'K.']

>> Named Entities are: 
 [('GPE', 'Bakshi')] 

>> Stemming using Porter Stemmer: 
 [('Bakshi', 'bakshi'), (',', ','), ('K.', 'k.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bakshi', 'bakshi'), (',', ','), ('K.', 'k.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Bakshi', 'Bakshi'), (',', ','), ('K.', 'K.'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 650 =============================

Considerations for big data: Architecture and approach conference. 


>> Tokens are: 
 ['Considerations', 'big', 'data', ':', 'Architecture', 'approach', 'conference', '.']

>> Bigrams are: 
 [('Considerations', 'big'), ('big', 'data'), ('data', ':'), (':', 'Architecture'), ('Architecture', 'approach'), ('approach', 'conference'), ('conference', '.')]

>> Trigrams are: 
 [('Considerations', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'Architecture'), (':', 'Architecture', 'approach'), ('Architecture', 'approach', 'conference'), ('approach', 'conference', '.')]

>> POS Tags are: 
 [('Considerations', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('Architecture', 'NNP'), ('approach', 'NN'), ('conference', 'NN'), ('.', '.')]

 (S
  (NP Considerations/NNS)
  (NP big/JJ data/NNS)
  :/:
  (NP Architecture/NNP approach/NN conference/NN)
  ./.) 


>> Noun Phrases are: 
 ['Considerations', 'big data', 'Architecture approach conference']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Considerations', 'consider'), ('big', 'big'), ('data', 'data'), (':', ':'), ('Architecture', 'architectur'), ('approach', 'approach'), ('conference', 'confer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Considerations', 'consider'), ('big', 'big'), ('data', 'data'), (':', ':'), ('Architecture', 'architectur'), ('approach', 'approach'), ('conference', 'confer'), ('.', '.')]

>> Lemmatization: 
 [('Considerations', 'Considerations'), ('big', 'big'), ('data', 'data'), (':', ':'), ('Architecture', 'Architecture'), ('approach', 'approach'), ('conference', 'conference'), ('.', '.')]



============================ Sentence 651 =============================

s.l., IEEE,   pp. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 652 =============================

(1-7). 


>> Tokens are: 
 ['(', '1-7', ')', '.']

>> Bigrams are: 
 [('(', '1-7'), ('1-7', ')'), (')', '.')]

>> Trigrams are: 
 [('(', '1-7', ')'), ('1-7', ')', '.')]

>> POS Tags are: 
 [('(', '('), ('1-7', 'JJ'), (')', ')'), ('.', '.')]

 (S (/( 1-7/JJ )/) ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('(', '('), ('1-7', '1-7'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('(', '('), ('1-7', '1-7'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('(', '('), ('1-7', '1-7'), (')', ')'), ('.', '.')]



============================ Sentence 653 =============================

Banerjee, A., Bandyopadhyay, T. and Acharya, P., 2013. 


>> Tokens are: 
 ['Banerjee', ',', 'A.', ',', 'Bandyopadhyay', ',', 'T.', 'Acharya', ',', 'P.', ',', '2013', '.']

>> Bigrams are: 
 [('Banerjee', ','), (',', 'A.'), ('A.', ','), (',', 'Bandyopadhyay'), ('Bandyopadhyay', ','), (',', 'T.'), ('T.', 'Acharya'), ('Acharya', ','), (',', 'P.'), ('P.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Banerjee', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Bandyopadhyay'), (',', 'Bandyopadhyay', ','), ('Bandyopadhyay', ',', 'T.'), (',', 'T.', 'Acharya'), ('T.', 'Acharya', ','), ('Acharya', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Banerjee', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Bandyopadhyay', 'NNP'), (',', ','), ('T.', 'NNP'), ('Acharya', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Banerjee/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Bandyopadhyay/NNP)
  ,/,
  (NP T./NNP Acharya/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Banerjee', 'A.', 'Bandyopadhyay', 'T. Acharya', 'P.']

>> Named Entities are: 
 [('GPE', 'Banerjee'), ('GPE', 'Bandyopadhyay')] 

>> Stemming using Porter Stemmer: 
 [('Banerjee', 'banerje'), (',', ','), ('A.', 'a.'), (',', ','), ('Bandyopadhyay', 'bandyopadhyay'), (',', ','), ('T.', 't.'), ('Acharya', 'acharya'), (',', ','), ('P.', 'p.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Banerjee', 'banerje'), (',', ','), ('A.', 'a.'), (',', ','), ('Bandyopadhyay', 'bandyopadhyay'), (',', ','), ('T.', 't.'), ('Acharya', 'acharya'), (',', ','), ('P.', 'p.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Banerjee', 'Banerjee'), (',', ','), ('A.', 'A.'), (',', ','), ('Bandyopadhyay', 'Bandyopadhyay'), (',', ','), ('T.', 'T.'), ('Acharya', 'Acharya'), (',', ','), ('P.', 'P.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 654 =============================

Data analytics: Hyped up aspirations or   true potential?. 


>> Tokens are: 
 ['Data', 'analytics', ':', 'Hyped', 'aspirations', 'true', 'potential', '?', '.']

>> Bigrams are: 
 [('Data', 'analytics'), ('analytics', ':'), (':', 'Hyped'), ('Hyped', 'aspirations'), ('aspirations', 'true'), ('true', 'potential'), ('potential', '?'), ('?', '.')]

>> Trigrams are: 
 [('Data', 'analytics', ':'), ('analytics', ':', 'Hyped'), (':', 'Hyped', 'aspirations'), ('Hyped', 'aspirations', 'true'), ('aspirations', 'true', 'potential'), ('true', 'potential', '?'), ('potential', '?', '.')]

>> POS Tags are: 
 [('Data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('Hyped', 'NNP'), ('aspirations', 'NNS'), ('true', 'JJ'), ('potential', 'JJ'), ('?', '.'), ('.', '.')]

 (S
  (NP Data/NNS analytics/NNS)
  :/:
  (NP Hyped/NNP aspirations/NNS)
  true/JJ
  potential/JJ
  ?/.
  ./.) 


>> Noun Phrases are: 
 ['Data analytics', 'Hyped aspirations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Hyped', 'hype'), ('aspirations', 'aspir'), ('true', 'true'), ('potential', 'potenti'), ('?', '?'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Hyped', 'hype'), ('aspirations', 'aspir'), ('true', 'true'), ('potential', 'potenti'), ('?', '?'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('analytics', 'analytics'), (':', ':'), ('Hyped', 'Hyped'), ('aspirations', 'aspiration'), ('true', 'true'), ('potential', 'potential'), ('?', '?'), ('.', '.')]



============================ Sentence 655 =============================

Vikalpa journal, Volume 38, pp. 


>> Tokens are: 
 ['Vikalpa', 'journal', ',', 'Volume', '38', ',', 'pp', '.']

>> Bigrams are: 
 [('Vikalpa', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '38'), ('38', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Vikalpa', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '38'), ('Volume', '38', ','), ('38', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Vikalpa', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('38', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Vikalpa/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  38/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Vikalpa journal', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Vikalpa'), ('ORGANIZATION', 'Volume 38')] 

>> Stemming using Porter Stemmer: 
 [('Vikalpa', 'vikalpa'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('38', '38'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vikalpa', 'vikalpa'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('38', '38'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Vikalpa', 'Vikalpa'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('38', '38'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 656 =============================

1-12. 


>> Tokens are: 
 ['1-12', '.']

>> Bigrams are: 
 [('1-12', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1-12', 'JJ'), ('.', '.')]

 (S 1-12/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-12', '1-12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-12', '1-12'), ('.', '.')]

>> Lemmatization: 
 [('1-12', '1-12'), ('.', '.')]



============================ Sentence 657 =============================

Blazquez, D. and Domenech, J., 2018. 


>> Tokens are: 
 ['Blazquez', ',', 'D.', 'Domenech', ',', 'J.', ',', '2018', '.']

>> Bigrams are: 
 [('Blazquez', ','), (',', 'D.'), ('D.', 'Domenech'), ('Domenech', ','), (',', 'J.'), ('J.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Blazquez', ',', 'D.'), (',', 'D.', 'Domenech'), ('D.', 'Domenech', ','), ('Domenech', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Blazquez', 'NNP'), (',', ','), ('D.', 'NNP'), ('Domenech', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Blazquez/NNP)
  ,/,
  (NP D./NNP Domenech/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Blazquez', 'D. Domenech', 'J.']

>> Named Entities are: 
 [('GPE', 'Blazquez')] 

>> Stemming using Porter Stemmer: 
 [('Blazquez', 'blazquez'), (',', ','), ('D.', 'd.'), ('Domenech', 'domenech'), (',', ','), ('J.', 'j.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Blazquez', 'blazquez'), (',', ','), ('D.', 'd.'), ('Domenech', 'domenech'), (',', ','), ('J.', 'j.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Blazquez', 'Blazquez'), (',', ','), ('D.', 'D.'), ('Domenech', 'Domenech'), (',', ','), ('J.', 'J.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 658 =============================

Big Data sources and methods for social and economic   analyses. 


>> Tokens are: 
 ['Big', 'Data', 'sources', 'methods', 'social', 'economic', 'analyses', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'sources'), ('sources', 'methods'), ('methods', 'social'), ('social', 'economic'), ('economic', 'analyses'), ('analyses', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'sources'), ('Data', 'sources', 'methods'), ('sources', 'methods', 'social'), ('methods', 'social', 'economic'), ('social', 'economic', 'analyses'), ('economic', 'analyses', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('sources', 'NNS'), ('methods', 'VBD'), ('social', 'JJ'), ('economic', 'JJ'), ('analyses', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP sources/NNS)
  methods/VBD
  (NP social/JJ economic/JJ analyses/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big Data sources', 'social economic analyses']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('sources', 'sourc'), ('methods', 'method'), ('social', 'social'), ('economic', 'econom'), ('analyses', 'analys'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('sources', 'sourc'), ('methods', 'method'), ('social', 'social'), ('economic', 'econom'), ('analyses', 'analys'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('sources', 'source'), ('methods', 'method'), ('social', 'social'), ('economic', 'economic'), ('analyses', 'analysis'), ('.', '.')]



============================ Sentence 659 =============================

Technological Forecasting and Social Change journal, Volume 130, pp. 


>> Tokens are: 
 ['Technological', 'Forecasting', 'Social', 'Change', 'journal', ',', 'Volume', '130', ',', 'pp', '.']

>> Bigrams are: 
 [('Technological', 'Forecasting'), ('Forecasting', 'Social'), ('Social', 'Change'), ('Change', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '130'), ('130', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Technological', 'Forecasting', 'Social'), ('Forecasting', 'Social', 'Change'), ('Social', 'Change', 'journal'), ('Change', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '130'), ('Volume', '130', ','), ('130', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Technological', 'JJ'), ('Forecasting', 'NNP'), ('Social', 'NNP'), ('Change', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('130', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    Technological/JJ
    Forecasting/NNP
    Social/NNP
    Change/NNP
    journal/NN)
  ,/,
  (NP Volume/NN)
  130/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Technological Forecasting Social Change journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 130')] 

>> Stemming using Porter Stemmer: 
 [('Technological', 'technolog'), ('Forecasting', 'forecast'), ('Social', 'social'), ('Change', 'chang'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('130', '130'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Technological', 'technolog'), ('Forecasting', 'forecast'), ('Social', 'social'), ('Change', 'chang'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('130', '130'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Technological', 'Technological'), ('Forecasting', 'Forecasting'), ('Social', 'Social'), ('Change', 'Change'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('130', '130'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 660 =============================

99--113. 


>> Tokens are: 
 ['99', '--', '113', '.']

>> Bigrams are: 
 [('99', '--'), ('--', '113'), ('113', '.')]

>> Trigrams are: 
 [('99', '--', '113'), ('--', '113', '.')]

>> POS Tags are: 
 [('99', 'CD'), ('--', ':'), ('113', 'CD'), ('.', '.')]

 (S 99/CD --/: 113/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('99', '99'), ('--', '--'), ('113', '113'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('99', '99'), ('--', '--'), ('113', '113'), ('.', '.')]

>> Lemmatization: 
 [('99', '99'), ('--', '--'), ('113', '113'), ('.', '.')]



============================ Sentence 661 =============================

Boyd-Graber, J., Mimno, D. and Newman, D., 2014. 


>> Tokens are: 
 ['Boyd-Graber', ',', 'J.', ',', 'Mimno', ',', 'D.', 'Newman', ',', 'D.', ',', '2014', '.']

>> Bigrams are: 
 [('Boyd-Graber', ','), (',', 'J.'), ('J.', ','), (',', 'Mimno'), ('Mimno', ','), (',', 'D.'), ('D.', 'Newman'), ('Newman', ','), (',', 'D.'), ('D.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Boyd-Graber', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Mimno'), (',', 'Mimno', ','), ('Mimno', ',', 'D.'), (',', 'D.', 'Newman'), ('D.', 'Newman', ','), ('Newman', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Boyd-Graber', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Mimno', 'NNP'), (',', ','), ('D.', 'NNP'), ('Newman', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Boyd-Graber/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Mimno/NNP)
  ,/,
  (NP D./NNP Newman/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Boyd-Graber', 'J.', 'Mimno', 'D. Newman', 'D.']

>> Named Entities are: 
 [('PERSON', 'Mimno')] 

>> Stemming using Porter Stemmer: 
 [('Boyd-Graber', 'boyd-grab'), (',', ','), ('J.', 'j.'), (',', ','), ('Mimno', 'mimno'), (',', ','), ('D.', 'd.'), ('Newman', 'newman'), (',', ','), ('D.', 'd.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Boyd-Graber', 'boyd-grab'), (',', ','), ('J.', 'j.'), (',', ','), ('Mimno', 'mimno'), (',', ','), ('D.', 'd.'), ('Newman', 'newman'), (',', ','), ('D.', 'd.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Boyd-Graber', 'Boyd-Graber'), (',', ','), ('J.', 'J.'), (',', ','), ('Mimno', 'Mimno'), (',', ','), ('D.', 'D.'), ('Newman', 'Newman'), (',', ','), ('D.', 'D.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 662 =============================

Care and feeding of topic models: Problems,   diagnostics, and improvements.. Handbook of mixed membership models and their applications   Journal , Volume 225255. 


>> Tokens are: 
 ['Care', 'feeding', 'topic', 'models', ':', 'Problems', ',', 'diagnostics', ',', 'improvements', '..', 'Handbook', 'mixed', 'membership', 'models', 'applications', 'Journal', ',', 'Volume', '225255', '.']

>> Bigrams are: 
 [('Care', 'feeding'), ('feeding', 'topic'), ('topic', 'models'), ('models', ':'), (':', 'Problems'), ('Problems', ','), (',', 'diagnostics'), ('diagnostics', ','), (',', 'improvements'), ('improvements', '..'), ('..', 'Handbook'), ('Handbook', 'mixed'), ('mixed', 'membership'), ('membership', 'models'), ('models', 'applications'), ('applications', 'Journal'), ('Journal', ','), (',', 'Volume'), ('Volume', '225255'), ('225255', '.')]

>> Trigrams are: 
 [('Care', 'feeding', 'topic'), ('feeding', 'topic', 'models'), ('topic', 'models', ':'), ('models', ':', 'Problems'), (':', 'Problems', ','), ('Problems', ',', 'diagnostics'), (',', 'diagnostics', ','), ('diagnostics', ',', 'improvements'), (',', 'improvements', '..'), ('improvements', '..', 'Handbook'), ('..', 'Handbook', 'mixed'), ('Handbook', 'mixed', 'membership'), ('mixed', 'membership', 'models'), ('membership', 'models', 'applications'), ('models', 'applications', 'Journal'), ('applications', 'Journal', ','), ('Journal', ',', 'Volume'), (',', 'Volume', '225255'), ('Volume', '225255', '.')]

>> POS Tags are: 
 [('Care', 'NNP'), ('feeding', 'VBG'), ('topic', 'NN'), ('models', 'NNS'), (':', ':'), ('Problems', 'NNP'), (',', ','), ('diagnostics', 'NNS'), (',', ','), ('improvements', 'NNS'), ('..', 'VBP'), ('Handbook', 'NNP'), ('mixed', 'JJ'), ('membership', 'NN'), ('models', 'NNS'), ('applications', 'NNS'), ('Journal', 'NNP'), (',', ','), ('Volume', 'NN'), ('225255', 'CD'), ('.', '.')]

 (S
  (NP Care/NNP)
  feeding/VBG
  (NP topic/NN models/NNS)
  :/:
  (NP Problems/NNP)
  ,/,
  (NP diagnostics/NNS)
  ,/,
  (NP improvements/NNS)
  ../VBP
  (NP Handbook/NNP)
  (NP mixed/JJ membership/NN models/NNS applications/NNS Journal/NNP)
  ,/,
  (NP Volume/NN)
  225255/CD
  ./.) 


>> Noun Phrases are: 
 ['Care', 'topic models', 'Problems', 'diagnostics', 'improvements', 'Handbook', 'mixed membership models applications Journal', 'Volume']

>> Named Entities are: 
 [('GPE', 'Care'), ('PERSON', 'Handbook'), ('ORGANIZATION', 'Volume 225255')] 

>> Stemming using Porter Stemmer: 
 [('Care', 'care'), ('feeding', 'feed'), ('topic', 'topic'), ('models', 'model'), (':', ':'), ('Problems', 'problem'), (',', ','), ('diagnostics', 'diagnost'), (',', ','), ('improvements', 'improv'), ('..', '..'), ('Handbook', 'handbook'), ('mixed', 'mix'), ('membership', 'membership'), ('models', 'model'), ('applications', 'applic'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('225255', '225255'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Care', 'care'), ('feeding', 'feed'), ('topic', 'topic'), ('models', 'model'), (':', ':'), ('Problems', 'problem'), (',', ','), ('diagnostics', 'diagnost'), (',', ','), ('improvements', 'improv'), ('..', '..'), ('Handbook', 'handbook'), ('mixed', 'mix'), ('membership', 'membership'), ('models', 'model'), ('applications', 'applic'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('225255', '225255'), ('.', '.')]

>> Lemmatization: 
 [('Care', 'Care'), ('feeding', 'feeding'), ('topic', 'topic'), ('models', 'model'), (':', ':'), ('Problems', 'Problems'), (',', ','), ('diagnostics', 'diagnostics'), (',', ','), ('improvements', 'improvement'), ('..', '..'), ('Handbook', 'Handbook'), ('mixed', 'mixed'), ('membership', 'membership'), ('models', 'model'), ('applications', 'application'), ('Journal', 'Journal'), (',', ','), ('Volume', 'Volume'), ('225255', '225255'), ('.', '.')]



============================ Sentence 663 =============================

Bradlow, E.T., Gangwar, M., Kopalle, P. and Voleti, S., 2017. 


>> Tokens are: 
 ['Bradlow', ',', 'E.T.', ',', 'Gangwar', ',', 'M.', ',', 'Kopalle', ',', 'P.', 'Voleti', ',', 'S.', ',', '2017', '.']

>> Bigrams are: 
 [('Bradlow', ','), (',', 'E.T.'), ('E.T.', ','), (',', 'Gangwar'), ('Gangwar', ','), (',', 'M.'), ('M.', ','), (',', 'Kopalle'), ('Kopalle', ','), (',', 'P.'), ('P.', 'Voleti'), ('Voleti', ','), (',', 'S.'), ('S.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Bradlow', ',', 'E.T.'), (',', 'E.T.', ','), ('E.T.', ',', 'Gangwar'), (',', 'Gangwar', ','), ('Gangwar', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Kopalle'), (',', 'Kopalle', ','), ('Kopalle', ',', 'P.'), (',', 'P.', 'Voleti'), ('P.', 'Voleti', ','), ('Voleti', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Bradlow', 'NNP'), (',', ','), ('E.T.', 'NNP'), (',', ','), ('Gangwar', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Kopalle', 'NNP'), (',', ','), ('P.', 'NNP'), ('Voleti', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Bradlow/NNP)
  ,/,
  (NP E.T./NNP)
  ,/,
  (NP Gangwar/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Kopalle/NNP)
  ,/,
  (NP P./NNP Voleti/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Bradlow', 'E.T.', 'Gangwar', 'M.', 'Kopalle', 'P. Voleti', 'S.']

>> Named Entities are: 
 [('GPE', 'Bradlow'), ('PERSON', 'Gangwar'), ('GPE', 'Kopalle')] 

>> Stemming using Porter Stemmer: 
 [('Bradlow', 'bradlow'), (',', ','), ('E.T.', 'e.t.'), (',', ','), ('Gangwar', 'gangwar'), (',', ','), ('M.', 'm.'), (',', ','), ('Kopalle', 'kopal'), (',', ','), ('P.', 'p.'), ('Voleti', 'voleti'), (',', ','), ('S.', 's.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bradlow', 'bradlow'), (',', ','), ('E.T.', 'e.t.'), (',', ','), ('Gangwar', 'gangwar'), (',', ','), ('M.', 'm.'), (',', ','), ('Kopalle', 'kopall'), (',', ','), ('P.', 'p.'), ('Voleti', 'voleti'), (',', ','), ('S.', 's.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Bradlow', 'Bradlow'), (',', ','), ('E.T.', 'E.T.'), (',', ','), ('Gangwar', 'Gangwar'), (',', ','), ('M.', 'M.'), (',', ','), ('Kopalle', 'Kopalle'), (',', ','), ('P.', 'P.'), ('Voleti', 'Voleti'), (',', ','), ('S.', 'S.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 664 =============================

The role of big data and predictive   analytics in retailing. 


>> Tokens are: 
 ['The', 'role', 'big', 'data', 'predictive', 'analytics', 'retailing', '.']

>> Bigrams are: 
 [('The', 'role'), ('role', 'big'), ('big', 'data'), ('data', 'predictive'), ('predictive', 'analytics'), ('analytics', 'retailing'), ('retailing', '.')]

>> Trigrams are: 
 [('The', 'role', 'big'), ('role', 'big', 'data'), ('big', 'data', 'predictive'), ('data', 'predictive', 'analytics'), ('predictive', 'analytics', 'retailing'), ('analytics', 'retailing', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('role', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('predictive', 'JJ'), ('analytics', 'NNS'), ('retailing', 'NN'), ('.', '.')]

 (S
  (NP The/DT role/NN)
  (NP big/JJ data/NNS)
  (NP predictive/JJ analytics/NNS retailing/NN)
  ./.) 


>> Noun Phrases are: 
 ['The role', 'big data', 'predictive analytics retailing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('predictive', 'predict'), ('analytics', 'analyt'), ('retailing', 'retail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('predictive', 'predict'), ('analytics', 'analyt'), ('retailing', 'retail'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('role', 'role'), ('big', 'big'), ('data', 'data'), ('predictive', 'predictive'), ('analytics', 'analytics'), ('retailing', 'retailing'), ('.', '.')]



============================ Sentence 665 =============================

Journal of Retailing, pp. 


>> Tokens are: 
 ['Journal', 'Retailing', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Retailing'), ('Retailing', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Retailing', ','), ('Retailing', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Retailing', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP Journal/NNP Retailing/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Journal Retailing', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal Retailing')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Retailing', 'retail'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Retailing', 'retail'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Retailing', 'Retailing'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 666 =============================

79-95. 


>> Tokens are: 
 ['79-95', '.']

>> Bigrams are: 
 [('79-95', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('79-95', 'JJ'), ('.', '.')]

 (S 79-95/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('79-95', '79-95'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('79-95', '79-95'), ('.', '.')]

>> Lemmatization: 
 [('79-95', '79-95'), ('.', '.')]



============================ Sentence 667 =============================

Sarah Al-Shiakhli   48      Breed, D.G. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '48', 'Breed', ',', 'D.G', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '48'), ('48', 'Breed'), ('Breed', ','), (',', 'D.G'), ('D.G', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '48'), ('Al-Shiakhli', '48', 'Breed'), ('48', 'Breed', ','), ('Breed', ',', 'D.G'), (',', 'D.G', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('48', 'CD'), ('Breed', 'NNP'), (',', ','), ('D.G', 'NNP'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  48/CD
  (NP Breed/NNP)
  ,/,
  (NP D.G/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Breed', 'D.G']

>> Named Entities are: 
 [('PERSON', 'Sarah')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('48', '48'), ('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('48', '48'), ('Breed', 'breed'), (',', ','), ('D.G', 'd.g'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('48', '48'), ('Breed', 'Breed'), (',', ','), ('D.G', 'D.G'), ('.', '.')]



============================ Sentence 668 =============================

and Verster, T., 2019. 


>> Tokens are: 
 ['Verster', ',', 'T.', ',', '2019', '.']

>> Bigrams are: 
 [('Verster', ','), (',', 'T.'), ('T.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Verster', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Verster', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S (NP Verster/NNP) ,/, (NP T./NNP) ,/, 2019/CD ./.) 


>> Noun Phrases are: 
 ['Verster', 'T.']

>> Named Entities are: 
 [('PERSON', 'Verster')] 

>> Stemming using Porter Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Verster', 'verster'), (',', ','), ('T.', 't.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Verster', 'Verster'), (',', ','), ('T.', 'T.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 669 =============================

An empirical investigation of alternative semi-supervised   segmentation methodologies. 


>> Tokens are: 
 ['An', 'empirical', 'investigation', 'alternative', 'semi-supervised', 'segmentation', 'methodologies', '.']

>> Bigrams are: 
 [('An', 'empirical'), ('empirical', 'investigation'), ('investigation', 'alternative'), ('alternative', 'semi-supervised'), ('semi-supervised', 'segmentation'), ('segmentation', 'methodologies'), ('methodologies', '.')]

>> Trigrams are: 
 [('An', 'empirical', 'investigation'), ('empirical', 'investigation', 'alternative'), ('investigation', 'alternative', 'semi-supervised'), ('alternative', 'semi-supervised', 'segmentation'), ('semi-supervised', 'segmentation', 'methodologies'), ('segmentation', 'methodologies', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('empirical', 'JJ'), ('investigation', 'NN'), ('alternative', 'JJ'), ('semi-supervised', 'JJ'), ('segmentation', 'NN'), ('methodologies', 'NNS'), ('.', '.')]

 (S
  (NP An/DT empirical/JJ investigation/NN)
  (NP
    alternative/JJ
    semi-supervised/JJ
    segmentation/NN
    methodologies/NNS)
  ./.) 


>> Noun Phrases are: 
 ['An empirical investigation', 'alternative semi-supervised segmentation methodologies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('empirical', 'empir'), ('investigation', 'investig'), ('alternative', 'altern'), ('semi-supervised', 'semi-supervis'), ('segmentation', 'segment'), ('methodologies', 'methodolog'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('empirical', 'empir'), ('investigation', 'investig'), ('alternative', 'altern'), ('semi-supervised', 'semi-supervis'), ('segmentation', 'segment'), ('methodologies', 'methodolog'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('empirical', 'empirical'), ('investigation', 'investigation'), ('alternative', 'alternative'), ('semi-supervised', 'semi-supervised'), ('segmentation', 'segmentation'), ('methodologies', 'methodology'), ('.', '.')]



============================ Sentence 670 =============================

South African Journal of Science, Volume 115, pp. 


>> Tokens are: 
 ['South', 'African', 'Journal', 'Science', ',', 'Volume', '115', ',', 'pp', '.']

>> Bigrams are: 
 [('South', 'African'), ('African', 'Journal'), ('Journal', 'Science'), ('Science', ','), (',', 'Volume'), ('Volume', '115'), ('115', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('South', 'African', 'Journal'), ('African', 'Journal', 'Science'), ('Journal', 'Science', ','), ('Science', ',', 'Volume'), (',', 'Volume', '115'), ('Volume', '115', ','), ('115', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('South', 'JJ'), ('African', 'JJ'), ('Journal', 'NNP'), ('Science', 'NNP'), (',', ','), ('Volume', 'NN'), ('115', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP South/JJ African/JJ Journal/NNP Science/NNP)
  ,/,
  (NP Volume/NN)
  115/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['South African Journal Science', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'South'), ('ORGANIZATION', 'African Journal Science'), ('ORGANIZATION', 'Volume 115')] 

>> Stemming using Porter Stemmer: 
 [('South', 'south'), ('African', 'african'), ('Journal', 'journal'), ('Science', 'scienc'), (',', ','), ('Volume', 'volum'), ('115', '115'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('South', 'south'), ('African', 'african'), ('Journal', 'journal'), ('Science', 'scienc'), (',', ','), ('Volume', 'volum'), ('115', '115'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('South', 'South'), ('African', 'African'), ('Journal', 'Journal'), ('Science', 'Science'), (',', ','), ('Volume', 'Volume'), ('115', '115'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 671 =============================

pp.92-98. 


>> Tokens are: 
 ['pp.92-98', '.']

>> Bigrams are: 
 [('pp.92-98', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('pp.92-98', 'NN'), ('.', '.')]

 (S (NP pp.92-98/NN) ./.) 


>> Noun Phrases are: 
 ['pp.92-98']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('pp.92-98', 'pp.92-98'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('pp.92-98', 'pp.92-98'), ('.', '.')]

>> Lemmatization: 
 [('pp.92-98', 'pp.92-98'), ('.', '.')]



============================ Sentence 672 =============================

Bughin, J., Chui, M. and Manyika, J., 2010. 


>> Tokens are: 
 ['Bughin', ',', 'J.', ',', 'Chui', ',', 'M.', 'Manyika', ',', 'J.', ',', '2010', '.']

>> Bigrams are: 
 [('Bughin', ','), (',', 'J.'), ('J.', ','), (',', 'Chui'), ('Chui', ','), (',', 'M.'), ('M.', 'Manyika'), ('Manyika', ','), (',', 'J.'), ('J.', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Bughin', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Chui'), (',', 'Chui', ','), ('Chui', ',', 'M.'), (',', 'M.', 'Manyika'), ('M.', 'Manyika', ','), ('Manyika', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Bughin', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Chui', 'NNP'), (',', ','), ('M.', 'NNP'), ('Manyika', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

 (S
  (NP Bughin/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Chui/NNP)
  ,/,
  (NP M./NNP Manyika/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  2010/CD
  ./.) 


>> Noun Phrases are: 
 ['Bughin', 'J.', 'Chui', 'M. Manyika', 'J.']

>> Named Entities are: 
 [('GPE', 'Bughin'), ('PERSON', 'Chui')] 

>> Stemming using Porter Stemmer: 
 [('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), ('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), ('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Bughin', 'Bughin'), (',', ','), ('J.', 'J.'), (',', ','), ('Chui', 'Chui'), (',', ','), ('M.', 'M.'), ('Manyika', 'Manyika'), (',', ','), ('J.', 'J.'), (',', ','), ('2010', '2010'), ('.', '.')]



============================ Sentence 673 =============================

Clouds, big data, and smart assets: Ten tech-enabled   business trends to watch.. McKinsey quarterly, Volume 56, pp. 


>> Tokens are: 
 ['Clouds', ',', 'big', 'data', ',', 'smart', 'assets', ':', 'Ten', 'tech-enabled', 'business', 'trends', 'watch', '..', 'McKinsey', 'quarterly', ',', 'Volume', '56', ',', 'pp', '.']

>> Bigrams are: 
 [('Clouds', ','), (',', 'big'), ('big', 'data'), ('data', ','), (',', 'smart'), ('smart', 'assets'), ('assets', ':'), (':', 'Ten'), ('Ten', 'tech-enabled'), ('tech-enabled', 'business'), ('business', 'trends'), ('trends', 'watch'), ('watch', '..'), ('..', 'McKinsey'), ('McKinsey', 'quarterly'), ('quarterly', ','), (',', 'Volume'), ('Volume', '56'), ('56', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Clouds', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ','), ('data', ',', 'smart'), (',', 'smart', 'assets'), ('smart', 'assets', ':'), ('assets', ':', 'Ten'), (':', 'Ten', 'tech-enabled'), ('Ten', 'tech-enabled', 'business'), ('tech-enabled', 'business', 'trends'), ('business', 'trends', 'watch'), ('trends', 'watch', '..'), ('watch', '..', 'McKinsey'), ('..', 'McKinsey', 'quarterly'), ('McKinsey', 'quarterly', ','), ('quarterly', ',', 'Volume'), (',', 'Volume', '56'), ('Volume', '56', ','), ('56', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Clouds', 'NNP'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (',', ','), ('smart', 'JJ'), ('assets', 'NNS'), (':', ':'), ('Ten', 'CD'), ('tech-enabled', 'JJ'), ('business', 'NN'), ('trends', 'NNS'), ('watch', 'VBP'), ('..', 'NNP'), ('McKinsey', 'NNP'), ('quarterly', 'RB'), (',', ','), ('Volume', 'NN'), ('56', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Clouds/NNP)
  ,/,
  (NP big/JJ data/NNS)
  ,/,
  (NP smart/JJ assets/NNS)
  :/:
  Ten/CD
  (NP tech-enabled/JJ business/NN trends/NNS)
  watch/VBP
  (NP ../NNP McKinsey/NNP)
  quarterly/RB
  ,/,
  (NP Volume/NN)
  56/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Clouds', 'big data', 'smart assets', 'tech-enabled business trends', '.. McKinsey', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Clouds'), ('ORGANIZATION', 'Volume 56')] 

>> Stemming using Porter Stemmer: 
 [('Clouds', 'cloud'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('smart', 'smart'), ('assets', 'asset'), (':', ':'), ('Ten', 'ten'), ('tech-enabled', 'tech-en'), ('business', 'busi'), ('trends', 'trend'), ('watch', 'watch'), ('..', '..'), ('McKinsey', 'mckinsey'), ('quarterly', 'quarterli'), (',', ','), ('Volume', 'volum'), ('56', '56'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Clouds', 'cloud'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('smart', 'smart'), ('assets', 'asset'), (':', ':'), ('Ten', 'ten'), ('tech-enabled', 'tech-en'), ('business', 'busi'), ('trends', 'trend'), ('watch', 'watch'), ('..', '..'), ('McKinsey', 'mckinsey'), ('quarterly', 'quarter'), (',', ','), ('Volume', 'volum'), ('56', '56'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Clouds', 'Clouds'), (',', ','), ('big', 'big'), ('data', 'data'), (',', ','), ('smart', 'smart'), ('assets', 'asset'), (':', ':'), ('Ten', 'Ten'), ('tech-enabled', 'tech-enabled'), ('business', 'business'), ('trends', 'trend'), ('watch', 'watch'), ('..', '..'), ('McKinsey', 'McKinsey'), ('quarterly', 'quarterly'), (',', ','), ('Volume', 'Volume'), ('56', '56'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 674 =============================

75-86. 


>> Tokens are: 
 ['75-86', '.']

>> Bigrams are: 
 [('75-86', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('75-86', 'JJ'), ('.', '.')]

 (S 75-86/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('75-86', '75-86'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('75-86', '75-86'), ('.', '.')]

>> Lemmatization: 
 [('75-86', '75-86'), ('.', '.')]



============================ Sentence 675 =============================

Casadesus-Masanell, R. and Ricart, J.E, 2010. 


>> Tokens are: 
 ['Casadesus-Masanell', ',', 'R.', 'Ricart', ',', 'J.E', ',', '2010', '.']

>> Bigrams are: 
 [('Casadesus-Masanell', ','), (',', 'R.'), ('R.', 'Ricart'), ('Ricart', ','), (',', 'J.E'), ('J.E', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Casadesus-Masanell', ',', 'R.'), (',', 'R.', 'Ricart'), ('R.', 'Ricart', ','), ('Ricart', ',', 'J.E'), (',', 'J.E', ','), ('J.E', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Casadesus-Masanell', 'NNP'), (',', ','), ('R.', 'NNP'), ('Ricart', 'NNP'), (',', ','), ('J.E', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

 (S
  (NP Casadesus-Masanell/NNP)
  ,/,
  (NP R./NNP Ricart/NNP)
  ,/,
  (NP J.E/NNP)
  ,/,
  2010/CD
  ./.) 


>> Noun Phrases are: 
 ['Casadesus-Masanell', 'R. Ricart', 'J.E']

>> Named Entities are: 
 [('PERSON', 'Ricart')] 

>> Stemming using Porter Stemmer: 
 [('Casadesus-Masanell', 'casadesus-masanel'), (',', ','), ('R.', 'r.'), ('Ricart', 'ricart'), (',', ','), ('J.E', 'j.e'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Casadesus-Masanell', 'casadesus-masanel'), (',', ','), ('R.', 'r.'), ('Ricart', 'ricart'), (',', ','), ('J.E', 'j.e'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Casadesus-Masanell', 'Casadesus-Masanell'), (',', ','), ('R.', 'R.'), ('Ricart', 'Ricart'), (',', ','), ('J.E', 'J.E'), (',', ','), ('2010', '2010'), ('.', '.')]



============================ Sentence 676 =============================

From strategy to business models and onto tactics. 


>> Tokens are: 
 ['From', 'strategy', 'business', 'models', 'onto', 'tactics', '.']

>> Bigrams are: 
 [('From', 'strategy'), ('strategy', 'business'), ('business', 'models'), ('models', 'onto'), ('onto', 'tactics'), ('tactics', '.')]

>> Trigrams are: 
 [('From', 'strategy', 'business'), ('strategy', 'business', 'models'), ('business', 'models', 'onto'), ('models', 'onto', 'tactics'), ('onto', 'tactics', '.')]

>> POS Tags are: 
 [('From', 'IN'), ('strategy', 'NN'), ('business', 'NN'), ('models', 'NNS'), ('onto', 'IN'), ('tactics', 'NNS'), ('.', '.')]

 (S
  From/IN
  (NP strategy/NN business/NN models/NNS)
  onto/IN
  (NP tactics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['strategy business models', 'tactics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('From', 'from'), ('strategy', 'strategi'), ('business', 'busi'), ('models', 'model'), ('onto', 'onto'), ('tactics', 'tactic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('From', 'from'), ('strategy', 'strategi'), ('business', 'busi'), ('models', 'model'), ('onto', 'onto'), ('tactics', 'tactic'), ('.', '.')]

>> Lemmatization: 
 [('From', 'From'), ('strategy', 'strategy'), ('business', 'business'), ('models', 'model'), ('onto', 'onto'), ('tactics', 'tactic'), ('.', '.')]



============================ Sentence 677 =============================

Long range planning journal, Volume 43, pp. 


>> Tokens are: 
 ['Long', 'range', 'planning', 'journal', ',', 'Volume', '43', ',', 'pp', '.']

>> Bigrams are: 
 [('Long', 'range'), ('range', 'planning'), ('planning', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '43'), ('43', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Long', 'range', 'planning'), ('range', 'planning', 'journal'), ('planning', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '43'), ('Volume', '43', ','), ('43', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Long', 'JJ'), ('range', 'NN'), ('planning', 'NN'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('43', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Long/JJ range/NN planning/NN journal/NN)
  ,/,
  (NP Volume/NN)
  43/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Long range planning journal', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Long'), ('ORGANIZATION', 'Volume 43')] 

>> Stemming using Porter Stemmer: 
 [('Long', 'long'), ('range', 'rang'), ('planning', 'plan'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('43', '43'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Long', 'long'), ('range', 'rang'), ('planning', 'plan'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('43', '43'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Long', 'Long'), ('range', 'range'), ('planning', 'planning'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('43', '43'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 678 =============================

195-215. 


>> Tokens are: 
 ['195-215', '.']

>> Bigrams are: 
 [('195-215', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('195-215', 'JJ'), ('.', '.')]

 (S 195-215/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('195-215', '195-215'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('195-215', '195-215'), ('.', '.')]

>> Lemmatization: 
 [('195-215', '195-215'), ('.', '.')]



============================ Sentence 679 =============================

Çelebi, Ö.F., Zeydan, E., Kurt, Ö.F., Dedeoğlu, Ö., İieri, Ö., AykutSungur, B., Akan, A. and Ergüt,   S., 2013. 


>> Tokens are: 
 ['Çelebi', ',', 'Ö.F.', ',', 'Zeydan', ',', 'E.', ',', 'Kurt', ',', 'Ö.F.', ',', 'Dedeoğlu', ',', 'Ö.', ',', 'İieri', ',', 'Ö.', ',', 'AykutSungur', ',', 'B.', ',', 'Akan', ',', 'A.', 'Ergüt', ',', 'S.', ',', '2013', '.']

>> Bigrams are: 
 [('Çelebi', ','), (',', 'Ö.F.'), ('Ö.F.', ','), (',', 'Zeydan'), ('Zeydan', ','), (',', 'E.'), ('E.', ','), (',', 'Kurt'), ('Kurt', ','), (',', 'Ö.F.'), ('Ö.F.', ','), (',', 'Dedeoğlu'), ('Dedeoğlu', ','), (',', 'Ö.'), ('Ö.', ','), (',', 'İieri'), ('İieri', ','), (',', 'Ö.'), ('Ö.', ','), (',', 'AykutSungur'), ('AykutSungur', ','), (',', 'B.'), ('B.', ','), (',', 'Akan'), ('Akan', ','), (',', 'A.'), ('A.', 'Ergüt'), ('Ergüt', ','), (',', 'S.'), ('S.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Çelebi', ',', 'Ö.F.'), (',', 'Ö.F.', ','), ('Ö.F.', ',', 'Zeydan'), (',', 'Zeydan', ','), ('Zeydan', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Kurt'), (',', 'Kurt', ','), ('Kurt', ',', 'Ö.F.'), (',', 'Ö.F.', ','), ('Ö.F.', ',', 'Dedeoğlu'), (',', 'Dedeoğlu', ','), ('Dedeoğlu', ',', 'Ö.'), (',', 'Ö.', ','), ('Ö.', ',', 'İieri'), (',', 'İieri', ','), ('İieri', ',', 'Ö.'), (',', 'Ö.', ','), ('Ö.', ',', 'AykutSungur'), (',', 'AykutSungur', ','), ('AykutSungur', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Akan'), (',', 'Akan', ','), ('Akan', ',', 'A.'), (',', 'A.', 'Ergüt'), ('A.', 'Ergüt', ','), ('Ergüt', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Çelebi', 'NN'), (',', ','), ('Ö.F.', 'NNP'), (',', ','), ('Zeydan', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Kurt', 'NNP'), (',', ','), ('Ö.F.', 'NNP'), (',', ','), ('Dedeoğlu', 'NNP'), (',', ','), ('Ö.', 'NNP'), (',', ','), ('İieri', 'NNP'), (',', ','), ('Ö.', 'NNP'), (',', ','), ('AykutSungur', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Akan', 'NNP'), (',', ','), ('A.', 'NNP'), ('Ergüt', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Çelebi/NN)
  ,/,
  (NP Ö.F./NNP)
  ,/,
  (NP Zeydan/NNP)
  ,/,
  (NP E./NNP)
  ,/,
  (NP Kurt/NNP)
  ,/,
  (NP Ö.F./NNP)
  ,/,
  (NP Dedeoğlu/NNP)
  ,/,
  (NP Ö./NNP)
  ,/,
  (NP İieri/NNP)
  ,/,
  (NP Ö./NNP)
  ,/,
  (NP AykutSungur/NNP)
  ,/,
  (NP B./NNP)
  ,/,
  (NP Akan/NNP)
  ,/,
  (NP A./NNP Ergüt/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Çelebi', 'Ö.F.', 'Zeydan', 'E.', 'Kurt', 'Ö.F.', 'Dedeoğlu', 'Ö.', 'İieri', 'Ö.', 'AykutSungur', 'B.', 'Akan', 'A. Ergüt', 'S.']

>> Named Entities are: 
 [('GPE', 'Çelebi'), ('GPE', 'Zeydan'), ('PERSON', 'Kurt'), ('GPE', 'Dedeoğlu'), ('PERSON', 'İieri'), ('ORGANIZATION', 'AykutSungur'), ('PERSON', 'Akan')] 

>> Stemming using Porter Stemmer: 
 [('Çelebi', 'çelebi'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Zeydan', 'zeydan'), (',', ','), ('E.', 'e.'), (',', ','), ('Kurt', 'kurt'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Dedeoğlu', 'dedeoğlu'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('İieri', 'i̇ieri'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('AykutSungur', 'aykutsungur'), (',', ','), ('B.', 'b.'), (',', ','), ('Akan', 'akan'), (',', ','), ('A.', 'a.'), ('Ergüt', 'ergüt'), (',', ','), ('S.', 's.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Çelebi', 'çelebi'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Zeydan', 'zeydan'), (',', ','), ('E.', 'e.'), (',', ','), ('Kurt', 'kurt'), (',', ','), ('Ö.F.', 'ö.f.'), (',', ','), ('Dedeoğlu', 'dedeoğlu'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('İieri', 'i̇ieri'), (',', ','), ('Ö.', 'ö.'), (',', ','), ('AykutSungur', 'aykutsungur'), (',', ','), ('B.', 'b.'), (',', ','), ('Akan', 'akan'), (',', ','), ('A.', 'a.'), ('Ergüt', 'ergüt'), (',', ','), ('S.', 's.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Çelebi', 'Çelebi'), (',', ','), ('Ö.F.', 'Ö.F.'), (',', ','), ('Zeydan', 'Zeydan'), (',', ','), ('E.', 'E.'), (',', ','), ('Kurt', 'Kurt'), (',', ','), ('Ö.F.', 'Ö.F.'), (',', ','), ('Dedeoğlu', 'Dedeoğlu'), (',', ','), ('Ö.', 'Ö.'), (',', ','), ('İieri', 'İieri'), (',', ','), ('Ö.', 'Ö.'), (',', ','), ('AykutSungur', 'AykutSungur'), (',', ','), ('B.', 'B.'), (',', ','), ('Akan', 'Akan'), (',', ','), ('A.', 'A.'), ('Ergüt', 'Ergüt'), (',', ','), ('S.', 'S.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 680 =============================

On use of big data for enhancing network coverage analysis. 


>> Tokens are: 
 ['On', 'use', 'big', 'data', 'enhancing', 'network', 'coverage', 'analysis', '.']

>> Bigrams are: 
 [('On', 'use'), ('use', 'big'), ('big', 'data'), ('data', 'enhancing'), ('enhancing', 'network'), ('network', 'coverage'), ('coverage', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('On', 'use', 'big'), ('use', 'big', 'data'), ('big', 'data', 'enhancing'), ('data', 'enhancing', 'network'), ('enhancing', 'network', 'coverage'), ('network', 'coverage', 'analysis'), ('coverage', 'analysis', '.')]

>> POS Tags are: 
 [('On', 'IN'), ('use', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('enhancing', 'VBG'), ('network', 'NN'), ('coverage', 'NN'), ('analysis', 'NN'), ('.', '.')]

 (S
  On/IN
  (NP use/NN)
  (NP big/JJ data/NNS)
  enhancing/VBG
  (NP network/NN coverage/NN analysis/NN)
  ./.) 


>> Noun Phrases are: 
 ['use', 'big data', 'network coverage analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('On', 'on'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('enhancing', 'enhanc'), ('network', 'network'), ('coverage', 'coverag'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('On', 'on'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('enhancing', 'enhanc'), ('network', 'network'), ('coverage', 'coverag'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('On', 'On'), ('use', 'use'), ('big', 'big'), ('data', 'data'), ('enhancing', 'enhancing'), ('network', 'network'), ('coverage', 'coverage'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 681 =============================

In ICT 2013 IEEE journal,   pp. 


>> Tokens are: 
 ['In', 'ICT', '2013', 'IEEE', 'journal', ',', 'pp', '.']

>> Bigrams are: 
 [('In', 'ICT'), ('ICT', '2013'), ('2013', 'IEEE'), ('IEEE', 'journal'), ('journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('In', 'ICT', '2013'), ('ICT', '2013', 'IEEE'), ('2013', 'IEEE', 'journal'), ('IEEE', 'journal', ','), ('journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('In', 'IN'), ('ICT', 'NNP'), ('2013', 'CD'), ('IEEE', 'NNP'), ('journal', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  In/IN
  (NP ICT/NNP)
  2013/CD
  (NP IEEE/NNP journal/NN)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['ICT', 'IEEE journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ICT'), ('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('In', 'in'), ('ICT', 'ict'), ('2013', '2013'), ('IEEE', 'ieee'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('In', 'in'), ('ICT', 'ict'), ('2013', '2013'), ('IEEE', 'ieee'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('In', 'In'), ('ICT', 'ICT'), ('2013', '2013'), ('IEEE', 'IEEE'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 682 =============================

1-5. 


>> Tokens are: 
 ['1-5', '.']

>> Bigrams are: 
 [('1-5', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1-5', 'JJ'), ('.', '.')]

 (S 1-5/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1-5', '1-5'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1-5', '1-5'), ('.', '.')]

>> Lemmatization: 
 [('1-5', '1-5'), ('.', '.')]



============================ Sentence 683 =============================

Challita, S., Zalila, F., Gourdin, C. and Merle, P., 2018 . 


>> Tokens are: 
 ['Challita', ',', 'S.', ',', 'Zalila', ',', 'F.', ',', 'Gourdin', ',', 'C.', 'Merle', ',', 'P.', ',', '2018', '.']

>> Bigrams are: 
 [('Challita', ','), (',', 'S.'), ('S.', ','), (',', 'Zalila'), ('Zalila', ','), (',', 'F.'), ('F.', ','), (',', 'Gourdin'), ('Gourdin', ','), (',', 'C.'), ('C.', 'Merle'), ('Merle', ','), (',', 'P.'), ('P.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Challita', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Zalila'), (',', 'Zalila', ','), ('Zalila', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Gourdin'), (',', 'Gourdin', ','), ('Gourdin', ',', 'C.'), (',', 'C.', 'Merle'), ('C.', 'Merle', ','), ('Merle', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Challita', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Zalila', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Gourdin', 'NNP'), (',', ','), ('C.', 'NNP'), ('Merle', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Challita/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Zalila/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  (NP Gourdin/NNP)
  ,/,
  (NP C./NNP Merle/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Challita', 'S.', 'Zalila', 'F.', 'Gourdin', 'C. Merle', 'P.']

>> Named Entities are: 
 [('GPE', 'Challita'), ('PERSON', 'Zalila'), ('PERSON', 'Gourdin')] 

>> Stemming using Porter Stemmer: 
 [('Challita', 'challita'), (',', ','), ('S.', 's.'), (',', ','), ('Zalila', 'zalila'), (',', ','), ('F.', 'f.'), (',', ','), ('Gourdin', 'gourdin'), (',', ','), ('C.', 'c.'), ('Merle', 'merl'), (',', ','), ('P.', 'p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Challita', 'challita'), (',', ','), ('S.', 's.'), (',', ','), ('Zalila', 'zalila'), (',', ','), ('F.', 'f.'), (',', ','), ('Gourdin', 'gourdin'), (',', ','), ('C.', 'c.'), ('Merle', 'merl'), (',', ','), ('P.', 'p.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Challita', 'Challita'), (',', ','), ('S.', 'S.'), (',', ','), ('Zalila', 'Zalila'), (',', ','), ('F.', 'F.'), (',', ','), ('Gourdin', 'Gourdin'), (',', ','), ('C.', 'C.'), ('Merle', 'Merle'), (',', ','), ('P.', 'P.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 684 =============================

A Precise Model for Google Cloud   Platform.. 


>> Tokens are: 
 ['A', 'Precise', 'Model', 'Google', 'Cloud', 'Platform', '..']

>> Bigrams are: 
 [('A', 'Precise'), ('Precise', 'Model'), ('Model', 'Google'), ('Google', 'Cloud'), ('Cloud', 'Platform'), ('Platform', '..')]

>> Trigrams are: 
 [('A', 'Precise', 'Model'), ('Precise', 'Model', 'Google'), ('Model', 'Google', 'Cloud'), ('Google', 'Cloud', 'Platform'), ('Cloud', 'Platform', '..')]

>> POS Tags are: 
 [('A', 'DT'), ('Precise', 'NNP'), ('Model', 'NNP'), ('Google', 'NNP'), ('Cloud', 'NNP'), ('Platform', 'NNP'), ('..', 'NN')]

 (S
  (NP
    A/DT
    Precise/NNP
    Model/NNP
    Google/NNP
    Cloud/NNP
    Platform/NNP
    ../NN)) 


>> Noun Phrases are: 
 ['A Precise Model Google Cloud Platform ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Precise', 'precis'), ('Model', 'model'), ('Google', 'googl'), ('Cloud', 'cloud'), ('Platform', 'platform'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Precise', 'precis'), ('Model', 'model'), ('Google', 'googl'), ('Cloud', 'cloud'), ('Platform', 'platform'), ('..', '..')]

>> Lemmatization: 
 [('A', 'A'), ('Precise', 'Precise'), ('Model', 'Model'), ('Google', 'Google'), ('Cloud', 'Cloud'), ('Platform', 'Platform'), ('..', '..')]



============================ Sentence 685 =============================

s.l., IEEE, pp. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 686 =============================

177-183. 


>> Tokens are: 
 ['177-183', '.']

>> Bigrams are: 
 [('177-183', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('177-183', 'JJ'), ('.', '.')]

 (S 177-183/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('177-183', '177-183'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('177-183', '177-183'), ('.', '.')]

>> Lemmatization: 
 [('177-183', '177-183'), ('.', '.')]



============================ Sentence 687 =============================

Chen G, Guo X., 2016. 


>> Tokens are: 
 ['Chen', 'G', ',', 'Guo', 'X.', ',', '2016', '.']

>> Bigrams are: 
 [('Chen', 'G'), ('G', ','), (',', 'Guo'), ('Guo', 'X.'), ('X.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Chen', 'G', ','), ('G', ',', 'Guo'), (',', 'Guo', 'X.'), ('Guo', 'X.', ','), ('X.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), ('G', 'NNP'), (',', ','), ('Guo', 'NNP'), ('X.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S (NP Chen/NNP G/NNP) ,/, (NP Guo/NNP X./NNP) ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 ['Chen G', 'Guo X.']

>> Named Entities are: 
 [('PERSON', 'Chen'), ('ORGANIZATION', 'G'), ('PERSON', 'Guo X.')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), ('G', 'g'), (',', ','), ('Guo', 'guo'), ('X.', 'x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), ('G', 'g'), (',', ','), ('Guo', 'guo'), ('X.', 'x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), ('G', 'G'), (',', ','), ('Guo', 'Guo'), ('X.', 'X.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 688 =============================

Big data commerce. 


>> Tokens are: 
 ['Big', 'data', 'commerce', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'commerce'), ('commerce', '.')]

>> Trigrams are: 
 [('Big', 'data', 'commerce'), ('data', 'commerce', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('commerce', 'NN'), ('.', '.')]

 (S (NP Big/NNP data/NNS commerce/NN) ./.) 


>> Noun Phrases are: 
 ['Big data commerce']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('commerce', 'commerc'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('commerce', 'commerc'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('commerce', 'commerce'), ('.', '.')]



============================ Sentence 689 =============================

Inf Manag. 


>> Tokens are: 
 ['Inf', 'Manag', '.']

>> Bigrams are: 
 [('Inf', 'Manag'), ('Manag', '.')]

>> Trigrams are: 
 [('Inf', 'Manag', '.')]

>> POS Tags are: 
 [('Inf', 'NNP'), ('Manag', 'NNP'), ('.', '.')]

 (S (NP Inf/NNP Manag/NNP) ./.) 


>> Noun Phrases are: 
 ['Inf Manag']

>> Named Entities are: 
 [('PERSON', 'Inf'), ('ORGANIZATION', 'Manag')] 

>> Stemming using Porter Stemmer: 
 [('Inf', 'inf'), ('Manag', 'manag'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Inf', 'inf'), ('Manag', 'manag'), ('.', '.')]

>> Lemmatization: 
 [('Inf', 'Inf'), ('Manag', 'Manag'), ('.', '.')]



============================ Sentence 690 =============================

Journal. 


>> Tokens are: 
 ['Journal', '.']

>> Bigrams are: 
 [('Journal', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Journal', 'NNP'), ('.', '.')]

 (S (NP Journal/NNP) ./.) 


>> Noun Phrases are: 
 ['Journal']

>> Named Entities are: 
 [('GPE', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('.', '.')]



============================ Sentence 691 =============================

Chen, C.P and Zhang, Chun-Yang, 2014. 


>> Tokens are: 
 ['Chen', ',', 'C.P', 'Zhang', ',', 'Chun-Yang', ',', '2014', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'C.P'), ('C.P', 'Zhang'), ('Zhang', ','), (',', 'Chun-Yang'), ('Chun-Yang', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Chen', ',', 'C.P'), (',', 'C.P', 'Zhang'), ('C.P', 'Zhang', ','), ('Zhang', ',', 'Chun-Yang'), (',', 'Chun-Yang', ','), ('Chun-Yang', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('C.P', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('Chun-Yang', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Chen/NNP)
  ,/,
  (NP C.P/NNP Zhang/NNP)
  ,/,
  (NP Chun-Yang/NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Chen', 'C.P Zhang', 'Chun-Yang']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Zhang'), ('PERSON', 'Chun-Yang')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('C.P', 'c.p'), ('Zhang', 'zhang'), (',', ','), ('Chun-Yang', 'chun-yang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('C.P', 'c.p'), ('Zhang', 'zhang'), (',', ','), ('Chun-Yang', 'chun-yang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('C.P', 'C.P'), ('Zhang', 'Zhang'), (',', ','), ('Chun-Yang', 'Chun-Yang'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 692 =============================

Data-intensive applications, challenges, techniques and   technologies: A survey on Big Data. 


>> Tokens are: 
 ['Data-intensive', 'applications', ',', 'challenges', ',', 'techniques', 'technologies', ':', 'A', 'survey', 'Big', 'Data', '.']

>> Bigrams are: 
 [('Data-intensive', 'applications'), ('applications', ','), (',', 'challenges'), ('challenges', ','), (',', 'techniques'), ('techniques', 'technologies'), ('technologies', ':'), (':', 'A'), ('A', 'survey'), ('survey', 'Big'), ('Big', 'Data'), ('Data', '.')]

>> Trigrams are: 
 [('Data-intensive', 'applications', ','), ('applications', ',', 'challenges'), (',', 'challenges', ','), ('challenges', ',', 'techniques'), (',', 'techniques', 'technologies'), ('techniques', 'technologies', ':'), ('technologies', ':', 'A'), (':', 'A', 'survey'), ('A', 'survey', 'Big'), ('survey', 'Big', 'Data'), ('Big', 'Data', '.')]

>> POS Tags are: 
 [('Data-intensive', 'JJ'), ('applications', 'NNS'), (',', ','), ('challenges', 'NNS'), (',', ','), ('techniques', 'NNS'), ('technologies', 'NNS'), (':', ':'), ('A', 'DT'), ('survey', 'NN'), ('Big', 'NNP'), ('Data', 'NNP'), ('.', '.')]

 (S
  (NP Data-intensive/JJ applications/NNS)
  ,/,
  (NP challenges/NNS)
  ,/,
  (NP techniques/NNS technologies/NNS)
  :/:
  (NP A/DT survey/NN Big/NNP Data/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Data-intensive applications', 'challenges', 'techniques technologies', 'A survey Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Data-intensive', 'data-intens'), ('applications', 'applic'), (',', ','), ('challenges', 'challeng'), (',', ','), ('techniques', 'techniqu'), ('technologies', 'technolog'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data-intensive', 'data-intens'), ('applications', 'applic'), (',', ','), ('challenges', 'challeng'), (',', ','), ('techniques', 'techniqu'), ('technologies', 'technolog'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Data-intensive', 'Data-intensive'), ('applications', 'application'), (',', ','), ('challenges', 'challenge'), (',', ','), ('techniques', 'technique'), ('technologies', 'technology'), (':', ':'), ('A', 'A'), ('survey', 'survey'), ('Big', 'Big'), ('Data', 'Data'), ('.', '.')]



============================ Sentence 693 =============================

Information sciences Journal, Volume 275, p. 314–347. 


>> Tokens are: 
 ['Information', 'sciences', 'Journal', ',', 'Volume', '275', ',', 'p.', '314–347', '.']

>> Bigrams are: 
 [('Information', 'sciences'), ('sciences', 'Journal'), ('Journal', ','), (',', 'Volume'), ('Volume', '275'), ('275', ','), (',', 'p.'), ('p.', '314–347'), ('314–347', '.')]

>> Trigrams are: 
 [('Information', 'sciences', 'Journal'), ('sciences', 'Journal', ','), ('Journal', ',', 'Volume'), (',', 'Volume', '275'), ('Volume', '275', ','), ('275', ',', 'p.'), (',', 'p.', '314–347'), ('p.', '314–347', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('sciences', 'NNS'), ('Journal', 'NNP'), (',', ','), ('Volume', 'NN'), ('275', 'CD'), (',', ','), ('p.', 'RB'), ('314–347', 'CD'), ('.', '.')]

 (S
  (NP Information/NN sciences/NNS Journal/NNP)
  ,/,
  (NP Volume/NN)
  275/CD
  ,/,
  p./RB
  314–347/CD
  ./.) 


>> Noun Phrases are: 
 ['Information sciences Journal', 'Volume']

>> Named Entities are: 
 [('GPE', 'Information'), ('ORGANIZATION', 'Volume 275')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('sciences', 'scienc'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('275', '275'), (',', ','), ('p.', 'p.'), ('314–347', '314–347'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('sciences', 'scienc'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('275', '275'), (',', ','), ('p.', 'p.'), ('314–347', '314–347'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('sciences', 'science'), ('Journal', 'Journal'), (',', ','), ('Volume', 'Volume'), ('275', '275'), (',', ','), ('p.', 'p.'), ('314–347', '314–347'), ('.', '.')]



============================ Sentence 694 =============================

Chen, H., Chiang, R.H. and Storey, V.C., 2012. Business intelligence and analytics: from big data   to big impact.. MIS quarterly, pp. 


>> Tokens are: 
 ['Chen', ',', 'H.', ',', 'Chiang', ',', 'R.H.', 'Storey', ',', 'V.C.', ',', '2012.', 'Business', 'intelligence', 'analytics', ':', 'big', 'data', 'big', 'impact', '..', 'MIS', 'quarterly', ',', 'pp', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'H.'), ('H.', ','), (',', 'Chiang'), ('Chiang', ','), (',', 'R.H.'), ('R.H.', 'Storey'), ('Storey', ','), (',', 'V.C.'), ('V.C.', ','), (',', '2012.'), ('2012.', 'Business'), ('Business', 'intelligence'), ('intelligence', 'analytics'), ('analytics', ':'), (':', 'big'), ('big', 'data'), ('data', 'big'), ('big', 'impact'), ('impact', '..'), ('..', 'MIS'), ('MIS', 'quarterly'), ('quarterly', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Chen', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Chiang'), (',', 'Chiang', ','), ('Chiang', ',', 'R.H.'), (',', 'R.H.', 'Storey'), ('R.H.', 'Storey', ','), ('Storey', ',', 'V.C.'), (',', 'V.C.', ','), ('V.C.', ',', '2012.'), (',', '2012.', 'Business'), ('2012.', 'Business', 'intelligence'), ('Business', 'intelligence', 'analytics'), ('intelligence', 'analytics', ':'), ('analytics', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'big'), ('data', 'big', 'impact'), ('big', 'impact', '..'), ('impact', '..', 'MIS'), ('..', 'MIS', 'quarterly'), ('MIS', 'quarterly', ','), ('quarterly', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Chiang', 'NNP'), (',', ','), ('R.H.', 'NNP'), ('Storey', 'NNP'), (',', ','), ('V.C.', 'NNP'), (',', ','), ('2012.', 'CD'), ('Business', 'NNP'), ('intelligence', 'NN'), ('analytics', 'NNS'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('big', 'JJ'), ('impact', 'NN'), ('..', 'NNP'), ('MIS', 'NNP'), ('quarterly', 'RB'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Chen/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Chiang/NNP)
  ,/,
  (NP R.H./NNP Storey/NNP)
  ,/,
  (NP V.C./NNP)
  ,/,
  2012./CD
  (NP Business/NNP intelligence/NN analytics/NNS)
  :/:
  (NP big/JJ data/NNS)
  (NP big/JJ impact/NN ../NNP MIS/NNP)
  quarterly/RB
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Chen', 'H.', 'Chiang', 'R.H. Storey', 'V.C.', 'Business intelligence analytics', 'big data', 'big impact .. MIS', 'pp']

>> Named Entities are: 
 [('GPE', 'Chen'), ('GPE', 'Chiang')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('H.', 'h.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), ('Storey', 'storey'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2012.', '2012.'), ('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (':', ':'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('impact', 'impact'), ('..', '..'), ('MIS', 'mi'), ('quarterly', 'quarterli'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('H.', 'h.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), ('Storey', 'storey'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2012.', '2012.'), ('Business', 'busi'), ('intelligence', 'intellig'), ('analytics', 'analyt'), (':', ':'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('impact', 'impact'), ('..', '..'), ('MIS', 'mis'), ('quarterly', 'quarter'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('H.', 'H.'), (',', ','), ('Chiang', 'Chiang'), (',', ','), ('R.H.', 'R.H.'), ('Storey', 'Storey'), (',', ','), ('V.C.', 'V.C.'), (',', ','), ('2012.', '2012.'), ('Business', 'Business'), ('intelligence', 'intelligence'), ('analytics', 'analytics'), (':', ':'), ('big', 'big'), ('data', 'data'), ('big', 'big'), ('impact', 'impact'), ('..', '..'), ('MIS', 'MIS'), ('quarterly', 'quarterly'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 695 =============================

1165-1188. 


>> Tokens are: 
 ['1165-1188', '.']

>> Bigrams are: 
 [('1165-1188', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1165-1188', 'JJ'), ('.', '.')]

 (S 1165-1188/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1165-1188', '1165-1188'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1165-1188', '1165-1188'), ('.', '.')]

>> Lemmatization: 
 [('1165-1188', '1165-1188'), ('.', '.')]



============================ Sentence 696 =============================

Chen, M., Mao, S. and Liu, Y., 2014. 


>> Tokens are: 
 ['Chen', ',', 'M.', ',', 'Mao', ',', 'S.', 'Liu', ',', 'Y.', ',', '2014', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', 'Liu'), ('S.', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Mao/NNP)
  ,/,
  (NP S./NNP Liu/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Chen', 'M.', 'Mao', 'S. Liu', 'Y.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 697 =============================

Big data: A survey.. Journal of mobile networks and   applications, Volume 19, pp. 


>> Tokens are: 
 ['Big', 'data', ':', 'A', 'survey', '..', 'Journal', 'mobile', 'networks', 'applications', ',', 'Volume', '19', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'A'), ('A', 'survey'), ('survey', '..'), ('..', 'Journal'), ('Journal', 'mobile'), ('mobile', 'networks'), ('networks', 'applications'), ('applications', ','), (',', 'Volume'), ('Volume', '19'), ('19', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'A'), (':', 'A', 'survey'), ('A', 'survey', '..'), ('survey', '..', 'Journal'), ('..', 'Journal', 'mobile'), ('Journal', 'mobile', 'networks'), ('mobile', 'networks', 'applications'), ('networks', 'applications', ','), ('applications', ',', 'Volume'), (',', 'Volume', '19'), ('Volume', '19', ','), ('19', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('A', 'DT'), ('survey', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('mobile', 'NN'), ('networks', 'NNS'), ('applications', 'NNS'), (',', ','), ('Volume', 'NN'), ('19', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  (NP
    A/DT
    survey/NN
    ../NNP
    Journal/NNP
    mobile/NN
    networks/NNS
    applications/NNS)
  ,/,
  (NP Volume/NN)
  19/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'A survey .. Journal mobile networks applications', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 19')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('mobile', 'mobil'), ('networks', 'network'), ('applications', 'applic'), (',', ','), ('Volume', 'volum'), ('19', '19'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('mobile', 'mobil'), ('networks', 'network'), ('applications', 'applic'), (',', ','), ('Volume', 'volum'), ('19', '19'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('A', 'A'), ('survey', 'survey'), ('..', '..'), ('Journal', 'Journal'), ('mobile', 'mobile'), ('networks', 'network'), ('applications', 'application'), (',', ','), ('Volume', 'Volume'), ('19', '19'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 698 =============================

171-209. 


>> Tokens are: 
 ['171-209', '.']

>> Bigrams are: 
 [('171-209', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('171-209', 'JJ'), ('.', '.')]

 (S 171-209/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('171-209', '171-209'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('171-209', '171-209'), ('.', '.')]

>> Lemmatization: 
 [('171-209', '171-209'), ('.', '.')]



============================ Sentence 699 =============================

Chen, M., Mao, S., Zhang, Y. and Leung, V.C., 2014. 


>> Tokens are: 
 ['Chen', ',', 'M.', ',', 'Mao', ',', 'S.', ',', 'Zhang', ',', 'Y.', 'Leung', ',', 'V.C.', ',', '2014', '.']

>> Bigrams are: 
 [('Chen', ','), (',', 'M.'), ('M.', ','), (',', 'Mao'), ('Mao', ','), (',', 'S.'), ('S.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'Y.'), ('Y.', 'Leung'), ('Leung', ','), (',', 'V.C.'), ('V.C.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Chen', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Mao'), (',', 'Mao', ','), ('Mao', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'Y.'), (',', 'Y.', 'Leung'), ('Y.', 'Leung', ','), ('Leung', ',', 'V.C.'), (',', 'V.C.', ','), ('V.C.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Chen', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Mao', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Leung', 'NNP'), (',', ','), ('V.C.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Chen/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Mao/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Zhang/NNP)
  ,/,
  (NP Y./NNP Leung/NNP)
  ,/,
  (NP V.C./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Chen', 'M.', 'Mao', 'S.', 'Zhang', 'Y. Leung', 'V.C.']

>> Named Entities are: 
 [('GPE', 'Chen'), ('PERSON', 'Mao'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), ('Leung', 'leung'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Chen', 'chen'), (',', ','), ('M.', 'm.'), (',', ','), ('Mao', 'mao'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), ('Leung', 'leung'), (',', ','), ('V.C.', 'v.c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Chen', 'Chen'), (',', ','), ('M.', 'M.'), (',', ','), ('Mao', 'Mao'), (',', ','), ('S.', 'S.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('Y.', 'Y.'), ('Leung', 'Leung'), (',', ','), ('V.C.', 'V.C.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 700 =============================

Big data: related technologies, challenges   and future prospects. 


>> Tokens are: 
 ['Big', 'data', ':', 'related', 'technologies', ',', 'challenges', 'future', 'prospects', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'related'), ('related', 'technologies'), ('technologies', ','), (',', 'challenges'), ('challenges', 'future'), ('future', 'prospects'), ('prospects', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'related'), (':', 'related', 'technologies'), ('related', 'technologies', ','), ('technologies', ',', 'challenges'), (',', 'challenges', 'future'), ('challenges', 'future', 'prospects'), ('future', 'prospects', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('related', 'JJ'), ('technologies', 'NNS'), (',', ','), ('challenges', 'NNS'), ('future', 'VBP'), ('prospects', 'NNS'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  (NP related/JJ technologies/NNS)
  ,/,
  (NP challenges/NNS)
  future/VBP
  (NP prospects/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'related technologies', 'challenges', 'prospects']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('related', 'relat'), ('technologies', 'technolog'), (',', ','), ('challenges', 'challeng'), ('future', 'futur'), ('prospects', 'prospect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('related', 'relat'), ('technologies', 'technolog'), (',', ','), ('challenges', 'challeng'), ('future', 'futur'), ('prospects', 'prospect'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('related', 'related'), ('technologies', 'technology'), (',', ','), ('challenges', 'challenge'), ('future', 'future'), ('prospects', 'prospect'), ('.', '.')]



============================ Sentence 701 =============================

s.l.:Springer. 


>> Tokens are: 
 ['s.l', '.', ':', 'Springer', '.']

>> Bigrams are: 
 [('s.l', '.'), ('.', ':'), (':', 'Springer'), ('Springer', '.')]

>> Trigrams are: 
 [('s.l', '.', ':'), ('.', ':', 'Springer'), (':', 'Springer', '.')]

>> POS Tags are: 
 [('s.l', 'NN'), ('.', '.'), (':', ':'), ('Springer', 'NN'), ('.', '.')]

 (S (NP s.l/NN) ./. :/: (NP Springer/NN) ./.) 


>> Noun Phrases are: 
 ['s.l', 'Springer']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l', 's.l'), ('.', '.'), (':', ':'), ('Springer', 'springer'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l', 's.l'), ('.', '.'), (':', ':'), ('Springer', 'springer'), ('.', '.')]

>> Lemmatization: 
 [('s.l', 's.l'), ('.', '.'), (':', ':'), ('Springer', 'Springer'), ('.', '.')]



============================ Sentence 702 =============================

Cheon, J. and Choe, T.Y., 2013. 


>> Tokens are: 
 ['Cheon', ',', 'J.', 'Choe', ',', 'T.Y.', ',', '2013', '.']

>> Bigrams are: 
 [('Cheon', ','), (',', 'J.'), ('J.', 'Choe'), ('Choe', ','), (',', 'T.Y.'), ('T.Y.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Cheon', ',', 'J.'), (',', 'J.', 'Choe'), ('J.', 'Choe', ','), ('Choe', ',', 'T.Y.'), (',', 'T.Y.', ','), ('T.Y.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Cheon', 'NNP'), (',', ','), ('J.', 'NNP'), ('Choe', 'NNP'), (',', ','), ('T.Y.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Cheon/NNP)
  ,/,
  (NP J./NNP Choe/NNP)
  ,/,
  (NP T.Y./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Cheon', 'J. Choe', 'T.Y.']

>> Named Entities are: 
 [('GPE', 'Cheon'), ('PERSON', 'J. Choe')] 

>> Stemming using Porter Stemmer: 
 [('Cheon', 'cheon'), (',', ','), ('J.', 'j.'), ('Choe', 'choe'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cheon', 'cheon'), (',', ','), ('J.', 'j.'), ('Choe', 'choe'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Cheon', 'Cheon'), (',', ','), ('J.', 'J.'), ('Choe', 'Choe'), (',', ','), ('T.Y.', 'T.Y.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 703 =============================

Distributed processing of snort alert log using hadoop..   International Journal of Engineering and Technology IJET, Volume 5, pp. 


>> Tokens are: 
 ['Distributed', 'processing', 'snort', 'alert', 'log', 'using', 'hadoop', '..', 'International', 'Journal', 'Engineering', 'Technology', 'IJET', ',', 'Volume', '5', ',', 'pp', '.']

>> Bigrams are: 
 [('Distributed', 'processing'), ('processing', 'snort'), ('snort', 'alert'), ('alert', 'log'), ('log', 'using'), ('using', 'hadoop'), ('hadoop', '..'), ('..', 'International'), ('International', 'Journal'), ('Journal', 'Engineering'), ('Engineering', 'Technology'), ('Technology', 'IJET'), ('IJET', ','), (',', 'Volume'), ('Volume', '5'), ('5', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Distributed', 'processing', 'snort'), ('processing', 'snort', 'alert'), ('snort', 'alert', 'log'), ('alert', 'log', 'using'), ('log', 'using', 'hadoop'), ('using', 'hadoop', '..'), ('hadoop', '..', 'International'), ('..', 'International', 'Journal'), ('International', 'Journal', 'Engineering'), ('Journal', 'Engineering', 'Technology'), ('Engineering', 'Technology', 'IJET'), ('Technology', 'IJET', ','), ('IJET', ',', 'Volume'), (',', 'Volume', '5'), ('Volume', '5', ','), ('5', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Distributed', 'VBN'), ('processing', 'VBG'), ('snort', 'NN'), ('alert', 'NN'), ('log', 'NN'), ('using', 'VBG'), ('hadoop', 'NN'), ('..', 'NNP'), ('International', 'NNP'), ('Journal', 'NNP'), ('Engineering', 'NNP'), ('Technology', 'NNP'), ('IJET', 'NNP'), (',', ','), ('Volume', 'NN'), ('5', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  Distributed/VBN
  processing/VBG
  (NP snort/NN alert/NN log/NN)
  using/VBG
  (NP
    hadoop/NN
    ../NNP
    International/NNP
    Journal/NNP
    Engineering/NNP
    Technology/NNP
    IJET/NNP)
  ,/,
  (NP Volume/NN)
  5/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['snort alert log', 'hadoop .. International Journal Engineering Technology IJET', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('Distributed', 'distribut'), ('processing', 'process'), ('snort', 'snort'), ('alert', 'alert'), ('log', 'log'), ('using', 'use'), ('hadoop', 'hadoop'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Engineering', 'engin'), ('Technology', 'technolog'), ('IJET', 'ijet'), (',', ','), ('Volume', 'volum'), ('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Distributed', 'distribut'), ('processing', 'process'), ('snort', 'snort'), ('alert', 'alert'), ('log', 'log'), ('using', 'use'), ('hadoop', 'hadoop'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Engineering', 'engin'), ('Technology', 'technolog'), ('IJET', 'ijet'), (',', ','), ('Volume', 'volum'), ('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Distributed', 'Distributed'), ('processing', 'processing'), ('snort', 'snort'), ('alert', 'alert'), ('log', 'log'), ('using', 'using'), ('hadoop', 'hadoop'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal'), ('Engineering', 'Engineering'), ('Technology', 'Technology'), ('IJET', 'IJET'), (',', ','), ('Volume', 'Volume'), ('5', '5'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 704 =============================

2685-2690. 


>> Tokens are: 
 ['2685-2690', '.']

>> Bigrams are: 
 [('2685-2690', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2685-2690', 'JJ'), ('.', '.')]

 (S 2685-2690/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2685-2690', '2685-2690'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2685-2690', '2685-2690'), ('.', '.')]

>> Lemmatization: 
 [('2685-2690', '2685-2690'), ('.', '.')]



============================ Sentence 705 =============================

Clarke, R., 2016. 


>> Tokens are: 
 ['Clarke', ',', 'R.', ',', '2016', '.']

>> Bigrams are: 
 [('Clarke', ','), (',', 'R.'), ('R.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Clarke', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Clarke', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S (NP Clarke/NNP) ,/, (NP R./NNP) ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 ['Clarke', 'R.']

>> Named Entities are: 
 [('GPE', 'Clarke')] 

>> Stemming using Porter Stemmer: 
 [('Clarke', 'clark'), (',', ','), ('R.', 'r.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Clarke', 'clark'), (',', ','), ('R.', 'r.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Clarke', 'Clarke'), (',', ','), ('R.', 'R.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 706 =============================

Big data, big risks. 


>> Tokens are: 
 ['Big', 'data', ',', 'big', 'risks', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'big'), ('big', 'risks'), ('risks', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'big'), (',', 'big', 'risks'), ('big', 'risks', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('risks', 'NNS'), ('.', '.')]

 (S (NP Big/NNP data/NNS) ,/, (NP big/JJ risks/NNS) ./.) 


>> Noun Phrases are: 
 ['Big data', 'big risks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('risks', 'risk'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('risks', 'risk'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('big', 'big'), ('risks', 'risk'), ('.', '.')]



============================ Sentence 707 =============================

Information Systems Journal, Volume 26, pp. 


>> Tokens are: 
 ['Information', 'Systems', 'Journal', ',', 'Volume', '26', ',', 'pp', '.']

>> Bigrams are: 
 [('Information', 'Systems'), ('Systems', 'Journal'), ('Journal', ','), (',', 'Volume'), ('Volume', '26'), ('26', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Information', 'Systems', 'Journal'), ('Systems', 'Journal', ','), ('Journal', ',', 'Volume'), (',', 'Volume', '26'), ('Volume', '26', ','), ('26', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Information', 'NN'), ('Systems', 'NNP'), ('Journal', 'NNP'), (',', ','), ('Volume', 'NN'), ('26', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Information/NN Systems/NNP Journal/NNP)
  ,/,
  (NP Volume/NN)
  26/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Information Systems Journal', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Systems Journal'), ('ORGANIZATION', 'Volume 26')] 

>> Stemming using Porter Stemmer: 
 [('Information', 'inform'), ('Systems', 'system'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Information', 'inform'), ('Systems', 'system'), ('Journal', 'journal'), (',', ','), ('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Information', 'Information'), ('Systems', 'Systems'), ('Journal', 'Journal'), (',', ','), ('Volume', 'Volume'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 708 =============================

77-90. 


>> Tokens are: 
 ['77-90', '.']

>> Bigrams are: 
 [('77-90', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('77-90', 'JJ'), ('.', '.')]

 (S 77-90/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('77-90', '77-90'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('77-90', '77-90'), ('.', '.')]

>> Lemmatization: 
 [('77-90', '77-90'), ('.', '.')]



============================ Sentence 709 =============================

Constantiou, I.D. 


>> Tokens are: 
 ['Constantiou', ',', 'I.D', '.']

>> Bigrams are: 
 [('Constantiou', ','), (',', 'I.D'), ('I.D', '.')]

>> Trigrams are: 
 [('Constantiou', ',', 'I.D'), (',', 'I.D', '.')]

>> POS Tags are: 
 [('Constantiou', 'NNP'), (',', ','), ('I.D', 'NNP'), ('.', '.')]

 (S (NP Constantiou/NNP) ,/, (NP I.D/NNP) ./.) 


>> Noun Phrases are: 
 ['Constantiou', 'I.D']

>> Named Entities are: 
 [('GSP', 'Constantiou')] 

>> Stemming using Porter Stemmer: 
 [('Constantiou', 'constanti'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Constantiou', 'constantiou'), (',', ','), ('I.D', 'i.d'), ('.', '.')]

>> Lemmatization: 
 [('Constantiou', 'Constantiou'), (',', ','), ('I.D', 'I.D'), ('.', '.')]



============================ Sentence 710 =============================

and Kallinikos, J., 2015. 


>> Tokens are: 
 ['Kallinikos', ',', 'J.', ',', '2015', '.']

>> Bigrams are: 
 [('Kallinikos', ','), (',', 'J.'), ('J.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Kallinikos', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Kallinikos', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S (NP Kallinikos/NNP) ,/, (NP J./NNP) ,/, 2015/CD ./.) 


>> Noun Phrases are: 
 ['Kallinikos', 'J.']

>> Named Entities are: 
 [('GPE', 'Kallinikos')] 

>> Stemming using Porter Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kallinikos', 'kalliniko'), (',', ','), ('J.', 'j.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Kallinikos', 'Kallinikos'), (',', ','), ('J.', 'J.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 711 =============================

New games, new rules: big data and the changing   context of strategy. 


>> Tokens are: 
 ['New', 'games', ',', 'new', 'rules', ':', 'big', 'data', 'changing', 'context', 'strategy', '.']

>> Bigrams are: 
 [('New', 'games'), ('games', ','), (',', 'new'), ('new', 'rules'), ('rules', ':'), (':', 'big'), ('big', 'data'), ('data', 'changing'), ('changing', 'context'), ('context', 'strategy'), ('strategy', '.')]

>> Trigrams are: 
 [('New', 'games', ','), ('games', ',', 'new'), (',', 'new', 'rules'), ('new', 'rules', ':'), ('rules', ':', 'big'), (':', 'big', 'data'), ('big', 'data', 'changing'), ('data', 'changing', 'context'), ('changing', 'context', 'strategy'), ('context', 'strategy', '.')]

>> POS Tags are: 
 [('New', 'NNP'), ('games', 'NNS'), (',', ','), ('new', 'JJ'), ('rules', 'NNS'), (':', ':'), ('big', 'JJ'), ('data', 'NNS'), ('changing', 'VBG'), ('context', 'NN'), ('strategy', 'NN'), ('.', '.')]

 (S
  (NP New/NNP games/NNS)
  ,/,
  (NP new/JJ rules/NNS)
  :/:
  (NP big/JJ data/NNS)
  changing/VBG
  (NP context/NN strategy/NN)
  ./.) 


>> Noun Phrases are: 
 ['New games', 'new rules', 'big data', 'context strategy']

>> Named Entities are: 
 [('GPE', 'New')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('games', 'game'), (',', ','), ('new', 'new'), ('rules', 'rule'), (':', ':'), ('big', 'big'), ('data', 'data'), ('changing', 'chang'), ('context', 'context'), ('strategy', 'strategi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('games', 'game'), (',', ','), ('new', 'new'), ('rules', 'rule'), (':', ':'), ('big', 'big'), ('data', 'data'), ('changing', 'chang'), ('context', 'context'), ('strategy', 'strategi'), ('.', '.')]

>> Lemmatization: 
 [('New', 'New'), ('games', 'game'), (',', ','), ('new', 'new'), ('rules', 'rule'), (':', ':'), ('big', 'big'), ('data', 'data'), ('changing', 'changing'), ('context', 'context'), ('strategy', 'strategy'), ('.', '.')]



============================ Sentence 712 =============================

Journal of Information Technology, Volume 30, pp. 


>> Tokens are: 
 ['Journal', 'Information', 'Technology', ',', 'Volume', '30', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Information'), ('Information', 'Technology'), ('Technology', ','), (',', 'Volume'), ('Volume', '30'), ('30', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Information', 'Technology'), ('Information', 'Technology', ','), ('Technology', ',', 'Volume'), (',', 'Volume', '30'), ('Volume', '30', ','), ('30', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Volume', 'NN'), ('30', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Journal/NNP Information/NNP Technology/NNP)
  ,/,
  (NP Volume/NN)
  30/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Journal Information Technology', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Information Technology'), ('ORGANIZATION', 'Volume 30')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('Volume', 'Volume'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 713 =============================

44-57. 


>> Tokens are: 
 ['44-57', '.']

>> Bigrams are: 
 [('44-57', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('44-57', 'JJ'), ('.', '.')]

 (S 44-57/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('44-57', '44-57'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('44-57', '44-57'), ('.', '.')]

>> Lemmatization: 
 [('44-57', '44-57'), ('.', '.')]



============================ Sentence 714 =============================

Cronin, P., Ryan, F. and Coughlan, M., 2008. 


>> Tokens are: 
 ['Cronin', ',', 'P.', ',', 'Ryan', ',', 'F.', 'Coughlan', ',', 'M.', ',', '2008', '.']

>> Bigrams are: 
 [('Cronin', ','), (',', 'P.'), ('P.', ','), (',', 'Ryan'), ('Ryan', ','), (',', 'F.'), ('F.', 'Coughlan'), ('Coughlan', ','), (',', 'M.'), ('M.', ','), (',', '2008'), ('2008', '.')]

>> Trigrams are: 
 [('Cronin', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Ryan'), (',', 'Ryan', ','), ('Ryan', ',', 'F.'), (',', 'F.', 'Coughlan'), ('F.', 'Coughlan', ','), ('Coughlan', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2008'), (',', '2008', '.')]

>> POS Tags are: 
 [('Cronin', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Ryan', 'NNP'), (',', ','), ('F.', 'NNP'), ('Coughlan', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2008', 'CD'), ('.', '.')]

 (S
  (NP Cronin/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  (NP Ryan/NNP)
  ,/,
  (NP F./NNP Coughlan/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2008/CD
  ./.) 


>> Noun Phrases are: 
 ['Cronin', 'P.', 'Ryan', 'F. Coughlan', 'M.']

>> Named Entities are: 
 [('GPE', 'Cronin'), ('PERSON', 'Ryan')] 

>> Stemming using Porter Stemmer: 
 [('Cronin', 'cronin'), (',', ','), ('P.', 'p.'), (',', ','), ('Ryan', 'ryan'), (',', ','), ('F.', 'f.'), ('Coughlan', 'coughlan'), (',', ','), ('M.', 'm.'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cronin', 'cronin'), (',', ','), ('P.', 'p.'), (',', ','), ('Ryan', 'ryan'), (',', ','), ('F.', 'f.'), ('Coughlan', 'coughlan'), (',', ','), ('M.', 'm.'), (',', ','), ('2008', '2008'), ('.', '.')]

>> Lemmatization: 
 [('Cronin', 'Cronin'), (',', ','), ('P.', 'P.'), (',', ','), ('Ryan', 'Ryan'), (',', ','), ('F.', 'F.'), ('Coughlan', 'Coughlan'), (',', ','), ('M.', 'M.'), (',', ','), ('2008', '2008'), ('.', '.')]



============================ Sentence 715 =============================

Undertaking a literature review: a step-by-step   approach.. British journal of nursing, pp. 


>> Tokens are: 
 ['Undertaking', 'literature', 'review', ':', 'step-by-step', 'approach', '..', 'British', 'journal', 'nursing', ',', 'pp', '.']

>> Bigrams are: 
 [('Undertaking', 'literature'), ('literature', 'review'), ('review', ':'), (':', 'step-by-step'), ('step-by-step', 'approach'), ('approach', '..'), ('..', 'British'), ('British', 'journal'), ('journal', 'nursing'), ('nursing', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Undertaking', 'literature', 'review'), ('literature', 'review', ':'), ('review', ':', 'step-by-step'), (':', 'step-by-step', 'approach'), ('step-by-step', 'approach', '..'), ('approach', '..', 'British'), ('..', 'British', 'journal'), ('British', 'journal', 'nursing'), ('journal', 'nursing', ','), ('nursing', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Undertaking', 'VBG'), ('literature', 'NN'), ('review', 'NN'), (':', ':'), ('step-by-step', 'JJ'), ('approach', 'NN'), ('..', 'JJ'), ('British', 'JJ'), ('journal', 'NN'), ('nursing', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  Undertaking/VBG
  (NP literature/NN review/NN)
  :/:
  (NP step-by-step/JJ approach/NN)
  (NP ../JJ British/JJ journal/NN nursing/NN)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['literature review', 'step-by-step approach', '.. British journal nursing', 'pp']

>> Named Entities are: 
 [('GPE', 'British')] 

>> Stemming using Porter Stemmer: 
 [('Undertaking', 'undertak'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('step-by-step', 'step-by-step'), ('approach', 'approach'), ('..', '..'), ('British', 'british'), ('journal', 'journal'), ('nursing', 'nurs'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Undertaking', 'undertak'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('step-by-step', 'step-by-step'), ('approach', 'approach'), ('..', '..'), ('British', 'british'), ('journal', 'journal'), ('nursing', 'nurs'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Undertaking', 'Undertaking'), ('literature', 'literature'), ('review', 'review'), (':', ':'), ('step-by-step', 'step-by-step'), ('approach', 'approach'), ('..', '..'), ('British', 'British'), ('journal', 'journal'), ('nursing', 'nursing'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 716 =============================

38-43. 


>> Tokens are: 
 ['38-43', '.']

>> Bigrams are: 
 [('38-43', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('38-43', 'JJ'), ('.', '.')]

 (S 38-43/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('38-43', '38-43'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('38-43', '38-43'), ('.', '.')]

>> Lemmatization: 
 [('38-43', '38-43'), ('.', '.')]



============================ Sentence 717 =============================

Cui, Q., Gong, Z., Ni, W., Hou, Y., Chen, X., Tao, X. and Zhang, P., 2019. 


>> Tokens are: 
 ['Cui', ',', 'Q.', ',', 'Gong', ',', 'Z.', ',', 'Ni', ',', 'W.', ',', 'Hou', ',', 'Y.', ',', 'Chen', ',', 'X.', ',', 'Tao', ',', 'X.', 'Zhang', ',', 'P.', ',', '2019', '.']

>> Bigrams are: 
 [('Cui', ','), (',', 'Q.'), ('Q.', ','), (',', 'Gong'), ('Gong', ','), (',', 'Z.'), ('Z.', ','), (',', 'Ni'), ('Ni', ','), (',', 'W.'), ('W.', ','), (',', 'Hou'), ('Hou', ','), (',', 'Y.'), ('Y.', ','), (',', 'Chen'), ('Chen', ','), (',', 'X.'), ('X.', ','), (',', 'Tao'), ('Tao', ','), (',', 'X.'), ('X.', 'Zhang'), ('Zhang', ','), (',', 'P.'), ('P.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Cui', ',', 'Q.'), (',', 'Q.', ','), ('Q.', ',', 'Gong'), (',', 'Gong', ','), ('Gong', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Ni'), (',', 'Ni', ','), ('Ni', ',', 'W.'), (',', 'W.', ','), ('W.', ',', 'Hou'), (',', 'Hou', ','), ('Hou', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Chen'), (',', 'Chen', ','), ('Chen', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Tao'), (',', 'Tao', ','), ('Tao', ',', 'X.'), (',', 'X.', 'Zhang'), ('X.', 'Zhang', ','), ('Zhang', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Cui', 'NNP'), (',', ','), ('Q.', 'NNP'), (',', ','), ('Gong', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Ni', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('Hou', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Chen', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Tao', 'NNP'), (',', ','), ('X.', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Cui/NNP)
  ,/,
  (NP Q./NNP)
  ,/,
  (NP Gong/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  (NP Ni/NNP)
  ,/,
  (NP W./NNP)
  ,/,
  (NP Hou/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Chen/NNP)
  ,/,
  (NP X./NNP)
  ,/,
  (NP Tao/NNP)
  ,/,
  (NP X./NNP Zhang/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Cui', 'Q.', 'Gong', 'Z.', 'Ni', 'W.', 'Hou', 'Y.', 'Chen', 'X.', 'Tao', 'X. Zhang', 'P.']

>> Named Entities are: 
 [('GPE', 'Cui'), ('GPE', 'Gong'), ('GPE', 'Ni'), ('PERSON', 'Hou'), ('GPE', 'Chen'), ('PERSON', 'Tao'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Cui', 'cui'), (',', ','), ('Q.', 'q.'), (',', ','), ('Gong', 'gong'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ni', 'ni'), (',', ','), ('W.', 'w.'), (',', ','), ('Hou', 'hou'), (',', ','), ('Y.', 'y.'), (',', ','), ('Chen', 'chen'), (',', ','), ('X.', 'x.'), (',', ','), ('Tao', 'tao'), (',', ','), ('X.', 'x.'), ('Zhang', 'zhang'), (',', ','), ('P.', 'p.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cui', 'cui'), (',', ','), ('Q.', 'q.'), (',', ','), ('Gong', 'gong'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ni', 'ni'), (',', ','), ('W.', 'w.'), (',', ','), ('Hou', 'hou'), (',', ','), ('Y.', 'y.'), (',', ','), ('Chen', 'chen'), (',', ','), ('X.', 'x.'), (',', ','), ('Tao', 'tao'), (',', ','), ('X.', 'x.'), ('Zhang', 'zhang'), (',', ','), ('P.', 'p.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Cui', 'Cui'), (',', ','), ('Q.', 'Q.'), (',', ','), ('Gong', 'Gong'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Ni', 'Ni'), (',', ','), ('W.', 'W.'), (',', ','), ('Hou', 'Hou'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Chen', 'Chen'), (',', ','), ('X.', 'X.'), (',', ','), ('Tao', 'Tao'), (',', ','), ('X.', 'X.'), ('Zhang', 'Zhang'), (',', ','), ('P.', 'P.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 718 =============================

Stochastic Online   Learning for Mobile Edge Computing: Learning from Changes.. IEEE Communications Magazine   journal, Volume 57, pp. 


>> Tokens are: 
 ['Stochastic', 'Online', 'Learning', 'Mobile', 'Edge', 'Computing', ':', 'Learning', 'Changes', '..', 'IEEE', 'Communications', 'Magazine', 'journal', ',', 'Volume', '57', ',', 'pp', '.']

>> Bigrams are: 
 [('Stochastic', 'Online'), ('Online', 'Learning'), ('Learning', 'Mobile'), ('Mobile', 'Edge'), ('Edge', 'Computing'), ('Computing', ':'), (':', 'Learning'), ('Learning', 'Changes'), ('Changes', '..'), ('..', 'IEEE'), ('IEEE', 'Communications'), ('Communications', 'Magazine'), ('Magazine', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '57'), ('57', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Stochastic', 'Online', 'Learning'), ('Online', 'Learning', 'Mobile'), ('Learning', 'Mobile', 'Edge'), ('Mobile', 'Edge', 'Computing'), ('Edge', 'Computing', ':'), ('Computing', ':', 'Learning'), (':', 'Learning', 'Changes'), ('Learning', 'Changes', '..'), ('Changes', '..', 'IEEE'), ('..', 'IEEE', 'Communications'), ('IEEE', 'Communications', 'Magazine'), ('Communications', 'Magazine', 'journal'), ('Magazine', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '57'), ('Volume', '57', ','), ('57', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Stochastic', 'JJ'), ('Online', 'NNP'), ('Learning', 'NNP'), ('Mobile', 'NNP'), ('Edge', 'NNP'), ('Computing', 'NNP'), (':', ':'), ('Learning', 'NNP'), ('Changes', 'NNP'), ('..', 'NNP'), ('IEEE', 'NNP'), ('Communications', 'NNP'), ('Magazine', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('57', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    Stochastic/JJ
    Online/NNP
    Learning/NNP
    Mobile/NNP
    Edge/NNP
    Computing/NNP)
  :/:
  (NP
    Learning/NNP
    Changes/NNP
    ../NNP
    IEEE/NNP
    Communications/NNP
    Magazine/NNP
    journal/NN)
  ,/,
  (NP Volume/NN)
  57/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Stochastic Online Learning Mobile Edge Computing', 'Learning Changes .. IEEE Communications Magazine journal', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Online Learning Mobile Edge'), ('ORGANIZATION', 'IEEE Communications Magazine'), ('ORGANIZATION', 'Volume 57')] 

>> Stemming using Porter Stemmer: 
 [('Stochastic', 'stochast'), ('Online', 'onlin'), ('Learning', 'learn'), ('Mobile', 'mobil'), ('Edge', 'edg'), ('Computing', 'comput'), (':', ':'), ('Learning', 'learn'), ('Changes', 'chang'), ('..', '..'), ('IEEE', 'ieee'), ('Communications', 'commun'), ('Magazine', 'magazin'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Stochastic', 'stochast'), ('Online', 'onlin'), ('Learning', 'learn'), ('Mobile', 'mobil'), ('Edge', 'edg'), ('Computing', 'comput'), (':', ':'), ('Learning', 'learn'), ('Changes', 'chang'), ('..', '..'), ('IEEE', 'ieee'), ('Communications', 'communic'), ('Magazine', 'magazin'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Stochastic', 'Stochastic'), ('Online', 'Online'), ('Learning', 'Learning'), ('Mobile', 'Mobile'), ('Edge', 'Edge'), ('Computing', 'Computing'), (':', ':'), ('Learning', 'Learning'), ('Changes', 'Changes'), ('..', '..'), ('IEEE', 'IEEE'), ('Communications', 'Communications'), ('Magazine', 'Magazine'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 719 =============================

63-69. 


>> Tokens are: 
 ['63-69', '.']

>> Bigrams are: 
 [('63-69', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('63-69', 'JJ'), ('.', '.')]

 (S 63-69/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('63-69', '63-69'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('63-69', '63-69'), ('.', '.')]

>> Lemmatization: 
 [('63-69', '63-69'), ('.', '.')]



============================ Sentence 720 =============================

Data, D.B., 2012. 


>> Tokens are: 
 ['Data', ',', 'D.B.', ',', '2012', '.']

>> Bigrams are: 
 [('Data', ','), (',', 'D.B.'), ('D.B.', ','), (',', '2012'), ('2012', '.')]

>> Trigrams are: 
 [('Data', ',', 'D.B.'), (',', 'D.B.', ','), ('D.B.', ',', '2012'), (',', '2012', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), (',', ','), ('D.B.', 'NNP'), (',', ','), ('2012', 'CD'), ('.', '.')]

 (S (NP Data/NNP) ,/, (NP D.B./NNP) ,/, 2012/CD ./.) 


>> Noun Phrases are: 
 ['Data', 'D.B.']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), (',', ','), ('D.B.', 'd.b.'), (',', ','), ('2012', '2012'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), (',', ','), ('D.B.', 'D.B.'), (',', ','), ('2012', '2012'), ('.', '.')]



============================ Sentence 721 =============================

A Practical Guide to Transforming the Business of Government.. TechAmerica   Foundation‟ s Federal Big Data Commission Journal. 


>> Tokens are: 
 ['A', 'Practical', 'Guide', 'Transforming', 'Business', 'Government', '..', 'TechAmerica', 'Foundation‟', 'Federal', 'Big', 'Data', 'Commission', 'Journal', '.']

>> Bigrams are: 
 [('A', 'Practical'), ('Practical', 'Guide'), ('Guide', 'Transforming'), ('Transforming', 'Business'), ('Business', 'Government'), ('Government', '..'), ('..', 'TechAmerica'), ('TechAmerica', 'Foundation‟'), ('Foundation‟', 'Federal'), ('Federal', 'Big'), ('Big', 'Data'), ('Data', 'Commission'), ('Commission', 'Journal'), ('Journal', '.')]

>> Trigrams are: 
 [('A', 'Practical', 'Guide'), ('Practical', 'Guide', 'Transforming'), ('Guide', 'Transforming', 'Business'), ('Transforming', 'Business', 'Government'), ('Business', 'Government', '..'), ('Government', '..', 'TechAmerica'), ('..', 'TechAmerica', 'Foundation‟'), ('TechAmerica', 'Foundation‟', 'Federal'), ('Foundation‟', 'Federal', 'Big'), ('Federal', 'Big', 'Data'), ('Big', 'Data', 'Commission'), ('Data', 'Commission', 'Journal'), ('Commission', 'Journal', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('Practical', 'NNP'), ('Guide', 'NNP'), ('Transforming', 'NNP'), ('Business', 'NNP'), ('Government', 'NNP'), ('..', 'NNP'), ('TechAmerica', 'NNP'), ('Foundation‟', 'NNP'), ('Federal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Commission', 'NNP'), ('Journal', 'NNP'), ('.', '.')]

 (S
  (NP
    A/DT
    Practical/NNP
    Guide/NNP
    Transforming/NNP
    Business/NNP
    Government/NNP
    ../NNP
    TechAmerica/NNP
    Foundation‟/NNP
    Federal/NNP
    Big/NNP
    Data/NNP
    Commission/NNP
    Journal/NNP)
  ./.) 


>> Noun Phrases are: 
 ['A Practical Guide Transforming Business Government .. TechAmerica Foundation‟ Federal Big Data Commission Journal']

>> Named Entities are: 
 [('ORGANIZATION', 'Practical Guide'), ('ORGANIZATION', 'TechAmerica')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Transforming', 'transform'), ('Business', 'busi'), ('Government', 'govern'), ('..', '..'), ('TechAmerica', 'techamerica'), ('Foundation‟', 'foundation‟'), ('Federal', 'feder'), ('Big', 'big'), ('Data', 'data'), ('Commission', 'commiss'), ('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('Practical', 'practic'), ('Guide', 'guid'), ('Transforming', 'transform'), ('Business', 'busi'), ('Government', 'govern'), ('..', '..'), ('TechAmerica', 'techamerica'), ('Foundation‟', 'foundation‟'), ('Federal', 'feder'), ('Big', 'big'), ('Data', 'data'), ('Commission', 'commiss'), ('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('Practical', 'Practical'), ('Guide', 'Guide'), ('Transforming', 'Transforming'), ('Business', 'Business'), ('Government', 'Government'), ('..', '..'), ('TechAmerica', 'TechAmerica'), ('Foundation‟', 'Foundation‟'), ('Federal', 'Federal'), ('Big', 'Big'), ('Data', 'Data'), ('Commission', 'Commission'), ('Journal', 'Journal'), ('.', '.')]



============================ Sentence 722 =============================

Davenport, T.H. 


>> Tokens are: 
 ['Davenport', ',', 'T.H', '.']

>> Bigrams are: 
 [('Davenport', ','), (',', 'T.H'), ('T.H', '.')]

>> Trigrams are: 
 [('Davenport', ',', 'T.H'), (',', 'T.H', '.')]

>> POS Tags are: 
 [('Davenport', 'NNP'), (',', ','), ('T.H', 'NNP'), ('.', '.')]

 (S (NP Davenport/NNP) ,/, (NP T.H/NNP) ./.) 


>> Noun Phrases are: 
 ['Davenport', 'T.H']

>> Named Entities are: 
 [('GPE', 'Davenport')] 

>> Stemming using Porter Stemmer: 
 [('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Davenport', 'davenport'), (',', ','), ('T.H', 't.h'), ('.', '.')]

>> Lemmatization: 
 [('Davenport', 'Davenport'), (',', ','), ('T.H', 'T.H'), ('.', '.')]



============================ Sentence 723 =============================

and Dyché, J., 2013. 


>> Tokens are: 
 ['Dyché', ',', 'J.', ',', '2013', '.']

>> Bigrams are: 
 [('Dyché', ','), (',', 'J.'), ('J.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Dyché', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Dyché', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S (NP Dyché/NNP) ,/, (NP J./NNP) ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 ['Dyché', 'J.']

>> Named Entities are: 
 [('GPE', 'Dyché')] 

>> Stemming using Porter Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Dyché', 'dyché'), (',', ','), ('J.', 'j.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Dyché', 'Dyché'), (',', ','), ('J.', 'J.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 724 =============================

Big data in big companies. 


>> Tokens are: 
 ['Big', 'data', 'big', 'companies', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'big'), ('big', 'companies'), ('companies', '.')]

>> Trigrams are: 
 [('Big', 'data', 'big'), ('data', 'big', 'companies'), ('big', 'companies', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('big', 'JJ'), ('companies', 'NNS'), ('.', '.')]

 (S (NP Big/NNP data/NNS) (NP big/JJ companies/NNS) ./.) 


>> Noun Phrases are: 
 ['Big data', 'big companies']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('big', 'big'), ('companies', 'compani'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('big', 'big'), ('companies', 'compani'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('big', 'big'), ('companies', 'company'), ('.', '.')]



============================ Sentence 725 =============================

International Institute for   Analytics. 


>> Tokens are: 
 ['International', 'Institute', 'Analytics', '.']

>> Bigrams are: 
 [('International', 'Institute'), ('Institute', 'Analytics'), ('Analytics', '.')]

>> Trigrams are: 
 [('International', 'Institute', 'Analytics'), ('Institute', 'Analytics', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Institute', 'NNP'), ('Analytics', 'NNP'), ('.', '.')]

 (S (NP International/NNP Institute/NNP Analytics/NNP) ./.) 


>> Noun Phrases are: 
 ['International Institute Analytics']

>> Named Entities are: 
 [('ORGANIZATION', 'International'), ('PERSON', 'Institute Analytics')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Institute', 'institut'), ('Analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Institute', 'institut'), ('Analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Institute', 'Institute'), ('Analytics', 'Analytics'), ('.', '.')]



============================ Sentence 726 =============================

Di Martino, B., Aversa, R., Cretella, G., Esposito, A. and Kołodziej, J., 2014. 


>> Tokens are: 
 ['Di', 'Martino', ',', 'B.', ',', 'Aversa', ',', 'R.', ',', 'Cretella', ',', 'G.', ',', 'Esposito', ',', 'A.', 'Kołodziej', ',', 'J.', ',', '2014', '.']

>> Bigrams are: 
 [('Di', 'Martino'), ('Martino', ','), (',', 'B.'), ('B.', ','), (',', 'Aversa'), ('Aversa', ','), (',', 'R.'), ('R.', ','), (',', 'Cretella'), ('Cretella', ','), (',', 'G.'), ('G.', ','), (',', 'Esposito'), ('Esposito', ','), (',', 'A.'), ('A.', 'Kołodziej'), ('Kołodziej', ','), (',', 'J.'), ('J.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Di', 'Martino', ','), ('Martino', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Aversa'), (',', 'Aversa', ','), ('Aversa', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Cretella'), (',', 'Cretella', ','), ('Cretella', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Esposito'), (',', 'Esposito', ','), ('Esposito', ',', 'A.'), (',', 'A.', 'Kołodziej'), ('A.', 'Kołodziej', ','), ('Kołodziej', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Di', 'NNP'), ('Martino', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Aversa', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Cretella', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Esposito', 'NNP'), (',', ','), ('A.', 'NNP'), ('Kołodziej', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Di/NNP Martino/NNP)
  ,/,
  (NP B./NNP)
  ,/,
  (NP Aversa/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Cretella/NNP)
  ,/,
  (NP G./NNP)
  ,/,
  (NP Esposito/NNP)
  ,/,
  (NP A./NNP Kołodziej/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Di Martino', 'B.', 'Aversa', 'R.', 'Cretella', 'G.', 'Esposito', 'A. Kołodziej', 'J.']

>> Named Entities are: 
 [('PERSON', 'Martino'), ('GPE', 'Aversa'), ('GPE', 'Cretella'), ('GPE', 'Esposito')] 

>> Stemming using Porter Stemmer: 
 [('Di', 'di'), ('Martino', 'martino'), (',', ','), ('B.', 'b.'), (',', ','), ('Aversa', 'aversa'), (',', ','), ('R.', 'r.'), (',', ','), ('Cretella', 'cretella'), (',', ','), ('G.', 'g.'), (',', ','), ('Esposito', 'esposito'), (',', ','), ('A.', 'a.'), ('Kołodziej', 'kołodziej'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Di', 'di'), ('Martino', 'martino'), (',', ','), ('B.', 'b.'), (',', ','), ('Aversa', 'aversa'), (',', ','), ('R.', 'r.'), (',', ','), ('Cretella', 'cretella'), (',', ','), ('G.', 'g.'), (',', ','), ('Esposito', 'esposito'), (',', ','), ('A.', 'a.'), ('Kołodziej', 'kołodziej'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Di', 'Di'), ('Martino', 'Martino'), (',', ','), ('B.', 'B.'), (',', ','), ('Aversa', 'Aversa'), (',', ','), ('R.', 'R.'), (',', ','), ('Cretella', 'Cretella'), (',', ','), ('G.', 'G.'), (',', ','), ('Esposito', 'Esposito'), (',', ','), ('A.', 'A.'), ('Kołodziej', 'Kołodziej'), (',', ','), ('J.', 'J.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 727 =============================

Big data (lost) in the   cloud.. International Journal of Big Data Intelligence, Volume 1, pp. 


>> Tokens are: 
 ['Big', 'data', '(', 'lost', ')', 'cloud', '..', 'International', 'Journal', 'Big', 'Data', 'Intelligence', ',', 'Volume', '1', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', '('), ('(', 'lost'), ('lost', ')'), (')', 'cloud'), ('cloud', '..'), ('..', 'International'), ('International', 'Journal'), ('Journal', 'Big'), ('Big', 'Data'), ('Data', 'Intelligence'), ('Intelligence', ','), (',', 'Volume'), ('Volume', '1'), ('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'data', '('), ('data', '(', 'lost'), ('(', 'lost', ')'), ('lost', ')', 'cloud'), (')', 'cloud', '..'), ('cloud', '..', 'International'), ('..', 'International', 'Journal'), ('International', 'Journal', 'Big'), ('Journal', 'Big', 'Data'), ('Big', 'Data', 'Intelligence'), ('Data', 'Intelligence', ','), ('Intelligence', ',', 'Volume'), (',', 'Volume', '1'), ('Volume', '1', ','), ('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), ('(', '('), ('lost', 'VBN'), (')', ')'), ('cloud', 'NN'), ('..', 'JJ'), ('International', 'NNP'), ('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Intelligence', 'NNP'), (',', ','), ('Volume', 'NN'), ('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  (/(
  lost/VBN
  )/)
  (NP cloud/NN)
  (NP
    ../JJ
    International/NNP
    Journal/NNP
    Big/NNP
    Data/NNP
    Intelligence/NNP)
  ,/,
  (NP Volume/NN)
  1/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'cloud', '.. International Journal Big Data Intelligence', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal'), ('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('(', '('), ('lost', 'lost'), (')', ')'), ('cloud', 'cloud'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('Intelligence', 'intellig'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('(', '('), ('lost', 'lost'), (')', ')'), ('cloud', 'cloud'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), ('Intelligence', 'intellig'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('(', '('), ('lost', 'lost'), (')', ')'), ('cloud', 'cloud'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), ('Intelligence', 'Intelligence'), (',', ','), ('Volume', 'Volume'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 728 =============================

3-17. 


>> Tokens are: 
 ['3-17', '.']

>> Bigrams are: 
 [('3-17', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3-17', 'JJ'), ('.', '.')]

 (S 3-17/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-17', '3-17'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-17', '3-17'), ('.', '.')]

>> Lemmatization: 
 [('3-17', '3-17'), ('.', '.')]



============================ Sentence 729 =============================

Sarah Al-Shiakhli   49      Ekbia, H., Mattioli, M., Kouper, I., Arave, G., Ghazinejad, A., Bowman, T., Suri, V.R., Tsou, A.,   Weingart, S. and Sugimoto, C.R., 2015. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '49', 'Ekbia', ',', 'H.', ',', 'Mattioli', ',', 'M.', ',', 'Kouper', ',', 'I.', ',', 'Arave', ',', 'G.', ',', 'Ghazinejad', ',', 'A.', ',', 'Bowman', ',', 'T.', ',', 'Suri', ',', 'V.R.', ',', 'Tsou', ',', 'A.', ',', 'Weingart', ',', 'S.', 'Sugimoto', ',', 'C.R.', ',', '2015', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '49'), ('49', 'Ekbia'), ('Ekbia', ','), (',', 'H.'), ('H.', ','), (',', 'Mattioli'), ('Mattioli', ','), (',', 'M.'), ('M.', ','), (',', 'Kouper'), ('Kouper', ','), (',', 'I.'), ('I.', ','), (',', 'Arave'), ('Arave', ','), (',', 'G.'), ('G.', ','), (',', 'Ghazinejad'), ('Ghazinejad', ','), (',', 'A.'), ('A.', ','), (',', 'Bowman'), ('Bowman', ','), (',', 'T.'), ('T.', ','), (',', 'Suri'), ('Suri', ','), (',', 'V.R.'), ('V.R.', ','), (',', 'Tsou'), ('Tsou', ','), (',', 'A.'), ('A.', ','), (',', 'Weingart'), ('Weingart', ','), (',', 'S.'), ('S.', 'Sugimoto'), ('Sugimoto', ','), (',', 'C.R.'), ('C.R.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '49'), ('Al-Shiakhli', '49', 'Ekbia'), ('49', 'Ekbia', ','), ('Ekbia', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Mattioli'), (',', 'Mattioli', ','), ('Mattioli', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Kouper'), (',', 'Kouper', ','), ('Kouper', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Arave'), (',', 'Arave', ','), ('Arave', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Ghazinejad'), (',', 'Ghazinejad', ','), ('Ghazinejad', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Bowman'), (',', 'Bowman', ','), ('Bowman', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Suri'), (',', 'Suri', ','), ('Suri', ',', 'V.R.'), (',', 'V.R.', ','), ('V.R.', ',', 'Tsou'), (',', 'Tsou', ','), ('Tsou', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Weingart'), (',', 'Weingart', ','), ('Weingart', ',', 'S.'), (',', 'S.', 'Sugimoto'), ('S.', 'Sugimoto', ','), ('Sugimoto', ',', 'C.R.'), (',', 'C.R.', ','), ('C.R.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('49', 'CD'), ('Ekbia', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Mattioli', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Kouper', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Arave', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Ghazinejad', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Bowman', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Suri', 'NNP'), (',', ','), ('V.R.', 'NNP'), (',', ','), ('Tsou', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Weingart', 'NNP'), (',', ','), ('S.', 'NNP'), ('Sugimoto', 'NNP'), (',', ','), ('C.R.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  49/CD
  (NP Ekbia/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Mattioli/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Kouper/NNP)
  ,/,
  (NP I./NNP)
  ,/,
  (NP Arave/NNP)
  ,/,
  (NP G./NNP)
  ,/,
  (NP Ghazinejad/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Bowman/NNP)
  ,/,
  (NP T./NNP)
  ,/,
  (NP Suri/NNP)
  ,/,
  (NP V.R./NNP)
  ,/,
  (NP Tsou/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Weingart/NNP)
  ,/,
  (NP S./NNP Sugimoto/NNP)
  ,/,
  (NP C.R./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Ekbia', 'H.', 'Mattioli', 'M.', 'Kouper', 'I.', 'Arave', 'G.', 'Ghazinejad', 'A.', 'Bowman', 'T.', 'Suri', 'V.R.', 'Tsou', 'A.', 'Weingart', 'S. Sugimoto', 'C.R.']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('GPE', 'Ekbia'), ('PERSON', 'Mattioli'), ('GPE', 'Kouper'), ('PERSON', 'Arave'), ('PERSON', 'Ghazinejad'), ('PERSON', 'Bowman'), ('PERSON', 'Suri'), ('PERSON', 'Tsou'), ('PERSON', 'Weingart')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('49', '49'), ('Ekbia', 'ekbia'), (',', ','), ('H.', 'h.'), (',', ','), ('Mattioli', 'mattioli'), (',', ','), ('M.', 'm.'), (',', ','), ('Kouper', 'kouper'), (',', ','), ('I.', 'i.'), (',', ','), ('Arave', 'arav'), (',', ','), ('G.', 'g.'), (',', ','), ('Ghazinejad', 'ghazinejad'), (',', ','), ('A.', 'a.'), (',', ','), ('Bowman', 'bowman'), (',', ','), ('T.', 't.'), (',', ','), ('Suri', 'suri'), (',', ','), ('V.R.', 'v.r.'), (',', ','), ('Tsou', 'tsou'), (',', ','), ('A.', 'a.'), (',', ','), ('Weingart', 'weingart'), (',', ','), ('S.', 's.'), ('Sugimoto', 'sugimoto'), (',', ','), ('C.R.', 'c.r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('49', '49'), ('Ekbia', 'ekbia'), (',', ','), ('H.', 'h.'), (',', ','), ('Mattioli', 'mattioli'), (',', ','), ('M.', 'm.'), (',', ','), ('Kouper', 'kouper'), (',', ','), ('I.', 'i.'), (',', ','), ('Arave', 'arav'), (',', ','), ('G.', 'g.'), (',', ','), ('Ghazinejad', 'ghazinejad'), (',', ','), ('A.', 'a.'), (',', ','), ('Bowman', 'bowman'), (',', ','), ('T.', 't.'), (',', ','), ('Suri', 'suri'), (',', ','), ('V.R.', 'v.r.'), (',', ','), ('Tsou', 'tsou'), (',', ','), ('A.', 'a.'), (',', ','), ('Weingart', 'weingart'), (',', ','), ('S.', 's.'), ('Sugimoto', 'sugimoto'), (',', ','), ('C.R.', 'c.r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('49', '49'), ('Ekbia', 'Ekbia'), (',', ','), ('H.', 'H.'), (',', ','), ('Mattioli', 'Mattioli'), (',', ','), ('M.', 'M.'), (',', ','), ('Kouper', 'Kouper'), (',', ','), ('I.', 'I.'), (',', ','), ('Arave', 'Arave'), (',', ','), ('G.', 'G.'), (',', ','), ('Ghazinejad', 'Ghazinejad'), (',', ','), ('A.', 'A.'), (',', ','), ('Bowman', 'Bowman'), (',', ','), ('T.', 'T.'), (',', ','), ('Suri', 'Suri'), (',', ','), ('V.R.', 'V.R.'), (',', ','), ('Tsou', 'Tsou'), (',', ','), ('A.', 'A.'), (',', ','), ('Weingart', 'Weingart'), (',', ','), ('S.', 'S.'), ('Sugimoto', 'Sugimoto'), (',', ','), ('C.R.', 'C.R.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 730 =============================

Big data, bigger dilemmas: A critical review. 


>> Tokens are: 
 ['Big', 'data', ',', 'bigger', 'dilemmas', ':', 'A', 'critical', 'review', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'bigger'), ('bigger', 'dilemmas'), ('dilemmas', ':'), (':', 'A'), ('A', 'critical'), ('critical', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'bigger'), (',', 'bigger', 'dilemmas'), ('bigger', 'dilemmas', ':'), ('dilemmas', ':', 'A'), (':', 'A', 'critical'), ('A', 'critical', 'review'), ('critical', 'review', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('bigger', 'JJR'), ('dilemmas', 'NN'), (':', ':'), ('A', 'DT'), ('critical', 'JJ'), ('review', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  ,/,
  bigger/JJR
  (NP dilemmas/NN)
  :/:
  (NP A/DT critical/JJ review/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'dilemmas', 'A critical review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('bigger', 'bigger'), ('dilemmas', 'dilemma'), (':', ':'), ('A', 'a'), ('critical', 'critic'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('bigger', 'bigger'), ('dilemmas', 'dilemma'), (':', ':'), ('A', 'a'), ('critical', 'critic'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('bigger', 'bigger'), ('dilemmas', 'dilemma'), (':', ':'), ('A', 'A'), ('critical', 'critical'), ('review', 'review'), ('.', '.')]



============================ Sentence 731 =============================

Journal of   the Association for Information Science and Technology, Volume 66, pp. 


>> Tokens are: 
 ['Journal', 'Association', 'Information', 'Science', 'Technology', ',', 'Volume', '66', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Association'), ('Association', 'Information'), ('Information', 'Science'), ('Science', 'Technology'), ('Technology', ','), (',', 'Volume'), ('Volume', '66'), ('66', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Association', 'Information'), ('Association', 'Information', 'Science'), ('Information', 'Science', 'Technology'), ('Science', 'Technology', ','), ('Technology', ',', 'Volume'), (',', 'Volume', '66'), ('Volume', '66', ','), ('66', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Association', 'NNP'), ('Information', 'NNP'), ('Science', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Volume', 'NN'), ('66', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    Journal/NNP
    Association/NNP
    Information/NNP
    Science/NNP
    Technology/NNP)
  ,/,
  (NP Volume/NN)
  66/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Journal Association Information Science Technology', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Association Information Science Technology'), ('ORGANIZATION', 'Volume 66')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Association', 'associ'), ('Information', 'inform'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('66', '66'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Association', 'associ'), ('Information', 'inform'), ('Science', 'scienc'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('66', '66'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Association', 'Association'), ('Information', 'Information'), ('Science', 'Science'), ('Technology', 'Technology'), (',', ','), ('Volume', 'Volume'), ('66', '66'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 732 =============================

1523-1545. 


>> Tokens are: 
 ['1523-1545', '.']

>> Bigrams are: 
 [('1523-1545', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1523-1545', 'JJ'), ('.', '.')]

 (S 1523-1545/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1523-1545', '1523-1545'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1523-1545', '1523-1545'), ('.', '.')]

>> Lemmatization: 
 [('1523-1545', '1523-1545'), ('.', '.')]



============================ Sentence 733 =============================

Eldawy, A. and Mokbel, M.F., 2015. 


>> Tokens are: 
 ['Eldawy', ',', 'A.', 'Mokbel', ',', 'M.F.', ',', '2015', '.']

>> Bigrams are: 
 [('Eldawy', ','), (',', 'A.'), ('A.', 'Mokbel'), ('Mokbel', ','), (',', 'M.F.'), ('M.F.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Eldawy', ',', 'A.'), (',', 'A.', 'Mokbel'), ('A.', 'Mokbel', ','), ('Mokbel', ',', 'M.F.'), (',', 'M.F.', ','), ('M.F.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Eldawy', 'NNP'), (',', ','), ('A.', 'NNP'), ('Mokbel', 'NNP'), (',', ','), ('M.F.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Eldawy/NNP)
  ,/,
  (NP A./NNP Mokbel/NNP)
  ,/,
  (NP M.F./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Eldawy', 'A. Mokbel', 'M.F.']

>> Named Entities are: 
 [('GPE', 'Eldawy')] 

>> Stemming using Porter Stemmer: 
 [('Eldawy', 'eldawi'), (',', ','), ('A.', 'a.'), ('Mokbel', 'mokbel'), (',', ','), ('M.F.', 'm.f.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Eldawy', 'eldawi'), (',', ','), ('A.', 'a.'), ('Mokbel', 'mokbel'), (',', ','), ('M.F.', 'm.f.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Eldawy', 'Eldawy'), (',', ','), ('A.', 'A.'), ('Mokbel', 'Mokbel'), (',', ','), ('M.F.', 'M.F.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 734 =============================

Spatialhadoop: A mapreduce framework for spatial data. 


>> Tokens are: 
 ['Spatialhadoop', ':', 'A', 'mapreduce', 'framework', 'spatial', 'data', '.']

>> Bigrams are: 
 [('Spatialhadoop', ':'), (':', 'A'), ('A', 'mapreduce'), ('mapreduce', 'framework'), ('framework', 'spatial'), ('spatial', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Spatialhadoop', ':', 'A'), (':', 'A', 'mapreduce'), ('A', 'mapreduce', 'framework'), ('mapreduce', 'framework', 'spatial'), ('framework', 'spatial', 'data'), ('spatial', 'data', '.')]

>> POS Tags are: 
 [('Spatialhadoop', 'NN'), (':', ':'), ('A', 'DT'), ('mapreduce', 'NN'), ('framework', 'NN'), ('spatial', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  (NP Spatialhadoop/NN)
  :/:
  (NP A/DT mapreduce/NN framework/NN)
  (NP spatial/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Spatialhadoop', 'A mapreduce framework', 'spatial data']

>> Named Entities are: 
 [('GPE', 'Spatialhadoop')] 

>> Stemming using Porter Stemmer: 
 [('Spatialhadoop', 'spatialhadoop'), (':', ':'), ('A', 'a'), ('mapreduce', 'mapreduc'), ('framework', 'framework'), ('spatial', 'spatial'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Spatialhadoop', 'spatialhadoop'), (':', ':'), ('A', 'a'), ('mapreduce', 'mapreduc'), ('framework', 'framework'), ('spatial', 'spatial'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Spatialhadoop', 'Spatialhadoop'), (':', ':'), ('A', 'A'), ('mapreduce', 'mapreduce'), ('framework', 'framework'), ('spatial', 'spatial'), ('data', 'data'), ('.', '.')]



============================ Sentence 735 =============================

s.l., IEEE. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), ('.', '.')]



============================ Sentence 736 =============================

Elgendy, N. and Elragal, A., 2014. 


>> Tokens are: 
 ['Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2014', '.']

>> Bigrams are: 
 [('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 737 =============================

Big data analytics: a literature review paper. 


>> Tokens are: 
 ['Big', 'data', 'analytics', ':', 'literature', 'review', 'paper', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'literature'), ('literature', 'review'), ('review', 'paper'), ('paper', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'literature'), (':', 'literature', 'review'), ('literature', 'review', 'paper'), ('review', 'paper', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('literature', 'NN'), ('review', 'NN'), ('paper', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  :/:
  (NP literature/NN review/NN paper/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'literature review paper']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('literature', 'literatur'), ('review', 'review'), ('paper', 'paper'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('literature', 'literatur'), ('review', 'review'), ('paper', 'paper'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('literature', 'literature'), ('review', 'review'), ('paper', 'paper'), ('.', '.')]



============================ Sentence 738 =============================

s.l., Springer,   cham, pp. 


>> Tokens are: 
 ['s.l.', ',', 'Springer', ',', 'cham', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'Springer'), ('Springer', ','), (',', 'cham'), ('cham', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'Springer'), (',', 'Springer', ','), ('Springer', ',', 'cham'), (',', 'cham', ','), ('cham', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('Springer', 'NNP'), (',', ','), ('cham', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP s.l./NN)
  ,/,
  (NP Springer/NNP)
  ,/,
  (NP cham/NN)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['s.l.', 'Springer', 'cham', 'pp']

>> Named Entities are: 
 [('PERSON', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Springer', 'springer'), (',', ','), ('cham', 'cham'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Springer', 'springer'), (',', ','), ('cham', 'cham'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('Springer', 'Springer'), (',', ','), ('cham', 'cham'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 739 =============================

214-227. 


>> Tokens are: 
 ['214-227', '.']

>> Bigrams are: 
 [('214-227', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('214-227', 'JJ'), ('.', '.')]

 (S 214-227/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('214-227', '214-227'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('214-227', '214-227'), ('.', '.')]

>> Lemmatization: 
 [('214-227', '214-227'), ('.', '.')]



============================ Sentence 740 =============================

Elgendy, N. and Elragal, A., 2016. 


>> Tokens are: 
 ['Elgendy', ',', 'N.', 'Elragal', ',', 'A.', ',', '2016', '.']

>> Bigrams are: 
 [('Elgendy', ','), (',', 'N.'), ('N.', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Elgendy', ',', 'N.'), (',', 'N.', 'Elragal'), ('N.', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Elgendy/NNP)
  ,/,
  (NP N./NNP Elragal/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Elgendy', 'N. Elragal', 'A.']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 741 =============================

Big Data Analytics in Support of the Decision Making Process. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Support', 'Decision', 'Making', 'Process', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Support'), ('Support', 'Decision'), ('Decision', 'Making'), ('Making', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Support'), ('Analytics', 'Support', 'Decision'), ('Support', 'Decision', 'Making'), ('Decision', 'Making', 'Process'), ('Making', 'Process', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Support', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('Process', 'NNP'), ('.', '.')]

 (S
  (NP
    Big/NNP
    Data/NNP
    Analytics/NNP
    Support/NNP
    Decision/NNP
    Making/NNP
    Process/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics Support Decision Making Process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Support', 'Support'), ('Decision', 'Decision'), ('Making', 'Making'), ('Process', 'Process'), ('.', '.')]



============================ Sentence 742 =============================

s.l., Elsevier. 


>> Tokens are: 
 ['s.l.', ',', 'Elsevier', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'Elsevier'), ('Elsevier', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'Elsevier'), (',', 'Elsevier', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('Elsevier', 'NNP'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP Elsevier/NNP) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'Elsevier']

>> Named Entities are: 
 [('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'Elsevier'), ('.', '.')]



============================ Sentence 743 =============================

Elgendy, N., 2013. 


>> Tokens are: 
 ['Elgendy', ',', 'N.', ',', '2013', '.']

>> Bigrams are: 
 [('Elgendy', ','), (',', 'N.'), ('N.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Elgendy', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Elgendy', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S (NP Elgendy/NNP) ,/, (NP N./NNP) ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 ['Elgendy', 'N.']

>> Named Entities are: 
 [('GPE', 'Elgendy')] 

>> Stemming using Porter Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elgendy', 'elgendi'), (',', ','), ('N.', 'n.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Elgendy', 'Elgendy'), (',', ','), ('N.', 'N.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 744 =============================

Big Data Analytics in Support of the Decision Making Process. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Support', 'Decision', 'Making', 'Process', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Support'), ('Support', 'Decision'), ('Decision', 'Making'), ('Making', 'Process'), ('Process', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Support'), ('Analytics', 'Support', 'Decision'), ('Support', 'Decision', 'Making'), ('Decision', 'Making', 'Process'), ('Making', 'Process', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Support', 'NNP'), ('Decision', 'NNP'), ('Making', 'NNP'), ('Process', 'NNP'), ('.', '.')]

 (S
  (NP
    Big/NNP
    Data/NNP
    Analytics/NNP
    Support/NNP
    Decision/NNP
    Making/NNP
    Process/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics Support Decision Making Process']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Support', 'support'), ('Decision', 'decis'), ('Making', 'make'), ('Process', 'process'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Support', 'Support'), ('Decision', 'Decision'), ('Making', 'Making'), ('Process', 'Process'), ('.', '.')]



============================ Sentence 745 =============================

MSc Thesis. 


>> Tokens are: 
 ['MSc', 'Thesis', '.']

>> Bigrams are: 
 [('MSc', 'Thesis'), ('Thesis', '.')]

>> Trigrams are: 
 [('MSc', 'Thesis', '.')]

>> POS Tags are: 
 [('MSc', 'NNP'), ('Thesis', 'NNP'), ('.', '.')]

 (S (NP MSc/NNP Thesis/NNP) ./.) 


>> Noun Phrases are: 
 ['MSc Thesis']

>> Named Entities are: 
 [('ORGANIZATION', 'MSc')] 

>> Stemming using Porter Stemmer: 
 [('MSc', 'msc'), ('Thesis', 'thesi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MSc', 'msc'), ('Thesis', 'thesi'), ('.', '.')]

>> Lemmatization: 
 [('MSc', 'MSc'), ('Thesis', 'Thesis'), ('.', '.')]



============================ Sentence 746 =============================

p. 164. 


>> Tokens are: 
 ['p.', '164', '.']

>> Bigrams are: 
 [('p.', '164'), ('164', '.')]

>> Trigrams are: 
 [('p.', '164', '.')]

>> POS Tags are: 
 [('p.', 'NN'), ('164', 'CD'), ('.', '.')]

 (S (NP p./NN) 164/CD ./.) 


>> Noun Phrases are: 
 ['p.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('p.', 'p.'), ('164', '164'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('p.', 'p.'), ('164', '164'), ('.', '.')]

>> Lemmatization: 
 [('p.', 'p.'), ('164', '164'), ('.', '.')]



============================ Sentence 747 =============================

Elragal, A. and Klischewski, R., 2017. 


>> Tokens are: 
 ['Elragal', ',', 'A.', 'Klischewski', ',', 'R.', ',', '2017', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', 'A.'), ('A.', 'Klischewski'), ('Klischewski', ','), (',', 'R.'), ('R.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Elragal', ',', 'A.'), (',', 'A.', 'Klischewski'), ('A.', 'Klischewski', ','), ('Klischewski', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), ('Klischewski', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Elragal/NNP)
  ,/,
  (NP A./NNP Klischewski/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Elragal', 'A. Klischewski', 'R.']

>> Named Entities are: 
 [('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Klischewski', 'klischewski'), (',', ','), ('R.', 'r.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Klischewski', 'klischewski'), (',', ','), ('R.', 'r.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), ('Klischewski', 'Klischewski'), (',', ','), ('R.', 'R.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 748 =============================

Theory-driven or process-driven prediction? 


>> Tokens are: 
 ['Theory-driven', 'process-driven', 'prediction', '?']

>> Bigrams are: 
 [('Theory-driven', 'process-driven'), ('process-driven', 'prediction'), ('prediction', '?')]

>> Trigrams are: 
 [('Theory-driven', 'process-driven', 'prediction'), ('process-driven', 'prediction', '?')]

>> POS Tags are: 
 [('Theory-driven', 'JJ'), ('process-driven', 'JJ'), ('prediction', 'NN'), ('?', '.')]

 (S (NP Theory-driven/JJ process-driven/JJ prediction/NN) ?/.) 


>> Noun Phrases are: 
 ['Theory-driven process-driven prediction']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Theory-driven', 'theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'predict'), ('?', '?')]

>> Lemmatization: 
 [('Theory-driven', 'Theory-driven'), ('process-driven', 'process-driven'), ('prediction', 'prediction'), ('?', '?')]



============================ Sentence 749 =============================

Epistemological challenges of big data analytics. 


>> Tokens are: 
 ['Epistemological', 'challenges', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Epistemological', 'challenges'), ('challenges', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Epistemological', 'challenges', 'big'), ('challenges', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Epistemological', 'JJ'), ('challenges', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Epistemological/JJ challenges/NNS)
  (NP big/JJ data/NNS analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Epistemological challenges', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Epistemological')] 

>> Stemming using Porter Stemmer: 
 [('Epistemological', 'epistemolog'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Epistemological', 'epistemolog'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Epistemological', 'Epistemological'), ('challenges', 'challenge'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 750 =============================

Journal of Big Data, p. 19. 


>> Tokens are: 
 ['Journal', 'Big', 'Data', ',', 'p.', '19', '.']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'p.'), ('p.', '19'), ('19', '.')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'p.'), (',', 'p.', '19'), ('p.', '19', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('p.', 'NN'), ('19', 'CD'), ('.', '.')]

 (S (NP Journal/NNP Big/NNP Data/NNP) ,/, (NP p./NN) 19/CD ./.) 


>> Noun Phrases are: 
 ['Journal Big Data', 'p.']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('19', '19'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('19', '19'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('p.', 'p.'), ('19', '19'), ('.', '.')]



============================ Sentence 751 =============================

Elragal, A, 2014. 


>> Tokens are: 
 ['Elragal', ',', 'A', ',', '2014', '.']

>> Bigrams are: 
 [('Elragal', ','), (',', 'A'), ('A', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Elragal', ',', 'A'), (',', 'A', ','), ('A', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Elragal', 'NNP'), (',', ','), ('A', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Elragal/NNP) ,/, (NP A/NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Elragal', 'A']

>> Named Entities are: 
 [('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Elragal', 'elrag'), (',', ','), ('A', 'a'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Elragal', 'Elragal'), (',', ','), ('A', 'A'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 752 =============================

ERP and big data: the inept couple. 


>> Tokens are: 
 ['ERP', 'big', 'data', ':', 'inept', 'couple', '.']

>> Bigrams are: 
 [('ERP', 'big'), ('big', 'data'), ('data', ':'), (':', 'inept'), ('inept', 'couple'), ('couple', '.')]

>> Trigrams are: 
 [('ERP', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'inept'), (':', 'inept', 'couple'), ('inept', 'couple', '.')]

>> POS Tags are: 
 [('ERP', 'NNP'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('inept', 'JJ'), ('couple', 'NN'), ('.', '.')]

 (S (NP ERP/NNP) (NP big/JJ data/NNS) :/: (NP inept/JJ couple/NN) ./.) 


>> Noun Phrases are: 
 ['ERP', 'big data', 'inept couple']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('ERP', 'erp'), ('big', 'big'), ('data', 'data'), (':', ':'), ('inept', 'inept'), ('couple', 'coupl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ERP', 'erp'), ('big', 'big'), ('data', 'data'), (':', ':'), ('inept', 'inept'), ('couple', 'coupl'), ('.', '.')]

>> Lemmatization: 
 [('ERP', 'ERP'), ('big', 'big'), ('data', 'data'), (':', ':'), ('inept', 'inept'), ('couple', 'couple'), ('.', '.')]



============================ Sentence 753 =============================

s.l., Elsevier, pp. 


>> Tokens are: 
 ['s.l.', ',', 'Elsevier', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'Elsevier'), ('Elsevier', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'Elsevier'), (',', 'Elsevier', ','), ('Elsevier', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('Elsevier', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP Elsevier/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'Elsevier', 'pp']

>> Named Entities are: 
 [('GPE', 'Elsevier')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'elsevi'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('Elsevier', 'Elsevier'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 754 =============================

242-249. 


>> Tokens are: 
 ['242-249', '.']

>> Bigrams are: 
 [('242-249', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('242-249', 'JJ'), ('.', '.')]

 (S 242-249/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('242-249', '242-249'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('242-249', '242-249'), ('.', '.')]

>> Lemmatization: 
 [('242-249', '242-249'), ('.', '.')]



============================ Sentence 755 =============================

Fan, J., Han, F. and Liu, H., 2014. 


>> Tokens are: 
 ['Fan', ',', 'J.', ',', 'Han', ',', 'F.', 'Liu', ',', 'H.', ',', '2014', '.']

>> Bigrams are: 
 [('Fan', ','), (',', 'J.'), ('J.', ','), (',', 'Han'), ('Han', ','), (',', 'F.'), ('F.', 'Liu'), ('Liu', ','), (',', 'H.'), ('H.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Fan', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Han'), (',', 'Han', ','), ('Han', ',', 'F.'), (',', 'F.', 'Liu'), ('F.', 'Liu', ','), ('Liu', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Fan', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Han', 'NNP'), (',', ','), ('F.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Fan/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Han/NNP)
  ,/,
  (NP F./NNP Liu/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Fan', 'J.', 'Han', 'F. Liu', 'H.']

>> Named Entities are: 
 [('GPE', 'Fan'), ('PERSON', 'Han')] 

>> Stemming using Porter Stemmer: 
 [('Fan', 'fan'), (',', ','), ('J.', 'j.'), (',', ','), ('Han', 'han'), (',', ','), ('F.', 'f.'), ('Liu', 'liu'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fan', 'fan'), (',', ','), ('J.', 'j.'), (',', ','), ('Han', 'han'), (',', ','), ('F.', 'f.'), ('Liu', 'liu'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Fan', 'Fan'), (',', ','), ('J.', 'J.'), (',', ','), ('Han', 'Han'), (',', ','), ('F.', 'F.'), ('Liu', 'Liu'), (',', ','), ('H.', 'H.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 756 =============================

Challenges of big data analysis. 


>> Tokens are: 
 ['Challenges', 'big', 'data', 'analysis', '.']

>> Bigrams are: 
 [('Challenges', 'big'), ('big', 'data'), ('data', 'analysis'), ('analysis', '.')]

>> Trigrams are: 
 [('Challenges', 'big', 'data'), ('big', 'data', 'analysis'), ('data', 'analysis', '.')]

>> POS Tags are: 
 [('Challenges', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('analysis', 'NN'), ('.', '.')]

 (S (NP Challenges/NNS) (NP big/JJ data/NNS analysis/NN) ./.) 


>> Noun Phrases are: 
 ['Challenges', 'big data analysis']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysi'), ('.', '.')]

>> Lemmatization: 
 [('Challenges', 'Challenges'), ('big', 'big'), ('data', 'data'), ('analysis', 'analysis'), ('.', '.')]



============================ Sentence 757 =============================

National science review,   Volume 1, pp. 


>> Tokens are: 
 ['National', 'science', 'review', ',', 'Volume', '1', ',', 'pp', '.']

>> Bigrams are: 
 [('National', 'science'), ('science', 'review'), ('review', ','), (',', 'Volume'), ('Volume', '1'), ('1', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('National', 'science', 'review'), ('science', 'review', ','), ('review', ',', 'Volume'), (',', 'Volume', '1'), ('Volume', '1', ','), ('1', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('National', 'NNP'), ('science', 'NN'), ('review', 'NN'), (',', ','), ('Volume', 'NN'), ('1', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP National/NNP science/NN review/NN)
  ,/,
  (NP Volume/NN)
  1/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['National science review', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'National'), ('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('National', 'nation'), ('science', 'scienc'), ('review', 'review'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('National', 'nation'), ('science', 'scienc'), ('review', 'review'), (',', ','), ('Volume', 'volum'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('National', 'National'), ('science', 'science'), ('review', 'review'), (',', ','), ('Volume', 'Volume'), ('1', '1'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 758 =============================

293-314. 


>> Tokens are: 
 ['293-314', '.']

>> Bigrams are: 
 [('293-314', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('293-314', 'JJ'), ('.', '.')]

 (S 293-314/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('293-314', '293-314'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('293-314', '293-314'), ('.', '.')]

>> Lemmatization: 
 [('293-314', '293-314'), ('.', '.')]



============================ Sentence 759 =============================

Gandomi, A. and Haider, M., 2015. 


>> Tokens are: 
 ['Gandomi', ',', 'A.', 'Haider', ',', 'M.', ',', '2015', '.']

>> Bigrams are: 
 [('Gandomi', ','), (',', 'A.'), ('A.', 'Haider'), ('Haider', ','), (',', 'M.'), ('M.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Gandomi', ',', 'A.'), (',', 'A.', 'Haider'), ('A.', 'Haider', ','), ('Haider', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Gandomi', 'NNP'), (',', ','), ('A.', 'NNP'), ('Haider', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Gandomi/NNP)
  ,/,
  (NP A./NNP Haider/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Gandomi', 'A. Haider', 'M.']

>> Named Entities are: 
 [('GPE', 'Gandomi')] 

>> Stemming using Porter Stemmer: 
 [('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Gandomi', 'gandomi'), (',', ','), ('A.', 'a.'), ('Haider', 'haider'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Gandomi', 'Gandomi'), (',', ','), ('A.', 'A.'), ('Haider', 'Haider'), (',', ','), ('M.', 'M.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 760 =============================

Beyond the hype: Big data concepts, methods, and analytics. 


>> Tokens are: 
 ['Beyond', 'hype', ':', 'Big', 'data', 'concepts', ',', 'methods', ',', 'analytics', '.']

>> Bigrams are: 
 [('Beyond', 'hype'), ('hype', ':'), (':', 'Big'), ('Big', 'data'), ('data', 'concepts'), ('concepts', ','), (',', 'methods'), ('methods', ','), (',', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Beyond', 'hype', ':'), ('hype', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', 'concepts'), ('data', 'concepts', ','), ('concepts', ',', 'methods'), (',', 'methods', ','), ('methods', ',', 'analytics'), (',', 'analytics', '.')]

>> POS Tags are: 
 [('Beyond', 'IN'), ('hype', 'NN'), (':', ':'), ('Big', 'NNP'), ('data', 'NNS'), ('concepts', 'NNS'), (',', ','), ('methods', 'NNS'), (',', ','), ('analytics', 'NNS'), ('.', '.')]

 (S
  Beyond/IN
  (NP hype/NN)
  :/:
  (NP Big/NNP data/NNS concepts/NNS)
  ,/,
  (NP methods/NNS)
  ,/,
  (NP analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['hype', 'Big data concepts', 'methods', 'analytics']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Beyond', 'beyond'), ('hype', 'hype'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('concepts', 'concept'), (',', ','), ('methods', 'method'), (',', ','), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Beyond', 'beyond'), ('hype', 'hype'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('concepts', 'concept'), (',', ','), ('methods', 'method'), (',', ','), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Beyond', 'Beyond'), ('hype', 'hype'), (':', ':'), ('Big', 'Big'), ('data', 'data'), ('concepts', 'concept'), (',', ','), ('methods', 'method'), (',', ','), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 761 =============================

International Journal of Information Management, Volume 35, pp. 


>> Tokens are: 
 ['International', 'Journal', 'Information', 'Management', ',', 'Volume', '35', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Information'), ('Information', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '35'), ('35', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Information'), ('Journal', 'Information', 'Management'), ('Information', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '35'), ('Volume', '35', ','), ('35', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('35', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP International/NNP Journal/NNP Information/NNP Management/NNP)
  ,/,
  (NP Volume/NN)
  35/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['International Journal Information Management', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Information Management'), ('ORGANIZATION', 'Volume 35')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Information', 'Information'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 762 =============================

137-144. 


>> Tokens are: 
 ['137-144', '.']

>> Bigrams are: 
 [('137-144', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('137-144', 'JJ'), ('.', '.')]

 (S 137-144/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('137-144', '137-144'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('137-144', '137-144'), ('.', '.')]

>> Lemmatization: 
 [('137-144', '137-144'), ('.', '.')]



============================ Sentence 763 =============================

García, S., Ramírez-Gallego, S., Luengo, J., Benítez, J.M. 


>> Tokens are: 
 ['García', ',', 'S.', ',', 'Ramírez-Gallego', ',', 'S.', ',', 'Luengo', ',', 'J.', ',', 'Benítez', ',', 'J.M', '.']

>> Bigrams are: 
 [('García', ','), (',', 'S.'), ('S.', ','), (',', 'Ramírez-Gallego'), ('Ramírez-Gallego', ','), (',', 'S.'), ('S.', ','), (',', 'Luengo'), ('Luengo', ','), (',', 'J.'), ('J.', ','), (',', 'Benítez'), ('Benítez', ','), (',', 'J.M'), ('J.M', '.')]

>> Trigrams are: 
 [('García', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ramírez-Gallego'), (',', 'Ramírez-Gallego', ','), ('Ramírez-Gallego', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Luengo'), (',', 'Luengo', ','), ('Luengo', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Benítez'), (',', 'Benítez', ','), ('Benítez', ',', 'J.M'), (',', 'J.M', '.')]

>> POS Tags are: 
 [('García', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ramírez-Gallego', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Luengo', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Benítez', 'NNP'), (',', ','), ('J.M', 'NNP'), ('.', '.')]

 (S
  (NP García/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Ramírez-Gallego/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Luengo/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Benítez/NNP)
  ,/,
  (NP J.M/NNP)
  ./.) 


>> Noun Phrases are: 
 ['García', 'S.', 'Ramírez-Gallego', 'S.', 'Luengo', 'J.', 'Benítez', 'J.M']

>> Named Entities are: 
 [('GPE', 'García'), ('GPE', 'Luengo'), ('PERSON', 'Benítez')] 

>> Stemming using Porter Stemmer: 
 [('García', 'garcía'), (',', ','), ('S.', 's.'), (',', ','), ('Ramírez-Gallego', 'ramírez-gallego'), (',', ','), ('S.', 's.'), (',', ','), ('Luengo', 'luengo'), (',', ','), ('J.', 'j.'), (',', ','), ('Benítez', 'benítez'), (',', ','), ('J.M', 'j.m'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('García', 'garcía'), (',', ','), ('S.', 's.'), (',', ','), ('Ramírez-Gallego', 'ramírez-gallego'), (',', ','), ('S.', 's.'), (',', ','), ('Luengo', 'luengo'), (',', ','), ('J.', 'j.'), (',', ','), ('Benítez', 'benítez'), (',', ','), ('J.M', 'j.m'), ('.', '.')]

>> Lemmatization: 
 [('García', 'García'), (',', ','), ('S.', 'S.'), (',', ','), ('Ramírez-Gallego', 'Ramírez-Gallego'), (',', ','), ('S.', 'S.'), (',', ','), ('Luengo', 'Luengo'), (',', ','), ('J.', 'J.'), (',', ','), ('Benítez', 'Benítez'), (',', ','), ('J.M', 'J.M'), ('.', '.')]



============================ Sentence 764 =============================

and Herrera, F., 2016. 


>> Tokens are: 
 ['Herrera', ',', 'F.', ',', '2016', '.']

>> Bigrams are: 
 [('Herrera', ','), (',', 'F.'), ('F.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Herrera', ',', 'F.'), (',', 'F.', ','), ('F.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Herrera', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S (NP Herrera/NNP) ,/, (NP F./NNP) ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 ['Herrera', 'F.']

>> Named Entities are: 
 [('GPE', 'Herrera')] 

>> Stemming using Porter Stemmer: 
 [('Herrera', 'herrera'), (',', ','), ('F.', 'f.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Herrera', 'herrera'), (',', ','), ('F.', 'f.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Herrera', 'Herrera'), (',', ','), ('F.', 'F.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 765 =============================

Big data   preprocessing: methods and prospects.. Big Data Analytics Journal, p. 9. 


>> Tokens are: 
 ['Big', 'data', 'preprocessing', ':', 'methods', 'prospects', '..', 'Big', 'Data', 'Analytics', 'Journal', ',', 'p.', '9', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'preprocessing'), ('preprocessing', ':'), (':', 'methods'), ('methods', 'prospects'), ('prospects', '..'), ('..', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Journal'), ('Journal', ','), (',', 'p.'), ('p.', '9'), ('9', '.')]

>> Trigrams are: 
 [('Big', 'data', 'preprocessing'), ('data', 'preprocessing', ':'), ('preprocessing', ':', 'methods'), (':', 'methods', 'prospects'), ('methods', 'prospects', '..'), ('prospects', '..', 'Big'), ('..', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Journal'), ('Analytics', 'Journal', ','), ('Journal', ',', 'p.'), (',', 'p.', '9'), ('p.', '9', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('preprocessing', 'NN'), (':', ':'), ('methods', 'NNS'), ('prospects', 'NNS'), ('..', 'VBP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('9', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS preprocessing/NN)
  :/:
  (NP methods/NNS prospects/NNS)
  ../VBP
  (NP Big/NNP Data/NNP Analytics/NNP Journal/NNP)
  ,/,
  p./VBD
  9/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data preprocessing', 'methods prospects', 'Big Data Analytics Journal']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('preprocessing', 'preprocess'), (':', ':'), ('methods', 'method'), ('prospects', 'prospect'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('preprocessing', 'preprocess'), (':', ':'), ('methods', 'method'), ('prospects', 'prospect'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('preprocessing', 'preprocessing'), (':', ':'), ('methods', 'method'), ('prospects', 'prospect'), ('..', '..'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]



============================ Sentence 766 =============================

Goncharov, I., 2019. 


>> Tokens are: 
 ['Goncharov', ',', 'I.', ',', '2019', '.']

>> Bigrams are: 
 [('Goncharov', ','), (',', 'I.'), ('I.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Goncharov', ',', 'I.'), (',', 'I.', ','), ('I.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Goncharov', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S (NP Goncharov/NNP) ,/, (NP I./NNP) ,/, 2019/CD ./.) 


>> Noun Phrases are: 
 ['Goncharov', 'I.']

>> Named Entities are: 
 [('GPE', 'Goncharov')] 

>> Stemming using Porter Stemmer: 
 [('Goncharov', 'goncharov'), (',', ','), ('I.', 'i.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Goncharov', 'goncharov'), (',', ','), ('I.', 'i.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Goncharov', 'Goncharov'), (',', ','), ('I.', 'I.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 767 =============================

Big Data and AI Landscape in 2018 , s.l. 


>> Tokens are: 
 ['Big', 'Data', 'AI', 'Landscape', '2018', ',', 's.l', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'AI'), ('AI', 'Landscape'), ('Landscape', '2018'), ('2018', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'AI'), ('Data', 'AI', 'Landscape'), ('AI', 'Landscape', '2018'), ('Landscape', '2018', ','), ('2018', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('AI', 'NNP'), ('Landscape', 'NNP'), ('2018', 'CD'), (',', ','), ('s.l', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP AI/NNP Landscape/NNP)
  2018/CD
  ,/,
  (NP s.l/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big Data AI Landscape', 's.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('AI', 'ai'), ('Landscape', 'landscap'), ('2018', '2018'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('AI', 'AI'), ('Landscape', 'Landscape'), ('2018', '2018'), (',', ','), ('s.l', 's.l'), ('.', '.')]



============================ Sentence 768 =============================

: Four Megatrends in Big Data in   2019 and Beyond . 


>> Tokens are: 
 [':', 'Four', 'Megatrends', 'Big', 'Data', '2019', 'Beyond', '.']

>> Bigrams are: 
 [(':', 'Four'), ('Four', 'Megatrends'), ('Megatrends', 'Big'), ('Big', 'Data'), ('Data', '2019'), ('2019', 'Beyond'), ('Beyond', '.')]

>> Trigrams are: 
 [(':', 'Four', 'Megatrends'), ('Four', 'Megatrends', 'Big'), ('Megatrends', 'Big', 'Data'), ('Big', 'Data', '2019'), ('Data', '2019', 'Beyond'), ('2019', 'Beyond', '.')]

>> POS Tags are: 
 [(':', ':'), ('Four', 'CD'), ('Megatrends', 'NNS'), ('Big', 'NNP'), ('Data', 'NNP'), ('2019', 'CD'), ('Beyond', 'NNP'), ('.', '.')]

 (S
  :/:
  Four/CD
  (NP Megatrends/NNS Big/NNP Data/NNP)
  2019/CD
  (NP Beyond/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Megatrends Big Data', 'Beyond']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Four', 'four'), ('Megatrends', 'megatrend'), ('Big', 'big'), ('Data', 'data'), ('2019', '2019'), ('Beyond', 'beyond'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Four', 'four'), ('Megatrends', 'megatrend'), ('Big', 'big'), ('Data', 'data'), ('2019', '2019'), ('Beyond', 'beyond'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Four', 'Four'), ('Megatrends', 'Megatrends'), ('Big', 'Big'), ('Data', 'Data'), ('2019', '2019'), ('Beyond', 'Beyond'), ('.', '.')]



============================ Sentence 769 =============================

Grover, P. and Kar, A.K., 2017. 


>> Tokens are: 
 ['Grover', ',', 'P.', 'Kar', ',', 'A.K.', ',', '2017', '.']

>> Bigrams are: 
 [('Grover', ','), (',', 'P.'), ('P.', 'Kar'), ('Kar', ','), (',', 'A.K.'), ('A.K.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Grover', ',', 'P.'), (',', 'P.', 'Kar'), ('P.', 'Kar', ','), ('Kar', ',', 'A.K.'), (',', 'A.K.', ','), ('A.K.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), (',', ','), ('P.', 'NNP'), ('Kar', 'NNP'), (',', ','), ('A.K.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Grover/NNP)
  ,/,
  (NP P./NNP Kar/NNP)
  ,/,
  (NP A.K./NNP)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Grover', 'P. Kar', 'A.K.']

>> Named Entities are: 
 [('GPE', 'Grover')] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), (',', ','), ('P.', 'p.'), ('Kar', 'kar'), (',', ','), ('A.K.', 'a.k.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), (',', ','), ('P.', 'p.'), ('Kar', 'kar'), (',', ','), ('A.K.', 'a.k.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), (',', ','), ('P.', 'P.'), ('Kar', 'Kar'), (',', ','), ('A.K.', 'A.K.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 770 =============================

Big data analytics: a review on theoretical contributions and tools   used in literature.. 


>> Tokens are: 
 ['Big', 'data', 'analytics', ':', 'review', 'theoretical', 'contributions', 'tools', 'used', 'literature', '..']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'review'), ('review', 'theoretical'), ('theoretical', 'contributions'), ('contributions', 'tools'), ('tools', 'used'), ('used', 'literature'), ('literature', '..')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'review'), (':', 'review', 'theoretical'), ('review', 'theoretical', 'contributions'), ('theoretical', 'contributions', 'tools'), ('contributions', 'tools', 'used'), ('tools', 'used', 'literature'), ('used', 'literature', '..')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('review', 'VB'), ('theoretical', 'JJ'), ('contributions', 'NNS'), ('tools', 'NNS'), ('used', 'JJ'), ('literature', 'NN'), ('..', 'NN')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  :/:
  review/VB
  (NP theoretical/JJ contributions/NNS tools/NNS)
  (NP used/JJ literature/NN ../NN)) 


>> Noun Phrases are: 
 ['Big data analytics', 'theoretical contributions tools', 'used literature ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('review', 'review'), ('theoretical', 'theoret'), ('contributions', 'contribut'), ('tools', 'tool'), ('used', 'use'), ('literature', 'literatur'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('review', 'review'), ('theoretical', 'theoret'), ('contributions', 'contribut'), ('tools', 'tool'), ('used', 'use'), ('literature', 'literatur'), ('..', '..')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('review', 'review'), ('theoretical', 'theoretical'), ('contributions', 'contribution'), ('tools', 'tool'), ('used', 'used'), ('literature', 'literature'), ('..', '..')]



============================ Sentence 771 =============================

Global Journal of Flexible Systems Management, 18(3), pp. 


>> Tokens are: 
 ['Global', 'Journal', 'Flexible', 'Systems', 'Management', ',', '18', '(', '3', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Global', 'Journal'), ('Journal', 'Flexible'), ('Flexible', 'Systems'), ('Systems', 'Management'), ('Management', ','), (',', '18'), ('18', '('), ('(', '3'), ('3', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Global', 'Journal', 'Flexible'), ('Journal', 'Flexible', 'Systems'), ('Flexible', 'Systems', 'Management'), ('Systems', 'Management', ','), ('Management', ',', '18'), (',', '18', '('), ('18', '(', '3'), ('(', '3', ')'), ('3', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Global', 'JJ'), ('Journal', 'NNP'), ('Flexible', 'NNP'), ('Systems', 'NNPS'), ('Management', 'NNP'), (',', ','), ('18', 'CD'), ('(', '('), ('3', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Global/JJ Journal/NNP Flexible/NNP)
  Systems/NNPS
  (NP Management/NNP)
  ,/,
  18/CD
  (/(
  3/CD
  )/)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Global Journal Flexible', 'Management', 'pp']

>> Named Entities are: 
 [('PERSON', 'Global'), ('ORGANIZATION', 'Journal Flexible Systems Management')] 

>> Stemming using Porter Stemmer: 
 [('Global', 'global'), ('Journal', 'journal'), ('Flexible', 'flexibl'), ('Systems', 'system'), ('Management', 'manag'), (',', ','), ('18', '18'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Global', 'global'), ('Journal', 'journal'), ('Flexible', 'flexibl'), ('Systems', 'system'), ('Management', 'manag'), (',', ','), ('18', '18'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Global', 'Global'), ('Journal', 'Journal'), ('Flexible', 'Flexible'), ('Systems', 'Systems'), ('Management', 'Management'), (',', ','), ('18', '18'), ('(', '('), ('3', '3'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 772 =============================

203-229. 


>> Tokens are: 
 ['203-229', '.']

>> Bigrams are: 
 [('203-229', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('203-229', 'JJ'), ('.', '.')]

 (S 203-229/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('203-229', '203-229'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('203-229', '203-229'), ('.', '.')]

>> Lemmatization: 
 [('203-229', '203-229'), ('.', '.')]



============================ Sentence 773 =============================

Grover, V., Chiang, R.H., Liang, T.P. 


>> Tokens are: 
 ['Grover', ',', 'V.', ',', 'Chiang', ',', 'R.H.', ',', 'Liang', ',', 'T.P', '.']

>> Bigrams are: 
 [('Grover', ','), (',', 'V.'), ('V.', ','), (',', 'Chiang'), ('Chiang', ','), (',', 'R.H.'), ('R.H.', ','), (',', 'Liang'), ('Liang', ','), (',', 'T.P'), ('T.P', '.')]

>> Trigrams are: 
 [('Grover', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Chiang'), (',', 'Chiang', ','), ('Chiang', ',', 'R.H.'), (',', 'R.H.', ','), ('R.H.', ',', 'Liang'), (',', 'Liang', ','), ('Liang', ',', 'T.P'), (',', 'T.P', '.')]

>> POS Tags are: 
 [('Grover', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Chiang', 'NNP'), (',', ','), ('R.H.', 'NNP'), (',', ','), ('Liang', 'NNP'), (',', ','), ('T.P', 'NNP'), ('.', '.')]

 (S
  (NP Grover/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  (NP Chiang/NNP)
  ,/,
  (NP R.H./NNP)
  ,/,
  (NP Liang/NNP)
  ,/,
  (NP T.P/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Grover', 'V.', 'Chiang', 'R.H.', 'Liang', 'T.P']

>> Named Entities are: 
 [('GPE', 'Grover'), ('GPE', 'Chiang'), ('PERSON', 'Liang')] 

>> Stemming using Porter Stemmer: 
 [('Grover', 'grover'), (',', ','), ('V.', 'v.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), (',', ','), ('Liang', 'liang'), (',', ','), ('T.P', 't.p'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Grover', 'grover'), (',', ','), ('V.', 'v.'), (',', ','), ('Chiang', 'chiang'), (',', ','), ('R.H.', 'r.h.'), (',', ','), ('Liang', 'liang'), (',', ','), ('T.P', 't.p'), ('.', '.')]

>> Lemmatization: 
 [('Grover', 'Grover'), (',', ','), ('V.', 'V.'), (',', ','), ('Chiang', 'Chiang'), (',', ','), ('R.H.', 'R.H.'), (',', ','), ('Liang', 'Liang'), (',', ','), ('T.P', 'T.P'), ('.', '.')]



============================ Sentence 774 =============================

and Zhang, D., 2018. 


>> Tokens are: 
 ['Zhang', ',', 'D.', ',', '2018', '.']

>> Bigrams are: 
 [('Zhang', ','), (',', 'D.'), ('D.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Zhang', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Zhang', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S (NP Zhang/NNP) ,/, (NP D./NNP) ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 ['Zhang', 'D.']

>> Named Entities are: 
 [('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Zhang', 'zhang'), (',', ','), ('D.', 'd.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhang', 'zhang'), (',', ','), ('D.', 'd.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Zhang', 'Zhang'), (',', ','), ('D.', 'D.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 775 =============================

Creating Strategic Business Value   from Big Data Analytics: A Research Framework.. Journal of Management Information Systems,   pp. 


>> Tokens are: 
 ['Creating', 'Strategic', 'Business', 'Value', 'Big', 'Data', 'Analytics', ':', 'A', 'Research', 'Framework', '..', 'Journal', 'Management', 'Information', 'Systems', ',', 'pp', '.']

>> Bigrams are: 
 [('Creating', 'Strategic'), ('Strategic', 'Business'), ('Business', 'Value'), ('Value', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', ':'), (':', 'A'), ('A', 'Research'), ('Research', 'Framework'), ('Framework', '..'), ('..', 'Journal'), ('Journal', 'Management'), ('Management', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Creating', 'Strategic', 'Business'), ('Strategic', 'Business', 'Value'), ('Business', 'Value', 'Big'), ('Value', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', ':'), ('Analytics', ':', 'A'), (':', 'A', 'Research'), ('A', 'Research', 'Framework'), ('Research', 'Framework', '..'), ('Framework', '..', 'Journal'), ('..', 'Journal', 'Management'), ('Journal', 'Management', 'Information'), ('Management', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Creating', 'VBG'), ('Strategic', 'NNP'), ('Business', 'NNP'), ('Value', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS'), (':', ':'), ('A', 'DT'), ('Research', 'NNP'), ('Framework', 'NNP'), ('..', 'NNP'), ('Journal', 'NNP'), ('Management', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  Creating/VBG
  (NP
    Strategic/NNP
    Business/NNP
    Value/NNP
    Big/NNP
    Data/NNP
    Analytics/NNS)
  :/:
  (NP
    A/DT
    Research/NNP
    Framework/NNP
    ../NNP
    Journal/NNP
    Management/NNP
    Information/NNP
    Systems/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Strategic Business Value Big Data Analytics', 'A Research Framework .. Journal Management Information Systems', 'pp']

>> Named Entities are: 
 [('PERSON', 'Strategic Business Value')] 

>> Stemming using Porter Stemmer: 
 [('Creating', 'creat'), ('Strategic', 'strateg'), ('Business', 'busi'), ('Value', 'valu'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Research', 'research'), ('Framework', 'framework'), ('..', '..'), ('Journal', 'journal'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Creating', 'creat'), ('Strategic', 'strateg'), ('Business', 'busi'), ('Value', 'valu'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('A', 'a'), ('Research', 'research'), ('Framework', 'framework'), ('..', '..'), ('Journal', 'journal'), ('Management', 'manag'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Creating', 'Creating'), ('Strategic', 'Strategic'), ('Business', 'Business'), ('Value', 'Value'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), (':', ':'), ('A', 'A'), ('Research', 'Research'), ('Framework', 'Framework'), ('..', '..'), ('Journal', 'Journal'), ('Management', 'Management'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 776 =============================

388-423. 


>> Tokens are: 
 ['388-423', '.']

>> Bigrams are: 
 [('388-423', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('388-423', 'JJ'), ('.', '.')]

 (S 388-423/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('388-423', '388-423'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('388-423', '388-423'), ('.', '.')]

>> Lemmatization: 
 [('388-423', '388-423'), ('.', '.')]



============================ Sentence 777 =============================

Günther, W.A., Mehrizi, M.H.R., Huysman, M. and Feldberg, F., 2017. 


>> Tokens are: 
 ['Günther', ',', 'W.A.', ',', 'Mehrizi', ',', 'M.H.R.', ',', 'Huysman', ',', 'M.', 'Feldberg', ',', 'F.', ',', '2017', '.']

>> Bigrams are: 
 [('Günther', ','), (',', 'W.A.'), ('W.A.', ','), (',', 'Mehrizi'), ('Mehrizi', ','), (',', 'M.H.R.'), ('M.H.R.', ','), (',', 'Huysman'), ('Huysman', ','), (',', 'M.'), ('M.', 'Feldberg'), ('Feldberg', ','), (',', 'F.'), ('F.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Günther', ',', 'W.A.'), (',', 'W.A.', ','), ('W.A.', ',', 'Mehrizi'), (',', 'Mehrizi', ','), ('Mehrizi', ',', 'M.H.R.'), (',', 'M.H.R.', ','), ('M.H.R.', ',', 'Huysman'), (',', 'Huysman', ','), ('Huysman', ',', 'M.'), (',', 'M.', 'Feldberg'), ('M.', 'Feldberg', ','), ('Feldberg', ',', 'F.'), (',', 'F.', ','), ('F.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Günther', 'NNP'), (',', ','), ('W.A.', 'NNP'), (',', ','), ('Mehrizi', 'NNP'), (',', ','), ('M.H.R.', 'NNP'), (',', ','), ('Huysman', 'NNP'), (',', ','), ('M.', 'NNP'), ('Feldberg', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Günther/NNP)
  ,/,
  (NP W.A./NNP)
  ,/,
  (NP Mehrizi/NNP)
  ,/,
  (NP M.H.R./NNP)
  ,/,
  (NP Huysman/NNP)
  ,/,
  (NP M./NNP Feldberg/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Günther', 'W.A.', 'Mehrizi', 'M.H.R.', 'Huysman', 'M. Feldberg', 'F.']

>> Named Entities are: 
 [('GPE', 'Günther'), ('ORGANIZATION', 'W.A.'), ('PERSON', 'Mehrizi'), ('PERSON', 'Huysman')] 

>> Stemming using Porter Stemmer: 
 [('Günther', 'günther'), (',', ','), ('W.A.', 'w.a.'), (',', ','), ('Mehrizi', 'mehrizi'), (',', ','), ('M.H.R.', 'm.h.r.'), (',', ','), ('Huysman', 'huysman'), (',', ','), ('M.', 'm.'), ('Feldberg', 'feldberg'), (',', ','), ('F.', 'f.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Günther', 'günther'), (',', ','), ('W.A.', 'w.a.'), (',', ','), ('Mehrizi', 'mehrizi'), (',', ','), ('M.H.R.', 'm.h.r.'), (',', ','), ('Huysman', 'huysman'), (',', ','), ('M.', 'm.'), ('Feldberg', 'feldberg'), (',', ','), ('F.', 'f.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Günther', 'Günther'), (',', ','), ('W.A.', 'W.A.'), (',', ','), ('Mehrizi', 'Mehrizi'), (',', ','), ('M.H.R.', 'M.H.R.'), (',', ','), ('Huysman', 'Huysman'), (',', ','), ('M.', 'M.'), ('Feldberg', 'Feldberg'), (',', ','), ('F.', 'F.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 778 =============================

Debating big data: A   literature review on realizing value from big data. 


>> Tokens are: 
 ['Debating', 'big', 'data', ':', 'A', 'literature', 'review', 'realizing', 'value', 'big', 'data', '.']

>> Bigrams are: 
 [('Debating', 'big'), ('big', 'data'), ('data', ':'), (':', 'A'), ('A', 'literature'), ('literature', 'review'), ('review', 'realizing'), ('realizing', 'value'), ('value', 'big'), ('big', 'data'), ('data', '.')]

>> Trigrams are: 
 [('Debating', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'A'), (':', 'A', 'literature'), ('A', 'literature', 'review'), ('literature', 'review', 'realizing'), ('review', 'realizing', 'value'), ('realizing', 'value', 'big'), ('value', 'big', 'data'), ('big', 'data', '.')]

>> POS Tags are: 
 [('Debating', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('A', 'DT'), ('literature', 'NN'), ('review', 'NN'), ('realizing', 'VBG'), ('value', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('.', '.')]

 (S
  Debating/VBG
  (NP big/JJ data/NNS)
  :/:
  (NP A/DT literature/NN review/NN)
  realizing/VBG
  (NP value/NN)
  (NP big/JJ data/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data', 'A literature review', 'value', 'big data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Debating', 'debat'), ('big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('realizing', 'realiz'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Debating', 'debat'), ('big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('literature', 'literatur'), ('review', 'review'), ('realizing', 'realiz'), ('value', 'valu'), ('big', 'big'), ('data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Debating', 'Debating'), ('big', 'big'), ('data', 'data'), (':', ':'), ('A', 'A'), ('literature', 'literature'), ('review', 'review'), ('realizing', 'realizing'), ('value', 'value'), ('big', 'big'), ('data', 'data'), ('.', '.')]



============================ Sentence 779 =============================

The Journal of Strategic Information Systems,   Volume 26, pp. 


>> Tokens are: 
 ['The', 'Journal', 'Strategic', 'Information', 'Systems', ',', 'Volume', '26', ',', 'pp', '.']

>> Bigrams are: 
 [('The', 'Journal'), ('Journal', 'Strategic'), ('Strategic', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'Volume'), ('Volume', '26'), ('26', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('The', 'Journal', 'Strategic'), ('Journal', 'Strategic', 'Information'), ('Strategic', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'Volume'), (',', 'Volume', '26'), ('Volume', '26', ','), ('26', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('Journal', 'NNP'), ('Strategic', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Volume', 'NN'), ('26', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP The/DT Journal/NNP Strategic/NNP Information/NNP Systems/NNP)
  ,/,
  (NP Volume/NN)
  26/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['The Journal Strategic Information Systems', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Journal Strategic Information Systems'), ('ORGANIZATION', 'Volume 26')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Journal', 'journal'), ('Strategic', 'strateg'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Journal', 'journal'), ('Strategic', 'strateg'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('Journal', 'Journal'), ('Strategic', 'Strategic'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('Volume', 'Volume'), ('26', '26'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 780 =============================

191-209. 


>> Tokens are: 
 ['191-209', '.']

>> Bigrams are: 
 [('191-209', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('191-209', 'JJ'), ('.', '.')]

 (S 191-209/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('191-209', '191-209'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('191-209', '191-209'), ('.', '.')]

>> Lemmatization: 
 [('191-209', '191-209'), ('.', '.')]



============================ Sentence 781 =============================

H. Eszter, 2015. 


>> Tokens are: 
 ['H.', 'Eszter', ',', '2015', '.']

>> Bigrams are: 
 [('H.', 'Eszter'), ('Eszter', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('H.', 'Eszter', ','), ('Eszter', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('H.', 'NNP'), ('Eszter', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S (NP H./NNP Eszter/NNP) ,/, 2015/CD ./.) 


>> Noun Phrases are: 
 ['H. Eszter']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('H.', 'h.'), ('Eszter', 'eszter'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('H.', 'H.'), ('Eszter', 'Eszter'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 782 =============================

Is bigger always better? 


>> Tokens are: 
 ['Is', 'bigger', 'always', 'better', '?']

>> Bigrams are: 
 [('Is', 'bigger'), ('bigger', 'always'), ('always', 'better'), ('better', '?')]

>> Trigrams are: 
 [('Is', 'bigger', 'always'), ('bigger', 'always', 'better'), ('always', 'better', '?')]

>> POS Tags are: 
 [('Is', 'VBZ'), ('bigger', 'JJR'), ('always', 'RB'), ('better', 'RBR'), ('?', '.')]

 (S Is/VBZ bigger/JJR always/RB better/RBR ?/.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Is', 'is'), ('bigger', 'bigger'), ('always', 'alway'), ('better', 'better'), ('?', '?')]

>> Stemming using Snowball Stemmer: 
 [('Is', 'is'), ('bigger', 'bigger'), ('always', 'alway'), ('better', 'better'), ('?', '?')]

>> Lemmatization: 
 [('Is', 'Is'), ('bigger', 'bigger'), ('always', 'always'), ('better', 'better'), ('?', '?')]



============================ Sentence 783 =============================

Potential biases of big data derived from social network   sites. 


>> Tokens are: 
 ['Potential', 'biases', 'big', 'data', 'derived', 'social', 'network', 'sites', '.']

>> Bigrams are: 
 [('Potential', 'biases'), ('biases', 'big'), ('big', 'data'), ('data', 'derived'), ('derived', 'social'), ('social', 'network'), ('network', 'sites'), ('sites', '.')]

>> Trigrams are: 
 [('Potential', 'biases', 'big'), ('biases', 'big', 'data'), ('big', 'data', 'derived'), ('data', 'derived', 'social'), ('derived', 'social', 'network'), ('social', 'network', 'sites'), ('network', 'sites', '.')]

>> POS Tags are: 
 [('Potential', 'JJ'), ('biases', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('derived', 'VBD'), ('social', 'JJ'), ('network', 'NN'), ('sites', 'NNS'), ('.', '.')]

 (S
  (NP Potential/JJ biases/NNS)
  (NP big/JJ data/NNS)
  derived/VBD
  (NP social/JJ network/NN sites/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Potential biases', 'big data', 'social network sites']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Potential', 'potenti'), ('biases', 'bias'), ('big', 'big'), ('data', 'data'), ('derived', 'deriv'), ('social', 'social'), ('network', 'network'), ('sites', 'site'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Potential', 'potenti'), ('biases', 'bias'), ('big', 'big'), ('data', 'data'), ('derived', 'deriv'), ('social', 'social'), ('network', 'network'), ('sites', 'site'), ('.', '.')]

>> Lemmatization: 
 [('Potential', 'Potential'), ('biases', 'bias'), ('big', 'big'), ('data', 'data'), ('derived', 'derived'), ('social', 'social'), ('network', 'network'), ('sites', 'site'), ('.', '.')]



============================ Sentence 784 =============================

The ANNALS of the American Academy of Political and Social Science journal, Volume 659,   pp. 


>> Tokens are: 
 ['The', 'ANNALS', 'American', 'Academy', 'Political', 'Social', 'Science', 'journal', ',', 'Volume', '659', ',', 'pp', '.']

>> Bigrams are: 
 [('The', 'ANNALS'), ('ANNALS', 'American'), ('American', 'Academy'), ('Academy', 'Political'), ('Political', 'Social'), ('Social', 'Science'), ('Science', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '659'), ('659', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('The', 'ANNALS', 'American'), ('ANNALS', 'American', 'Academy'), ('American', 'Academy', 'Political'), ('Academy', 'Political', 'Social'), ('Political', 'Social', 'Science'), ('Social', 'Science', 'journal'), ('Science', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '659'), ('Volume', '659', ','), ('659', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('ANNALS', 'NNP'), ('American', 'NNP'), ('Academy', 'NNP'), ('Political', 'NNP'), ('Social', 'NNP'), ('Science', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('659', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    The/DT
    ANNALS/NNP
    American/NNP
    Academy/NNP
    Political/NNP
    Social/NNP
    Science/NNP
    journal/NN)
  ,/,
  (NP Volume/NN)
  659/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['The ANNALS American Academy Political Social Science journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ANNALS American Academy'), ('ORGANIZATION', 'Volume 659')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('ANNALS', 'annal'), ('American', 'american'), ('Academy', 'academi'), ('Political', 'polit'), ('Social', 'social'), ('Science', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('659', '659'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('ANNALS', 'annal'), ('American', 'american'), ('Academy', 'academi'), ('Political', 'polit'), ('Social', 'social'), ('Science', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('659', '659'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('ANNALS', 'ANNALS'), ('American', 'American'), ('Academy', 'Academy'), ('Political', 'Political'), ('Social', 'Social'), ('Science', 'Science'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('659', '659'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 785 =============================

63-76. 


>> Tokens are: 
 ['63-76', '.']

>> Bigrams are: 
 [('63-76', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('63-76', 'JJ'), ('.', '.')]

 (S 63-76/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('63-76', '63-76'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('63-76', '63-76'), ('.', '.')]

>> Lemmatization: 
 [('63-76', '63-76'), ('.', '.')]



============================ Sentence 786 =============================

Hart, C., 2018. 


>> Tokens are: 
 ['Hart', ',', 'C.', ',', '2018', '.']

>> Bigrams are: 
 [('Hart', ','), (',', 'C.'), ('C.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Hart', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Hart', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S (NP Hart/NNP) ,/, (NP C./NNP) ,/, 2018/CD ./.) 


>> Noun Phrases are: 
 ['Hart', 'C.']

>> Named Entities are: 
 [('GPE', 'Hart')] 

>> Stemming using Porter Stemmer: 
 [('Hart', 'hart'), (',', ','), ('C.', 'c.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hart', 'hart'), (',', ','), ('C.', 'c.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Hart', 'Hart'), (',', ','), ('C.', 'C.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 787 =============================

Doing a literature review: Releasing the research imagination.. 


>> Tokens are: 
 ['Doing', 'literature', 'review', ':', 'Releasing', 'research', 'imagination', '..']

>> Bigrams are: 
 [('Doing', 'literature'), ('literature', 'review'), ('review', ':'), (':', 'Releasing'), ('Releasing', 'research'), ('research', 'imagination'), ('imagination', '..')]

>> Trigrams are: 
 [('Doing', 'literature', 'review'), ('literature', 'review', ':'), ('review', ':', 'Releasing'), (':', 'Releasing', 'research'), ('Releasing', 'research', 'imagination'), ('research', 'imagination', '..')]

>> POS Tags are: 
 [('Doing', 'VBG'), ('literature', 'NN'), ('review', 'NN'), (':', ':'), ('Releasing', 'NNP'), ('research', 'NN'), ('imagination', 'NN'), ('..', 'NN')]

 (S
  Doing/VBG
  (NP literature/NN review/NN)
  :/:
  (NP Releasing/NNP research/NN imagination/NN ../NN)) 


>> Noun Phrases are: 
 ['literature review', 'Releasing research imagination ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Doing', 'do'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('Releasing', 'releas'), ('research', 'research'), ('imagination', 'imagin'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Doing', 'do'), ('literature', 'literatur'), ('review', 'review'), (':', ':'), ('Releasing', 'releas'), ('research', 'research'), ('imagination', 'imagin'), ('..', '..')]

>> Lemmatization: 
 [('Doing', 'Doing'), ('literature', 'literature'), ('review', 'review'), (':', ':'), ('Releasing', 'Releasing'), ('research', 'research'), ('imagination', 'imagination'), ('..', '..')]



============================ Sentence 788 =============================

s.l.:Sage. 


>> Tokens are: 
 ['s.l', '.', ':', 'Sage', '.']

>> Bigrams are: 
 [('s.l', '.'), ('.', ':'), (':', 'Sage'), ('Sage', '.')]

>> Trigrams are: 
 [('s.l', '.', ':'), ('.', ':', 'Sage'), (':', 'Sage', '.')]

>> POS Tags are: 
 [('s.l', 'NN'), ('.', '.'), (':', ':'), ('Sage', 'NN'), ('.', '.')]

 (S (NP s.l/NN) ./. :/: (NP Sage/NN) ./.) 


>> Noun Phrases are: 
 ['s.l', 'Sage']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l', 's.l'), ('.', '.'), (':', ':'), ('Sage', 'sage'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l', 's.l'), ('.', '.'), (':', ':'), ('Sage', 'sage'), ('.', '.')]

>> Lemmatization: 
 [('s.l', 's.l'), ('.', '.'), (':', ':'), ('Sage', 'Sage'), ('.', '.')]



============================ Sentence 789 =============================

Hartmann, T., Fouquet, F., Moawad, A., Rouvoy, R. and Le Traon, Y., 2019. 


>> Tokens are: 
 ['Hartmann', ',', 'T.', ',', 'Fouquet', ',', 'F.', ',', 'Moawad', ',', 'A.', ',', 'Rouvoy', ',', 'R.', 'Le', 'Traon', ',', 'Y.', ',', '2019', '.']

>> Bigrams are: 
 [('Hartmann', ','), (',', 'T.'), ('T.', ','), (',', 'Fouquet'), ('Fouquet', ','), (',', 'F.'), ('F.', ','), (',', 'Moawad'), ('Moawad', ','), (',', 'A.'), ('A.', ','), (',', 'Rouvoy'), ('Rouvoy', ','), (',', 'R.'), ('R.', 'Le'), ('Le', 'Traon'), ('Traon', ','), (',', 'Y.'), ('Y.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Hartmann', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Fouquet'), (',', 'Fouquet', ','), ('Fouquet', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Moawad'), (',', 'Moawad', ','), ('Moawad', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Rouvoy'), (',', 'Rouvoy', ','), ('Rouvoy', ',', 'R.'), (',', 'R.', 'Le'), ('R.', 'Le', 'Traon'), ('Le', 'Traon', ','), ('Traon', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Hartmann', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Fouquet', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Moawad', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Rouvoy', 'NNP'), (',', ','), ('R.', 'NNP'), ('Le', 'NNP'), ('Traon', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Hartmann/NNP)
  ,/,
  (NP T./NNP)
  ,/,
  (NP Fouquet/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  (NP Moawad/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Rouvoy/NNP)
  ,/,
  (NP R./NNP Le/NNP Traon/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Hartmann', 'T.', 'Fouquet', 'F.', 'Moawad', 'A.', 'Rouvoy', 'R. Le Traon', 'Y.']

>> Named Entities are: 
 [('GPE', 'Hartmann'), ('PERSON', 'Fouquet'), ('GPE', 'Moawad'), ('GPE', 'Rouvoy')] 

>> Stemming using Porter Stemmer: 
 [('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), (',', ','), ('Fouquet', 'fouquet'), (',', ','), ('F.', 'f.'), (',', ','), ('Moawad', 'moawad'), (',', ','), ('A.', 'a.'), (',', ','), ('Rouvoy', 'rouvoy'), (',', ','), ('R.', 'r.'), ('Le', 'le'), ('Traon', 'traon'), (',', ','), ('Y.', 'y.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hartmann', 'hartmann'), (',', ','), ('T.', 't.'), (',', ','), ('Fouquet', 'fouquet'), (',', ','), ('F.', 'f.'), (',', ','), ('Moawad', 'moawad'), (',', ','), ('A.', 'a.'), (',', ','), ('Rouvoy', 'rouvoy'), (',', ','), ('R.', 'r.'), ('Le', 'le'), ('Traon', 'traon'), (',', ','), ('Y.', 'y.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Hartmann', 'Hartmann'), (',', ','), ('T.', 'T.'), (',', ','), ('Fouquet', 'Fouquet'), (',', ','), ('F.', 'F.'), (',', ','), ('Moawad', 'Moawad'), (',', ','), ('A.', 'A.'), (',', ','), ('Rouvoy', 'Rouvoy'), (',', ','), ('R.', 'R.'), ('Le', 'Le'), ('Traon', 'Traon'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 790 =============================

GreyCat: Efficient   what-if analytics for data in motion at scale.. Information Systems journal. 


>> Tokens are: 
 ['GreyCat', ':', 'Efficient', 'what-if', 'analytics', 'data', 'motion', 'scale', '..', 'Information', 'Systems', 'journal', '.']

>> Bigrams are: 
 [('GreyCat', ':'), (':', 'Efficient'), ('Efficient', 'what-if'), ('what-if', 'analytics'), ('analytics', 'data'), ('data', 'motion'), ('motion', 'scale'), ('scale', '..'), ('..', 'Information'), ('Information', 'Systems'), ('Systems', 'journal'), ('journal', '.')]

>> Trigrams are: 
 [('GreyCat', ':', 'Efficient'), (':', 'Efficient', 'what-if'), ('Efficient', 'what-if', 'analytics'), ('what-if', 'analytics', 'data'), ('analytics', 'data', 'motion'), ('data', 'motion', 'scale'), ('motion', 'scale', '..'), ('scale', '..', 'Information'), ('..', 'Information', 'Systems'), ('Information', 'Systems', 'journal'), ('Systems', 'journal', '.')]

>> POS Tags are: 
 [('GreyCat', 'NN'), (':', ':'), ('Efficient', 'JJ'), ('what-if', 'JJ'), ('analytics', 'NNS'), ('data', 'NNS'), ('motion', 'NN'), ('scale', 'NN'), ('..', 'JJ'), ('Information', 'NNP'), ('Systems', 'NNP'), ('journal', 'NN'), ('.', '.')]

 (S
  (NP GreyCat/NN)
  :/:
  (NP
    Efficient/JJ
    what-if/JJ
    analytics/NNS
    data/NNS
    motion/NN
    scale/NN)
  (NP ../JJ Information/NNP Systems/NNP journal/NN)
  ./.) 


>> Noun Phrases are: 
 ['GreyCat', 'Efficient what-if analytics data motion scale', '.. Information Systems journal']

>> Named Entities are: 
 [('GPE', 'GreyCat')] 

>> Stemming using Porter Stemmer: 
 [('GreyCat', 'greycat'), (':', ':'), ('Efficient', 'effici'), ('what-if', 'what-if'), ('analytics', 'analyt'), ('data', 'data'), ('motion', 'motion'), ('scale', 'scale'), ('..', '..'), ('Information', 'inform'), ('Systems', 'system'), ('journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('GreyCat', 'greycat'), (':', ':'), ('Efficient', 'effici'), ('what-if', 'what-if'), ('analytics', 'analyt'), ('data', 'data'), ('motion', 'motion'), ('scale', 'scale'), ('..', '..'), ('Information', 'inform'), ('Systems', 'system'), ('journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('GreyCat', 'GreyCat'), (':', ':'), ('Efficient', 'Efficient'), ('what-if', 'what-if'), ('analytics', 'analytics'), ('data', 'data'), ('motion', 'motion'), ('scale', 'scale'), ('..', '..'), ('Information', 'Information'), ('Systems', 'Systems'), ('journal', 'journal'), ('.', '.')]



============================ Sentence 791 =============================

Hasselt, H.V., 2010. 


>> Tokens are: 
 ['Hasselt', ',', 'H.V.', ',', '2010', '.']

>> Bigrams are: 
 [('Hasselt', ','), (',', 'H.V.'), ('H.V.', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Hasselt', ',', 'H.V.'), (',', 'H.V.', ','), ('H.V.', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Hasselt', 'NNP'), (',', ','), ('H.V.', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

 (S (NP Hasselt/NNP) ,/, (NP H.V./NNP) ,/, 2010/CD ./.) 


>> Noun Phrases are: 
 ['Hasselt', 'H.V.']

>> Named Entities are: 
 [('GPE', 'Hasselt')] 

>> Stemming using Porter Stemmer: 
 [('Hasselt', 'hasselt'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hasselt', 'hasselt'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Hasselt', 'Hasselt'), (',', ','), ('H.V.', 'H.V.'), (',', ','), ('2010', '2010'), ('.', '.')]



============================ Sentence 792 =============================

Double Q-learning. 


>> Tokens are: 
 ['Double', 'Q-learning', '.']

>> Bigrams are: 
 [('Double', 'Q-learning'), ('Q-learning', '.')]

>> Trigrams are: 
 [('Double', 'Q-learning', '.')]

>> POS Tags are: 
 [('Double', 'JJ'), ('Q-learning', 'NN'), ('.', '.')]

 (S (NP Double/JJ Q-learning/NN) ./.) 


>> Noun Phrases are: 
 ['Double Q-learning']

>> Named Entities are: 
 [('GPE', 'Double')] 

>> Stemming using Porter Stemmer: 
 [('Double', 'doubl'), ('Q-learning', 'q-learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Double', 'doubl'), ('Q-learning', 'q-learn'), ('.', '.')]

>> Lemmatization: 
 [('Double', 'Double'), ('Q-learning', 'Q-learning'), ('.', '.')]



============================ Sentence 793 =============================

s.l., s.n., pp. 


>> Tokens are: 
 ['s.l.', ',', 's.n.', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n.'), ('s.n.', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n.'), (',', 's.n.', ','), ('s.n.', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n.', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP s.n./NN) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 's.n.', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 794 =============================

2613-2621. 


>> Tokens are: 
 ['2613-2621', '.']

>> Bigrams are: 
 [('2613-2621', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('2613-2621', 'JJ'), ('.', '.')]

 (S 2613-2621/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('2613-2621', '2613-2621'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('2613-2621', '2613-2621'), ('.', '.')]

>> Lemmatization: 
 [('2613-2621', '2613-2621'), ('.', '.')]



============================ Sentence 795 =============================

Sarah Al-Shiakhli   50      He, Y., Lee, R., Huai, Y., Shao, Z., Jain, N., Zhang, X. and Xu, Z., 2011. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '50', 'He', ',', 'Y.', ',', 'Lee', ',', 'R.', ',', 'Huai', ',', 'Y.', ',', 'Shao', ',', 'Z.', ',', 'Jain', ',', 'N.', ',', 'Zhang', ',', 'X.', 'Xu', ',', 'Z.', ',', '2011', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '50'), ('50', 'He'), ('He', ','), (',', 'Y.'), ('Y.', ','), (',', 'Lee'), ('Lee', ','), (',', 'R.'), ('R.', ','), (',', 'Huai'), ('Huai', ','), (',', 'Y.'), ('Y.', ','), (',', 'Shao'), ('Shao', ','), (',', 'Z.'), ('Z.', ','), (',', 'Jain'), ('Jain', ','), (',', 'N.'), ('N.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'X.'), ('X.', 'Xu'), ('Xu', ','), (',', 'Z.'), ('Z.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '50'), ('Al-Shiakhli', '50', 'He'), ('50', 'He', ','), ('He', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Lee'), (',', 'Lee', ','), ('Lee', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Huai'), (',', 'Huai', ','), ('Huai', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Shao'), (',', 'Shao', ','), ('Shao', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Jain'), (',', 'Jain', ','), ('Jain', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'X.'), (',', 'X.', 'Xu'), ('X.', 'Xu', ','), ('Xu', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('50', 'CD'), ('He', 'PRP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Lee', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Huai', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Shao', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Jain', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('X.', 'NNP'), ('Xu', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  50/CD
  He/PRP
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Lee/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Huai/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Shao/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  (NP Jain/NNP)
  ,/,
  (NP N./NNP)
  ,/,
  (NP Zhang/NNP)
  ,/,
  (NP X./NNP Xu/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  2011/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Y.', 'Lee', 'R.', 'Huai', 'Y.', 'Shao', 'Z.', 'Jain', 'N.', 'Zhang', 'X. Xu', 'Z.']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Lee'), ('PERSON', 'Huai'), ('PERSON', 'Shao'), ('GPE', 'Jain'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('50', '50'), ('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lee', 'lee'), (',', ','), ('R.', 'r.'), (',', ','), ('Huai', 'huai'), (',', ','), ('Y.', 'y.'), (',', ','), ('Shao', 'shao'), (',', ','), ('Z.', 'z.'), (',', ','), ('Jain', 'jain'), (',', ','), ('N.', 'n.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('X.', 'x.'), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('50', '50'), ('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Lee', 'lee'), (',', ','), ('R.', 'r.'), (',', ','), ('Huai', 'huai'), (',', ','), ('Y.', 'y.'), (',', ','), ('Shao', 'shao'), (',', ','), ('Z.', 'z.'), (',', ','), ('Jain', 'jain'), (',', ','), ('N.', 'n.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('X.', 'x.'), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('50', '50'), ('He', 'He'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Lee', 'Lee'), (',', ','), ('R.', 'R.'), (',', ','), ('Huai', 'Huai'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Shao', 'Shao'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Jain', 'Jain'), (',', ','), ('N.', 'N.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('X.', 'X.'), ('Xu', 'Xu'), (',', ','), ('Z.', 'Z.'), (',', ','), ('2011', '2011'), ('.', '.')]



============================ Sentence 796 =============================

RCFile: A fast and space-  efficient data placement structure in MapReduce-based warehouse systems. 


>> Tokens are: 
 ['RCFile', ':', 'A', 'fast', 'space-', 'efficient', 'data', 'placement', 'structure', 'MapReduce-based', 'warehouse', 'systems', '.']

>> Bigrams are: 
 [('RCFile', ':'), (':', 'A'), ('A', 'fast'), ('fast', 'space-'), ('space-', 'efficient'), ('efficient', 'data'), ('data', 'placement'), ('placement', 'structure'), ('structure', 'MapReduce-based'), ('MapReduce-based', 'warehouse'), ('warehouse', 'systems'), ('systems', '.')]

>> Trigrams are: 
 [('RCFile', ':', 'A'), (':', 'A', 'fast'), ('A', 'fast', 'space-'), ('fast', 'space-', 'efficient'), ('space-', 'efficient', 'data'), ('efficient', 'data', 'placement'), ('data', 'placement', 'structure'), ('placement', 'structure', 'MapReduce-based'), ('structure', 'MapReduce-based', 'warehouse'), ('MapReduce-based', 'warehouse', 'systems'), ('warehouse', 'systems', '.')]

>> POS Tags are: 
 [('RCFile', 'NN'), (':', ':'), ('A', 'DT'), ('fast', 'JJ'), ('space-', 'JJ'), ('efficient', 'NN'), ('data', 'NNS'), ('placement', 'NN'), ('structure', 'NN'), ('MapReduce-based', 'JJ'), ('warehouse', 'NN'), ('systems', 'NNS'), ('.', '.')]

 (S
  (NP RCFile/NN)
  :/:
  (NP
    A/DT
    fast/JJ
    space-/JJ
    efficient/NN
    data/NNS
    placement/NN
    structure/NN)
  (NP MapReduce-based/JJ warehouse/NN systems/NNS)
  ./.) 


>> Noun Phrases are: 
 ['RCFile', 'A fast space- efficient data placement structure', 'MapReduce-based warehouse systems']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('RCFile', 'rcfile'), (':', ':'), ('A', 'a'), ('fast', 'fast'), ('space-', 'space-'), ('efficient', 'effici'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur'), ('MapReduce-based', 'mapreduce-bas'), ('warehouse', 'warehous'), ('systems', 'system'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('RCFile', 'rcfile'), (':', ':'), ('A', 'a'), ('fast', 'fast'), ('space-', 'space-'), ('efficient', 'effici'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structur'), ('MapReduce-based', 'mapreduce-bas'), ('warehouse', 'warehous'), ('systems', 'system'), ('.', '.')]

>> Lemmatization: 
 [('RCFile', 'RCFile'), (':', ':'), ('A', 'A'), ('fast', 'fast'), ('space-', 'space-'), ('efficient', 'efficient'), ('data', 'data'), ('placement', 'placement'), ('structure', 'structure'), ('MapReduce-based', 'MapReduce-based'), ('warehouse', 'warehouse'), ('systems', 'system'), ('.', '.')]



============================ Sentence 797 =============================

s.l., IEEE, pp. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 798 =============================

1199-  12. 


>> Tokens are: 
 ['1199-', '12', '.']

>> Bigrams are: 
 [('1199-', '12'), ('12', '.')]

>> Trigrams are: 
 [('1199-', '12', '.')]

>> POS Tags are: 
 [('1199-', 'JJ'), ('12', 'CD'), ('.', '.')]

 (S 1199-/JJ 12/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1199-', '1199-'), ('12', '12'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1199-', '1199-'), ('12', '12'), ('.', '.')]

>> Lemmatization: 
 [('1199-', '1199-'), ('12', '12'), ('.', '.')]



============================ Sentence 799 =============================

He, Y., Yu, F.R., Zhao, N., Yin, H., Yao, H. and Qiu, R.C., 2016. 


>> Tokens are: 
 ['He', ',', 'Y.', ',', 'Yu', ',', 'F.R.', ',', 'Zhao', ',', 'N.', ',', 'Yin', ',', 'H.', ',', 'Yao', ',', 'H.', 'Qiu', ',', 'R.C.', ',', '2016', '.']

>> Bigrams are: 
 [('He', ','), (',', 'Y.'), ('Y.', ','), (',', 'Yu'), ('Yu', ','), (',', 'F.R.'), ('F.R.', ','), (',', 'Zhao'), ('Zhao', ','), (',', 'N.'), ('N.', ','), (',', 'Yin'), ('Yin', ','), (',', 'H.'), ('H.', ','), (',', 'Yao'), ('Yao', ','), (',', 'H.'), ('H.', 'Qiu'), ('Qiu', ','), (',', 'R.C.'), ('R.C.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('He', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Yu'), (',', 'Yu', ','), ('Yu', ',', 'F.R.'), (',', 'F.R.', ','), ('F.R.', ',', 'Zhao'), (',', 'Zhao', ','), ('Zhao', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Yin'), (',', 'Yin', ','), ('Yin', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Yao'), (',', 'Yao', ','), ('Yao', ',', 'H.'), (',', 'H.', 'Qiu'), ('H.', 'Qiu', ','), ('Qiu', ',', 'R.C.'), (',', 'R.C.', ','), ('R.C.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('He', 'PRP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Yu', 'NNP'), (',', ','), ('F.R.', 'NNP'), (',', ','), ('Zhao', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Yin', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Yao', 'NNP'), (',', ','), ('H.', 'NNP'), ('Qiu', 'NNP'), (',', ','), ('R.C.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  He/PRP
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Yu/NNP)
  ,/,
  (NP F.R./NNP)
  ,/,
  (NP Zhao/NNP)
  ,/,
  (NP N./NNP)
  ,/,
  (NP Yin/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Yao/NNP)
  ,/,
  (NP H./NNP Qiu/NNP)
  ,/,
  (NP R.C./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Y.', 'Yu', 'F.R.', 'Zhao', 'N.', 'Yin', 'H.', 'Yao', 'H. Qiu', 'R.C.']

>> Named Entities are: 
 [('GPE', 'Yu'), ('PERSON', 'Zhao'), ('PERSON', 'Yin'), ('PERSON', 'Yao')] 

>> Stemming using Porter Stemmer: 
 [('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Yu', 'yu'), (',', ','), ('F.R.', 'f.r.'), (',', ','), ('Zhao', 'zhao'), (',', ','), ('N.', 'n.'), (',', ','), ('Yin', 'yin'), (',', ','), ('H.', 'h.'), (',', ','), ('Yao', 'yao'), (',', ','), ('H.', 'h.'), ('Qiu', 'qiu'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('He', 'he'), (',', ','), ('Y.', 'y.'), (',', ','), ('Yu', 'yu'), (',', ','), ('F.R.', 'f.r.'), (',', ','), ('Zhao', 'zhao'), (',', ','), ('N.', 'n.'), (',', ','), ('Yin', 'yin'), (',', ','), ('H.', 'h.'), (',', ','), ('Yao', 'yao'), (',', ','), ('H.', 'h.'), ('Qiu', 'qiu'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('He', 'He'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Yu', 'Yu'), (',', ','), ('F.R.', 'F.R.'), (',', ','), ('Zhao', 'Zhao'), (',', ','), ('N.', 'N.'), (',', ','), ('Yin', 'Yin'), (',', ','), ('H.', 'H.'), (',', ','), ('Yao', 'Yao'), (',', ','), ('H.', 'H.'), ('Qiu', 'Qiu'), (',', ','), ('R.C.', 'R.C.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 800 =============================

Big data analytics in mobile   cellular networks. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'mobile', 'cellular', 'networks', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'mobile'), ('mobile', 'cellular'), ('cellular', 'networks'), ('networks', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'mobile'), ('analytics', 'mobile', 'cellular'), ('mobile', 'cellular', 'networks'), ('cellular', 'networks', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('mobile', 'JJ'), ('cellular', 'JJ'), ('networks', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  (NP mobile/JJ cellular/JJ networks/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'mobile cellular networks']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('mobile', 'mobil'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('mobile', 'mobile'), ('cellular', 'cellular'), ('networks', 'network'), ('.', '.')]



============================ Sentence 801 =============================

IEEE access, Volume 4, pp. 


>> Tokens are: 
 ['IEEE', 'access', ',', 'Volume', '4', ',', 'pp', '.']

>> Bigrams are: 
 [('IEEE', 'access'), ('access', ','), (',', 'Volume'), ('Volume', '4'), ('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', 'access', ','), ('access', ',', 'Volume'), (',', 'Volume', '4'), ('Volume', '4', ','), ('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('access', 'NN'), (',', ','), ('Volume', 'NN'), ('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP IEEE/NNP access/NN)
  ,/,
  (NP Volume/NN)
  4/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['IEEE access', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('access', 'access'), (',', ','), ('Volume', 'volum'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('access', 'access'), (',', ','), ('Volume', 'volum'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('access', 'access'), (',', ','), ('Volume', 'Volume'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 802 =============================

1985-1996. 


>> Tokens are: 
 ['1985-1996', '.']

>> Bigrams are: 
 [('1985-1996', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1985-1996', 'JJ'), ('.', '.')]

 (S 1985-1996/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1985-1996', '1985-1996'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1985-1996', '1985-1996'), ('.', '.')]

>> Lemmatization: 
 [('1985-1996', '1985-1996'), ('.', '.')]



============================ Sentence 803 =============================

Hester, T., Vecerik, M., Pietquin, O., Lanctot, M., Schaul, T., Piot, B., Horgan, D., Quan, J.,   Sendonaris, A., Osband, I. and Dulac-Arnold, G., 2018. 


>> Tokens are: 
 ['Hester', ',', 'T.', ',', 'Vecerik', ',', 'M.', ',', 'Pietquin', ',', 'O.', ',', 'Lanctot', ',', 'M.', ',', 'Schaul', ',', 'T.', ',', 'Piot', ',', 'B.', ',', 'Horgan', ',', 'D.', ',', 'Quan', ',', 'J.', ',', 'Sendonaris', ',', 'A.', ',', 'Osband', ',', 'I.', 'Dulac-Arnold', ',', 'G.', ',', '2018', '.']

>> Bigrams are: 
 [('Hester', ','), (',', 'T.'), ('T.', ','), (',', 'Vecerik'), ('Vecerik', ','), (',', 'M.'), ('M.', ','), (',', 'Pietquin'), ('Pietquin', ','), (',', 'O.'), ('O.', ','), (',', 'Lanctot'), ('Lanctot', ','), (',', 'M.'), ('M.', ','), (',', 'Schaul'), ('Schaul', ','), (',', 'T.'), ('T.', ','), (',', 'Piot'), ('Piot', ','), (',', 'B.'), ('B.', ','), (',', 'Horgan'), ('Horgan', ','), (',', 'D.'), ('D.', ','), (',', 'Quan'), ('Quan', ','), (',', 'J.'), ('J.', ','), (',', 'Sendonaris'), ('Sendonaris', ','), (',', 'A.'), ('A.', ','), (',', 'Osband'), ('Osband', ','), (',', 'I.'), ('I.', 'Dulac-Arnold'), ('Dulac-Arnold', ','), (',', 'G.'), ('G.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Hester', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Vecerik'), (',', 'Vecerik', ','), ('Vecerik', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Pietquin'), (',', 'Pietquin', ','), ('Pietquin', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Lanctot'), (',', 'Lanctot', ','), ('Lanctot', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Schaul'), (',', 'Schaul', ','), ('Schaul', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Piot'), (',', 'Piot', ','), ('Piot', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Horgan'), (',', 'Horgan', ','), ('Horgan', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Quan'), (',', 'Quan', ','), ('Quan', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Sendonaris'), (',', 'Sendonaris', ','), ('Sendonaris', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Osband'), (',', 'Osband', ','), ('Osband', ',', 'I.'), (',', 'I.', 'Dulac-Arnold'), ('I.', 'Dulac-Arnold', ','), ('Dulac-Arnold', ',', 'G.'), (',', 'G.', ','), ('G.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Hester', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Vecerik', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Pietquin', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Lanctot', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Schaul', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Piot', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Horgan', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Quan', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Sendonaris', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Osband', 'NNP'), (',', ','), ('I.', 'NNP'), ('Dulac-Arnold', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Hester/NNP)
  ,/,
  (NP T./NNP)
  ,/,
  (NP Vecerik/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Pietquin/NNP)
  ,/,
  (NP O./NNP)
  ,/,
  (NP Lanctot/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Schaul/NNP)
  ,/,
  (NP T./NNP)
  ,/,
  (NP Piot/NNP)
  ,/,
  (NP B./NNP)
  ,/,
  (NP Horgan/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  (NP Quan/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Sendonaris/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Osband/NNP)
  ,/,
  (NP I./NNP Dulac-Arnold/NNP)
  ,/,
  (NP G./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Hester', 'T.', 'Vecerik', 'M.', 'Pietquin', 'O.', 'Lanctot', 'M.', 'Schaul', 'T.', 'Piot', 'B.', 'Horgan', 'D.', 'Quan', 'J.', 'Sendonaris', 'A.', 'Osband', 'I. Dulac-Arnold', 'G.']

>> Named Entities are: 
 [('GPE', 'Hester'), ('PERSON', 'Vecerik'), ('GPE', 'Pietquin'), ('PERSON', 'Lanctot'), ('PERSON', 'Schaul'), ('GPE', 'Piot'), ('GPE', 'Horgan'), ('PERSON', 'Quan'), ('GPE', 'Sendonaris'), ('GPE', 'Osband')] 

>> Stemming using Porter Stemmer: 
 [('Hester', 'hester'), (',', ','), ('T.', 't.'), (',', ','), ('Vecerik', 'vecerik'), (',', ','), ('M.', 'm.'), (',', ','), ('Pietquin', 'pietquin'), (',', ','), ('O.', 'o.'), (',', ','), ('Lanctot', 'lanctot'), (',', ','), ('M.', 'm.'), (',', ','), ('Schaul', 'schaul'), (',', ','), ('T.', 't.'), (',', ','), ('Piot', 'piot'), (',', ','), ('B.', 'b.'), (',', ','), ('Horgan', 'horgan'), (',', ','), ('D.', 'd.'), (',', ','), ('Quan', 'quan'), (',', ','), ('J.', 'j.'), (',', ','), ('Sendonaris', 'sendonari'), (',', ','), ('A.', 'a.'), (',', ','), ('Osband', 'osband'), (',', ','), ('I.', 'i.'), ('Dulac-Arnold', 'dulac-arnold'), (',', ','), ('G.', 'g.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hester', 'hester'), (',', ','), ('T.', 't.'), (',', ','), ('Vecerik', 'vecerik'), (',', ','), ('M.', 'm.'), (',', ','), ('Pietquin', 'pietquin'), (',', ','), ('O.', 'o.'), (',', ','), ('Lanctot', 'lanctot'), (',', ','), ('M.', 'm.'), (',', ','), ('Schaul', 'schaul'), (',', ','), ('T.', 't.'), (',', ','), ('Piot', 'piot'), (',', ','), ('B.', 'b.'), (',', ','), ('Horgan', 'horgan'), (',', ','), ('D.', 'd.'), (',', ','), ('Quan', 'quan'), (',', ','), ('J.', 'j.'), (',', ','), ('Sendonaris', 'sendonari'), (',', ','), ('A.', 'a.'), (',', ','), ('Osband', 'osband'), (',', ','), ('I.', 'i.'), ('Dulac-Arnold', 'dulac-arnold'), (',', ','), ('G.', 'g.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Hester', 'Hester'), (',', ','), ('T.', 'T.'), (',', ','), ('Vecerik', 'Vecerik'), (',', ','), ('M.', 'M.'), (',', ','), ('Pietquin', 'Pietquin'), (',', ','), ('O.', 'O.'), (',', ','), ('Lanctot', 'Lanctot'), (',', ','), ('M.', 'M.'), (',', ','), ('Schaul', 'Schaul'), (',', ','), ('T.', 'T.'), (',', ','), ('Piot', 'Piot'), (',', ','), ('B.', 'B.'), (',', ','), ('Horgan', 'Horgan'), (',', ','), ('D.', 'D.'), (',', ','), ('Quan', 'Quan'), (',', ','), ('J.', 'J.'), (',', ','), ('Sendonaris', 'Sendonaris'), (',', ','), ('A.', 'A.'), (',', ','), ('Osband', 'Osband'), (',', ','), ('I.', 'I.'), ('Dulac-Arnold', 'Dulac-Arnold'), (',', ','), ('G.', 'G.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 804 =============================

Deep q-learning from demonstrations. 


>> Tokens are: 
 ['Deep', 'q-learning', 'demonstrations', '.']

>> Bigrams are: 
 [('Deep', 'q-learning'), ('q-learning', 'demonstrations'), ('demonstrations', '.')]

>> Trigrams are: 
 [('Deep', 'q-learning', 'demonstrations'), ('q-learning', 'demonstrations', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('q-learning', 'JJ'), ('demonstrations', 'NNS'), ('.', '.')]

 (S (NP Deep/JJ q-learning/JJ demonstrations/NNS) ./.) 


>> Noun Phrases are: 
 ['Deep q-learning demonstrations']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('q-learning', 'q-learn'), ('demonstrations', 'demonstr'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('q-learning', 'q-learn'), ('demonstrations', 'demonstr'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('q-learning', 'q-learning'), ('demonstrations', 'demonstration'), ('.', '.')]



============================ Sentence 805 =============================

s.l.,   s.n. 


>> Tokens are: 
 ['s.l.', ',', 's.n', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n'), ('s.n', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n'), (',', 's.n', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP s.n/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 's.n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]



============================ Sentence 806 =============================

Hofmann, E. and Rutschmann, E., 2018. 


>> Tokens are: 
 ['Hofmann', ',', 'E.', 'Rutschmann', ',', 'E.', ',', '2018', '.']

>> Bigrams are: 
 [('Hofmann', ','), (',', 'E.'), ('E.', 'Rutschmann'), ('Rutschmann', ','), (',', 'E.'), ('E.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Hofmann', ',', 'E.'), (',', 'E.', 'Rutschmann'), ('E.', 'Rutschmann', ','), ('Rutschmann', ',', 'E.'), (',', 'E.', ','), ('E.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Hofmann', 'NNP'), (',', ','), ('E.', 'NNP'), ('Rutschmann', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Hofmann/NNP)
  ,/,
  (NP E./NNP Rutschmann/NNP)
  ,/,
  (NP E./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Hofmann', 'E. Rutschmann', 'E.']

>> Named Entities are: 
 [('GPE', 'Hofmann')] 

>> Stemming using Porter Stemmer: 
 [('Hofmann', 'hofmann'), (',', ','), ('E.', 'e.'), ('Rutschmann', 'rutschmann'), (',', ','), ('E.', 'e.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hofmann', 'hofmann'), (',', ','), ('E.', 'e.'), ('Rutschmann', 'rutschmann'), (',', ','), ('E.', 'e.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Hofmann', 'Hofmann'), (',', ','), ('E.', 'E.'), ('Rutschmann', 'Rutschmann'), (',', ','), ('E.', 'E.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 807 =============================

Big data analytics and demand forecasting in supply   chains: a conceptual analysis.. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'demand', 'forecasting', 'supply', 'chains', ':', 'conceptual', 'analysis', '..']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'demand'), ('demand', 'forecasting'), ('forecasting', 'supply'), ('supply', 'chains'), ('chains', ':'), (':', 'conceptual'), ('conceptual', 'analysis'), ('analysis', '..')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'demand'), ('analytics', 'demand', 'forecasting'), ('demand', 'forecasting', 'supply'), ('forecasting', 'supply', 'chains'), ('supply', 'chains', ':'), ('chains', ':', 'conceptual'), (':', 'conceptual', 'analysis'), ('conceptual', 'analysis', '..')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('demand', 'VBP'), ('forecasting', 'VBG'), ('supply', 'NN'), ('chains', 'NNS'), (':', ':'), ('conceptual', 'JJ'), ('analysis', 'NN'), ('..', 'NN')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  demand/VBP
  forecasting/VBG
  (NP supply/NN chains/NNS)
  :/:
  (NP conceptual/JJ analysis/NN ../NN)) 


>> Noun Phrases are: 
 ['Big data analytics', 'supply chains', 'conceptual analysis ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('demand', 'demand'), ('forecasting', 'forecast'), ('supply', 'suppli'), ('chains', 'chain'), (':', ':'), ('conceptual', 'conceptu'), ('analysis', 'analysi'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('demand', 'demand'), ('forecasting', 'forecast'), ('supply', 'suppli'), ('chains', 'chain'), (':', ':'), ('conceptual', 'conceptu'), ('analysis', 'analysi'), ('..', '..')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('demand', 'demand'), ('forecasting', 'forecasting'), ('supply', 'supply'), ('chains', 'chain'), (':', ':'), ('conceptual', 'conceptual'), ('analysis', 'analysis'), ('..', '..')]



============================ Sentence 808 =============================

The International Journal of Logistics Management, Volume 29,   pp. 


>> Tokens are: 
 ['The', 'International', 'Journal', 'Logistics', 'Management', ',', 'Volume', '29', ',', 'pp', '.']

>> Bigrams are: 
 [('The', 'International'), ('International', 'Journal'), ('Journal', 'Logistics'), ('Logistics', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '29'), ('29', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('The', 'International', 'Journal'), ('International', 'Journal', 'Logistics'), ('Journal', 'Logistics', 'Management'), ('Logistics', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '29'), ('Volume', '29', ','), ('29', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('International', 'NNP'), ('Journal', 'NNP'), ('Logistics', 'NNP'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('29', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    The/DT
    International/NNP
    Journal/NNP
    Logistics/NNP
    Management/NNP)
  ,/,
  (NP Volume/NN)
  29/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['The International Journal Logistics Management', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Logistics Management'), ('ORGANIZATION', 'Volume 29')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('International', 'intern'), ('Journal', 'journal'), ('Logistics', 'logist'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('29', '29'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('International', 'intern'), ('Journal', 'journal'), ('Logistics', 'logist'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('29', '29'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('International', 'International'), ('Journal', 'Journal'), ('Logistics', 'Logistics'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('29', '29'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 809 =============================

739-766. 


>> Tokens are: 
 ['739-766', '.']

>> Bigrams are: 
 [('739-766', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('739-766', 'JJ'), ('.', '.')]

 (S 739-766/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('739-766', '739-766'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('739-766', '739-766'), ('.', '.')]

>> Lemmatization: 
 [('739-766', '739-766'), ('.', '.')]



============================ Sentence 810 =============================

Jagadish, H.V., Gehrke, J., Labrinidis, A., Papakonstantinou, Y., Patel, J.M., Ramakrishnan, R.   and Shahabi, C., 2014. 


>> Tokens are: 
 ['Jagadish', ',', 'H.V.', ',', 'Gehrke', ',', 'J.', ',', 'Labrinidis', ',', 'A.', ',', 'Papakonstantinou', ',', 'Y.', ',', 'Patel', ',', 'J.M.', ',', 'Ramakrishnan', ',', 'R.', 'Shahabi', ',', 'C.', ',', '2014', '.']

>> Bigrams are: 
 [('Jagadish', ','), (',', 'H.V.'), ('H.V.', ','), (',', 'Gehrke'), ('Gehrke', ','), (',', 'J.'), ('J.', ','), (',', 'Labrinidis'), ('Labrinidis', ','), (',', 'A.'), ('A.', ','), (',', 'Papakonstantinou'), ('Papakonstantinou', ','), (',', 'Y.'), ('Y.', ','), (',', 'Patel'), ('Patel', ','), (',', 'J.M.'), ('J.M.', ','), (',', 'Ramakrishnan'), ('Ramakrishnan', ','), (',', 'R.'), ('R.', 'Shahabi'), ('Shahabi', ','), (',', 'C.'), ('C.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Jagadish', ',', 'H.V.'), (',', 'H.V.', ','), ('H.V.', ',', 'Gehrke'), (',', 'Gehrke', ','), ('Gehrke', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Labrinidis'), (',', 'Labrinidis', ','), ('Labrinidis', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Papakonstantinou'), (',', 'Papakonstantinou', ','), ('Papakonstantinou', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Patel'), (',', 'Patel', ','), ('Patel', ',', 'J.M.'), (',', 'J.M.', ','), ('J.M.', ',', 'Ramakrishnan'), (',', 'Ramakrishnan', ','), ('Ramakrishnan', ',', 'R.'), (',', 'R.', 'Shahabi'), ('R.', 'Shahabi', ','), ('Shahabi', ',', 'C.'), (',', 'C.', ','), ('C.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Jagadish', 'JJ'), (',', ','), ('H.V.', 'NNP'), (',', ','), ('Gehrke', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Labrinidis', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Papakonstantinou', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Patel', 'NNP'), (',', ','), ('J.M.', 'NNP'), (',', ','), ('Ramakrishnan', 'NNP'), (',', ','), ('R.', 'NNP'), ('Shahabi', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  Jagadish/JJ
  ,/,
  (NP H.V./NNP)
  ,/,
  (NP Gehrke/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Labrinidis/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Papakonstantinou/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Patel/NNP)
  ,/,
  (NP J.M./NNP)
  ,/,
  (NP Ramakrishnan/NNP)
  ,/,
  (NP R./NNP Shahabi/NNP)
  ,/,
  (NP C./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['H.V.', 'Gehrke', 'J.', 'Labrinidis', 'A.', 'Papakonstantinou', 'Y.', 'Patel', 'J.M.', 'Ramakrishnan', 'R. Shahabi', 'C.']

>> Named Entities are: 
 [('GPE', 'Jagadish'), ('GPE', 'Gehrke'), ('ORGANIZATION', 'Labrinidis'), ('PERSON', 'Papakonstantinou'), ('PERSON', 'Patel'), ('PERSON', 'Ramakrishnan')] 

>> Stemming using Porter Stemmer: 
 [('Jagadish', 'jagadish'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('Gehrke', 'gehrk'), (',', ','), ('J.', 'j.'), (',', ','), ('Labrinidis', 'labrinidi'), (',', ','), ('A.', 'a.'), (',', ','), ('Papakonstantinou', 'papakonstantin'), (',', ','), ('Y.', 'y.'), (',', ','), ('Patel', 'patel'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), (',', ','), ('R.', 'r.'), ('Shahabi', 'shahabi'), (',', ','), ('C.', 'c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jagadish', 'jagadish'), (',', ','), ('H.V.', 'h.v.'), (',', ','), ('Gehrke', 'gehrk'), (',', ','), ('J.', 'j.'), (',', ','), ('Labrinidis', 'labrinidi'), (',', ','), ('A.', 'a.'), (',', ','), ('Papakonstantinou', 'papakonstantinou'), (',', ','), ('Y.', 'y.'), (',', ','), ('Patel', 'patel'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('Ramakrishnan', 'ramakrishnan'), (',', ','), ('R.', 'r.'), ('Shahabi', 'shahabi'), (',', ','), ('C.', 'c.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Jagadish', 'Jagadish'), (',', ','), ('H.V.', 'H.V.'), (',', ','), ('Gehrke', 'Gehrke'), (',', ','), ('J.', 'J.'), (',', ','), ('Labrinidis', 'Labrinidis'), (',', ','), ('A.', 'A.'), (',', ','), ('Papakonstantinou', 'Papakonstantinou'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Patel', 'Patel'), (',', ','), ('J.M.', 'J.M.'), (',', ','), ('Ramakrishnan', 'Ramakrishnan'), (',', ','), ('R.', 'R.'), ('Shahabi', 'Shahabi'), (',', ','), ('C.', 'C.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 811 =============================

Big data and its technical challenges. 


>> Tokens are: 
 ['Big', 'data', 'technical', 'challenges', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'technical'), ('technical', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('Big', 'data', 'technical'), ('data', 'technical', 'challenges'), ('technical', 'challenges', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('technical', 'JJ'), ('challenges', 'NNS'), ('.', '.')]

 (S (NP Big/NNP data/NNS) (NP technical/JJ challenges/NNS) ./.) 


>> Noun Phrases are: 
 ['Big data', 'technical challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('technical', 'technic'), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('technical', 'technical'), ('challenges', 'challenge'), ('.', '.')]



============================ Sentence 812 =============================

Communications of the ACM, Volume   57, pp. 


>> Tokens are: 
 ['Communications', 'ACM', ',', 'Volume', '57', ',', 'pp', '.']

>> Bigrams are: 
 [('Communications', 'ACM'), ('ACM', ','), (',', 'Volume'), ('Volume', '57'), ('57', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Communications', 'ACM', ','), ('ACM', ',', 'Volume'), (',', 'Volume', '57'), ('Volume', '57', ','), ('57', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Communications', 'NNS'), ('ACM', 'NNP'), (',', ','), ('Volume', 'NN'), ('57', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Communications/NNS ACM/NNP)
  ,/,
  (NP Volume/NN)
  57/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Communications ACM', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM'), ('ORGANIZATION', 'Volume 57')] 

>> Stemming using Porter Stemmer: 
 [('Communications', 'commun'), ('ACM', 'acm'), (',', ','), ('Volume', 'volum'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Communications', 'communic'), ('ACM', 'acm'), (',', ','), ('Volume', 'volum'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Communications', 'Communications'), ('ACM', 'ACM'), (',', ','), ('Volume', 'Volume'), ('57', '57'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 813 =============================

86-94. 


>> Tokens are: 
 ['86-94', '.']

>> Bigrams are: 
 [('86-94', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('86-94', 'CD'), ('.', '.')]

 (S 86-94/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('86-94', '86-94'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('86-94', '86-94'), ('.', '.')]

>> Lemmatization: 
 [('86-94', '86-94'), ('.', '.')]



============================ Sentence 814 =============================

Jiang, C., Zhang, H., Ren, Y., Han, Z., Chen, K.C. 


>> Tokens are: 
 ['Jiang', ',', 'C.', ',', 'Zhang', ',', 'H.', ',', 'Ren', ',', 'Y.', ',', 'Han', ',', 'Z.', ',', 'Chen', ',', 'K.C', '.']

>> Bigrams are: 
 [('Jiang', ','), (',', 'C.'), ('C.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'H.'), ('H.', ','), (',', 'Ren'), ('Ren', ','), (',', 'Y.'), ('Y.', ','), (',', 'Han'), ('Han', ','), (',', 'Z.'), ('Z.', ','), (',', 'Chen'), ('Chen', ','), (',', 'K.C'), ('K.C', '.')]

>> Trigrams are: 
 [('Jiang', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Ren'), (',', 'Ren', ','), ('Ren', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Han'), (',', 'Han', ','), ('Han', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Chen'), (',', 'Chen', ','), ('Chen', ',', 'K.C'), (',', 'K.C', '.')]

>> POS Tags are: 
 [('Jiang', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Ren', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Han', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Chen', 'NNP'), (',', ','), ('K.C', 'NNP'), ('.', '.')]

 (S
  (NP Jiang/NNP)
  ,/,
  (NP C./NNP)
  ,/,
  (NP Zhang/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Ren/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Han/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  (NP Chen/NNP)
  ,/,
  (NP K.C/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Jiang', 'C.', 'Zhang', 'H.', 'Ren', 'Y.', 'Han', 'Z.', 'Chen', 'K.C']

>> Named Entities are: 
 [('PERSON', 'Jiang'), ('PERSON', 'Zhang'), ('PERSON', 'Ren'), ('PERSON', 'Han'), ('GPE', 'Chen')] 

>> Stemming using Porter Stemmer: 
 [('Jiang', 'jiang'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.', 'h.'), (',', ','), ('Ren', 'ren'), (',', ','), ('Y.', 'y.'), (',', ','), ('Han', 'han'), (',', ','), ('Z.', 'z.'), (',', ','), ('Chen', 'chen'), (',', ','), ('K.C', 'k.c'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Jiang', 'jiang'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.', 'h.'), (',', ','), ('Ren', 'ren'), (',', ','), ('Y.', 'y.'), (',', ','), ('Han', 'han'), (',', ','), ('Z.', 'z.'), (',', ','), ('Chen', 'chen'), (',', ','), ('K.C', 'k.c'), ('.', '.')]

>> Lemmatization: 
 [('Jiang', 'Jiang'), (',', ','), ('C.', 'C.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('H.', 'H.'), (',', ','), ('Ren', 'Ren'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Han', 'Han'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Chen', 'Chen'), (',', ','), ('K.C', 'K.C'), ('.', '.')]



============================ Sentence 815 =============================

and Hanzo, L., 2017. 


>> Tokens are: 
 ['Hanzo', ',', 'L.', ',', '2017', '.']

>> Bigrams are: 
 [('Hanzo', ','), (',', 'L.'), ('L.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Hanzo', ',', 'L.'), (',', 'L.', ','), ('L.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Hanzo', 'NNP'), (',', ','), ('L.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S (NP Hanzo/NNP) ,/, (NP L./NNP) ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 ['Hanzo', 'L.']

>> Named Entities are: 
 [('GPE', 'Hanzo')] 

>> Stemming using Porter Stemmer: 
 [('Hanzo', 'hanzo'), (',', ','), ('L.', 'l.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hanzo', 'hanzo'), (',', ','), ('L.', 'l.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Hanzo', 'Hanzo'), (',', ','), ('L.', 'L.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 816 =============================

Machine learning   paradigms for next-generation wireless networks.. IEEE Wireless Communications journal,   Volume 24, pp. 


>> Tokens are: 
 ['Machine', 'learning', 'paradigms', 'next-generation', 'wireless', 'networks', '..', 'IEEE', 'Wireless', 'Communications', 'journal', ',', 'Volume', '24', ',', 'pp', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'paradigms'), ('paradigms', 'next-generation'), ('next-generation', 'wireless'), ('wireless', 'networks'), ('networks', '..'), ('..', 'IEEE'), ('IEEE', 'Wireless'), ('Wireless', 'Communications'), ('Communications', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '24'), ('24', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'paradigms'), ('learning', 'paradigms', 'next-generation'), ('paradigms', 'next-generation', 'wireless'), ('next-generation', 'wireless', 'networks'), ('wireless', 'networks', '..'), ('networks', '..', 'IEEE'), ('..', 'IEEE', 'Wireless'), ('IEEE', 'Wireless', 'Communications'), ('Wireless', 'Communications', 'journal'), ('Communications', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '24'), ('Volume', '24', ','), ('24', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('paradigms', 'JJ'), ('next-generation', 'JJ'), ('wireless', 'NN'), ('networks', 'NNS'), ('..', 'VBP'), ('IEEE', 'NNP'), ('Wireless', 'NNP'), ('Communications', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('24', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP paradigms/JJ next-generation/JJ wireless/NN networks/NNS)
  ../VBP
  (NP IEEE/NNP Wireless/NNP Communications/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  24/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'paradigms next-generation wireless networks', 'IEEE Wireless Communications journal', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Machine'), ('ORGANIZATION', 'IEEE Wireless Communications'), ('ORGANIZATION', 'Volume 24')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('paradigms', 'paradigm'), ('next-generation', 'next-gener'), ('wireless', 'wireless'), ('networks', 'network'), ('..', '..'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'commun'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('24', '24'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('paradigms', 'paradigm'), ('next-generation', 'next-gener'), ('wireless', 'wireless'), ('networks', 'network'), ('..', '..'), ('IEEE', 'ieee'), ('Wireless', 'wireless'), ('Communications', 'communic'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('24', '24'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('paradigms', 'paradigm'), ('next-generation', 'next-generation'), ('wireless', 'wireless'), ('networks', 'network'), ('..', '..'), ('IEEE', 'IEEE'), ('Wireless', 'Wireless'), ('Communications', 'Communications'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('24', '24'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 817 =============================

98-105. 


>> Tokens are: 
 ['98-105', '.']

>> Bigrams are: 
 [('98-105', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('98-105', 'CD'), ('.', '.')]

 (S 98-105/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('98-105', '98-105'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('98-105', '98-105'), ('.', '.')]

>> Lemmatization: 
 [('98-105', '98-105'), ('.', '.')]



============================ Sentence 818 =============================

Karpovsky, A. and Galliers, R.D., 2015. 


>> Tokens are: 
 ['Karpovsky', ',', 'A.', 'Galliers', ',', 'R.D.', ',', '2015', '.']

>> Bigrams are: 
 [('Karpovsky', ','), (',', 'A.'), ('A.', 'Galliers'), ('Galliers', ','), (',', 'R.D.'), ('R.D.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Karpovsky', ',', 'A.'), (',', 'A.', 'Galliers'), ('A.', 'Galliers', ','), ('Galliers', ',', 'R.D.'), (',', 'R.D.', ','), ('R.D.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Karpovsky', 'NNP'), (',', ','), ('A.', 'NNP'), ('Galliers', 'NNP'), (',', ','), ('R.D.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Karpovsky/NNP)
  ,/,
  (NP A./NNP Galliers/NNP)
  ,/,
  (NP R.D./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Karpovsky', 'A. Galliers', 'R.D.']

>> Named Entities are: 
 [('GPE', 'Karpovsky')] 

>> Stemming using Porter Stemmer: 
 [('Karpovsky', 'karpovski'), (',', ','), ('A.', 'a.'), ('Galliers', 'gallier'), (',', ','), ('R.D.', 'r.d.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Karpovsky', 'karpovski'), (',', ','), ('A.', 'a.'), ('Galliers', 'gallier'), (',', ','), ('R.D.', 'r.d.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Karpovsky', 'Karpovsky'), (',', ','), ('A.', 'A.'), ('Galliers', 'Galliers'), (',', ','), ('R.D.', 'R.D.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 819 =============================

Aligning in practice: from current cases to a new agenda. 


>> Tokens are: 
 ['Aligning', 'practice', ':', 'current', 'cases', 'new', 'agenda', '.']

>> Bigrams are: 
 [('Aligning', 'practice'), ('practice', ':'), (':', 'current'), ('current', 'cases'), ('cases', 'new'), ('new', 'agenda'), ('agenda', '.')]

>> Trigrams are: 
 [('Aligning', 'practice', ':'), ('practice', ':', 'current'), (':', 'current', 'cases'), ('current', 'cases', 'new'), ('cases', 'new', 'agenda'), ('new', 'agenda', '.')]

>> POS Tags are: 
 [('Aligning', 'VBG'), ('practice', 'NN'), (':', ':'), ('current', 'JJ'), ('cases', 'NNS'), ('new', 'JJ'), ('agenda', 'NN'), ('.', '.')]

 (S
  Aligning/VBG
  (NP practice/NN)
  :/:
  (NP current/JJ cases/NNS)
  (NP new/JJ agenda/NN)
  ./.) 


>> Noun Phrases are: 
 ['practice', 'current cases', 'new agenda']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Aligning', 'align'), ('practice', 'practic'), (':', ':'), ('current', 'current'), ('cases', 'case'), ('new', 'new'), ('agenda', 'agenda'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Aligning', 'align'), ('practice', 'practic'), (':', ':'), ('current', 'current'), ('cases', 'case'), ('new', 'new'), ('agenda', 'agenda'), ('.', '.')]

>> Lemmatization: 
 [('Aligning', 'Aligning'), ('practice', 'practice'), (':', ':'), ('current', 'current'), ('cases', 'case'), ('new', 'new'), ('agenda', 'agenda'), ('.', '.')]



============================ Sentence 820 =============================

Journal of Information Technology, pp. 


>> Tokens are: 
 ['Journal', 'Information', 'Technology', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Information'), ('Information', 'Technology'), ('Technology', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Information', 'Technology'), ('Information', 'Technology', ','), ('Technology', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Journal/NNP Information/NNP Technology/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Journal Information Technology', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Information Technology')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 821 =============================

136-160. 


>> Tokens are: 
 ['136-160', '.']

>> Bigrams are: 
 [('136-160', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('136-160', 'JJ'), ('.', '.')]

 (S 136-160/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('136-160', '136-160'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('136-160', '136-160'), ('.', '.')]

>> Lemmatization: 
 [('136-160', '136-160'), ('.', '.')]



============================ Sentence 822 =============================

Khan, N., Yaqoob, I., Hashem, I.A.T., Inayat, Z., Ali, M., Kamaleldin, W., Alam, M., Shiraz, M.   and Gani, A., 2014 . 


>> Tokens are: 
 ['Khan', ',', 'N.', ',', 'Yaqoob', ',', 'I.', ',', 'Hashem', ',', 'I.A.T.', ',', 'Inayat', ',', 'Z.', ',', 'Ali', ',', 'M.', ',', 'Kamaleldin', ',', 'W.', ',', 'Alam', ',', 'M.', ',', 'Shiraz', ',', 'M.', 'Gani', ',', 'A.', ',', '2014', '.']

>> Bigrams are: 
 [('Khan', ','), (',', 'N.'), ('N.', ','), (',', 'Yaqoob'), ('Yaqoob', ','), (',', 'I.'), ('I.', ','), (',', 'Hashem'), ('Hashem', ','), (',', 'I.A.T.'), ('I.A.T.', ','), (',', 'Inayat'), ('Inayat', ','), (',', 'Z.'), ('Z.', ','), (',', 'Ali'), ('Ali', ','), (',', 'M.'), ('M.', ','), (',', 'Kamaleldin'), ('Kamaleldin', ','), (',', 'W.'), ('W.', ','), (',', 'Alam'), ('Alam', ','), (',', 'M.'), ('M.', ','), (',', 'Shiraz'), ('Shiraz', ','), (',', 'M.'), ('M.', 'Gani'), ('Gani', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Khan', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Yaqoob'), (',', 'Yaqoob', ','), ('Yaqoob', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Hashem'), (',', 'Hashem', ','), ('Hashem', ',', 'I.A.T.'), (',', 'I.A.T.', ','), ('I.A.T.', ',', 'Inayat'), (',', 'Inayat', ','), ('Inayat', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Ali'), (',', 'Ali', ','), ('Ali', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Kamaleldin'), (',', 'Kamaleldin', ','), ('Kamaleldin', ',', 'W.'), (',', 'W.', ','), ('W.', ',', 'Alam'), (',', 'Alam', ','), ('Alam', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Shiraz'), (',', 'Shiraz', ','), ('Shiraz', ',', 'M.'), (',', 'M.', 'Gani'), ('M.', 'Gani', ','), ('Gani', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Khan', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Yaqoob', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Hashem', 'NNP'), (',', ','), ('I.A.T.', 'NNP'), (',', ','), ('Inayat', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Ali', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Kamaleldin', 'NNP'), (',', ','), ('W.', 'NNP'), (',', ','), ('Alam', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Shiraz', 'NNP'), (',', ','), ('M.', 'NNP'), ('Gani', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Khan/NNP)
  ,/,
  (NP N./NNP)
  ,/,
  (NP Yaqoob/NNP)
  ,/,
  (NP I./NNP)
  ,/,
  (NP Hashem/NNP)
  ,/,
  (NP I.A.T./NNP)
  ,/,
  (NP Inayat/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  (NP Ali/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Kamaleldin/NNP)
  ,/,
  (NP W./NNP)
  ,/,
  (NP Alam/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Shiraz/NNP)
  ,/,
  (NP M./NNP Gani/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Khan', 'N.', 'Yaqoob', 'I.', 'Hashem', 'I.A.T.', 'Inayat', 'Z.', 'Ali', 'M.', 'Kamaleldin', 'W.', 'Alam', 'M.', 'Shiraz', 'M. Gani', 'A.']

>> Named Entities are: 
 [('GPE', 'Khan'), ('GPE', 'Yaqoob'), ('GPE', 'Hashem'), ('GPE', 'Inayat'), ('PERSON', 'Ali'), ('PERSON', 'Kamaleldin'), ('PERSON', 'Alam'), ('GPE', 'Shiraz')] 

>> Stemming using Porter Stemmer: 
 [('Khan', 'khan'), (',', ','), ('N.', 'n.'), (',', ','), ('Yaqoob', 'yaqoob'), (',', ','), ('I.', 'i.'), (',', ','), ('Hashem', 'hashem'), (',', ','), ('I.A.T.', 'i.a.t.'), (',', ','), ('Inayat', 'inayat'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ali', 'ali'), (',', ','), ('M.', 'm.'), (',', ','), ('Kamaleldin', 'kamaleldin'), (',', ','), ('W.', 'w.'), (',', ','), ('Alam', 'alam'), (',', ','), ('M.', 'm.'), (',', ','), ('Shiraz', 'shiraz'), (',', ','), ('M.', 'm.'), ('Gani', 'gani'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Khan', 'khan'), (',', ','), ('N.', 'n.'), (',', ','), ('Yaqoob', 'yaqoob'), (',', ','), ('I.', 'i.'), (',', ','), ('Hashem', 'hashem'), (',', ','), ('I.A.T.', 'i.a.t.'), (',', ','), ('Inayat', 'inayat'), (',', ','), ('Z.', 'z.'), (',', ','), ('Ali', 'ali'), (',', ','), ('M.', 'm.'), (',', ','), ('Kamaleldin', 'kamaleldin'), (',', ','), ('W.', 'w.'), (',', ','), ('Alam', 'alam'), (',', ','), ('M.', 'm.'), (',', ','), ('Shiraz', 'shiraz'), (',', ','), ('M.', 'm.'), ('Gani', 'gani'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Khan', 'Khan'), (',', ','), ('N.', 'N.'), (',', ','), ('Yaqoob', 'Yaqoob'), (',', ','), ('I.', 'I.'), (',', ','), ('Hashem', 'Hashem'), (',', ','), ('I.A.T.', 'I.A.T.'), (',', ','), ('Inayat', 'Inayat'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Ali', 'Ali'), (',', ','), ('M.', 'M.'), (',', ','), ('Kamaleldin', 'Kamaleldin'), (',', ','), ('W.', 'W.'), (',', ','), ('Alam', 'Alam'), (',', ','), ('M.', 'M.'), (',', ','), ('Shiraz', 'Shiraz'), (',', ','), ('M.', 'M.'), ('Gani', 'Gani'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 823 =============================

Big data: survey, technologies, opportunities, and challenges. 


>> Tokens are: 
 ['Big', 'data', ':', 'survey', ',', 'technologies', ',', 'opportunities', ',', 'challenges', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'survey'), ('survey', ','), (',', 'technologies'), ('technologies', ','), (',', 'opportunities'), ('opportunities', ','), (',', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'survey'), (':', 'survey', ','), ('survey', ',', 'technologies'), (',', 'technologies', ','), ('technologies', ',', 'opportunities'), (',', 'opportunities', ','), ('opportunities', ',', 'challenges'), (',', 'challenges', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('survey', 'NN'), (',', ','), ('technologies', 'NNS'), (',', ','), ('opportunities', 'NNS'), (',', ','), ('challenges', 'NNS'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  (NP survey/NN)
  ,/,
  (NP technologies/NNS)
  ,/,
  (NP opportunities/NNS)
  ,/,
  (NP challenges/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'survey', 'technologies', 'opportunities', 'challenges']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('survey', 'survey'), (',', ','), ('technologies', 'technolog'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('survey', 'survey'), (',', ','), ('technologies', 'technolog'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('survey', 'survey'), (',', ','), ('technologies', 'technology'), (',', ','), ('opportunities', 'opportunity'), (',', ','), ('challenges', 'challenge'), ('.', '.')]



============================ Sentence 824 =============================

The Scientific   World Journal. 


>> Tokens are: 
 ['The', 'Scientific', 'World', 'Journal', '.']

>> Bigrams are: 
 [('The', 'Scientific'), ('Scientific', 'World'), ('World', 'Journal'), ('Journal', '.')]

>> Trigrams are: 
 [('The', 'Scientific', 'World'), ('Scientific', 'World', 'Journal'), ('World', 'Journal', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('Scientific', 'NNP'), ('World', 'NNP'), ('Journal', 'NNP'), ('.', '.')]

 (S (NP The/DT Scientific/NNP World/NNP Journal/NNP) ./.) 


>> Noun Phrases are: 
 ['The Scientific World Journal']

>> Named Entities are: 
 [('ORGANIZATION', 'Scientific')] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('Scientific', 'scientif'), ('World', 'world'), ('Journal', 'journal'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('Scientific', 'scientif'), ('World', 'world'), ('Journal', 'journal'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('Scientific', 'Scientific'), ('World', 'World'), ('Journal', 'Journal'), ('.', '.')]



============================ Sentence 825 =============================

Kiron, D., Prentice, P.K. 


>> Tokens are: 
 ['Kiron', ',', 'D.', ',', 'Prentice', ',', 'P.K', '.']

>> Bigrams are: 
 [('Kiron', ','), (',', 'D.'), ('D.', ','), (',', 'Prentice'), ('Prentice', ','), (',', 'P.K'), ('P.K', '.')]

>> Trigrams are: 
 [('Kiron', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Prentice'), (',', 'Prentice', ','), ('Prentice', ',', 'P.K'), (',', 'P.K', '.')]

>> POS Tags are: 
 [('Kiron', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Prentice', 'NNP'), (',', ','), ('P.K', 'NNP'), ('.', '.')]

 (S
  (NP Kiron/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  (NP Prentice/NNP)
  ,/,
  (NP P.K/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Kiron', 'D.', 'Prentice', 'P.K']

>> Named Entities are: 
 [('GPE', 'Kiron')] 

>> Stemming using Porter Stemmer: 
 [('Kiron', 'kiron'), (',', ','), ('D.', 'd.'), (',', ','), ('Prentice', 'prentic'), (',', ','), ('P.K', 'p.k'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kiron', 'kiron'), (',', ','), ('D.', 'd.'), (',', ','), ('Prentice', 'prentic'), (',', ','), ('P.K', 'p.k'), ('.', '.')]

>> Lemmatization: 
 [('Kiron', 'Kiron'), (',', ','), ('D.', 'D.'), (',', ','), ('Prentice', 'Prentice'), (',', ','), ('P.K', 'P.K'), ('.', '.')]



============================ Sentence 826 =============================

and Ferguson, R.B., 2014. 


>> Tokens are: 
 ['Ferguson', ',', 'R.B.', ',', '2014', '.']

>> Bigrams are: 
 [('Ferguson', ','), (',', 'R.B.'), ('R.B.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Ferguson', ',', 'R.B.'), (',', 'R.B.', ','), ('R.B.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Ferguson', 'NNP'), (',', ','), ('R.B.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Ferguson/NNP) ,/, (NP R.B./NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Ferguson', 'R.B.']

>> Named Entities are: 
 [('GPE', 'Ferguson')] 

>> Stemming using Porter Stemmer: 
 [('Ferguson', 'ferguson'), (',', ','), ('R.B.', 'r.b.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ferguson', 'ferguson'), (',', ','), ('R.B.', 'r.b.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Ferguson', 'Ferguson'), (',', ','), ('R.B.', 'R.B.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 827 =============================

The analytics mandate. 


>> Tokens are: 
 ['The', 'analytics', 'mandate', '.']

>> Bigrams are: 
 [('The', 'analytics'), ('analytics', 'mandate'), ('mandate', '.')]

>> Trigrams are: 
 [('The', 'analytics', 'mandate'), ('analytics', 'mandate', '.')]

>> POS Tags are: 
 [('The', 'DT'), ('analytics', 'NNS'), ('mandate', 'NN'), ('.', '.')]

 (S (NP The/DT analytics/NNS mandate/NN) ./.) 


>> Noun Phrases are: 
 ['The analytics mandate']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('The', 'the'), ('analytics', 'analyt'), ('mandate', 'mandat'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('The', 'the'), ('analytics', 'analyt'), ('mandate', 'mandat'), ('.', '.')]

>> Lemmatization: 
 [('The', 'The'), ('analytics', 'analytics'), ('mandate', 'mandate'), ('.', '.')]



============================ Sentence 828 =============================

MIT Sloan   management review, p. 1. 


>> Tokens are: 
 ['MIT', 'Sloan', 'management', 'review', ',', 'p.', '1', '.']

>> Bigrams are: 
 [('MIT', 'Sloan'), ('Sloan', 'management'), ('management', 'review'), ('review', ','), (',', 'p.'), ('p.', '1'), ('1', '.')]

>> Trigrams are: 
 [('MIT', 'Sloan', 'management'), ('Sloan', 'management', 'review'), ('management', 'review', ','), ('review', ',', 'p.'), (',', 'p.', '1'), ('p.', '1', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('Sloan', 'NNP'), ('management', 'NN'), ('review', 'NN'), (',', ','), ('p.', 'JJ'), ('1', 'CD'), ('.', '.')]

 (S (NP MIT/NNP Sloan/NNP management/NN review/NN) ,/, p./JJ 1/CD ./.) 


>> Noun Phrases are: 
 ['MIT Sloan management review']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT Sloan')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('Sloan', 'sloan'), ('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('Sloan', 'sloan'), ('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('Sloan', 'Sloan'), ('management', 'management'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]



============================ Sentence 829 =============================

Kitchin, R., 2014. 


>> Tokens are: 
 ['Kitchin', ',', 'R.', ',', '2014', '.']

>> Bigrams are: 
 [('Kitchin', ','), (',', 'R.'), ('R.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Kitchin', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Kitchin', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Kitchin/NNP) ,/, (NP R./NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Kitchin', 'R.']

>> Named Entities are: 
 [('GPE', 'Kitchin')] 

>> Stemming using Porter Stemmer: 
 [('Kitchin', 'kitchin'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kitchin', 'kitchin'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Kitchin', 'Kitchin'), (',', ','), ('R.', 'R.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 830 =============================

Big Data, new epistemologies and paradigm shifts.. Big Data & Society Journal,   p. 2053951714528481. 


>> Tokens are: 
 ['Big', 'Data', ',', 'new', 'epistemologies', 'paradigm', 'shifts', '..', 'Big', 'Data', '&', 'Society', 'Journal', ',', 'p.', '2053951714528481', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', ','), (',', 'new'), ('new', 'epistemologies'), ('epistemologies', 'paradigm'), ('paradigm', 'shifts'), ('shifts', '..'), ('..', 'Big'), ('Big', 'Data'), ('Data', '&'), ('&', 'Society'), ('Society', 'Journal'), ('Journal', ','), (',', 'p.'), ('p.', '2053951714528481'), ('2053951714528481', '.')]

>> Trigrams are: 
 [('Big', 'Data', ','), ('Data', ',', 'new'), (',', 'new', 'epistemologies'), ('new', 'epistemologies', 'paradigm'), ('epistemologies', 'paradigm', 'shifts'), ('paradigm', 'shifts', '..'), ('shifts', '..', 'Big'), ('..', 'Big', 'Data'), ('Big', 'Data', '&'), ('Data', '&', 'Society'), ('&', 'Society', 'Journal'), ('Society', 'Journal', ','), ('Journal', ',', 'p.'), (',', 'p.', '2053951714528481'), ('p.', '2053951714528481', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('new', 'JJ'), ('epistemologies', 'NNS'), ('paradigm', 'VBP'), ('shifts', 'NNS'), ('..', 'VBP'), ('Big', 'NNP'), ('Data', 'NNP'), ('&', 'CC'), ('Society', 'NNP'), ('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('2053951714528481', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP)
  ,/,
  (NP new/JJ epistemologies/NNS)
  paradigm/VBP
  (NP shifts/NNS)
  ../VBP
  (NP Big/NNP Data/NNP)
  &/CC
  (NP Society/NNP Journal/NNP)
  ,/,
  p./VBD
  2053951714528481/CD
  ./.) 


>> Noun Phrases are: 
 ['Big Data', 'new epistemologies', 'shifts', 'Big Data', 'Society Journal']

>> Named Entities are: 
 [('PERSON', 'Society Journal')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), (',', ','), ('new', 'new'), ('epistemologies', 'epistemolog'), ('paradigm', 'paradigm'), ('shifts', 'shift'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('&', '&'), ('Society', 'societi'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('2053951714528481', '2053951714528481'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), (',', ','), ('new', 'new'), ('epistemologies', 'epistemolog'), ('paradigm', 'paradigm'), ('shifts', 'shift'), ('..', '..'), ('Big', 'big'), ('Data', 'data'), ('&', '&'), ('Society', 'societi'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('2053951714528481', '2053951714528481'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), (',', ','), ('new', 'new'), ('epistemologies', 'epistemology'), ('paradigm', 'paradigm'), ('shifts', 'shift'), ('..', '..'), ('Big', 'Big'), ('Data', 'Data'), ('&', '&'), ('Society', 'Society'), ('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('2053951714528481', '2053951714528481'), ('.', '.')]



============================ Sentence 831 =============================

Kotsiantis, Sotiris B and Zaharakis, I and Pintelas, P, 2007. 


>> Tokens are: 
 ['Kotsiantis', ',', 'Sotiris', 'B', 'Zaharakis', ',', 'I', 'Pintelas', ',', 'P', ',', '2007', '.']

>> Bigrams are: 
 [('Kotsiantis', ','), (',', 'Sotiris'), ('Sotiris', 'B'), ('B', 'Zaharakis'), ('Zaharakis', ','), (',', 'I'), ('I', 'Pintelas'), ('Pintelas', ','), (',', 'P'), ('P', ','), (',', '2007'), ('2007', '.')]

>> Trigrams are: 
 [('Kotsiantis', ',', 'Sotiris'), (',', 'Sotiris', 'B'), ('Sotiris', 'B', 'Zaharakis'), ('B', 'Zaharakis', ','), ('Zaharakis', ',', 'I'), (',', 'I', 'Pintelas'), ('I', 'Pintelas', ','), ('Pintelas', ',', 'P'), (',', 'P', ','), ('P', ',', '2007'), (',', '2007', '.')]

>> POS Tags are: 
 [('Kotsiantis', 'NNP'), (',', ','), ('Sotiris', 'NNP'), ('B', 'NNP'), ('Zaharakis', 'NNP'), (',', ','), ('I', 'PRP'), ('Pintelas', 'VBP'), (',', ','), ('P', 'NNP'), (',', ','), ('2007', 'CD'), ('.', '.')]

 (S
  (NP Kotsiantis/NNP)
  ,/,
  (NP Sotiris/NNP B/NNP Zaharakis/NNP)
  ,/,
  I/PRP
  Pintelas/VBP
  ,/,
  (NP P/NNP)
  ,/,
  2007/CD
  ./.) 


>> Noun Phrases are: 
 ['Kotsiantis', 'Sotiris B Zaharakis', 'P']

>> Named Entities are: 
 [('GPE', 'Kotsiantis'), ('PERSON', 'Sotiris B Zaharakis'), ('PERSON', 'P')] 

>> Stemming using Porter Stemmer: 
 [('Kotsiantis', 'kotsianti'), (',', ','), ('Sotiris', 'sotiri'), ('B', 'b'), ('Zaharakis', 'zaharaki'), (',', ','), ('I', 'i'), ('Pintelas', 'pintela'), (',', ','), ('P', 'p'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kotsiantis', 'kotsianti'), (',', ','), ('Sotiris', 'sotiri'), ('B', 'b'), ('Zaharakis', 'zaharaki'), (',', ','), ('I', 'i'), ('Pintelas', 'pintela'), (',', ','), ('P', 'p'), (',', ','), ('2007', '2007'), ('.', '.')]

>> Lemmatization: 
 [('Kotsiantis', 'Kotsiantis'), (',', ','), ('Sotiris', 'Sotiris'), ('B', 'B'), ('Zaharakis', 'Zaharakis'), (',', ','), ('I', 'I'), ('Pintelas', 'Pintelas'), (',', ','), ('P', 'P'), (',', ','), ('2007', '2007'), ('.', '.')]



============================ Sentence 832 =============================

Supervised machine learning: A review   of classification techniques. 


>> Tokens are: 
 ['Supervised', 'machine', 'learning', ':', 'A', 'review', 'classification', 'techniques', '.']

>> Bigrams are: 
 [('Supervised', 'machine'), ('machine', 'learning'), ('learning', ':'), (':', 'A'), ('A', 'review'), ('review', 'classification'), ('classification', 'techniques'), ('techniques', '.')]

>> Trigrams are: 
 [('Supervised', 'machine', 'learning'), ('machine', 'learning', ':'), ('learning', ':', 'A'), (':', 'A', 'review'), ('A', 'review', 'classification'), ('review', 'classification', 'techniques'), ('classification', 'techniques', '.')]

>> POS Tags are: 
 [('Supervised', 'VBN'), ('machine', 'NN'), ('learning', 'NN'), (':', ':'), ('A', 'DT'), ('review', 'NN'), ('classification', 'NN'), ('techniques', 'NNS'), ('.', '.')]

 (S
  Supervised/VBN
  (NP machine/NN learning/NN)
  :/:
  (NP A/DT review/NN classification/NN techniques/NNS)
  ./.) 


>> Noun Phrases are: 
 ['machine learning', 'A review classification techniques']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), (':', ':'), ('A', 'a'), ('review', 'review'), ('classification', 'classif'), ('techniques', 'techniqu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Supervised', 'supervis'), ('machine', 'machin'), ('learning', 'learn'), (':', ':'), ('A', 'a'), ('review', 'review'), ('classification', 'classif'), ('techniques', 'techniqu'), ('.', '.')]

>> Lemmatization: 
 [('Supervised', 'Supervised'), ('machine', 'machine'), ('learning', 'learning'), (':', ':'), ('A', 'A'), ('review', 'review'), ('classification', 'classification'), ('techniques', 'technique'), ('.', '.')]



============================ Sentence 833 =============================

Emerging artificial intelligence applications in computer engineering   journal, 160(2), pp. 


>> Tokens are: 
 ['Emerging', 'artificial', 'intelligence', 'applications', 'computer', 'engineering', 'journal', ',', '160', '(', '2', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Emerging', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'applications'), ('applications', 'computer'), ('computer', 'engineering'), ('engineering', 'journal'), ('journal', ','), (',', '160'), ('160', '('), ('(', '2'), ('2', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Emerging', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'applications'), ('intelligence', 'applications', 'computer'), ('applications', 'computer', 'engineering'), ('computer', 'engineering', 'journal'), ('engineering', 'journal', ','), ('journal', ',', '160'), (',', '160', '('), ('160', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Emerging', 'VBG'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('applications', 'NNS'), ('computer', 'NN'), ('engineering', 'NN'), ('journal', 'NN'), (',', ','), ('160', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  Emerging/VBG
  (NP
    artificial/JJ
    intelligence/NN
    applications/NNS
    computer/NN
    engineering/NN
    journal/NN)
  ,/,
  160/CD
  (/(
  2/CD
  )/)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['artificial intelligence applications computer engineering journal', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Emerging', 'emerg'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('applications', 'applic'), ('computer', 'comput'), ('engineering', 'engin'), ('journal', 'journal'), (',', ','), ('160', '160'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Emerging', 'emerg'), ('artificial', 'artifici'), ('intelligence', 'intellig'), ('applications', 'applic'), ('computer', 'comput'), ('engineering', 'engin'), ('journal', 'journal'), (',', ','), ('160', '160'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Emerging', 'Emerging'), ('artificial', 'artificial'), ('intelligence', 'intelligence'), ('applications', 'application'), ('computer', 'computer'), ('engineering', 'engineering'), ('journal', 'journal'), (',', ','), ('160', '160'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 834 =============================

3--24. 


>> Tokens are: 
 ['3', '--', '24', '.']

>> Bigrams are: 
 [('3', '--'), ('--', '24'), ('24', '.')]

>> Trigrams are: 
 [('3', '--', '24'), ('--', '24', '.')]

>> POS Tags are: 
 [('3', 'CD'), ('--', ':'), ('24', 'CD'), ('.', '.')]

 (S 3/CD --/: 24/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3', '3'), ('--', '--'), ('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3', '3'), ('--', '--'), ('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('3', '3'), ('--', '--'), ('24', '24'), ('.', '.')]



============================ Sentence 835 =============================

Lan, F., Chunlei, W. and Guoqing, M., 2010. 


>> Tokens are: 
 ['Lan', ',', 'F.', ',', 'Chunlei', ',', 'W.', 'Guoqing', ',', 'M.', ',', '2010', '.']

>> Bigrams are: 
 [('Lan', ','), (',', 'F.'), ('F.', ','), (',', 'Chunlei'), ('Chunlei', ','), (',', 'W.'), ('W.', 'Guoqing'), ('Guoqing', ','), (',', 'M.'), ('M.', ','), (',', '2010'), ('2010', '.')]

>> Trigrams are: 
 [('Lan', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Chunlei'), (',', 'Chunlei', ','), ('Chunlei', ',', 'W.'), (',', 'W.', 'Guoqing'), ('W.', 'Guoqing', ','), ('Guoqing', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2010'), (',', '2010', '.')]

>> POS Tags are: 
 [('Lan', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Chunlei', 'NNP'), (',', ','), ('W.', 'NNP'), ('Guoqing', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2010', 'CD'), ('.', '.')]

 (S
  (NP Lan/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  (NP Chunlei/NNP)
  ,/,
  (NP W./NNP Guoqing/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2010/CD
  ./.) 


>> Noun Phrases are: 
 ['Lan', 'F.', 'Chunlei', 'W. Guoqing', 'M.']

>> Named Entities are: 
 [('GPE', 'Lan'), ('PERSON', 'Chunlei')] 

>> Stemming using Porter Stemmer: 
 [('Lan', 'lan'), (',', ','), ('F.', 'f.'), (',', ','), ('Chunlei', 'chunlei'), (',', ','), ('W.', 'w.'), ('Guoqing', 'guoq'), (',', ','), ('M.', 'm.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lan', 'lan'), (',', ','), ('F.', 'f.'), (',', ','), ('Chunlei', 'chunlei'), (',', ','), ('W.', 'w.'), ('Guoqing', 'guoq'), (',', ','), ('M.', 'm.'), (',', ','), ('2010', '2010'), ('.', '.')]

>> Lemmatization: 
 [('Lan', 'Lan'), (',', ','), ('F.', 'F.'), (',', ','), ('Chunlei', 'Chunlei'), (',', ','), ('W.', 'W.'), ('Guoqing', 'Guoqing'), (',', ','), ('M.', 'M.'), (',', ','), ('2010', '2010'), ('.', '.')]



============================ Sentence 836 =============================

A framework for network security situation   awareness based on knowledge discovery. 


>> Tokens are: 
 ['A', 'framework', 'network', 'security', 'situation', 'awareness', 'based', 'knowledge', 'discovery', '.']

>> Bigrams are: 
 [('A', 'framework'), ('framework', 'network'), ('network', 'security'), ('security', 'situation'), ('situation', 'awareness'), ('awareness', 'based'), ('based', 'knowledge'), ('knowledge', 'discovery'), ('discovery', '.')]

>> Trigrams are: 
 [('A', 'framework', 'network'), ('framework', 'network', 'security'), ('network', 'security', 'situation'), ('security', 'situation', 'awareness'), ('situation', 'awareness', 'based'), ('awareness', 'based', 'knowledge'), ('based', 'knowledge', 'discovery'), ('knowledge', 'discovery', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('framework', 'NN'), ('network', 'NN'), ('security', 'NN'), ('situation', 'NN'), ('awareness', 'NN'), ('based', 'VBN'), ('knowledge', 'NN'), ('discovery', 'NN'), ('.', '.')]

 (S
  (NP
    A/DT
    framework/NN
    network/NN
    security/NN
    situation/NN
    awareness/NN)
  based/VBN
  (NP knowledge/NN discovery/NN)
  ./.) 


>> Noun Phrases are: 
 ['A framework network security situation awareness', 'knowledge discovery']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('framework', 'framework'), ('network', 'network'), ('security', 'secur'), ('situation', 'situat'), ('awareness', 'awar'), ('based', 'base'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('framework', 'framework'), ('network', 'network'), ('security', 'secur'), ('situation', 'situat'), ('awareness', 'awar'), ('based', 'base'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('framework', 'framework'), ('network', 'network'), ('security', 'security'), ('situation', 'situation'), ('awareness', 'awareness'), ('based', 'based'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('.', '.')]



============================ Sentence 837 =============================

s.l., IEEE, pp. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 838 =============================

V1-226. 


>> Tokens are: 
 ['V1-226', '.']

>> Bigrams are: 
 [('V1-226', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('V1-226', 'NNP'), ('.', '.')]

 (S (NP V1-226/NNP) ./.) 


>> Noun Phrases are: 
 ['V1-226']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('V1-226', 'v1-226'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('V1-226', 'v1-226'), ('.', '.')]

>> Lemmatization: 
 [('V1-226', 'V1-226'), ('.', '.')]



============================ Sentence 839 =============================

Landset, S., Khoshgoftaar, T.M., Richter, A.N. 


>> Tokens are: 
 ['Landset', ',', 'S.', ',', 'Khoshgoftaar', ',', 'T.M.', ',', 'Richter', ',', 'A.N', '.']

>> Bigrams are: 
 [('Landset', ','), (',', 'S.'), ('S.', ','), (',', 'Khoshgoftaar'), ('Khoshgoftaar', ','), (',', 'T.M.'), ('T.M.', ','), (',', 'Richter'), ('Richter', ','), (',', 'A.N'), ('A.N', '.')]

>> Trigrams are: 
 [('Landset', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Khoshgoftaar'), (',', 'Khoshgoftaar', ','), ('Khoshgoftaar', ',', 'T.M.'), (',', 'T.M.', ','), ('T.M.', ',', 'Richter'), (',', 'Richter', ','), ('Richter', ',', 'A.N'), (',', 'A.N', '.')]

>> POS Tags are: 
 [('Landset', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Khoshgoftaar', 'NNP'), (',', ','), ('T.M.', 'NNP'), (',', ','), ('Richter', 'NNP'), (',', ','), ('A.N', 'NNP'), ('.', '.')]

 (S
  (NP Landset/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Khoshgoftaar/NNP)
  ,/,
  (NP T.M./NNP)
  ,/,
  (NP Richter/NNP)
  ,/,
  (NP A.N/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Landset', 'S.', 'Khoshgoftaar', 'T.M.', 'Richter', 'A.N']

>> Named Entities are: 
 [('GPE', 'Landset'), ('GPE', 'Khoshgoftaar'), ('PERSON', 'Richter')] 

>> Stemming using Porter Stemmer: 
 [('Landset', 'landset'), (',', ','), ('S.', 's.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Richter', 'richter'), (',', ','), ('A.N', 'a.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Landset', 'landset'), (',', ','), ('S.', 's.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Richter', 'richter'), (',', ','), ('A.N', 'a.n'), ('.', '.')]

>> Lemmatization: 
 [('Landset', 'Landset'), (',', ','), ('S.', 'S.'), (',', ','), ('Khoshgoftaar', 'Khoshgoftaar'), (',', ','), ('T.M.', 'T.M.'), (',', ','), ('Richter', 'Richter'), (',', ','), ('A.N', 'A.N'), ('.', '.')]



============================ Sentence 840 =============================

and Hasanin, T., 2015. 


>> Tokens are: 
 ['Hasanin', ',', 'T.', ',', '2015', '.']

>> Bigrams are: 
 [('Hasanin', ','), (',', 'T.'), ('T.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Hasanin', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Hasanin', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S (NP Hasanin/NNP) ,/, (NP T./NNP) ,/, 2015/CD ./.) 


>> Noun Phrases are: 
 ['Hasanin', 'T.']

>> Named Entities are: 
 [('GPE', 'Hasanin')] 

>> Stemming using Porter Stemmer: 
 [('Hasanin', 'hasanin'), (',', ','), ('T.', 't.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Hasanin', 'hasanin'), (',', ','), ('T.', 't.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Hasanin', 'Hasanin'), (',', ','), ('T.', 'T.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 841 =============================

A survey of open source   tools for machine learning with big data in the Hadoop ecosystem.. Journal of Big Data, Volume   2, p. 24. 


>> Tokens are: 
 ['A', 'survey', 'open', 'source', 'tools', 'machine', 'learning', 'big', 'data', 'Hadoop', 'ecosystem', '..', 'Journal', 'Big', 'Data', ',', 'Volume', '2', ',', 'p.', '24', '.']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'open'), ('open', 'source'), ('source', 'tools'), ('tools', 'machine'), ('machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'Hadoop'), ('Hadoop', 'ecosystem'), ('ecosystem', '..'), ('..', 'Journal'), ('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'Volume'), ('Volume', '2'), ('2', ','), (',', 'p.'), ('p.', '24'), ('24', '.')]

>> Trigrams are: 
 [('A', 'survey', 'open'), ('survey', 'open', 'source'), ('open', 'source', 'tools'), ('source', 'tools', 'machine'), ('tools', 'machine', 'learning'), ('machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'Hadoop'), ('data', 'Hadoop', 'ecosystem'), ('Hadoop', 'ecosystem', '..'), ('ecosystem', '..', 'Journal'), ('..', 'Journal', 'Big'), ('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'Volume'), (',', 'Volume', '2'), ('Volume', '2', ','), ('2', ',', 'p.'), (',', 'p.', '24'), ('p.', '24', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('open', 'JJ'), ('source', 'NN'), ('tools', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('Hadoop', 'NNP'), ('ecosystem', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('Volume', 'NN'), ('2', 'CD'), (',', ','), ('p.', 'RB'), ('24', 'CD'), ('.', '.')]

 (S
  (NP A/DT survey/NN)
  (NP open/JJ source/NN tools/NNS machine/NN)
  learning/VBG
  (NP
    big/JJ
    data/NNS
    Hadoop/NNP
    ecosystem/NN
    ../NNP
    Journal/NNP
    Big/NNP
    Data/NNP)
  ,/,
  (NP Volume/NN)
  2/CD
  ,/,
  p./RB
  24/CD
  ./.) 


>> Noun Phrases are: 
 ['A survey', 'open source tools machine', 'big data Hadoop ecosystem .. Journal Big Data', 'Volume']

>> Named Entities are: 
 [('PERSON', 'Hadoop'), ('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('open', 'open'), ('source', 'sourc'), ('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Volume', 'volum'), ('2', '2'), (',', ','), ('p.', 'p.'), ('24', '24'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('open', 'open'), ('source', 'sourc'), ('tools', 'tool'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('Hadoop', 'hadoop'), ('ecosystem', 'ecosystem'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('Volume', 'volum'), ('2', '2'), (',', ','), ('p.', 'p.'), ('24', '24'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('open', 'open'), ('source', 'source'), ('tools', 'tool'), ('machine', 'machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('Hadoop', 'Hadoop'), ('ecosystem', 'ecosystem'), ('..', '..'), ('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('Volume', 'Volume'), ('2', '2'), (',', ','), ('p.', 'p.'), ('24', '24'), ('.', '.')]



============================ Sentence 842 =============================

Laney, D., 2001. 


>> Tokens are: 
 ['Laney', ',', 'D.', ',', '2001', '.']

>> Bigrams are: 
 [('Laney', ','), (',', 'D.'), ('D.', ','), (',', '2001'), ('2001', '.')]

>> Trigrams are: 
 [('Laney', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2001'), (',', '2001', '.')]

>> POS Tags are: 
 [('Laney', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2001', 'CD'), ('.', '.')]

 (S (NP Laney/NNP) ,/, (NP D./NNP) ,/, 2001/CD ./.) 


>> Noun Phrases are: 
 ['Laney', 'D.']

>> Named Entities are: 
 [('GPE', 'Laney')] 

>> Stemming using Porter Stemmer: 
 [('Laney', 'laney'), (',', ','), ('D.', 'd.'), (',', ','), ('2001', '2001'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Laney', 'laney'), (',', ','), ('D.', 'd.'), (',', ','), ('2001', '2001'), ('.', '.')]

>> Lemmatization: 
 [('Laney', 'Laney'), (',', ','), ('D.', 'D.'), (',', ','), ('2001', '2001'), ('.', '.')]



============================ Sentence 843 =============================

3D data management: Controlling data volume, velocity and variety.. META   group research note, Volume 6, p. 1. 


>> Tokens are: 
 ['3D', 'data', 'management', ':', 'Controlling', 'data', 'volume', ',', 'velocity', 'variety', '..', 'META', 'group', 'research', 'note', ',', 'Volume', '6', ',', 'p.', '1', '.']

>> Bigrams are: 
 [('3D', 'data'), ('data', 'management'), ('management', ':'), (':', 'Controlling'), ('Controlling', 'data'), ('data', 'volume'), ('volume', ','), (',', 'velocity'), ('velocity', 'variety'), ('variety', '..'), ('..', 'META'), ('META', 'group'), ('group', 'research'), ('research', 'note'), ('note', ','), (',', 'Volume'), ('Volume', '6'), ('6', ','), (',', 'p.'), ('p.', '1'), ('1', '.')]

>> Trigrams are: 
 [('3D', 'data', 'management'), ('data', 'management', ':'), ('management', ':', 'Controlling'), (':', 'Controlling', 'data'), ('Controlling', 'data', 'volume'), ('data', 'volume', ','), ('volume', ',', 'velocity'), (',', 'velocity', 'variety'), ('velocity', 'variety', '..'), ('variety', '..', 'META'), ('..', 'META', 'group'), ('META', 'group', 'research'), ('group', 'research', 'note'), ('research', 'note', ','), ('note', ',', 'Volume'), (',', 'Volume', '6'), ('Volume', '6', ','), ('6', ',', 'p.'), (',', 'p.', '1'), ('p.', '1', '.')]

>> POS Tags are: 
 [('3D', 'CD'), ('data', 'NNS'), ('management', 'NN'), (':', ':'), ('Controlling', 'NNP'), ('data', 'NN'), ('volume', 'NN'), (',', ','), ('velocity', 'NN'), ('variety', 'NN'), ('..', 'NNP'), ('META', 'NNP'), ('group', 'NN'), ('research', 'NN'), ('note', 'NN'), (',', ','), ('Volume', 'NN'), ('6', 'CD'), (',', ','), ('p.', 'RB'), ('1', 'CD'), ('.', '.')]

 (S
  3D/CD
  (NP data/NNS management/NN)
  :/:
  (NP Controlling/NNP data/NN volume/NN)
  ,/,
  (NP
    velocity/NN
    variety/NN
    ../NNP
    META/NNP
    group/NN
    research/NN
    note/NN)
  ,/,
  (NP Volume/NN)
  6/CD
  ,/,
  p./RB
  1/CD
  ./.) 


>> Noun Phrases are: 
 ['data management', 'Controlling data volume', 'velocity variety .. META group research note', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'META')] 

>> Stemming using Porter Stemmer: 
 [('3D', '3d'), ('data', 'data'), ('management', 'manag'), (':', ':'), ('Controlling', 'control'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('variety', 'varieti'), ('..', '..'), ('META', 'meta'), ('group', 'group'), ('research', 'research'), ('note', 'note'), (',', ','), ('Volume', 'volum'), ('6', '6'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3D', '3d'), ('data', 'data'), ('management', 'manag'), (':', ':'), ('Controlling', 'control'), ('data', 'data'), ('volume', 'volum'), (',', ','), ('velocity', 'veloc'), ('variety', 'varieti'), ('..', '..'), ('META', 'meta'), ('group', 'group'), ('research', 'research'), ('note', 'note'), (',', ','), ('Volume', 'volum'), ('6', '6'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('3D', '3D'), ('data', 'data'), ('management', 'management'), (':', ':'), ('Controlling', 'Controlling'), ('data', 'data'), ('volume', 'volume'), (',', ','), ('velocity', 'velocity'), ('variety', 'variety'), ('..', '..'), ('META', 'META'), ('group', 'group'), ('research', 'research'), ('note', 'note'), (',', ','), ('Volume', 'Volume'), ('6', '6'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]



============================ Sentence 844 =============================

LaValle, S., Lesser, E., Shockley, R., Hopkins, M.S. 


>> Tokens are: 
 ['LaValle', ',', 'S.', ',', 'Lesser', ',', 'E.', ',', 'Shockley', ',', 'R.', ',', 'Hopkins', ',', 'M.S', '.']

>> Bigrams are: 
 [('LaValle', ','), (',', 'S.'), ('S.', ','), (',', 'Lesser'), ('Lesser', ','), (',', 'E.'), ('E.', ','), (',', 'Shockley'), ('Shockley', ','), (',', 'R.'), ('R.', ','), (',', 'Hopkins'), ('Hopkins', ','), (',', 'M.S'), ('M.S', '.')]

>> Trigrams are: 
 [('LaValle', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Lesser'), (',', 'Lesser', ','), ('Lesser', ',', 'E.'), (',', 'E.', ','), ('E.', ',', 'Shockley'), (',', 'Shockley', ','), ('Shockley', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Hopkins'), (',', 'Hopkins', ','), ('Hopkins', ',', 'M.S'), (',', 'M.S', '.')]

>> POS Tags are: 
 [('LaValle', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Lesser', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('Shockley', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Hopkins', 'NNP'), (',', ','), ('M.S', 'NNP'), ('.', '.')]

 (S
  (NP LaValle/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Lesser/NNP)
  ,/,
  (NP E./NNP)
  ,/,
  (NP Shockley/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Hopkins/NNP)
  ,/,
  (NP M.S/NNP)
  ./.) 


>> Noun Phrases are: 
 ['LaValle', 'S.', 'Lesser', 'E.', 'Shockley', 'R.', 'Hopkins', 'M.S']

>> Named Entities are: 
 [('GPE', 'LaValle'), ('PERSON', 'Lesser'), ('GPE', 'Shockley'), ('PERSON', 'Hopkins')] 

>> Stemming using Porter Stemmer: 
 [('LaValle', 'laval'), (',', ','), ('S.', 's.'), (',', ','), ('Lesser', 'lesser'), (',', ','), ('E.', 'e.'), (',', ','), ('Shockley', 'shockley'), (',', ','), ('R.', 'r.'), (',', ','), ('Hopkins', 'hopkin'), (',', ','), ('M.S', 'm.'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('LaValle', 'lavall'), (',', ','), ('S.', 's.'), (',', ','), ('Lesser', 'lesser'), (',', ','), ('E.', 'e.'), (',', ','), ('Shockley', 'shockley'), (',', ','), ('R.', 'r.'), (',', ','), ('Hopkins', 'hopkin'), (',', ','), ('M.S', 'm.s'), ('.', '.')]

>> Lemmatization: 
 [('LaValle', 'LaValle'), (',', ','), ('S.', 'S.'), (',', ','), ('Lesser', 'Lesser'), (',', ','), ('E.', 'E.'), (',', ','), ('Shockley', 'Shockley'), (',', ','), ('R.', 'R.'), (',', ','), ('Hopkins', 'Hopkins'), (',', ','), ('M.S', 'M.S'), ('.', '.')]



============================ Sentence 845 =============================

and Kruschwitz, N., 2011. 


>> Tokens are: 
 ['Kruschwitz', ',', 'N.', ',', '2011', '.']

>> Bigrams are: 
 [('Kruschwitz', ','), (',', 'N.'), ('N.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Kruschwitz', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Kruschwitz', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

 (S (NP Kruschwitz/NNP) ,/, (NP N./NNP) ,/, 2011/CD ./.) 


>> Noun Phrases are: 
 ['Kruschwitz', 'N.']

>> Named Entities are: 
 [('GPE', 'Kruschwitz')] 

>> Stemming using Porter Stemmer: 
 [('Kruschwitz', 'kruschwitz'), (',', ','), ('N.', 'n.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Kruschwitz', 'kruschwitz'), (',', ','), ('N.', 'n.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Kruschwitz', 'Kruschwitz'), (',', ','), ('N.', 'N.'), (',', ','), ('2011', '2011'), ('.', '.')]



============================ Sentence 846 =============================

Big data, analytics   and the path from insights to value. 


>> Tokens are: 
 ['Big', 'data', ',', 'analytics', 'path', 'insights', 'value', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'analytics'), ('analytics', 'path'), ('path', 'insights'), ('insights', 'value'), ('value', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'analytics'), (',', 'analytics', 'path'), ('analytics', 'path', 'insights'), ('path', 'insights', 'value'), ('insights', 'value', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('analytics', 'NNS'), ('path', 'VBP'), ('insights', 'NNS'), ('value', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  ,/,
  (NP analytics/NNS)
  path/VBP
  (NP insights/NNS value/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'analytics', 'insights value']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('analytics', 'analyt'), ('path', 'path'), ('insights', 'insight'), ('value', 'valu'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('analytics', 'analyt'), ('path', 'path'), ('insights', 'insight'), ('value', 'valu'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('analytics', 'analytics'), ('path', 'path'), ('insights', 'insight'), ('value', 'value'), ('.', '.')]



============================ Sentence 847 =============================

MIT sloan management review, p. 21. 


>> Tokens are: 
 ['MIT', 'sloan', 'management', 'review', ',', 'p.', '21', '.']

>> Bigrams are: 
 [('MIT', 'sloan'), ('sloan', 'management'), ('management', 'review'), ('review', ','), (',', 'p.'), ('p.', '21'), ('21', '.')]

>> Trigrams are: 
 [('MIT', 'sloan', 'management'), ('sloan', 'management', 'review'), ('management', 'review', ','), ('review', ',', 'p.'), (',', 'p.', '21'), ('p.', '21', '.')]

>> POS Tags are: 
 [('MIT', 'NNP'), ('sloan', 'VBD'), ('management', 'NN'), ('review', 'NN'), (',', ','), ('p.', 'JJ'), ('21', 'CD'), ('.', '.')]

 (S
  (NP MIT/NNP)
  sloan/VBD
  (NP management/NN review/NN)
  ,/,
  p./JJ
  21/CD
  ./.) 


>> Noun Phrases are: 
 ['MIT', 'management review']

>> Named Entities are: 
 [('ORGANIZATION', 'MIT')] 

>> Stemming using Porter Stemmer: 
 [('MIT', 'mit'), ('sloan', 'sloan'), ('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIT', 'mit'), ('sloan', 'sloan'), ('management', 'manag'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('MIT', 'MIT'), ('sloan', 'sloan'), ('management', 'management'), ('review', 'review'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]



============================ Sentence 848 =============================

Sarah Al-Shiakhli   51      Lee, J., Kao, H.A. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '51', 'Lee', ',', 'J.', ',', 'Kao', ',', 'H.A', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '51'), ('51', 'Lee'), ('Lee', ','), (',', 'J.'), ('J.', ','), (',', 'Kao'), ('Kao', ','), (',', 'H.A'), ('H.A', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '51'), ('Al-Shiakhli', '51', 'Lee'), ('51', 'Lee', ','), ('Lee', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Kao'), (',', 'Kao', ','), ('Kao', ',', 'H.A'), (',', 'H.A', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('51', 'CD'), ('Lee', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Kao', 'NNP'), (',', ','), ('H.A', 'NNP'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  51/CD
  (NP Lee/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Kao/NNP)
  ,/,
  (NP H.A/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Lee', 'J.', 'Kao', 'H.A']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Lee'), ('PERSON', 'Kao')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('51', '51'), ('Lee', 'lee'), (',', ','), ('J.', 'j.'), (',', ','), ('Kao', 'kao'), (',', ','), ('H.A', 'h.a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('51', '51'), ('Lee', 'lee'), (',', ','), ('J.', 'j.'), (',', ','), ('Kao', 'kao'), (',', ','), ('H.A', 'h.a'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('51', '51'), ('Lee', 'Lee'), (',', ','), ('J.', 'J.'), (',', ','), ('Kao', 'Kao'), (',', ','), ('H.A', 'H.A'), ('.', '.')]



============================ Sentence 849 =============================

and Yang, S., 2014. 


>> Tokens are: 
 ['Yang', ',', 'S.', ',', '2014', '.']

>> Bigrams are: 
 [('Yang', ','), (',', 'S.'), ('S.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Yang', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Yang', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Yang/NNP) ,/, (NP S./NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Yang', 'S.']

>> Named Entities are: 
 [('GPE', 'Yang')] 

>> Stemming using Porter Stemmer: 
 [('Yang', 'yang'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Yang', 'yang'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Yang', 'Yang'), (',', ','), ('S.', 'S.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 850 =============================

Service innovation and smart analytics for industry 4.0 and   big data environment.. Procedia Cirp Journal, pp. 


>> Tokens are: 
 ['Service', 'innovation', 'smart', 'analytics', 'industry', '4.0', 'big', 'data', 'environment', '..', 'Procedia', 'Cirp', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Service', 'innovation'), ('innovation', 'smart'), ('smart', 'analytics'), ('analytics', 'industry'), ('industry', '4.0'), ('4.0', 'big'), ('big', 'data'), ('data', 'environment'), ('environment', '..'), ('..', 'Procedia'), ('Procedia', 'Cirp'), ('Cirp', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Service', 'innovation', 'smart'), ('innovation', 'smart', 'analytics'), ('smart', 'analytics', 'industry'), ('analytics', 'industry', '4.0'), ('industry', '4.0', 'big'), ('4.0', 'big', 'data'), ('big', 'data', 'environment'), ('data', 'environment', '..'), ('environment', '..', 'Procedia'), ('..', 'Procedia', 'Cirp'), ('Procedia', 'Cirp', 'Journal'), ('Cirp', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Service', 'NNP'), ('innovation', 'NN'), ('smart', 'JJ'), ('analytics', 'NNS'), ('industry', 'NN'), ('4.0', 'CD'), ('big', 'JJ'), ('data', 'NNS'), ('environment', 'NN'), ('..', 'IN'), ('Procedia', 'NNP'), ('Cirp', 'NNP'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Service/NNP innovation/NN)
  (NP smart/JJ analytics/NNS industry/NN)
  4.0/CD
  (NP big/JJ data/NNS environment/NN)
  ../IN
  (NP Procedia/NNP Cirp/NNP Journal/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Service innovation', 'smart analytics industry', 'big data environment', 'Procedia Cirp Journal', 'pp']

>> Named Entities are: 
 [('GPE', 'Service'), ('ORGANIZATION', 'Procedia Cirp Journal')] 

>> Stemming using Porter Stemmer: 
 [('Service', 'servic'), ('innovation', 'innov'), ('smart', 'smart'), ('analytics', 'analyt'), ('industry', 'industri'), ('4.0', '4.0'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('..', '..'), ('Procedia', 'procedia'), ('Cirp', 'cirp'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Service', 'servic'), ('innovation', 'innov'), ('smart', 'smart'), ('analytics', 'analyt'), ('industry', 'industri'), ('4.0', '4.0'), ('big', 'big'), ('data', 'data'), ('environment', 'environ'), ('..', '..'), ('Procedia', 'procedia'), ('Cirp', 'cirp'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Service', 'Service'), ('innovation', 'innovation'), ('smart', 'smart'), ('analytics', 'analytics'), ('industry', 'industry'), ('4.0', '4.0'), ('big', 'big'), ('data', 'data'), ('environment', 'environment'), ('..', '..'), ('Procedia', 'Procedia'), ('Cirp', 'Cirp'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 851 =============================

3-8. 


>> Tokens are: 
 ['3-8', '.']

>> Bigrams are: 
 [('3-8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3-8', 'JJ'), ('.', '.')]

 (S 3-8/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3-8', '3-8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3-8', '3-8'), ('.', '.')]

>> Lemmatization: 
 [('3-8', '3-8'), ('.', '.')]



============================ Sentence 852 =============================

Lei, Y., Jia, F., Lin, J., Xing, S. and Ding, S.X., 2016. 


>> Tokens are: 
 ['Lei', ',', 'Y.', ',', 'Jia', ',', 'F.', ',', 'Lin', ',', 'J.', ',', 'Xing', ',', 'S.', 'Ding', ',', 'S.X.', ',', '2016', '.']

>> Bigrams are: 
 [('Lei', ','), (',', 'Y.'), ('Y.', ','), (',', 'Jia'), ('Jia', ','), (',', 'F.'), ('F.', ','), (',', 'Lin'), ('Lin', ','), (',', 'J.'), ('J.', ','), (',', 'Xing'), ('Xing', ','), (',', 'S.'), ('S.', 'Ding'), ('Ding', ','), (',', 'S.X.'), ('S.X.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Lei', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Jia'), (',', 'Jia', ','), ('Jia', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Lin'), (',', 'Lin', ','), ('Lin', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Xing'), (',', 'Xing', ','), ('Xing', ',', 'S.'), (',', 'S.', 'Ding'), ('S.', 'Ding', ','), ('Ding', ',', 'S.X.'), (',', 'S.X.', ','), ('S.X.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Lei', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Jia', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Lin', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Xing', 'NNP'), (',', ','), ('S.', 'NNP'), ('Ding', 'NNP'), (',', ','), ('S.X.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Lei/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Jia/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  (NP Lin/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Xing/NNP)
  ,/,
  (NP S./NNP Ding/NNP)
  ,/,
  (NP S.X./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Lei', 'Y.', 'Jia', 'F.', 'Lin', 'J.', 'Xing', 'S. Ding', 'S.X.']

>> Named Entities are: 
 [('GPE', 'Lei'), ('PERSON', 'Jia'), ('PERSON', 'Lin'), ('GPE', 'Xing')] 

>> Stemming using Porter Stemmer: 
 [('Lei', 'lei'), (',', ','), ('Y.', 'y.'), (',', ','), ('Jia', 'jia'), (',', ','), ('F.', 'f.'), (',', ','), ('Lin', 'lin'), (',', ','), ('J.', 'j.'), (',', ','), ('Xing', 'xing'), (',', ','), ('S.', 's.'), ('Ding', 'ding'), (',', ','), ('S.X.', 's.x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lei', 'lei'), (',', ','), ('Y.', 'y.'), (',', ','), ('Jia', 'jia'), (',', ','), ('F.', 'f.'), (',', ','), ('Lin', 'lin'), (',', ','), ('J.', 'j.'), (',', ','), ('Xing', 'xing'), (',', ','), ('S.', 's.'), ('Ding', 'ding'), (',', ','), ('S.X.', 's.x.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Lei', 'Lei'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Jia', 'Jia'), (',', ','), ('F.', 'F.'), (',', ','), ('Lin', 'Lin'), (',', ','), ('J.', 'J.'), (',', ','), ('Xing', 'Xing'), (',', ','), ('S.', 'S.'), ('Ding', 'Ding'), (',', ','), ('S.X.', 'S.X.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 853 =============================

An intelligent fault diagnosis method using   unsupervised feature learning towards mechanical big data.. IEEE Transactions on Industrial   Electronics journal, Volume 36, pp. 


>> Tokens are: 
 ['An', 'intelligent', 'fault', 'diagnosis', 'method', 'using', 'unsupervised', 'feature', 'learning', 'towards', 'mechanical', 'big', 'data', '..', 'IEEE', 'Transactions', 'Industrial', 'Electronics', 'journal', ',', 'Volume', '36', ',', 'pp', '.']

>> Bigrams are: 
 [('An', 'intelligent'), ('intelligent', 'fault'), ('fault', 'diagnosis'), ('diagnosis', 'method'), ('method', 'using'), ('using', 'unsupervised'), ('unsupervised', 'feature'), ('feature', 'learning'), ('learning', 'towards'), ('towards', 'mechanical'), ('mechanical', 'big'), ('big', 'data'), ('data', '..'), ('..', 'IEEE'), ('IEEE', 'Transactions'), ('Transactions', 'Industrial'), ('Industrial', 'Electronics'), ('Electronics', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '36'), ('36', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('An', 'intelligent', 'fault'), ('intelligent', 'fault', 'diagnosis'), ('fault', 'diagnosis', 'method'), ('diagnosis', 'method', 'using'), ('method', 'using', 'unsupervised'), ('using', 'unsupervised', 'feature'), ('unsupervised', 'feature', 'learning'), ('feature', 'learning', 'towards'), ('learning', 'towards', 'mechanical'), ('towards', 'mechanical', 'big'), ('mechanical', 'big', 'data'), ('big', 'data', '..'), ('data', '..', 'IEEE'), ('..', 'IEEE', 'Transactions'), ('IEEE', 'Transactions', 'Industrial'), ('Transactions', 'Industrial', 'Electronics'), ('Industrial', 'Electronics', 'journal'), ('Electronics', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '36'), ('Volume', '36', ','), ('36', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('An', 'DT'), ('intelligent', 'JJ'), ('fault', 'NN'), ('diagnosis', 'NN'), ('method', 'NN'), ('using', 'VBG'), ('unsupervised', 'JJ'), ('feature', 'NN'), ('learning', 'VBG'), ('towards', 'NNS'), ('mechanical', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('..', 'NNS'), ('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Industrial', 'NNP'), ('Electronics', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('36', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP An/DT intelligent/JJ fault/NN diagnosis/NN method/NN)
  using/VBG
  (NP unsupervised/JJ feature/NN)
  learning/VBG
  (NP towards/NNS)
  (NP
    mechanical/JJ
    big/JJ
    data/NNS
    ../NNS
    IEEE/NNP
    Transactions/NNP
    Industrial/NNP
    Electronics/NNP
    journal/NN)
  ,/,
  (NP Volume/NN)
  36/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['An intelligent fault diagnosis method', 'unsupervised feature', 'towards', 'mechanical big data .. IEEE Transactions Industrial Electronics journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Transactions Industrial Electronics'), ('ORGANIZATION', 'Volume 36')] 

>> Stemming using Porter Stemmer: 
 [('An', 'an'), ('intelligent', 'intellig'), ('fault', 'fault'), ('diagnosis', 'diagnosi'), ('method', 'method'), ('using', 'use'), ('unsupervised', 'unsupervis'), ('feature', 'featur'), ('learning', 'learn'), ('towards', 'toward'), ('mechanical', 'mechan'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri'), ('Electronics', 'electron'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('An', 'an'), ('intelligent', 'intellig'), ('fault', 'fault'), ('diagnosis', 'diagnosi'), ('method', 'method'), ('using', 'use'), ('unsupervised', 'unsupervis'), ('feature', 'featur'), ('learning', 'learn'), ('towards', 'toward'), ('mechanical', 'mechan'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri'), ('Electronics', 'electron'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('An', 'An'), ('intelligent', 'intelligent'), ('fault', 'fault'), ('diagnosis', 'diagnosis'), ('method', 'method'), ('using', 'using'), ('unsupervised', 'unsupervised'), ('feature', 'feature'), ('learning', 'learning'), ('towards', 'towards'), ('mechanical', 'mechanical'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Industrial', 'Industrial'), ('Electronics', 'Electronics'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 854 =============================

3137-3147. 


>> Tokens are: 
 ['3137-3147', '.']

>> Bigrams are: 
 [('3137-3147', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('3137-3147', 'JJ'), ('.', '.')]

 (S 3137-3147/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('3137-3147', '3137-3147'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('3137-3147', '3137-3147'), ('.', '.')]

>> Lemmatization: 
 [('3137-3147', '3137-3147'), ('.', '.')]



============================ Sentence 855 =============================

Lekhwar, S., Yadav, S. and Singh, A., 2019. 


>> Tokens are: 
 ['Lekhwar', ',', 'S.', ',', 'Yadav', ',', 'S.', 'Singh', ',', 'A.', ',', '2019', '.']

>> Bigrams are: 
 [('Lekhwar', ','), (',', 'S.'), ('S.', ','), (',', 'Yadav'), ('Yadav', ','), (',', 'S.'), ('S.', 'Singh'), ('Singh', ','), (',', 'A.'), ('A.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Lekhwar', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Yadav'), (',', 'Yadav', ','), ('Yadav', ',', 'S.'), (',', 'S.', 'Singh'), ('S.', 'Singh', ','), ('Singh', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Lekhwar', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Yadav', 'NNP'), (',', ','), ('S.', 'NNP'), ('Singh', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Lekhwar/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Yadav/NNP)
  ,/,
  (NP S./NNP Singh/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Lekhwar', 'S.', 'Yadav', 'S. Singh', 'A.']

>> Named Entities are: 
 [('GPE', 'Lekhwar'), ('PERSON', 'Yadav'), ('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Lekhwar', 'Lekhwar'), (',', ','), ('S.', 'S.'), (',', ','), ('Yadav', 'Yadav'), (',', ','), ('S.', 'S.'), ('Singh', 'Singh'), (',', ','), ('A.', 'A.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 856 =============================

Lekhwar, S., Yadav, S. and Singh, A., 2019. 


>> Tokens are: 
 ['Lekhwar', ',', 'S.', ',', 'Yadav', ',', 'S.', 'Singh', ',', 'A.', ',', '2019', '.']

>> Bigrams are: 
 [('Lekhwar', ','), (',', 'S.'), ('S.', ','), (',', 'Yadav'), ('Yadav', ','), (',', 'S.'), ('S.', 'Singh'), ('Singh', ','), (',', 'A.'), ('A.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Lekhwar', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Yadav'), (',', 'Yadav', ','), ('Yadav', ',', 'S.'), (',', 'S.', 'Singh'), ('S.', 'Singh', ','), ('Singh', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Lekhwar', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Yadav', 'NNP'), (',', ','), ('S.', 'NNP'), ('Singh', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Lekhwar/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Yadav/NNP)
  ,/,
  (NP S./NNP Singh/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Lekhwar', 'S.', 'Yadav', 'S. Singh', 'A.']

>> Named Entities are: 
 [('GPE', 'Lekhwar'), ('PERSON', 'Yadav'), ('PERSON', 'Singh')] 

>> Stemming using Porter Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lekhwar', 'lekhwar'), (',', ','), ('S.', 's.'), (',', ','), ('Yadav', 'yadav'), (',', ','), ('S.', 's.'), ('Singh', 'singh'), (',', ','), ('A.', 'a.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Lekhwar', 'Lekhwar'), (',', ','), ('S.', 'S.'), (',', ','), ('Yadav', 'Yadav'), (',', ','), ('S.', 'S.'), ('Singh', 'Singh'), (',', ','), ('A.', 'A.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 857 =============================

Big Data   Analytics in Retail. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Retail', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Retail'), ('Retail', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Retail'), ('Analytics', 'Retail', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Retail', 'NNP'), ('.', '.')]

 (S (NP Big/NNP Data/NNP Analytics/NNP Retail/NNP) ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics Retail']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Retail', 'retail'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Retail', 'retail'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Retail', 'Retail'), ('.', '.')]



============================ Sentence 858 =============================

Singapore, Springer, pp. 


>> Tokens are: 
 ['Singapore', ',', 'Springer', ',', 'pp', '.']

>> Bigrams are: 
 [('Singapore', ','), (',', 'Springer'), ('Springer', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Singapore', ',', 'Springer'), (',', 'Springer', ','), ('Springer', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Singapore', 'NNP'), (',', ','), ('Springer', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP Singapore/NNP) ,/, (NP Springer/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Singapore', 'Springer', 'pp']

>> Named Entities are: 
 [('GPE', 'Singapore'), ('PERSON', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('Singapore', 'singapor'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Singapore', 'singapor'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Singapore', 'Singapore'), (',', ','), ('Springer', 'Springer'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 859 =============================

469-477. 


>> Tokens are: 
 ['469-477', '.']

>> Bigrams are: 
 [('469-477', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('469-477', 'JJ'), ('.', '.')]

 (S 469-477/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('469-477', '469-477'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('469-477', '469-477'), ('.', '.')]

>> Lemmatization: 
 [('469-477', '469-477'), ('.', '.')]



============================ Sentence 860 =============================

Levy, Y. and Ellis, T.J., 2006. 


>> Tokens are: 
 ['Levy', ',', 'Y.', 'Ellis', ',', 'T.J.', ',', '2006', '.']

>> Bigrams are: 
 [('Levy', ','), (',', 'Y.'), ('Y.', 'Ellis'), ('Ellis', ','), (',', 'T.J.'), ('T.J.', ','), (',', '2006'), ('2006', '.')]

>> Trigrams are: 
 [('Levy', ',', 'Y.'), (',', 'Y.', 'Ellis'), ('Y.', 'Ellis', ','), ('Ellis', ',', 'T.J.'), (',', 'T.J.', ','), ('T.J.', ',', '2006'), (',', '2006', '.')]

>> POS Tags are: 
 [('Levy', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Ellis', 'NNP'), (',', ','), ('T.J.', 'NNP'), (',', ','), ('2006', 'CD'), ('.', '.')]

 (S
  (NP Levy/NNP)
  ,/,
  (NP Y./NNP Ellis/NNP)
  ,/,
  (NP T.J./NNP)
  ,/,
  2006/CD
  ./.) 


>> Noun Phrases are: 
 ['Levy', 'Y. Ellis', 'T.J.']

>> Named Entities are: 
 [('GPE', 'Levy')] 

>> Stemming using Porter Stemmer: 
 [('Levy', 'levi'), (',', ','), ('Y.', 'y.'), ('Ellis', 'elli'), (',', ','), ('T.J.', 't.j.'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Levy', 'levi'), (',', ','), ('Y.', 'y.'), ('Ellis', 'elli'), (',', ','), ('T.J.', 't.j.'), (',', ','), ('2006', '2006'), ('.', '.')]

>> Lemmatization: 
 [('Levy', 'Levy'), (',', ','), ('Y.', 'Y.'), ('Ellis', 'Ellis'), (',', ','), ('T.J.', 'T.J.'), (',', ','), ('2006', '2006'), ('.', '.')]



============================ Sentence 861 =============================

A systems approach to conduct an effective literature review in   support of information systems research.. Informing Science Journal, p. 9. 


>> Tokens are: 
 ['A', 'systems', 'approach', 'conduct', 'effective', 'literature', 'review', 'support', 'information', 'systems', 'research', '..', 'Informing', 'Science', 'Journal', ',', 'p.', '9', '.']

>> Bigrams are: 
 [('A', 'systems'), ('systems', 'approach'), ('approach', 'conduct'), ('conduct', 'effective'), ('effective', 'literature'), ('literature', 'review'), ('review', 'support'), ('support', 'information'), ('information', 'systems'), ('systems', 'research'), ('research', '..'), ('..', 'Informing'), ('Informing', 'Science'), ('Science', 'Journal'), ('Journal', ','), (',', 'p.'), ('p.', '9'), ('9', '.')]

>> Trigrams are: 
 [('A', 'systems', 'approach'), ('systems', 'approach', 'conduct'), ('approach', 'conduct', 'effective'), ('conduct', 'effective', 'literature'), ('effective', 'literature', 'review'), ('literature', 'review', 'support'), ('review', 'support', 'information'), ('support', 'information', 'systems'), ('information', 'systems', 'research'), ('systems', 'research', '..'), ('research', '..', 'Informing'), ('..', 'Informing', 'Science'), ('Informing', 'Science', 'Journal'), ('Science', 'Journal', ','), ('Journal', ',', 'p.'), (',', 'p.', '9'), ('p.', '9', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('systems', 'NNS'), ('approach', 'NN'), ('conduct', 'VBP'), ('effective', 'JJ'), ('literature', 'NN'), ('review', 'VB'), ('support', 'NN'), ('information', 'NN'), ('systems', 'NNS'), ('research', 'NN'), ('..', 'VBP'), ('Informing', 'VBG'), ('Science', 'NNP'), ('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('9', 'CD'), ('.', '.')]

 (S
  (NP A/DT systems/NNS approach/NN)
  conduct/VBP
  (NP effective/JJ literature/NN)
  review/VB
  (NP support/NN information/NN systems/NNS research/NN)
  ../VBP
  Informing/VBG
  (NP Science/NNP Journal/NNP)
  ,/,
  p./VBD
  9/CD
  ./.) 


>> Noun Phrases are: 
 ['A systems approach', 'effective literature', 'support information systems research', 'Science Journal']

>> Named Entities are: 
 [('PERSON', 'Science Journal')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('systems', 'system'), ('approach', 'approach'), ('conduct', 'conduct'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('support', 'support'), ('information', 'inform'), ('systems', 'system'), ('research', 'research'), ('..', '..'), ('Informing', 'inform'), ('Science', 'scienc'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('systems', 'system'), ('approach', 'approach'), ('conduct', 'conduct'), ('effective', 'effect'), ('literature', 'literatur'), ('review', 'review'), ('support', 'support'), ('information', 'inform'), ('systems', 'system'), ('research', 'research'), ('..', '..'), ('Informing', 'inform'), ('Science', 'scienc'), ('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('systems', 'system'), ('approach', 'approach'), ('conduct', 'conduct'), ('effective', 'effective'), ('literature', 'literature'), ('review', 'review'), ('support', 'support'), ('information', 'information'), ('systems', 'system'), ('research', 'research'), ('..', '..'), ('Informing', 'Informing'), ('Science', 'Science'), ('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('9', '9'), ('.', '.')]



============================ Sentence 862 =============================

Li, Y. and Schuurmans, D., 2011. 


>> Tokens are: 
 ['Li', ',', 'Y.', 'Schuurmans', ',', 'D.', ',', '2011', '.']

>> Bigrams are: 
 [('Li', ','), (',', 'Y.'), ('Y.', 'Schuurmans'), ('Schuurmans', ','), (',', 'D.'), ('D.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Li', ',', 'Y.'), (',', 'Y.', 'Schuurmans'), ('Y.', 'Schuurmans', ','), ('Schuurmans', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Li', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Schuurmans', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

 (S
  (NP Li/NNP)
  ,/,
  (NP Y./NNP Schuurmans/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  2011/CD
  ./.) 


>> Noun Phrases are: 
 ['Li', 'Y. Schuurmans', 'D.']

>> Named Entities are: 
 [('GPE', 'Li')] 

>> Stemming using Porter Stemmer: 
 [('Li', 'li'), (',', ','), ('Y.', 'y.'), ('Schuurmans', 'schuurman'), (',', ','), ('D.', 'd.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Li', 'li'), (',', ','), ('Y.', 'y.'), ('Schuurmans', 'schuurman'), (',', ','), ('D.', 'd.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Li', 'Li'), (',', ','), ('Y.', 'Y.'), ('Schuurmans', 'Schuurmans'), (',', ','), ('D.', 'D.'), (',', ','), ('2011', '2011'), ('.', '.')]



============================ Sentence 863 =============================

MapReduce for parallel reinforcement learning. 


>> Tokens are: 
 ['MapReduce', 'parallel', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('MapReduce', 'parallel'), ('parallel', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('MapReduce', 'parallel', 'reinforcement'), ('parallel', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('MapReduce', 'NNP'), ('parallel', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP MapReduce/NNP)
  (NP parallel/JJ reinforcement/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['MapReduce', 'parallel reinforcement learning']

>> Named Entities are: 
 [('ORGANIZATION', 'MapReduce')] 

>> Stemming using Porter Stemmer: 
 [('MapReduce', 'mapreduc'), ('parallel', 'parallel'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MapReduce', 'mapreduc'), ('parallel', 'parallel'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('MapReduce', 'MapReduce'), ('parallel', 'parallel'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 864 =============================

Berlin,   Heidelberg, Springer, pp. 


>> Tokens are: 
 ['Berlin', ',', 'Heidelberg', ',', 'Springer', ',', 'pp', '.']

>> Bigrams are: 
 [('Berlin', ','), (',', 'Heidelberg'), ('Heidelberg', ','), (',', 'Springer'), ('Springer', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Berlin', ',', 'Heidelberg'), (',', 'Heidelberg', ','), ('Heidelberg', ',', 'Springer'), (',', 'Springer', ','), ('Springer', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Berlin', 'NNP'), (',', ','), ('Heidelberg', 'NNP'), (',', ','), ('Springer', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Berlin/NNP)
  ,/,
  (NP Heidelberg/NNP)
  ,/,
  (NP Springer/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Berlin', 'Heidelberg', 'Springer', 'pp']

>> Named Entities are: 
 [('GPE', 'Berlin'), ('PERSON', 'Heidelberg'), ('PERSON', 'Springer')] 

>> Stemming using Porter Stemmer: 
 [('Berlin', 'berlin'), (',', ','), ('Heidelberg', 'heidelberg'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Berlin', 'berlin'), (',', ','), ('Heidelberg', 'heidelberg'), (',', ','), ('Springer', 'springer'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Berlin', 'Berlin'), (',', ','), ('Heidelberg', 'Heidelberg'), (',', ','), ('Springer', 'Springer'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 865 =============================

309-320. 


>> Tokens are: 
 ['309-320', '.']

>> Bigrams are: 
 [('309-320', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('309-320', 'JJ'), ('.', '.')]

 (S 309-320/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('309-320', '309-320'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('309-320', '309-320'), ('.', '.')]

>> Lemmatization: 
 [('309-320', '309-320'), ('.', '.')]



============================ Sentence 866 =============================

Lomotey, R. K., & Deters, R., 2014. 


>> Tokens are: 
 ['Lomotey', ',', 'R.', 'K.', ',', '&', 'Deters', ',', 'R.', ',', '2014', '.']

>> Bigrams are: 
 [('Lomotey', ','), (',', 'R.'), ('R.', 'K.'), ('K.', ','), (',', '&'), ('&', 'Deters'), ('Deters', ','), (',', 'R.'), ('R.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Lomotey', ',', 'R.'), (',', 'R.', 'K.'), ('R.', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Deters'), ('&', 'Deters', ','), ('Deters', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Lomotey', 'NNP'), (',', ','), ('R.', 'NNP'), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Deters', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Lomotey/NNP)
  ,/,
  (NP R./NNP K./NNP)
  ,/,
  &/CC
  (NP Deters/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Lomotey', 'R. K.', 'Deters', 'R.']

>> Named Entities are: 
 [('GPE', 'Lomotey'), ('GPE', 'Deters')] 

>> Stemming using Porter Stemmer: 
 [('Lomotey', 'lomotey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Deters', 'deter'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lomotey', 'lomotey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Deters', 'deter'), (',', ','), ('R.', 'r.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Lomotey', 'Lomotey'), (',', ','), ('R.', 'R.'), ('K.', 'K.'), (',', ','), ('&', '&'), ('Deters', 'Deters'), (',', ','), ('R.', 'R.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 867 =============================

Towards knowledge discovery in Big Data. 


>> Tokens are: 
 ['Towards', 'knowledge', 'discovery', 'Big', 'Data', '.']

>> Bigrams are: 
 [('Towards', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'Big'), ('Big', 'Data'), ('Data', '.')]

>> Trigrams are: 
 [('Towards', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'Big'), ('discovery', 'Big', 'Data'), ('Big', 'Data', '.')]

>> POS Tags are: 
 [('Towards', 'NNS'), ('knowledge', 'VBP'), ('discovery', 'RB'), ('Big', 'NNP'), ('Data', 'NNP'), ('.', '.')]

 (S
  (NP Towards/NNS)
  knowledge/VBP
  discovery/RB
  (NP Big/NNP Data/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Towards', 'Big Data']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Towards', 'toward'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Towards', 'toward'), ('knowledge', 'knowledg'), ('discovery', 'discoveri'), ('Big', 'big'), ('Data', 'data'), ('.', '.')]

>> Lemmatization: 
 [('Towards', 'Towards'), ('knowledge', 'knowledge'), ('discovery', 'discovery'), ('Big', 'Big'), ('Data', 'Data'), ('.', '.')]



============================ Sentence 868 =============================

s.l., IEEE   Computer Society, p. 181–191. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', 'Computer', 'Society', ',', 'p.', '181–191', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', 'Computer'), ('Computer', 'Society'), ('Society', ','), (',', 'p.'), ('p.', '181–191'), ('181–191', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', 'Computer'), ('IEEE', 'Computer', 'Society'), ('Computer', 'Society', ','), ('Society', ',', 'p.'), (',', 'p.', '181–191'), ('p.', '181–191', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), ('Computer', 'NNP'), ('Society', 'NNP'), (',', ','), ('p.', 'RB'), ('181–191', 'CD'), ('.', '.')]

 (S
  (NP s.l./NN)
  ,/,
  (NP IEEE/NNP Computer/NNP Society/NNP)
  ,/,
  p./RB
  181–191/CD
  ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE Computer Society']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Computer Society')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('Computer', 'comput'), ('Society', 'societi'), (',', ','), ('p.', 'p.'), ('181–191', '181–191'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('Computer', 'comput'), ('Society', 'societi'), (',', ','), ('p.', 'p.'), ('181–191', '181–191'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), ('Computer', 'Computer'), ('Society', 'Society'), (',', ','), ('p.', 'p.'), ('181–191', '181–191'), ('.', '.')]



============================ Sentence 869 =============================

Lv, Z., Song, H., Basanta-Val, P., Steed, A. and Jo, M., 2017. 


>> Tokens are: 
 ['Lv', ',', 'Z.', ',', 'Song', ',', 'H.', ',', 'Basanta-Val', ',', 'P.', ',', 'Steed', ',', 'A.', 'Jo', ',', 'M.', ',', '2017', '.']

>> Bigrams are: 
 [('Lv', ','), (',', 'Z.'), ('Z.', ','), (',', 'Song'), ('Song', ','), (',', 'H.'), ('H.', ','), (',', 'Basanta-Val'), ('Basanta-Val', ','), (',', 'P.'), ('P.', ','), (',', 'Steed'), ('Steed', ','), (',', 'A.'), ('A.', 'Jo'), ('Jo', ','), (',', 'M.'), ('M.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Lv', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Song'), (',', 'Song', ','), ('Song', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Basanta-Val'), (',', 'Basanta-Val', ','), ('Basanta-Val', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Steed'), (',', 'Steed', ','), ('Steed', ',', 'A.'), (',', 'A.', 'Jo'), ('A.', 'Jo', ','), ('Jo', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Lv', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Song', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Basanta-Val', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Steed', 'NNP'), (',', ','), ('A.', 'NNP'), ('Jo', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Lv/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  (NP Song/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Basanta-Val/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  (NP Steed/NNP)
  ,/,
  (NP A./NNP Jo/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Lv', 'Z.', 'Song', 'H.', 'Basanta-Val', 'P.', 'Steed', 'A. Jo', 'M.']

>> Named Entities are: 
 [('GPE', 'Lv'), ('GPE', 'Song'), ('PERSON', 'Steed')] 

>> Stemming using Porter Stemmer: 
 [('Lv', 'lv'), (',', ','), ('Z.', 'z.'), (',', ','), ('Song', 'song'), (',', ','), ('H.', 'h.'), (',', ','), ('Basanta-Val', 'basanta-v'), (',', ','), ('P.', 'p.'), (',', ','), ('Steed', 'steed'), (',', ','), ('A.', 'a.'), ('Jo', 'jo'), (',', ','), ('M.', 'm.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lv', 'lv'), (',', ','), ('Z.', 'z.'), (',', ','), ('Song', 'song'), (',', ','), ('H.', 'h.'), (',', ','), ('Basanta-Val', 'basanta-v'), (',', ','), ('P.', 'p.'), (',', ','), ('Steed', 'steed'), (',', ','), ('A.', 'a.'), ('Jo', 'jo'), (',', ','), ('M.', 'm.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Lv', 'Lv'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Song', 'Song'), (',', ','), ('H.', 'H.'), (',', ','), ('Basanta-Val', 'Basanta-Val'), (',', ','), ('P.', 'P.'), (',', ','), ('Steed', 'Steed'), (',', ','), ('A.', 'A.'), ('Jo', 'Jo'), (',', ','), ('M.', 'M.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 870 =============================

IEEE Transactions on Industrial   Informatics journal, Volume 13, pp. 


>> Tokens are: 
 ['IEEE', 'Transactions', 'Industrial', 'Informatics', 'journal', ',', 'Volume', '13', ',', 'pp', '.']

>> Bigrams are: 
 [('IEEE', 'Transactions'), ('Transactions', 'Industrial'), ('Industrial', 'Informatics'), ('Informatics', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '13'), ('13', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', 'Transactions', 'Industrial'), ('Transactions', 'Industrial', 'Informatics'), ('Industrial', 'Informatics', 'journal'), ('Informatics', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '13'), ('Volume', '13', ','), ('13', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Transactions', 'NNP'), ('Industrial', 'NNP'), ('Informatics', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('13', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    IEEE/NNP
    Transactions/NNP
    Industrial/NNP
    Informatics/NNP
    journal/NN)
  ,/,
  (NP Volume/NN)
  13/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['IEEE Transactions Industrial Informatics journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Transactions Industrial Informatics'), ('ORGANIZATION', 'Volume 13')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri'), ('Informatics', 'informat'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Transactions', 'transact'), ('Industrial', 'industri'), ('Informatics', 'informat'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Transactions', 'Transactions'), ('Industrial', 'Industrial'), ('Informatics', 'Informatics'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('13', '13'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 871 =============================

1891-1899. 


>> Tokens are: 
 ['1891-1899', '.']

>> Bigrams are: 
 [('1891-1899', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1891-1899', 'JJ'), ('.', '.')]

 (S 1891-1899/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1891-1899', '1891-1899'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1891-1899', '1891-1899'), ('.', '.')]

>> Lemmatization: 
 [('1891-1899', '1891-1899'), ('.', '.')]



============================ Sentence 872 =============================

Ma, C., Zhang, H.H. 


>> Tokens are: 
 ['Ma', ',', 'C.', ',', 'Zhang', ',', 'H.H', '.']

>> Bigrams are: 
 [('Ma', ','), (',', 'C.'), ('C.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'H.H'), ('H.H', '.')]

>> Trigrams are: 
 [('Ma', ',', 'C.'), (',', 'C.', ','), ('C.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'H.H'), (',', 'H.H', '.')]

>> POS Tags are: 
 [('Ma', 'NNP'), (',', ','), ('C.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('H.H', 'NNP'), ('.', '.')]

 (S
  (NP Ma/NNP)
  ,/,
  (NP C./NNP)
  ,/,
  (NP Zhang/NNP)
  ,/,
  (NP H.H/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Ma', 'C.', 'Zhang', 'H.H']

>> Named Entities are: 
 [('GPE', 'Ma'), ('PERSON', 'Zhang')] 

>> Stemming using Porter Stemmer: 
 [('Ma', 'ma'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.H', 'h.h'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ma', 'ma'), (',', ','), ('C.', 'c.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('H.H', 'h.h'), ('.', '.')]

>> Lemmatization: 
 [('Ma', 'Ma'), (',', ','), ('C.', 'C.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('H.H', 'H.H'), ('.', '.')]



============================ Sentence 873 =============================

and Wang, 2014. 


>> Tokens are: 
 ['Wang', ',', '2014', '.']

>> Bigrams are: 
 [('Wang', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Wang', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Wang', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Wang/NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Wang']

>> Named Entities are: 
 [('PERSON', 'Wang')] 

>> Stemming using Porter Stemmer: 
 [('Wang', 'wang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wang', 'wang'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Wang', 'Wang'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 874 =============================

Machine learning for big data analytics in plants.. XTrends   in plant science Journal, pp. 


>> Tokens are: 
 ['Machine', 'learning', 'big', 'data', 'analytics', 'plants', '..', 'XTrends', 'plant', 'science', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'plants'), ('plants', '..'), ('..', 'XTrends'), ('XTrends', 'plant'), ('plant', 'science'), ('science', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'plants'), ('analytics', 'plants', '..'), ('plants', '..', 'XTrends'), ('..', 'XTrends', 'plant'), ('XTrends', 'plant', 'science'), ('plant', 'science', 'Journal'), ('science', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('plants', 'NNS'), ('..', 'VB'), ('XTrends', 'NNS'), ('plant', 'NN'), ('science', 'NN'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Machine/NN)
  learning/VBG
  (NP big/JJ data/NNS analytics/NNS plants/NNS)
  ../VB
  (NP XTrends/NNS plant/NN science/NN Journal/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Machine', 'big data analytics plants', 'XTrends plant science Journal', 'pp']

>> Named Entities are: 
 [('GPE', 'Machine'), ('ORGANIZATION', 'XTrends')] 

>> Stemming using Porter Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plants', 'plant'), ('..', '..'), ('XTrends', 'xtrend'), ('plant', 'plant'), ('science', 'scienc'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('plants', 'plant'), ('..', '..'), ('XTrends', 'xtrend'), ('plant', 'plant'), ('science', 'scienc'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Machine', 'Machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('plants', 'plant'), ('..', '..'), ('XTrends', 'XTrends'), ('plant', 'plant'), ('science', 'science'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 875 =============================

798-808. 


>> Tokens are: 
 ['798-808', '.']

>> Bigrams are: 
 [('798-808', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('798-808', 'JJ'), ('.', '.')]

 (S 798-808/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('798-808', '798-808'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('798-808', '798-808'), ('.', '.')]

>> Lemmatization: 
 [('798-808', '798-808'), ('.', '.')]



============================ Sentence 876 =============================

Manyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C. and Byers, A.H., 2011. 


>> Tokens are: 
 ['Manyika', ',', 'J.', ',', 'Chui', ',', 'M.', ',', 'Brown', ',', 'B.', ',', 'Bughin', ',', 'J.', ',', 'Dobbs', ',', 'R.', ',', 'Roxburgh', ',', 'C.', 'Byers', ',', 'A.H.', ',', '2011', '.']

>> Bigrams are: 
 [('Manyika', ','), (',', 'J.'), ('J.', ','), (',', 'Chui'), ('Chui', ','), (',', 'M.'), ('M.', ','), (',', 'Brown'), ('Brown', ','), (',', 'B.'), ('B.', ','), (',', 'Bughin'), ('Bughin', ','), (',', 'J.'), ('J.', ','), (',', 'Dobbs'), ('Dobbs', ','), (',', 'R.'), ('R.', ','), (',', 'Roxburgh'), ('Roxburgh', ','), (',', 'C.'), ('C.', 'Byers'), ('Byers', ','), (',', 'A.H.'), ('A.H.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Manyika', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Chui'), (',', 'Chui', ','), ('Chui', ',', 'M.'), (',', 'M.', ','), ('M.', ',', 'Brown'), (',', 'Brown', ','), ('Brown', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Bughin'), (',', 'Bughin', ','), ('Bughin', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Dobbs'), (',', 'Dobbs', ','), ('Dobbs', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Roxburgh'), (',', 'Roxburgh', ','), ('Roxburgh', ',', 'C.'), (',', 'C.', 'Byers'), ('C.', 'Byers', ','), ('Byers', ',', 'A.H.'), (',', 'A.H.', ','), ('A.H.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Manyika', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Chui', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('Brown', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Bughin', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Dobbs', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Roxburgh', 'NNP'), (',', ','), ('C.', 'NNP'), ('Byers', 'NNP'), (',', ','), ('A.H.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

 (S
  (NP Manyika/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Chui/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  (NP Brown/NNP)
  ,/,
  (NP B./NNP)
  ,/,
  (NP Bughin/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Dobbs/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Roxburgh/NNP)
  ,/,
  (NP C./NNP Byers/NNP)
  ,/,
  (NP A.H./NNP)
  ,/,
  2011/CD
  ./.) 


>> Noun Phrases are: 
 ['Manyika', 'J.', 'Chui', 'M.', 'Brown', 'B.', 'Bughin', 'J.', 'Dobbs', 'R.', 'Roxburgh', 'C. Byers', 'A.H.']

>> Named Entities are: 
 [('GPE', 'Manyika'), ('PERSON', 'Chui'), ('PERSON', 'Brown'), ('PERSON', 'Bughin'), ('PERSON', 'Dobbs'), ('GPE', 'Roxburgh')] 

>> Stemming using Porter Stemmer: 
 [('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), (',', ','), ('Brown', 'brown'), (',', ','), ('B.', 'b.'), (',', ','), ('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Dobbs', 'dobb'), (',', ','), ('R.', 'r.'), (',', ','), ('Roxburgh', 'roxburgh'), (',', ','), ('C.', 'c.'), ('Byers', 'byer'), (',', ','), ('A.H.', 'a.h.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Manyika', 'manyika'), (',', ','), ('J.', 'j.'), (',', ','), ('Chui', 'chui'), (',', ','), ('M.', 'm.'), (',', ','), ('Brown', 'brown'), (',', ','), ('B.', 'b.'), (',', ','), ('Bughin', 'bughin'), (',', ','), ('J.', 'j.'), (',', ','), ('Dobbs', 'dobb'), (',', ','), ('R.', 'r.'), (',', ','), ('Roxburgh', 'roxburgh'), (',', ','), ('C.', 'c.'), ('Byers', 'byer'), (',', ','), ('A.H.', 'a.h.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Manyika', 'Manyika'), (',', ','), ('J.', 'J.'), (',', ','), ('Chui', 'Chui'), (',', ','), ('M.', 'M.'), (',', ','), ('Brown', 'Brown'), (',', ','), ('B.', 'B.'), (',', ','), ('Bughin', 'Bughin'), (',', ','), ('J.', 'J.'), (',', ','), ('Dobbs', 'Dobbs'), (',', ','), ('R.', 'R.'), (',', ','), ('Roxburgh', 'Roxburgh'), (',', ','), ('C.', 'C.'), ('Byers', 'Byers'), (',', ','), ('A.H.', 'A.H.'), (',', ','), ('2011', '2011'), ('.', '.')]



============================ Sentence 877 =============================

Big data: The next frontier for innovation, competition, and productivity..    Mayer-Schonberger, V. and Padova, Y., 2015. 


>> Tokens are: 
 ['Big', 'data', ':', 'The', 'next', 'frontier', 'innovation', ',', 'competition', ',', 'productivity', '..', 'Mayer-Schonberger', ',', 'V.', 'Padova', ',', 'Y.', ',', '2015', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'The'), ('The', 'next'), ('next', 'frontier'), ('frontier', 'innovation'), ('innovation', ','), (',', 'competition'), ('competition', ','), (',', 'productivity'), ('productivity', '..'), ('..', 'Mayer-Schonberger'), ('Mayer-Schonberger', ','), (',', 'V.'), ('V.', 'Padova'), ('Padova', ','), (',', 'Y.'), ('Y.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'The'), (':', 'The', 'next'), ('The', 'next', 'frontier'), ('next', 'frontier', 'innovation'), ('frontier', 'innovation', ','), ('innovation', ',', 'competition'), (',', 'competition', ','), ('competition', ',', 'productivity'), (',', 'productivity', '..'), ('productivity', '..', 'Mayer-Schonberger'), ('..', 'Mayer-Schonberger', ','), ('Mayer-Schonberger', ',', 'V.'), (',', 'V.', 'Padova'), ('V.', 'Padova', ','), ('Padova', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('The', 'DT'), ('next', 'JJ'), ('frontier', 'NN'), ('innovation', 'NN'), (',', ','), ('competition', 'NN'), (',', ','), ('productivity', 'NN'), ('..', 'NNP'), ('Mayer-Schonberger', 'NNP'), (',', ','), ('V.', 'NNP'), ('Padova', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  (NP The/DT next/JJ frontier/NN innovation/NN)
  ,/,
  (NP competition/NN)
  ,/,
  (NP productivity/NN ../NNP Mayer-Schonberger/NNP)
  ,/,
  (NP V./NNP Padova/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'The next frontier innovation', 'competition', 'productivity .. Mayer-Schonberger', 'V. Padova', 'Y.']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('The', 'the'), ('next', 'next'), ('frontier', 'frontier'), ('innovation', 'innov'), (',', ','), ('competition', 'competit'), (',', ','), ('productivity', 'product'), ('..', '..'), ('Mayer-Schonberger', 'mayer-schonberg'), (',', ','), ('V.', 'v.'), ('Padova', 'padova'), (',', ','), ('Y.', 'y.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('The', 'the'), ('next', 'next'), ('frontier', 'frontier'), ('innovation', 'innov'), (',', ','), ('competition', 'competit'), (',', ','), ('productivity', 'product'), ('..', '..'), ('Mayer-Schonberger', 'mayer-schonberg'), (',', ','), ('V.', 'v.'), ('Padova', 'padova'), (',', ','), ('Y.', 'y.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('The', 'The'), ('next', 'next'), ('frontier', 'frontier'), ('innovation', 'innovation'), (',', ','), ('competition', 'competition'), (',', ','), ('productivity', 'productivity'), ('..', '..'), ('Mayer-Schonberger', 'Mayer-Schonberger'), (',', ','), ('V.', 'V.'), ('Padova', 'Padova'), (',', ','), ('Y.', 'Y.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 878 =============================

Regime Change: Enabling Big Data through   Europe's New Data Protection Regulation.. Colum. 


>> Tokens are: 
 ['Regime', 'Change', ':', 'Enabling', 'Big', 'Data', 'Europe', "'s", 'New', 'Data', 'Protection', 'Regulation', '..', 'Colum', '.']

>> Bigrams are: 
 [('Regime', 'Change'), ('Change', ':'), (':', 'Enabling'), ('Enabling', 'Big'), ('Big', 'Data'), ('Data', 'Europe'), ('Europe', "'s"), ("'s", 'New'), ('New', 'Data'), ('Data', 'Protection'), ('Protection', 'Regulation'), ('Regulation', '..'), ('..', 'Colum'), ('Colum', '.')]

>> Trigrams are: 
 [('Regime', 'Change', ':'), ('Change', ':', 'Enabling'), (':', 'Enabling', 'Big'), ('Enabling', 'Big', 'Data'), ('Big', 'Data', 'Europe'), ('Data', 'Europe', "'s"), ('Europe', "'s", 'New'), ("'s", 'New', 'Data'), ('New', 'Data', 'Protection'), ('Data', 'Protection', 'Regulation'), ('Protection', 'Regulation', '..'), ('Regulation', '..', 'Colum'), ('..', 'Colum', '.')]

>> POS Tags are: 
 [('Regime', 'JJ'), ('Change', 'NN'), (':', ':'), ('Enabling', 'NN'), ('Big', 'NNP'), ('Data', 'NNP'), ('Europe', 'NNP'), ("'s", 'POS'), ('New', 'NNP'), ('Data', 'NNP'), ('Protection', 'NNP'), ('Regulation', 'NNP'), ('..', 'NNP'), ('Colum', 'NNP'), ('.', '.')]

 (S
  (NP Regime/JJ Change/NN)
  :/:
  (NP Enabling/NN Big/NNP Data/NNP Europe/NNP)
  's/POS
  (NP
    New/NNP
    Data/NNP
    Protection/NNP
    Regulation/NNP
    ../NNP
    Colum/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Regime Change', 'Enabling Big Data Europe', 'New Data Protection Regulation .. Colum']

>> Named Entities are: 
 [('PERSON', 'Europe'), ('ORGANIZATION', 'New Data Protection Regulation')] 

>> Stemming using Porter Stemmer: 
 [('Regime', 'regim'), ('Change', 'chang'), (':', ':'), ('Enabling', 'enabl'), ('Big', 'big'), ('Data', 'data'), ('Europe', 'europ'), ("'s", "'s"), ('New', 'new'), ('Data', 'data'), ('Protection', 'protect'), ('Regulation', 'regul'), ('..', '..'), ('Colum', 'colum'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Regime', 'regim'), ('Change', 'chang'), (':', ':'), ('Enabling', 'enabl'), ('Big', 'big'), ('Data', 'data'), ('Europe', 'europ'), ("'s", "'s"), ('New', 'new'), ('Data', 'data'), ('Protection', 'protect'), ('Regulation', 'regul'), ('..', '..'), ('Colum', 'colum'), ('.', '.')]

>> Lemmatization: 
 [('Regime', 'Regime'), ('Change', 'Change'), (':', ':'), ('Enabling', 'Enabling'), ('Big', 'Big'), ('Data', 'Data'), ('Europe', 'Europe'), ("'s", "'s"), ('New', 'New'), ('Data', 'Data'), ('Protection', 'Protection'), ('Regulation', 'Regulation'), ('..', '..'), ('Colum', 'Colum'), ('.', '.')]



============================ Sentence 879 =============================

Sci. 


>> Tokens are: 
 ['Sci', '.']

>> Bigrams are: 
 [('Sci', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('Sci', 'NNP'), ('.', '.')]

 (S (NP Sci/NNP) ./.) 


>> Noun Phrases are: 
 ['Sci']

>> Named Entities are: 
 [('GPE', 'Sci')] 

>> Stemming using Porter Stemmer: 
 [('Sci', 'sci'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sci', 'sci'), ('.', '.')]

>> Lemmatization: 
 [('Sci', 'Sci'), ('.', '.')]



============================ Sentence 880 =============================

& Tech. 


>> Tokens are: 
 ['&', 'Tech', '.']

>> Bigrams are: 
 [('&', 'Tech'), ('Tech', '.')]

>> Trigrams are: 
 [('&', 'Tech', '.')]

>> POS Tags are: 
 [('&', 'CC'), ('Tech', 'NNP'), ('.', '.')]

 (S &/CC (NP Tech/NNP) ./.) 


>> Noun Phrases are: 
 ['Tech']

>> Named Entities are: 
 [('GPE', 'Tech')] 

>> Stemming using Porter Stemmer: 
 [('&', '&'), ('Tech', 'tech'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('&', '&'), ('Tech', 'tech'), ('.', '.')]

>> Lemmatization: 
 [('&', '&'), ('Tech', 'Tech'), ('.', '.')]



============================ Sentence 881 =============================

L. Rev. 


>> Tokens are: 
 ['L.', 'Rev', '.']

>> Bigrams are: 
 [('L.', 'Rev'), ('Rev', '.')]

>> Trigrams are: 
 [('L.', 'Rev', '.')]

>> POS Tags are: 
 [('L.', 'NNP'), ('Rev', 'NNP'), ('.', '.')]

 (S (NP L./NNP Rev/NNP) ./.) 


>> Noun Phrases are: 
 ['L. Rev']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('L.', 'l.'), ('Rev', 'rev'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('L.', 'l.'), ('Rev', 'rev'), ('.', '.')]

>> Lemmatization: 
 [('L.', 'L.'), ('Rev', 'Rev'), ('.', '.')]



============================ Sentence 882 =============================

Journal, p. 315. 


>> Tokens are: 
 ['Journal', ',', 'p.', '315', '.']

>> Bigrams are: 
 [('Journal', ','), (',', 'p.'), ('p.', '315'), ('315', '.')]

>> Trigrams are: 
 [('Journal', ',', 'p.'), (',', 'p.', '315'), ('p.', '315', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), (',', ','), ('p.', 'VBD'), ('315', 'CD'), ('.', '.')]

 (S (NP Journal/NNP) ,/, p./VBD 315/CD ./.) 


>> Noun Phrases are: 
 ['Journal']

>> Named Entities are: 
 [('GPE', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('315', '315'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), (',', ','), ('p.', 'p.'), ('315', '315'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), (',', ','), ('p.', 'p.'), ('315', '315'), ('.', '.')]



============================ Sentence 883 =============================

Mergel, I., Rethemeyer, R. K., & Isett, K., 2016. 


>> Tokens are: 
 ['Mergel', ',', 'I.', ',', 'Rethemeyer', ',', 'R.', 'K.', ',', '&', 'Isett', ',', 'K.', ',', '2016', '.']

>> Bigrams are: 
 [('Mergel', ','), (',', 'I.'), ('I.', ','), (',', 'Rethemeyer'), ('Rethemeyer', ','), (',', 'R.'), ('R.', 'K.'), ('K.', ','), (',', '&'), ('&', 'Isett'), ('Isett', ','), (',', 'K.'), ('K.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Mergel', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Rethemeyer'), (',', 'Rethemeyer', ','), ('Rethemeyer', ',', 'R.'), (',', 'R.', 'K.'), ('R.', 'K.', ','), ('K.', ',', '&'), (',', '&', 'Isett'), ('&', 'Isett', ','), ('Isett', ',', 'K.'), (',', 'K.', ','), ('K.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Mergel', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Rethemeyer', 'NNP'), (',', ','), ('R.', 'NNP'), ('K.', 'NNP'), (',', ','), ('&', 'CC'), ('Isett', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Mergel/NNP)
  ,/,
  (NP I./NNP)
  ,/,
  (NP Rethemeyer/NNP)
  ,/,
  (NP R./NNP K./NNP)
  ,/,
  &/CC
  (NP Isett/NNP)
  ,/,
  (NP K./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Mergel', 'I.', 'Rethemeyer', 'R. K.', 'Isett', 'K.']

>> Named Entities are: 
 [('GPE', 'Mergel'), ('GPE', 'Rethemeyer'), ('PERSON', 'Isett')] 

>> Stemming using Porter Stemmer: 
 [('Mergel', 'mergel'), (',', ','), ('I.', 'i.'), (',', ','), ('Rethemeyer', 'rethemey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Isett', 'isett'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mergel', 'mergel'), (',', ','), ('I.', 'i.'), (',', ','), ('Rethemeyer', 'rethemey'), (',', ','), ('R.', 'r.'), ('K.', 'k.'), (',', ','), ('&', '&'), ('Isett', 'isett'), (',', ','), ('K.', 'k.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Mergel', 'Mergel'), (',', ','), ('I.', 'I.'), (',', ','), ('Rethemeyer', 'Rethemeyer'), (',', ','), ('R.', 'R.'), ('K.', 'K.'), (',', ','), ('&', '&'), ('Isett', 'Isett'), (',', ','), ('K.', 'K.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 884 =============================

Big data in public affairs. 


>> Tokens are: 
 ['Big', 'data', 'public', 'affairs', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'public'), ('public', 'affairs'), ('affairs', '.')]

>> Trigrams are: 
 [('Big', 'data', 'public'), ('data', 'public', 'affairs'), ('public', 'affairs', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('public', 'JJ'), ('affairs', 'NNS'), ('.', '.')]

 (S (NP Big/NNP data/NNS) (NP public/JJ affairs/NNS) ./.) 


>> Noun Phrases are: 
 ['Big data', 'public affairs']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('public', 'public'), ('affairs', 'affair'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('public', 'public'), ('affairs', 'affair'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('public', 'public'), ('affairs', 'affair'), ('.', '.')]



============================ Sentence 885 =============================

Public Administration   Review Journal, pp. 


>> Tokens are: 
 ['Public', 'Administration', 'Review', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Public', 'Administration'), ('Administration', 'Review'), ('Review', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Public', 'Administration', 'Review'), ('Administration', 'Review', 'Journal'), ('Review', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Public', 'NNP'), ('Administration', 'NNP'), ('Review', 'NNP'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Public/NNP Administration/NNP Review/NNP Journal/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Public Administration Review Journal', 'pp']

>> Named Entities are: 
 [('PERSON', 'Public'), ('ORGANIZATION', 'Administration Review Journal')] 

>> Stemming using Porter Stemmer: 
 [('Public', 'public'), ('Administration', 'administr'), ('Review', 'review'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Public', 'public'), ('Administration', 'administr'), ('Review', 'review'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Public', 'Public'), ('Administration', 'Administration'), ('Review', 'Review'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 886 =============================

928-937. 


>> Tokens are: 
 ['928-937', '.']

>> Bigrams are: 
 [('928-937', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('928-937', 'CD'), ('.', '.')]

 (S 928-937/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('928-937', '928-937'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('928-937', '928-937'), ('.', '.')]

>> Lemmatization: 
 [('928-937', '928-937'), ('.', '.')]



============================ Sentence 887 =============================

Mikalef, P., Pappas, I.O., Krogstie, J. and Giannakos, M., 2018. 


>> Tokens are: 
 ['Mikalef', ',', 'P.', ',', 'Pappas', ',', 'I.O.', ',', 'Krogstie', ',', 'J.', 'Giannakos', ',', 'M.', ',', '2018', '.']

>> Bigrams are: 
 [('Mikalef', ','), (',', 'P.'), ('P.', ','), (',', 'Pappas'), ('Pappas', ','), (',', 'I.O.'), ('I.O.', ','), (',', 'Krogstie'), ('Krogstie', ','), (',', 'J.'), ('J.', 'Giannakos'), ('Giannakos', ','), (',', 'M.'), ('M.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Mikalef', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Pappas'), (',', 'Pappas', ','), ('Pappas', ',', 'I.O.'), (',', 'I.O.', ','), ('I.O.', ',', 'Krogstie'), (',', 'Krogstie', ','), ('Krogstie', ',', 'J.'), (',', 'J.', 'Giannakos'), ('J.', 'Giannakos', ','), ('Giannakos', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Mikalef', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Pappas', 'NNP'), (',', ','), ('I.O.', 'NNP'), (',', ','), ('Krogstie', 'NNP'), (',', ','), ('J.', 'NNP'), ('Giannakos', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Mikalef/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  (NP Pappas/NNP)
  ,/,
  (NP I.O./NNP)
  ,/,
  (NP Krogstie/NNP)
  ,/,
  (NP J./NNP Giannakos/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Mikalef', 'P.', 'Pappas', 'I.O.', 'Krogstie', 'J. Giannakos', 'M.']

>> Named Entities are: 
 [('GPE', 'Mikalef'), ('PERSON', 'Pappas'), ('GPE', 'Krogstie'), ('PERSON', 'J. Giannakos')] 

>> Stemming using Porter Stemmer: 
 [('Mikalef', 'mikalef'), (',', ','), ('P.', 'p.'), (',', ','), ('Pappas', 'pappa'), (',', ','), ('I.O.', 'i.o.'), (',', ','), ('Krogstie', 'krogsti'), (',', ','), ('J.', 'j.'), ('Giannakos', 'giannako'), (',', ','), ('M.', 'm.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mikalef', 'mikalef'), (',', ','), ('P.', 'p.'), (',', ','), ('Pappas', 'pappa'), (',', ','), ('I.O.', 'i.o.'), (',', ','), ('Krogstie', 'krogsti'), (',', ','), ('J.', 'j.'), ('Giannakos', 'giannako'), (',', ','), ('M.', 'm.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Mikalef', 'Mikalef'), (',', ','), ('P.', 'P.'), (',', ','), ('Pappas', 'Pappas'), (',', ','), ('I.O.', 'I.O.'), (',', ','), ('Krogstie', 'Krogstie'), (',', ','), ('J.', 'J.'), ('Giannakos', 'Giannakos'), (',', ','), ('M.', 'M.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 888 =============================

Big data analytics capabilities: a   systematic literature review and research agenda.. Journal of Information Systems and e-Business   Management, Volume 3, pp. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'capabilities', ':', 'systematic', 'literature', 'review', 'research', 'agenda', '..', 'Journal', 'Information', 'Systems', 'e-Business', 'Management', ',', 'Volume', '3', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'capabilities'), ('capabilities', ':'), (':', 'systematic'), ('systematic', 'literature'), ('literature', 'review'), ('review', 'research'), ('research', 'agenda'), ('agenda', '..'), ('..', 'Journal'), ('Journal', 'Information'), ('Information', 'Systems'), ('Systems', 'e-Business'), ('e-Business', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '3'), ('3', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'capabilities'), ('analytics', 'capabilities', ':'), ('capabilities', ':', 'systematic'), (':', 'systematic', 'literature'), ('systematic', 'literature', 'review'), ('literature', 'review', 'research'), ('review', 'research', 'agenda'), ('research', 'agenda', '..'), ('agenda', '..', 'Journal'), ('..', 'Journal', 'Information'), ('Journal', 'Information', 'Systems'), ('Information', 'Systems', 'e-Business'), ('Systems', 'e-Business', 'Management'), ('e-Business', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '3'), ('Volume', '3', ','), ('3', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('capabilities', 'NNS'), (':', ':'), ('systematic', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('research', 'NN'), ('agenda', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), ('e-Business', 'JJ'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('3', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS capabilities/NNS)
  :/:
  (NP
    systematic/JJ
    literature/NN
    review/NN
    research/NN
    agenda/NN
    ../NNP
    Journal/NNP
    Information/NNP
    Systems/NNP)
  (NP e-Business/JJ Management/NNP)
  ,/,
  (NP Volume/NN)
  3/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics capabilities', 'systematic literature review research agenda .. Journal Information Systems', 'e-Business Management', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), (':', ':'), ('systematic', 'systemat'), ('literature', 'literatur'), ('review', 'review'), ('research', 'research'), ('agenda', 'agenda'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), ('e-Business', 'e-busi'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('capabilities', 'capabl'), (':', ':'), ('systematic', 'systemat'), ('literature', 'literatur'), ('review', 'review'), ('research', 'research'), ('agenda', 'agenda'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), ('e-Business', 'e-busi'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('capabilities', 'capability'), (':', ':'), ('systematic', 'systematic'), ('literature', 'literature'), ('review', 'review'), ('research', 'research'), ('agenda', 'agenda'), ('..', '..'), ('Journal', 'Journal'), ('Information', 'Information'), ('Systems', 'Systems'), ('e-Business', 'e-Business'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('3', '3'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 889 =============================

547-578. 


>> Tokens are: 
 ['547-578', '.']

>> Bigrams are: 
 [('547-578', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('547-578', 'JJ'), ('.', '.')]

 (S 547-578/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('547-578', '547-578'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('547-578', '547-578'), ('.', '.')]

>> Lemmatization: 
 [('547-578', '547-578'), ('.', '.')]



============================ Sentence 890 =============================

Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D. and Riedmiller,   M., 2013. 


>> Tokens are: 
 ['Mnih', ',', 'V.', ',', 'Kavukcuoglu', ',', 'K.', ',', 'Silver', ',', 'D.', ',', 'Graves', ',', 'A.', ',', 'Antonoglou', ',', 'I.', ',', 'Wierstra', ',', 'D.', 'Riedmiller', ',', 'M.', ',', '2013', '.']

>> Bigrams are: 
 [('Mnih', ','), (',', 'V.'), ('V.', ','), (',', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'K.'), ('K.', ','), (',', 'Silver'), ('Silver', ','), (',', 'D.'), ('D.', ','), (',', 'Graves'), ('Graves', ','), (',', 'A.'), ('A.', ','), (',', 'Antonoglou'), ('Antonoglou', ','), (',', 'I.'), ('I.', ','), (',', 'Wierstra'), ('Wierstra', ','), (',', 'D.'), ('D.', 'Riedmiller'), ('Riedmiller', ','), (',', 'M.'), ('M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Mnih', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Kavukcuoglu'), (',', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Silver'), (',', 'Silver', ','), ('Silver', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Graves'), (',', 'Graves', ','), ('Graves', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Antonoglou'), (',', 'Antonoglou', ','), ('Antonoglou', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Wierstra'), (',', 'Wierstra', ','), ('Wierstra', ',', 'D.'), (',', 'D.', 'Riedmiller'), ('D.', 'Riedmiller', ','), ('Riedmiller', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Kavukcuoglu', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Silver', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Graves', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Antonoglou', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Wierstra', 'NNP'), (',', ','), ('D.', 'NNP'), ('Riedmiller', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Mnih/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  (NP Kavukcuoglu/NNP)
  ,/,
  (NP K./NNP)
  ,/,
  (NP Silver/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  (NP Graves/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Antonoglou/NNP)
  ,/,
  (NP I./NNP)
  ,/,
  (NP Wierstra/NNP)
  ,/,
  (NP D./NNP Riedmiller/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Mnih', 'V.', 'Kavukcuoglu', 'K.', 'Silver', 'D.', 'Graves', 'A.', 'Antonoglou', 'I.', 'Wierstra', 'D. Riedmiller', 'M.']

>> Named Entities are: 
 [('GPE', 'Mnih'), ('GPE', 'Kavukcuoglu'), ('GPE', 'Silver'), ('GPE', 'Graves'), ('PERSON', 'Antonoglou'), ('GPE', 'Wierstra')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), (',', ','), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), (',', ','), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Antonoglou', 'antonogl'), (',', ','), ('I.', 'i.'), (',', ','), ('Wierstra', 'wierstra'), (',', ','), ('D.', 'd.'), ('Riedmiller', 'riedmil'), (',', ','), ('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('V.', 'v.'), (',', ','), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('K.', 'k.'), (',', ','), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('Graves', 'grave'), (',', ','), ('A.', 'a.'), (',', ','), ('Antonoglou', 'antonoglou'), (',', ','), ('I.', 'i.'), (',', ','), ('Wierstra', 'wierstra'), (',', ','), ('D.', 'd.'), ('Riedmiller', 'riedmil'), (',', ','), ('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('V.', 'V.'), (',', ','), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('K.', 'K.'), (',', ','), ('Silver', 'Silver'), (',', ','), ('D.', 'D.'), (',', ','), ('Graves', 'Graves'), (',', ','), ('A.', 'A.'), (',', ','), ('Antonoglou', 'Antonoglou'), (',', ','), ('I.', 'I.'), (',', ','), ('Wierstra', 'Wierstra'), (',', ','), ('D.', 'D.'), ('Riedmiller', 'Riedmiller'), (',', ','), ('M.', 'M.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 891 =============================

Playing atari with deep reinforcement learning. 


>> Tokens are: 
 ['Playing', 'atari', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Playing', 'atari'), ('atari', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Playing', 'atari', 'deep'), ('atari', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Playing', 'VBG'), ('atari', 'JJ'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  Playing/VBG
  (NP atari/JJ deep/JJ reinforcement/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['atari deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Playing', 'play'), ('atari', 'atari'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Playing', 'play'), ('atari', 'atari'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Playing', 'Playing'), ('atari', 'atari'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 892 =============================

arXiv preprint arXiv:1312.5602. 


>> Tokens are: 
 ['arXiv', 'preprint', 'arXiv:1312.5602', '.']

>> Bigrams are: 
 [('arXiv', 'preprint'), ('preprint', 'arXiv:1312.5602'), ('arXiv:1312.5602', '.')]

>> Trigrams are: 
 [('arXiv', 'preprint', 'arXiv:1312.5602'), ('preprint', 'arXiv:1312.5602', '.')]

>> POS Tags are: 
 [('arXiv', 'JJ'), ('preprint', 'NN'), ('arXiv:1312.5602', 'NN'), ('.', '.')]

 (S (NP arXiv/JJ preprint/NN arXiv:1312.5602/NN) ./.) 


>> Noun Phrases are: 
 ['arXiv preprint arXiv:1312.5602']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1312.5602', 'arxiv:1312.5602'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('arXiv', 'arxiv'), ('preprint', 'preprint'), ('arXiv:1312.5602', 'arxiv:1312.5602'), ('.', '.')]

>> Lemmatization: 
 [('arXiv', 'arXiv'), ('preprint', 'preprint'), ('arXiv:1312.5602', 'arXiv:1312.5602'), ('.', '.')]



============================ Sentence 893 =============================

Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and   Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray, 2016. 


>> Tokens are: 
 ['Mnih', ',', 'Volodymyr', 'Badia', ',', 'Adria', 'Puigdomenech', 'Mirza', ',', 'Mehdi', 'Graves', ',', 'Alex', 'Lillicrap', ',', 'Timothy', 'Harley', ',', 'Tim', 'Silver', ',', 'David', 'Kavukcuoglu', ',', 'Koray', ',', '2016', '.']

>> Bigrams are: 
 [('Mnih', ','), (',', 'Volodymyr'), ('Volodymyr', 'Badia'), ('Badia', ','), (',', 'Adria'), ('Adria', 'Puigdomenech'), ('Puigdomenech', 'Mirza'), ('Mirza', ','), (',', 'Mehdi'), ('Mehdi', 'Graves'), ('Graves', ','), (',', 'Alex'), ('Alex', 'Lillicrap'), ('Lillicrap', ','), (',', 'Timothy'), ('Timothy', 'Harley'), ('Harley', ','), (',', 'Tim'), ('Tim', 'Silver'), ('Silver', ','), (',', 'David'), ('David', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'Koray'), ('Koray', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Mnih', ',', 'Volodymyr'), (',', 'Volodymyr', 'Badia'), ('Volodymyr', 'Badia', ','), ('Badia', ',', 'Adria'), (',', 'Adria', 'Puigdomenech'), ('Adria', 'Puigdomenech', 'Mirza'), ('Puigdomenech', 'Mirza', ','), ('Mirza', ',', 'Mehdi'), (',', 'Mehdi', 'Graves'), ('Mehdi', 'Graves', ','), ('Graves', ',', 'Alex'), (',', 'Alex', 'Lillicrap'), ('Alex', 'Lillicrap', ','), ('Lillicrap', ',', 'Timothy'), (',', 'Timothy', 'Harley'), ('Timothy', 'Harley', ','), ('Harley', ',', 'Tim'), (',', 'Tim', 'Silver'), ('Tim', 'Silver', ','), ('Silver', ',', 'David'), (',', 'David', 'Kavukcuoglu'), ('David', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'Koray'), (',', 'Koray', ','), ('Koray', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('Volodymyr', 'NNP'), ('Badia', 'NNP'), (',', ','), ('Adria', 'NNP'), ('Puigdomenech', 'NNP'), ('Mirza', 'NNP'), (',', ','), ('Mehdi', 'NNP'), ('Graves', 'NNP'), (',', ','), ('Alex', 'NNP'), ('Lillicrap', 'NNP'), (',', ','), ('Timothy', 'NNP'), ('Harley', 'NNP'), (',', ','), ('Tim', 'NNP'), ('Silver', 'NNP'), (',', ','), ('David', 'NNP'), ('Kavukcuoglu', 'NNP'), (',', ','), ('Koray', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Mnih/NNP)
  ,/,
  (NP Volodymyr/NNP Badia/NNP)
  ,/,
  (NP Adria/NNP Puigdomenech/NNP Mirza/NNP)
  ,/,
  (NP Mehdi/NNP Graves/NNP)
  ,/,
  (NP Alex/NNP Lillicrap/NNP)
  ,/,
  (NP Timothy/NNP Harley/NNP)
  ,/,
  (NP Tim/NNP Silver/NNP)
  ,/,
  (NP David/NNP Kavukcuoglu/NNP)
  ,/,
  (NP Koray/NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Mnih', 'Volodymyr Badia', 'Adria Puigdomenech Mirza', 'Mehdi Graves', 'Alex Lillicrap', 'Timothy Harley', 'Tim Silver', 'David Kavukcuoglu', 'Koray']

>> Named Entities are: 
 [('GPE', 'Mnih'), ('PERSON', 'Volodymyr Badia'), ('PERSON', 'Adria Puigdomenech Mirza'), ('PERSON', 'Mehdi Graves'), ('PERSON', 'Alex Lillicrap'), ('PERSON', 'Timothy Harley'), ('PERSON', 'Tim Silver'), ('PERSON', 'David Kavukcuoglu'), ('GPE', 'Koray')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Badia', 'badia'), (',', ','), ('Adria', 'adria'), ('Puigdomenech', 'puigdomenech'), ('Mirza', 'mirza'), (',', ','), ('Mehdi', 'mehdi'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex'), ('Lillicrap', 'lillicrap'), (',', ','), ('Timothy', 'timothi'), ('Harley', 'harley'), (',', ','), ('Tim', 'tim'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Badia', 'badia'), (',', ','), ('Adria', 'adria'), ('Puigdomenech', 'puigdomenech'), ('Mirza', 'mirza'), (',', ','), ('Mehdi', 'mehdi'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex'), ('Lillicrap', 'lillicrap'), (',', ','), ('Timothy', 'timothi'), ('Harley', 'harley'), (',', ','), ('Tim', 'tim'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('Volodymyr', 'Volodymyr'), ('Badia', 'Badia'), (',', ','), ('Adria', 'Adria'), ('Puigdomenech', 'Puigdomenech'), ('Mirza', 'Mirza'), (',', ','), ('Mehdi', 'Mehdi'), ('Graves', 'Graves'), (',', ','), ('Alex', 'Alex'), ('Lillicrap', 'Lillicrap'), (',', ','), ('Timothy', 'Timothy'), ('Harley', 'Harley'), (',', ','), ('Tim', 'Tim'), ('Silver', 'Silver'), (',', ','), ('David', 'David'), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('Koray', 'Koray'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 894 =============================

Asynchronous methods for deep reinforcement learning. 


>> Tokens are: 
 ['Asynchronous', 'methods', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Asynchronous', 'methods'), ('methods', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Asynchronous', 'methods', 'deep'), ('methods', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Asynchronous', 'JJ'), ('methods', 'NNS'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Asynchronous/JJ methods/NNS)
  (NP deep/JJ reinforcement/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Asynchronous methods', 'deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Asynchronous', 'asynchron'), ('methods', 'method'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Asynchronous', 'asynchron'), ('methods', 'method'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Asynchronous', 'Asynchronous'), ('methods', 'method'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 895 =============================

New York, NY, US, s.n., pp. 


>> Tokens are: 
 ['New', 'York', ',', 'NY', ',', 'US', ',', 's.n.', ',', 'pp', '.']

>> Bigrams are: 
 [('New', 'York'), ('York', ','), (',', 'NY'), ('NY', ','), (',', 'US'), ('US', ','), (',', 's.n.'), ('s.n.', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('New', 'York', ','), ('York', ',', 'NY'), (',', 'NY', ','), ('NY', ',', 'US'), (',', 'US', ','), ('US', ',', 's.n.'), (',', 's.n.', ','), ('s.n.', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('New', 'NNP'), ('York', 'NNP'), (',', ','), ('NY', 'NNP'), (',', ','), ('US', 'NNP'), (',', ','), ('s.n.', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP New/NNP York/NNP)
  ,/,
  (NP NY/NNP)
  ,/,
  (NP US/NNP)
  ,/,
  (NP s.n./NN)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['New York', 'NY', 'US', 's.n.', 'pp']

>> Named Entities are: 
 [('GPE', 'New York'), ('ORGANIZATION', 'NY'), ('GSP', 'US')] 

>> Stemming using Porter Stemmer: 
 [('New', 'new'), ('York', 'york'), (',', ','), ('NY', 'ny'), (',', ','), ('US', 'us'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('New', 'new'), ('York', 'york'), (',', ','), ('NY', 'ny'), (',', ','), ('US', 'us'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('New', 'New'), ('York', 'York'), (',', ','), ('NY', 'NY'), (',', ','), ('US', 'US'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 896 =============================

1928--1937. 


>> Tokens are: 
 ['1928', '--', '1937', '.']

>> Bigrams are: 
 [('1928', '--'), ('--', '1937'), ('1937', '.')]

>> Trigrams are: 
 [('1928', '--', '1937'), ('--', '1937', '.')]

>> POS Tags are: 
 [('1928', 'CD'), ('--', ':'), ('1937', 'CD'), ('.', '.')]

 (S 1928/CD --/: 1937/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1928', '1928'), ('--', '--'), ('1937', '1937'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1928', '1928'), ('--', '--'), ('1937', '1937'), ('.', '.')]

>> Lemmatization: 
 [('1928', '1928'), ('--', '--'), ('1937', '1937'), ('.', '.')]



============================ Sentence 897 =============================

Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness,   Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K   and Ostrovski, Georg and others, 2015. 


>> Tokens are: 
 ['Mnih', ',', 'Volodymyr', 'Kavukcuoglu', ',', 'Koray', 'Silver', ',', 'David', 'Rusu', ',', 'Andrei', 'A', 'Veness', ',', 'Joel', 'Bellemare', ',', 'Marc', 'G', 'Graves', ',', 'Alex', 'Riedmiller', ',', 'Martin', 'Fidjeland', ',', 'Andreas', 'K', 'Ostrovski', ',', 'Georg', 'others', ',', '2015', '.']

>> Bigrams are: 
 [('Mnih', ','), (',', 'Volodymyr'), ('Volodymyr', 'Kavukcuoglu'), ('Kavukcuoglu', ','), (',', 'Koray'), ('Koray', 'Silver'), ('Silver', ','), (',', 'David'), ('David', 'Rusu'), ('Rusu', ','), (',', 'Andrei'), ('Andrei', 'A'), ('A', 'Veness'), ('Veness', ','), (',', 'Joel'), ('Joel', 'Bellemare'), ('Bellemare', ','), (',', 'Marc'), ('Marc', 'G'), ('G', 'Graves'), ('Graves', ','), (',', 'Alex'), ('Alex', 'Riedmiller'), ('Riedmiller', ','), (',', 'Martin'), ('Martin', 'Fidjeland'), ('Fidjeland', ','), (',', 'Andreas'), ('Andreas', 'K'), ('K', 'Ostrovski'), ('Ostrovski', ','), (',', 'Georg'), ('Georg', 'others'), ('others', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Mnih', ',', 'Volodymyr'), (',', 'Volodymyr', 'Kavukcuoglu'), ('Volodymyr', 'Kavukcuoglu', ','), ('Kavukcuoglu', ',', 'Koray'), (',', 'Koray', 'Silver'), ('Koray', 'Silver', ','), ('Silver', ',', 'David'), (',', 'David', 'Rusu'), ('David', 'Rusu', ','), ('Rusu', ',', 'Andrei'), (',', 'Andrei', 'A'), ('Andrei', 'A', 'Veness'), ('A', 'Veness', ','), ('Veness', ',', 'Joel'), (',', 'Joel', 'Bellemare'), ('Joel', 'Bellemare', ','), ('Bellemare', ',', 'Marc'), (',', 'Marc', 'G'), ('Marc', 'G', 'Graves'), ('G', 'Graves', ','), ('Graves', ',', 'Alex'), (',', 'Alex', 'Riedmiller'), ('Alex', 'Riedmiller', ','), ('Riedmiller', ',', 'Martin'), (',', 'Martin', 'Fidjeland'), ('Martin', 'Fidjeland', ','), ('Fidjeland', ',', 'Andreas'), (',', 'Andreas', 'K'), ('Andreas', 'K', 'Ostrovski'), ('K', 'Ostrovski', ','), ('Ostrovski', ',', 'Georg'), (',', 'Georg', 'others'), ('Georg', 'others', ','), ('others', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Mnih', 'NNP'), (',', ','), ('Volodymyr', 'NNP'), ('Kavukcuoglu', 'NNP'), (',', ','), ('Koray', 'NNP'), ('Silver', 'NNP'), (',', ','), ('David', 'NNP'), ('Rusu', 'NNP'), (',', ','), ('Andrei', 'NNP'), ('A', 'NNP'), ('Veness', 'NNP'), (',', ','), ('Joel', 'NNP'), ('Bellemare', 'NNP'), (',', ','), ('Marc', 'NNP'), ('G', 'NNP'), ('Graves', 'NNP'), (',', ','), ('Alex', 'NNP'), ('Riedmiller', 'NNP'), (',', ','), ('Martin', 'NNP'), ('Fidjeland', 'NNP'), (',', ','), ('Andreas', 'NNP'), ('K', 'NNP'), ('Ostrovski', 'NNP'), (',', ','), ('Georg', 'NNP'), ('others', 'NNS'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Mnih/NNP)
  ,/,
  (NP Volodymyr/NNP Kavukcuoglu/NNP)
  ,/,
  (NP Koray/NNP Silver/NNP)
  ,/,
  (NP David/NNP Rusu/NNP)
  ,/,
  (NP Andrei/NNP A/NNP Veness/NNP)
  ,/,
  (NP Joel/NNP Bellemare/NNP)
  ,/,
  (NP Marc/NNP G/NNP Graves/NNP)
  ,/,
  (NP Alex/NNP Riedmiller/NNP)
  ,/,
  (NP Martin/NNP Fidjeland/NNP)
  ,/,
  (NP Andreas/NNP K/NNP Ostrovski/NNP)
  ,/,
  (NP Georg/NNP others/NNS)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Mnih', 'Volodymyr Kavukcuoglu', 'Koray Silver', 'David Rusu', 'Andrei A Veness', 'Joel Bellemare', 'Marc G Graves', 'Alex Riedmiller', 'Martin Fidjeland', 'Andreas K Ostrovski', 'Georg others']

>> Named Entities are: 
 [('GPE', 'Mnih'), ('PERSON', 'Volodymyr Kavukcuoglu'), ('PERSON', 'Koray Silver'), ('PERSON', 'David Rusu'), ('PERSON', 'Andrei A Veness'), ('PERSON', 'Joel Bellemare'), ('PERSON', 'Marc G Graves'), ('PERSON', 'Alex Riedmiller'), ('PERSON', 'Martin Fidjeland'), ('PERSON', 'Andreas K Ostrovski'), ('GPE', 'Georg')] 

>> Stemming using Porter Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Rusu', 'rusu'), (',', ','), ('Andrei', 'andrei'), ('A', 'a'), ('Veness', 'veness'), (',', ','), ('Joel', 'joel'), ('Bellemare', 'bellemar'), (',', ','), ('Marc', 'marc'), ('G', 'g'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex'), ('Riedmiller', 'riedmil'), (',', ','), ('Martin', 'martin'), ('Fidjeland', 'fidjeland'), (',', ','), ('Andreas', 'andrea'), ('K', 'k'), ('Ostrovski', 'ostrovski'), (',', ','), ('Georg', 'georg'), ('others', 'other'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mnih', 'mnih'), (',', ','), ('Volodymyr', 'volodymyr'), ('Kavukcuoglu', 'kavukcuoglu'), (',', ','), ('Koray', 'koray'), ('Silver', 'silver'), (',', ','), ('David', 'david'), ('Rusu', 'rusu'), (',', ','), ('Andrei', 'andrei'), ('A', 'a'), ('Veness', 'veness'), (',', ','), ('Joel', 'joel'), ('Bellemare', 'bellemar'), (',', ','), ('Marc', 'marc'), ('G', 'g'), ('Graves', 'grave'), (',', ','), ('Alex', 'alex'), ('Riedmiller', 'riedmil'), (',', ','), ('Martin', 'martin'), ('Fidjeland', 'fidjeland'), (',', ','), ('Andreas', 'andrea'), ('K', 'k'), ('Ostrovski', 'ostrovski'), (',', ','), ('Georg', 'georg'), ('others', 'other'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Mnih', 'Mnih'), (',', ','), ('Volodymyr', 'Volodymyr'), ('Kavukcuoglu', 'Kavukcuoglu'), (',', ','), ('Koray', 'Koray'), ('Silver', 'Silver'), (',', ','), ('David', 'David'), ('Rusu', 'Rusu'), (',', ','), ('Andrei', 'Andrei'), ('A', 'A'), ('Veness', 'Veness'), (',', ','), ('Joel', 'Joel'), ('Bellemare', 'Bellemare'), (',', ','), ('Marc', 'Marc'), ('G', 'G'), ('Graves', 'Graves'), (',', ','), ('Alex', 'Alex'), ('Riedmiller', 'Riedmiller'), (',', ','), ('Martin', 'Martin'), ('Fidjeland', 'Fidjeland'), (',', ','), ('Andreas', 'Andreas'), ('K', 'K'), ('Ostrovski', 'Ostrovski'), (',', ','), ('Georg', 'Georg'), ('others', 'others'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 898 =============================

Human-level control through deep reinforcement learning. 


>> Tokens are: 
 ['Human-level', 'control', 'deep', 'reinforcement', 'learning', '.']

>> Bigrams are: 
 [('Human-level', 'control'), ('control', 'deep'), ('deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Human-level', 'control', 'deep'), ('control', 'deep', 'reinforcement'), ('deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', '.')]

>> POS Tags are: 
 [('Human-level', 'NNP'), ('control', 'NN'), ('deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Human-level/NNP control/NN)
  (NP deep/JJ reinforcement/NN learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Human-level control', 'deep reinforcement learning']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Human-level', 'human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Human-level', 'human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Human-level', 'Human-level'), ('control', 'control'), ('deep', 'deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 899 =============================

Nature journal, Volume 518, p. 529. 


>> Tokens are: 
 ['Nature', 'journal', ',', 'Volume', '518', ',', 'p.', '529', '.']

>> Bigrams are: 
 [('Nature', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '518'), ('518', ','), (',', 'p.'), ('p.', '529'), ('529', '.')]

>> Trigrams are: 
 [('Nature', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '518'), ('Volume', '518', ','), ('518', ',', 'p.'), (',', 'p.', '529'), ('p.', '529', '.')]

>> POS Tags are: 
 [('Nature', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('518', 'CD'), (',', ','), ('p.', 'RB'), ('529', 'CD'), ('.', '.')]

 (S
  (NP Nature/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  518/CD
  ,/,
  p./RB
  529/CD
  ./.) 


>> Noun Phrases are: 
 ['Nature journal', 'Volume']

>> Named Entities are: 
 [('GPE', 'Nature'), ('ORGANIZATION', 'Volume 518')] 

>> Stemming using Porter Stemmer: 
 [('Nature', 'natur'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('518', '518'), (',', ','), ('p.', 'p.'), ('529', '529'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nature', 'natur'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('518', '518'), (',', ','), ('p.', 'p.'), ('529', '529'), ('.', '.')]

>> Lemmatization: 
 [('Nature', 'Nature'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('518', '518'), (',', ','), ('p.', 'p.'), ('529', '529'), ('.', '.')]



============================ Sentence 900 =============================

Mouthami, K., Devi, K.N. 


>> Tokens are: 
 ['Mouthami', ',', 'K.', ',', 'Devi', ',', 'K.N', '.']

>> Bigrams are: 
 [('Mouthami', ','), (',', 'K.'), ('K.', ','), (',', 'Devi'), ('Devi', ','), (',', 'K.N'), ('K.N', '.')]

>> Trigrams are: 
 [('Mouthami', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Devi'), (',', 'Devi', ','), ('Devi', ',', 'K.N'), (',', 'K.N', '.')]

>> POS Tags are: 
 [('Mouthami', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Devi', 'NNP'), (',', ','), ('K.N', 'NNP'), ('.', '.')]

 (S
  (NP Mouthami/NNP)
  ,/,
  (NP K./NNP)
  ,/,
  (NP Devi/NNP)
  ,/,
  (NP K.N/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Mouthami', 'K.', 'Devi', 'K.N']

>> Named Entities are: 
 [('GPE', 'Mouthami'), ('PERSON', 'Devi')] 

>> Stemming using Porter Stemmer: 
 [('Mouthami', 'mouthami'), (',', ','), ('K.', 'k.'), (',', ','), ('Devi', 'devi'), (',', ','), ('K.N', 'k.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Mouthami', 'mouthami'), (',', ','), ('K.', 'k.'), (',', ','), ('Devi', 'devi'), (',', ','), ('K.N', 'k.n'), ('.', '.')]

>> Lemmatization: 
 [('Mouthami', 'Mouthami'), (',', ','), ('K.', 'K.'), (',', ','), ('Devi', 'Devi'), (',', ','), ('K.N', 'K.N'), ('.', '.')]



============================ Sentence 901 =============================

and Bhaskaran, V.M., 2013. 


>> Tokens are: 
 ['Bhaskaran', ',', 'V.M.', ',', '2013', '.']

>> Bigrams are: 
 [('Bhaskaran', ','), (',', 'V.M.'), ('V.M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Bhaskaran', ',', 'V.M.'), (',', 'V.M.', ','), ('V.M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Bhaskaran', 'NNP'), (',', ','), ('V.M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S (NP Bhaskaran/NNP) ,/, (NP V.M./NNP) ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 ['Bhaskaran', 'V.M.']

>> Named Entities are: 
 [('GPE', 'Bhaskaran')] 

>> Stemming using Porter Stemmer: 
 [('Bhaskaran', 'bhaskaran'), (',', ','), ('V.M.', 'v.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Bhaskaran', 'bhaskaran'), (',', ','), ('V.M.', 'v.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Bhaskaran', 'Bhaskaran'), (',', ','), ('V.M.', 'V.M.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 902 =============================

Sentiment analysis and classification based   on textual reviews.. 


>> Tokens are: 
 ['Sentiment', 'analysis', 'classification', 'based', 'textual', 'reviews', '..']

>> Bigrams are: 
 [('Sentiment', 'analysis'), ('analysis', 'classification'), ('classification', 'based'), ('based', 'textual'), ('textual', 'reviews'), ('reviews', '..')]

>> Trigrams are: 
 [('Sentiment', 'analysis', 'classification'), ('analysis', 'classification', 'based'), ('classification', 'based', 'textual'), ('based', 'textual', 'reviews'), ('textual', 'reviews', '..')]

>> POS Tags are: 
 [('Sentiment', 'NN'), ('analysis', 'NN'), ('classification', 'NN'), ('based', 'VBN'), ('textual', 'JJ'), ('reviews', 'NNS'), ('..', 'VBP')]

 (S
  (NP Sentiment/NN analysis/NN classification/NN)
  based/VBN
  (NP textual/JJ reviews/NNS)
  ../VBP) 


>> Noun Phrases are: 
 ['Sentiment analysis classification', 'textual reviews']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('classification', 'classif'), ('based', 'base'), ('textual', 'textual'), ('reviews', 'review'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Sentiment', 'sentiment'), ('analysis', 'analysi'), ('classification', 'classif'), ('based', 'base'), ('textual', 'textual'), ('reviews', 'review'), ('..', '..')]

>> Lemmatization: 
 [('Sentiment', 'Sentiment'), ('analysis', 'analysis'), ('classification', 'classification'), ('based', 'based'), ('textual', 'textual'), ('reviews', 'review'), ('..', '..')]



============================ Sentence 903 =============================

s.l., IEEE. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), ('.', '.')]



============================ Sentence 904 =============================

Sarah Al-Shiakhli   52      Müller, O., Junglas, I., Brocke, J.V. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '52', 'Müller', ',', 'O.', ',', 'Junglas', ',', 'I.', ',', 'Brocke', ',', 'J.V', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '52'), ('52', 'Müller'), ('Müller', ','), (',', 'O.'), ('O.', ','), (',', 'Junglas'), ('Junglas', ','), (',', 'I.'), ('I.', ','), (',', 'Brocke'), ('Brocke', ','), (',', 'J.V'), ('J.V', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '52'), ('Al-Shiakhli', '52', 'Müller'), ('52', 'Müller', ','), ('Müller', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Junglas'), (',', 'Junglas', ','), ('Junglas', ',', 'I.'), (',', 'I.', ','), ('I.', ',', 'Brocke'), (',', 'Brocke', ','), ('Brocke', ',', 'J.V'), (',', 'J.V', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('52', 'CD'), ('Müller', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Junglas', 'NNP'), (',', ','), ('I.', 'NNP'), (',', ','), ('Brocke', 'NNP'), (',', ','), ('J.V', 'NNP'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  52/CD
  (NP Müller/NNP)
  ,/,
  (NP O./NNP)
  ,/,
  (NP Junglas/NNP)
  ,/,
  (NP I./NNP)
  ,/,
  (NP Brocke/NNP)
  ,/,
  (NP J.V/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Müller', 'O.', 'Junglas', 'I.', 'Brocke', 'J.V']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Müller'), ('PERSON', 'Junglas'), ('GPE', 'Brocke')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('52', '52'), ('Müller', 'müller'), (',', ','), ('O.', 'o.'), (',', ','), ('Junglas', 'jungla'), (',', ','), ('I.', 'i.'), (',', ','), ('Brocke', 'brock'), (',', ','), ('J.V', 'j.v'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('52', '52'), ('Müller', 'müller'), (',', ','), ('O.', 'o.'), (',', ','), ('Junglas', 'jungla'), (',', ','), ('I.', 'i.'), (',', ','), ('Brocke', 'brock'), (',', ','), ('J.V', 'j.v'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('52', '52'), ('Müller', 'Müller'), (',', ','), ('O.', 'O.'), (',', ','), ('Junglas', 'Junglas'), (',', ','), ('I.', 'I.'), (',', ','), ('Brocke', 'Brocke'), (',', ','), ('J.V', 'J.V'), ('.', '.')]



============================ Sentence 905 =============================

and Debortoli, S., 2016. 


>> Tokens are: 
 ['Debortoli', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Debortoli', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Debortoli', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Debortoli', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S (NP Debortoli/NNP) ,/, (NP S./NNP) ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 ['Debortoli', 'S.']

>> Named Entities are: 
 [('GPE', 'Debortoli')] 

>> Stemming using Porter Stemmer: 
 [('Debortoli', 'debortoli'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Debortoli', 'debortoli'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Debortoli', 'Debortoli'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 906 =============================

Utilizing big data analytics for   information systems research: challenges, promises and guidelines. 


>> Tokens are: 
 ['Utilizing', 'big', 'data', 'analytics', 'information', 'systems', 'research', ':', 'challenges', ',', 'promises', 'guidelines', '.']

>> Bigrams are: 
 [('Utilizing', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'information'), ('information', 'systems'), ('systems', 'research'), ('research', ':'), (':', 'challenges'), ('challenges', ','), (',', 'promises'), ('promises', 'guidelines'), ('guidelines', '.')]

>> Trigrams are: 
 [('Utilizing', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'information'), ('analytics', 'information', 'systems'), ('information', 'systems', 'research'), ('systems', 'research', ':'), ('research', ':', 'challenges'), (':', 'challenges', ','), ('challenges', ',', 'promises'), (',', 'promises', 'guidelines'), ('promises', 'guidelines', '.')]

>> POS Tags are: 
 [('Utilizing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('information', 'NN'), ('systems', 'NNS'), ('research', 'NN'), (':', ':'), ('challenges', 'NNS'), (',', ','), ('promises', 'NNS'), ('guidelines', 'NNS'), ('.', '.')]

 (S
  Utilizing/VBG
  (NP
    big/JJ
    data/NNS
    analytics/NNS
    information/NN
    systems/NNS
    research/NN)
  :/:
  (NP challenges/NNS)
  ,/,
  (NP promises/NNS guidelines/NNS)
  ./.) 


>> Noun Phrases are: 
 ['big data analytics information systems research', 'challenges', 'promises guidelines']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('information', 'inform'), ('systems', 'system'), ('research', 'research'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('promises', 'promis'), ('guidelines', 'guidelin'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Utilizing', 'util'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('information', 'inform'), ('systems', 'system'), ('research', 'research'), (':', ':'), ('challenges', 'challeng'), (',', ','), ('promises', 'promis'), ('guidelines', 'guidelin'), ('.', '.')]

>> Lemmatization: 
 [('Utilizing', 'Utilizing'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('information', 'information'), ('systems', 'system'), ('research', 'research'), (':', ':'), ('challenges', 'challenge'), (',', ','), ('promises', 'promise'), ('guidelines', 'guideline'), ('.', '.')]



============================ Sentence 907 =============================

European Journal of   Information Systems, pp. 


>> Tokens are: 
 ['European', 'Journal', 'Information', 'Systems', ',', 'pp', '.']

>> Bigrams are: 
 [('European', 'Journal'), ('Journal', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('European', 'Journal', 'Information'), ('Journal', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('European', 'JJ'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP European/JJ Journal/NNP Information/NNP Systems/NNP)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['European Journal Information Systems', 'pp']

>> Named Entities are: 
 [('GPE', 'European'), ('ORGANIZATION', 'Journal Information Systems')] 

>> Stemming using Porter Stemmer: 
 [('European', 'european'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('European', 'european'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('European', 'European'), ('Journal', 'Journal'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 908 =============================

289-302. 


>> Tokens are: 
 ['289-302', '.']

>> Bigrams are: 
 [('289-302', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('289-302', 'JJ'), ('.', '.')]

 (S 289-302/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('289-302', '289-302'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('289-302', '289-302'), ('.', '.')]

>> Lemmatization: 
 [('289-302', '289-302'), ('.', '.')]



============================ Sentence 909 =============================

Nafus, D. and Sherman, J., 2014. 


>> Tokens are: 
 ['Nafus', ',', 'D.', 'Sherman', ',', 'J.', ',', '2014', '.']

>> Bigrams are: 
 [('Nafus', ','), (',', 'D.'), ('D.', 'Sherman'), ('Sherman', ','), (',', 'J.'), ('J.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Nafus', ',', 'D.'), (',', 'D.', 'Sherman'), ('D.', 'Sherman', ','), ('Sherman', ',', 'J.'), (',', 'J.', ','), ('J.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Nafus', 'NNP'), (',', ','), ('D.', 'NNP'), ('Sherman', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Nafus/NNP)
  ,/,
  (NP D./NNP Sherman/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Nafus', 'D. Sherman', 'J.']

>> Named Entities are: 
 [('GPE', 'Nafus')] 

>> Stemming using Porter Stemmer: 
 [('Nafus', 'nafu'), (',', ','), ('D.', 'd.'), ('Sherman', 'sherman'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nafus', 'nafus'), (',', ','), ('D.', 'd.'), ('Sherman', 'sherman'), (',', ','), ('J.', 'j.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Nafus', 'Nafus'), (',', ','), ('D.', 'D.'), ('Sherman', 'Sherman'), (',', ','), ('J.', 'J.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 910 =============================

Big data, big questions| this one does not go up to 11: the   quantified self movement as an alternative big data practice.. International journal of   communication, p. 11. 


>> Tokens are: 
 ['Big', 'data', ',', 'big', 'questions|', 'one', 'go', '11', ':', 'quantified', 'self', 'movement', 'alternative', 'big', 'data', 'practice', '..', 'International', 'journal', 'communication', ',', 'p.', '11', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ','), (',', 'big'), ('big', 'questions|'), ('questions|', 'one'), ('one', 'go'), ('go', '11'), ('11', ':'), (':', 'quantified'), ('quantified', 'self'), ('self', 'movement'), ('movement', 'alternative'), ('alternative', 'big'), ('big', 'data'), ('data', 'practice'), ('practice', '..'), ('..', 'International'), ('International', 'journal'), ('journal', 'communication'), ('communication', ','), (',', 'p.'), ('p.', '11'), ('11', '.')]

>> Trigrams are: 
 [('Big', 'data', ','), ('data', ',', 'big'), (',', 'big', 'questions|'), ('big', 'questions|', 'one'), ('questions|', 'one', 'go'), ('one', 'go', '11'), ('go', '11', ':'), ('11', ':', 'quantified'), (':', 'quantified', 'self'), ('quantified', 'self', 'movement'), ('self', 'movement', 'alternative'), ('movement', 'alternative', 'big'), ('alternative', 'big', 'data'), ('big', 'data', 'practice'), ('data', 'practice', '..'), ('practice', '..', 'International'), ('..', 'International', 'journal'), ('International', 'journal', 'communication'), ('journal', 'communication', ','), ('communication', ',', 'p.'), (',', 'p.', '11'), ('p.', '11', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), (',', ','), ('big', 'JJ'), ('questions|', 'NN'), ('one', 'CD'), ('go', 'NN'), ('11', 'CD'), (':', ':'), ('quantified', 'VBN'), ('self', 'PRP'), ('movement', 'NN'), ('alternative', 'JJ'), ('big', 'JJ'), ('data', 'NNS'), ('practice', 'NN'), ('..', 'NNP'), ('International', 'NNP'), ('journal', 'NN'), ('communication', 'NN'), (',', ','), ('p.', 'JJ'), ('11', 'CD'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS)
  ,/,
  (NP big/JJ questions|/NN)
  one/CD
  (NP go/NN)
  11/CD
  :/:
  quantified/VBN
  self/PRP
  (NP movement/NN)
  (NP
    alternative/JJ
    big/JJ
    data/NNS
    practice/NN
    ../NNP
    International/NNP
    journal/NN
    communication/NN)
  ,/,
  p./JJ
  11/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'big questions|', 'go', 'movement', 'alternative big data practice .. International journal communication']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('questions|', 'questions|'), ('one', 'one'), ('go', 'go'), ('11', '11'), (':', ':'), ('quantified', 'quantifi'), ('self', 'self'), ('movement', 'movement'), ('alternative', 'altern'), ('big', 'big'), ('data', 'data'), ('practice', 'practic'), ('..', '..'), ('International', 'intern'), ('journal', 'journal'), ('communication', 'commun'), (',', ','), ('p.', 'p.'), ('11', '11'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (',', ','), ('big', 'big'), ('questions|', 'questions|'), ('one', 'one'), ('go', 'go'), ('11', '11'), (':', ':'), ('quantified', 'quantifi'), ('self', 'self'), ('movement', 'movement'), ('alternative', 'altern'), ('big', 'big'), ('data', 'data'), ('practice', 'practic'), ('..', '..'), ('International', 'intern'), ('journal', 'journal'), ('communication', 'communic'), (',', ','), ('p.', 'p.'), ('11', '11'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (',', ','), ('big', 'big'), ('questions|', 'questions|'), ('one', 'one'), ('go', 'go'), ('11', '11'), (':', ':'), ('quantified', 'quantified'), ('self', 'self'), ('movement', 'movement'), ('alternative', 'alternative'), ('big', 'big'), ('data', 'data'), ('practice', 'practice'), ('..', '..'), ('International', 'International'), ('journal', 'journal'), ('communication', 'communication'), (',', ','), ('p.', 'p.'), ('11', '11'), ('.', '.')]



============================ Sentence 911 =============================

Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Wald, R. and Muharemagic,   E., 2015. 


>> Tokens are: 
 ['Najafabadi', ',', 'M.M.', ',', 'Villanustre', ',', 'F.', ',', 'Khoshgoftaar', ',', 'T.M.', ',', 'Seliya', ',', 'N.', ',', 'Wald', ',', 'R.', 'Muharemagic', ',', 'E.', ',', '2015', '.']

>> Bigrams are: 
 [('Najafabadi', ','), (',', 'M.M.'), ('M.M.', ','), (',', 'Villanustre'), ('Villanustre', ','), (',', 'F.'), ('F.', ','), (',', 'Khoshgoftaar'), ('Khoshgoftaar', ','), (',', 'T.M.'), ('T.M.', ','), (',', 'Seliya'), ('Seliya', ','), (',', 'N.'), ('N.', ','), (',', 'Wald'), ('Wald', ','), (',', 'R.'), ('R.', 'Muharemagic'), ('Muharemagic', ','), (',', 'E.'), ('E.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Najafabadi', ',', 'M.M.'), (',', 'M.M.', ','), ('M.M.', ',', 'Villanustre'), (',', 'Villanustre', ','), ('Villanustre', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Khoshgoftaar'), (',', 'Khoshgoftaar', ','), ('Khoshgoftaar', ',', 'T.M.'), (',', 'T.M.', ','), ('T.M.', ',', 'Seliya'), (',', 'Seliya', ','), ('Seliya', ',', 'N.'), (',', 'N.', ','), ('N.', ',', 'Wald'), (',', 'Wald', ','), ('Wald', ',', 'R.'), (',', 'R.', 'Muharemagic'), ('R.', 'Muharemagic', ','), ('Muharemagic', ',', 'E.'), (',', 'E.', ','), ('E.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Najafabadi', 'NNP'), (',', ','), ('M.M.', 'NNP'), (',', ','), ('Villanustre', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Khoshgoftaar', 'NNP'), (',', ','), ('T.M.', 'NNP'), (',', ','), ('Seliya', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('Wald', 'NNP'), (',', ','), ('R.', 'NNP'), ('Muharemagic', 'NNP'), (',', ','), ('E.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Najafabadi/NNP)
  ,/,
  (NP M.M./NNP)
  ,/,
  (NP Villanustre/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  (NP Khoshgoftaar/NNP)
  ,/,
  (NP T.M./NNP)
  ,/,
  (NP Seliya/NNP)
  ,/,
  (NP N./NNP)
  ,/,
  (NP Wald/NNP)
  ,/,
  (NP R./NNP Muharemagic/NNP)
  ,/,
  (NP E./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Najafabadi', 'M.M.', 'Villanustre', 'F.', 'Khoshgoftaar', 'T.M.', 'Seliya', 'N.', 'Wald', 'R. Muharemagic', 'E.']

>> Named Entities are: 
 [('GPE', 'Najafabadi'), ('GPE', 'Villanustre'), ('GPE', 'Khoshgoftaar'), ('GPE', 'Seliya'), ('PERSON', 'Wald')] 

>> Stemming using Porter Stemmer: 
 [('Najafabadi', 'najafabadi'), (',', ','), ('M.M.', 'm.m.'), (',', ','), ('Villanustre', 'villanustr'), (',', ','), ('F.', 'f.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Seliya', 'seliya'), (',', ','), ('N.', 'n.'), (',', ','), ('Wald', 'wald'), (',', ','), ('R.', 'r.'), ('Muharemagic', 'muharemag'), (',', ','), ('E.', 'e.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Najafabadi', 'najafabadi'), (',', ','), ('M.M.', 'm.m.'), (',', ','), ('Villanustre', 'villanustr'), (',', ','), ('F.', 'f.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M.', 't.m.'), (',', ','), ('Seliya', 'seliya'), (',', ','), ('N.', 'n.'), (',', ','), ('Wald', 'wald'), (',', ','), ('R.', 'r.'), ('Muharemagic', 'muharemag'), (',', ','), ('E.', 'e.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Najafabadi', 'Najafabadi'), (',', ','), ('M.M.', 'M.M.'), (',', ','), ('Villanustre', 'Villanustre'), (',', ','), ('F.', 'F.'), (',', ','), ('Khoshgoftaar', 'Khoshgoftaar'), (',', ','), ('T.M.', 'T.M.'), (',', ','), ('Seliya', 'Seliya'), (',', ','), ('N.', 'N.'), (',', ','), ('Wald', 'Wald'), (',', ','), ('R.', 'R.'), ('Muharemagic', 'Muharemagic'), (',', ','), ('E.', 'E.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 912 =============================

Deep learning applications and challenges in big data analytics. 


>> Tokens are: 
 ['Deep', 'learning', 'applications', 'challenges', 'big', 'data', 'analytics', '.']

>> Bigrams are: 
 [('Deep', 'learning'), ('learning', 'applications'), ('applications', 'challenges'), ('challenges', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', '.')]

>> Trigrams are: 
 [('Deep', 'learning', 'applications'), ('learning', 'applications', 'challenges'), ('applications', 'challenges', 'big'), ('challenges', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', '.')]

>> POS Tags are: 
 [('Deep', 'NNP'), ('learning', 'NN'), ('applications', 'NNS'), ('challenges', 'VBZ'), ('big', 'JJ'), ('data', 'NNS'), ('analytics', 'NNS'), ('.', '.')]

 (S
  (NP Deep/NNP learning/NN applications/NNS)
  challenges/VBZ
  (NP big/JJ data/NNS analytics/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Deep learning applications', 'big data analytics']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('applications', 'applic'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('learning', 'learn'), ('applications', 'applic'), ('challenges', 'challeng'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('learning', 'learning'), ('applications', 'application'), ('challenges', 'challenge'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('.', '.')]



============================ Sentence 913 =============================

Journal of Big Data, p.   1. 


>> Tokens are: 
 ['Journal', 'Big', 'Data', ',', 'p.', '1', '.']

>> Bigrams are: 
 [('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'p.'), ('p.', '1'), ('1', '.')]

>> Trigrams are: 
 [('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'p.'), (',', 'p.', '1'), ('p.', '1', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('p.', 'NN'), ('1', 'CD'), ('.', '.')]

 (S (NP Journal/NNP Big/NNP Data/NNP) ,/, (NP p./NN) 1/CD ./.) 


>> Noun Phrases are: 
 ['Journal Big Data', 'p.']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('p.', 'p.'), ('1', '1'), ('.', '.')]



============================ Sentence 914 =============================

Nashua, N., 2017. 


>> Tokens are: 
 ['Nashua', ',', 'N.', ',', '2017', '.']

>> Bigrams are: 
 [('Nashua', ','), (',', 'N.'), ('N.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Nashua', ',', 'N.'), (',', 'N.', ','), ('N.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Nashua', 'NNP'), (',', ','), ('N.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S (NP Nashua/NNP) ,/, (NP N./NNP) ,/, 2017/CD ./.) 


>> Noun Phrases are: 
 ['Nashua', 'N.']

>> Named Entities are: 
 [('GPE', 'Nashua')] 

>> Stemming using Porter Stemmer: 
 [('Nashua', 'nashua'), (',', ','), ('N.', 'n.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Nashua', 'nashua'), (',', ','), ('N.', 'n.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Nashua', 'Nashua'), (',', ','), ('N.', 'N.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 915 =============================

Big Data Analytics Market Study, s.l. 


>> Tokens are: 
 ['Big', 'Data', 'Analytics', 'Market', 'Study', ',', 's.l', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', 'Market'), ('Market', 'Study'), ('Study', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Analytics'), ('Data', 'Analytics', 'Market'), ('Analytics', 'Market', 'Study'), ('Market', 'Study', ','), ('Study', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNP'), ('Market', 'NNP'), ('Study', 'NNP'), (',', ','), ('s.l', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP Analytics/NNP Market/NNP Study/NNP)
  ,/,
  (NP s.l/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big Data Analytics Market Study', 's.l']

>> Named Entities are: 
 [('PERSON', 'Market Study')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Market', 'market'), ('Study', 'studi'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), ('Market', 'market'), ('Study', 'studi'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), ('Market', 'Market'), ('Study', 'Study'), (',', ','), ('s.l', 's.l'), ('.', '.')]



============================ Sentence 916 =============================

: Dresner Advisory Services. 


>> Tokens are: 
 [':', 'Dresner', 'Advisory', 'Services', '.']

>> Bigrams are: 
 [(':', 'Dresner'), ('Dresner', 'Advisory'), ('Advisory', 'Services'), ('Services', '.')]

>> Trigrams are: 
 [(':', 'Dresner', 'Advisory'), ('Dresner', 'Advisory', 'Services'), ('Advisory', 'Services', '.')]

>> POS Tags are: 
 [(':', ':'), ('Dresner', 'NN'), ('Advisory', 'NNP'), ('Services', 'NNPS'), ('.', '.')]

 (S :/: (NP Dresner/NN Advisory/NNP) Services/NNPS ./.) 


>> Noun Phrases are: 
 ['Dresner Advisory']

>> Named Entities are: 
 [('PERSON', 'Dresner Advisory Services')] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Dresner', 'dresner'), ('Advisory', 'advisori'), ('Services', 'servic'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Dresner', 'Dresner'), ('Advisory', 'Advisory'), ('Services', 'Services'), ('.', '.')]



============================ Sentence 917 =============================

Orange-Roglá, Sergio; Chalmeta, Ricardo, 2019. 


>> Tokens are: 
 ['Orange-Roglá', ',', 'Sergio', ';', 'Chalmeta', ',', 'Ricardo', ',', '2019', '.']

>> Bigrams are: 
 [('Orange-Roglá', ','), (',', 'Sergio'), ('Sergio', ';'), (';', 'Chalmeta'), ('Chalmeta', ','), (',', 'Ricardo'), ('Ricardo', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Orange-Roglá', ',', 'Sergio'), (',', 'Sergio', ';'), ('Sergio', ';', 'Chalmeta'), (';', 'Chalmeta', ','), ('Chalmeta', ',', 'Ricardo'), (',', 'Ricardo', ','), ('Ricardo', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Orange-Roglá', 'NNP'), (',', ','), ('Sergio', 'NNP'), (';', ':'), ('Chalmeta', 'NNP'), (',', ','), ('Ricardo', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Orange-Roglá/NNP)
  ,/,
  (NP Sergio/NNP)
  ;/:
  (NP Chalmeta/NNP)
  ,/,
  (NP Ricardo/NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Orange-Roglá', 'Sergio', 'Chalmeta', 'Ricardo']

>> Named Entities are: 
 [('GPE', 'Sergio'), ('PERSON', 'Chalmeta'), ('PERSON', 'Ricardo')] 

>> Stemming using Porter Stemmer: 
 [('Orange-Roglá', 'orange-roglá'), (',', ','), ('Sergio', 'sergio'), (';', ';'), ('Chalmeta', 'chalmeta'), (',', ','), ('Ricardo', 'ricardo'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Orange-Roglá', 'orange-roglá'), (',', ','), ('Sergio', 'sergio'), (';', ';'), ('Chalmeta', 'chalmeta'), (',', ','), ('Ricardo', 'ricardo'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Orange-Roglá', 'Orange-Roglá'), (',', ','), ('Sergio', 'Sergio'), (';', ';'), ('Chalmeta', 'Chalmeta'), (',', ','), ('Ricardo', 'Ricardo'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 918 =============================

Framework for implementing a big data   ecosystem in organizations.. Communications of the ACM Journal, 62(1). 


>> Tokens are: 
 ['Framework', 'implementing', 'big', 'data', 'ecosystem', 'organizations', '..', 'Communications', 'ACM', 'Journal', ',', '62', '(', '1', ')', '.']

>> Bigrams are: 
 [('Framework', 'implementing'), ('implementing', 'big'), ('big', 'data'), ('data', 'ecosystem'), ('ecosystem', 'organizations'), ('organizations', '..'), ('..', 'Communications'), ('Communications', 'ACM'), ('ACM', 'Journal'), ('Journal', ','), (',', '62'), ('62', '('), ('(', '1'), ('1', ')'), (')', '.')]

>> Trigrams are: 
 [('Framework', 'implementing', 'big'), ('implementing', 'big', 'data'), ('big', 'data', 'ecosystem'), ('data', 'ecosystem', 'organizations'), ('ecosystem', 'organizations', '..'), ('organizations', '..', 'Communications'), ('..', 'Communications', 'ACM'), ('Communications', 'ACM', 'Journal'), ('ACM', 'Journal', ','), ('Journal', ',', '62'), (',', '62', '('), ('62', '(', '1'), ('(', '1', ')'), ('1', ')', '.')]

>> POS Tags are: 
 [('Framework', 'NNP'), ('implementing', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('ecosystem', 'NN'), ('organizations', 'NNS'), ('..', 'VBP'), ('Communications', 'NNP'), ('ACM', 'NNP'), ('Journal', 'NNP'), (',', ','), ('62', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), ('.', '.')]

 (S
  (NP Framework/NNP)
  implementing/VBG
  (NP big/JJ data/NNS ecosystem/NN organizations/NNS)
  ../VBP
  (NP Communications/NNP ACM/NNP Journal/NNP)
  ,/,
  62/CD
  (/(
  1/CD
  )/)
  ./.) 


>> Noun Phrases are: 
 ['Framework', 'big data ecosystem organizations', 'Communications ACM Journal']

>> Named Entities are: 
 [('GPE', 'Framework'), ('ORGANIZATION', 'Communications')] 

>> Stemming using Porter Stemmer: 
 [('Framework', 'framework'), ('implementing', 'implement'), ('big', 'big'), ('data', 'data'), ('ecosystem', 'ecosystem'), ('organizations', 'organ'), ('..', '..'), ('Communications', 'commun'), ('ACM', 'acm'), ('Journal', 'journal'), (',', ','), ('62', '62'), ('(', '('), ('1', '1'), (')', ')'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Framework', 'framework'), ('implementing', 'implement'), ('big', 'big'), ('data', 'data'), ('ecosystem', 'ecosystem'), ('organizations', 'organ'), ('..', '..'), ('Communications', 'communic'), ('ACM', 'acm'), ('Journal', 'journal'), (',', ','), ('62', '62'), ('(', '('), ('1', '1'), (')', ')'), ('.', '.')]

>> Lemmatization: 
 [('Framework', 'Framework'), ('implementing', 'implementing'), ('big', 'big'), ('data', 'data'), ('ecosystem', 'ecosystem'), ('organizations', 'organization'), ('..', '..'), ('Communications', 'Communications'), ('ACM', 'ACM'), ('Journal', 'Journal'), (',', ','), ('62', '62'), ('(', '('), ('1', '1'), (')', ')'), ('.', '.')]



============================ Sentence 919 =============================

Oussous, A., Benjelloun, F.Z., Lahcen, A.A. and Belfkih, S., 2018. 


>> Tokens are: 
 ['Oussous', ',', 'A.', ',', 'Benjelloun', ',', 'F.Z.', ',', 'Lahcen', ',', 'A.A.', 'Belfkih', ',', 'S.', ',', '2018', '.']

>> Bigrams are: 
 [('Oussous', ','), (',', 'A.'), ('A.', ','), (',', 'Benjelloun'), ('Benjelloun', ','), (',', 'F.Z.'), ('F.Z.', ','), (',', 'Lahcen'), ('Lahcen', ','), (',', 'A.A.'), ('A.A.', 'Belfkih'), ('Belfkih', ','), (',', 'S.'), ('S.', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Oussous', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Benjelloun'), (',', 'Benjelloun', ','), ('Benjelloun', ',', 'F.Z.'), (',', 'F.Z.', ','), ('F.Z.', ',', 'Lahcen'), (',', 'Lahcen', ','), ('Lahcen', ',', 'A.A.'), (',', 'A.A.', 'Belfkih'), ('A.A.', 'Belfkih', ','), ('Belfkih', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Oussous', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Benjelloun', 'NNP'), (',', ','), ('F.Z.', 'NNP'), (',', ','), ('Lahcen', 'NNP'), (',', ','), ('A.A.', 'NNP'), ('Belfkih', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Oussous/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Benjelloun/NNP)
  ,/,
  (NP F.Z./NNP)
  ,/,
  (NP Lahcen/NNP)
  ,/,
  (NP A.A./NNP Belfkih/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Oussous', 'A.', 'Benjelloun', 'F.Z.', 'Lahcen', 'A.A. Belfkih', 'S.']

>> Named Entities are: 
 [('GPE', 'Oussous'), ('PERSON', 'Benjelloun'), ('GPE', 'Lahcen'), ('ORGANIZATION', 'A.A. Belfkih')] 

>> Stemming using Porter Stemmer: 
 [('Oussous', 'oussou'), (',', ','), ('A.', 'a.'), (',', ','), ('Benjelloun', 'benjelloun'), (',', ','), ('F.Z.', 'f.z.'), (',', ','), ('Lahcen', 'lahcen'), (',', ','), ('A.A.', 'a.a.'), ('Belfkih', 'belfkih'), (',', ','), ('S.', 's.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Oussous', 'oussous'), (',', ','), ('A.', 'a.'), (',', ','), ('Benjelloun', 'benjelloun'), (',', ','), ('F.Z.', 'f.z.'), (',', ','), ('Lahcen', 'lahcen'), (',', ','), ('A.A.', 'a.a.'), ('Belfkih', 'belfkih'), (',', ','), ('S.', 's.'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Oussous', 'Oussous'), (',', ','), ('A.', 'A.'), (',', ','), ('Benjelloun', 'Benjelloun'), (',', ','), ('F.Z.', 'F.Z.'), (',', ','), ('Lahcen', 'Lahcen'), (',', ','), ('A.A.', 'A.A.'), ('Belfkih', 'Belfkih'), (',', ','), ('S.', 'S.'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 920 =============================

Big Data technologies: A   survey. 


>> Tokens are: 
 ['Big', 'Data', 'technologies', ':', 'A', 'survey', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'technologies'), ('technologies', ':'), (':', 'A'), ('A', 'survey'), ('survey', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'technologies'), ('Data', 'technologies', ':'), ('technologies', ':', 'A'), (':', 'A', 'survey'), ('A', 'survey', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('technologies', 'NNS'), (':', ':'), ('A', 'DT'), ('survey', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP technologies/NNS)
  :/:
  (NP A/DT survey/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big Data technologies', 'A survey']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('technologies', 'technolog'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('technologies', 'technolog'), (':', ':'), ('A', 'a'), ('survey', 'survey'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('technologies', 'technology'), (':', ':'), ('A', 'A'), ('survey', 'survey'), ('.', '.')]



============================ Sentence 921 =============================

Journal of King Saud University-Computer and Information Sciences, pp. 


>> Tokens are: 
 ['Journal', 'King', 'Saud', 'University-Computer', 'Information', 'Sciences', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'King'), ('King', 'Saud'), ('Saud', 'University-Computer'), ('University-Computer', 'Information'), ('Information', 'Sciences'), ('Sciences', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'King', 'Saud'), ('King', 'Saud', 'University-Computer'), ('Saud', 'University-Computer', 'Information'), ('University-Computer', 'Information', 'Sciences'), ('Information', 'Sciences', ','), ('Sciences', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('King', 'NNP'), ('Saud', 'NNP'), ('University-Computer', 'NNP'), ('Information', 'NNP'), ('Sciences', 'NNPS'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    Journal/NNP
    King/NNP
    Saud/NNP
    University-Computer/NNP
    Information/NNP)
  Sciences/NNPS
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Journal King Saud University-Computer Information', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('King', 'king'), ('Saud', 'saud'), ('University-Computer', 'university-comput'), ('Information', 'inform'), ('Sciences', 'scienc'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('King', 'king'), ('Saud', 'saud'), ('University-Computer', 'university-comput'), ('Information', 'inform'), ('Sciences', 'scienc'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('King', 'King'), ('Saud', 'Saud'), ('University-Computer', 'University-Computer'), ('Information', 'Information'), ('Sciences', 'Sciences'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 922 =============================

431-448. 


>> Tokens are: 
 ['431-448', '.']

>> Bigrams are: 
 [('431-448', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('431-448', 'JJ'), ('.', '.')]

 (S 431-448/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('431-448', '431-448'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('431-448', '431-448'), ('.', '.')]

>> Lemmatization: 
 [('431-448', '431-448'), ('.', '.')]



============================ Sentence 923 =============================

Provost, F. and Fawcett, T., 2013. 


>> Tokens are: 
 ['Provost', ',', 'F.', 'Fawcett', ',', 'T.', ',', '2013', '.']

>> Bigrams are: 
 [('Provost', ','), (',', 'F.'), ('F.', 'Fawcett'), ('Fawcett', ','), (',', 'T.'), ('T.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Provost', ',', 'F.'), (',', 'F.', 'Fawcett'), ('F.', 'Fawcett', ','), ('Fawcett', ',', 'T.'), (',', 'T.', ','), ('T.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Provost', 'NNP'), (',', ','), ('F.', 'NNP'), ('Fawcett', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Provost/NNP)
  ,/,
  (NP F./NNP Fawcett/NNP)
  ,/,
  (NP T./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Provost', 'F. Fawcett', 'T.']

>> Named Entities are: 
 [('GPE', 'Provost'), ('PERSON', 'Fawcett')] 

>> Stemming using Porter Stemmer: 
 [('Provost', 'provost'), (',', ','), ('F.', 'f.'), ('Fawcett', 'fawcett'), (',', ','), ('T.', 't.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Provost', 'provost'), (',', ','), ('F.', 'f.'), ('Fawcett', 'fawcett'), (',', ','), ('T.', 't.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Provost', 'Provost'), (',', ','), ('F.', 'F.'), ('Fawcett', 'Fawcett'), (',', ','), ('T.', 'T.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 924 =============================

Data science and its relationship to big data and data-driven   decision making. 


>> Tokens are: 
 ['Data', 'science', 'relationship', 'big', 'data', 'data-driven', 'decision', 'making', '.']

>> Bigrams are: 
 [('Data', 'science'), ('science', 'relationship'), ('relationship', 'big'), ('big', 'data'), ('data', 'data-driven'), ('data-driven', 'decision'), ('decision', 'making'), ('making', '.')]

>> Trigrams are: 
 [('Data', 'science', 'relationship'), ('science', 'relationship', 'big'), ('relationship', 'big', 'data'), ('big', 'data', 'data-driven'), ('data', 'data-driven', 'decision'), ('data-driven', 'decision', 'making'), ('decision', 'making', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('science', 'NN'), ('relationship', 'NN'), ('big', 'JJ'), ('data', 'NNS'), ('data-driven', 'JJ'), ('decision', 'NN'), ('making', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP science/NN relationship/NN)
  (NP big/JJ data/NNS)
  (NP data-driven/JJ decision/NN making/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data science relationship', 'big data', 'data-driven decision making']

>> Named Entities are: 
 [('GPE', 'Data')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), ('relationship', 'relationship'), ('big', 'big'), ('data', 'data'), ('data-driven', 'data-driven'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), ('relationship', 'relationship'), ('big', 'big'), ('data', 'data'), ('data-driven', 'data-driven'), ('decision', 'decis'), ('making', 'make'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('science', 'science'), ('relationship', 'relationship'), ('big', 'big'), ('data', 'data'), ('data-driven', 'data-driven'), ('decision', 'decision'), ('making', 'making'), ('.', '.')]



============================ Sentence 925 =============================

Big Data Journal, pp. 


>> Tokens are: 
 ['Big', 'Data', 'Journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'Journal'), ('Journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'Journal'), ('Data', 'Journal', ','), ('Journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('Data', 'NNP'), ('Journal', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP Big/JJ Data/NNP Journal/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Big Data Journal', 'pp']

>> Named Entities are: 
 [('PERSON', 'Data Journal')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('Journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('Journal', 'Journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 926 =============================

51-59. 


>> Tokens are: 
 ['51-59', '.']

>> Bigrams are: 
 [('51-59', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('51-59', 'JJ'), ('.', '.')]

 (S 51-59/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('51-59', '51-59'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('51-59', '51-59'), ('.', '.')]

>> Lemmatization: 
 [('51-59', '51-59'), ('.', '.')]



============================ Sentence 927 =============================

Qiu, J., Wu, Q., Ding, G., Xu, Y. and Feng, S., 2016. 


>> Tokens are: 
 ['Qiu', ',', 'J.', ',', 'Wu', ',', 'Q.', ',', 'Ding', ',', 'G.', ',', 'Xu', ',', 'Y.', 'Feng', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Qiu', ','), (',', 'J.'), ('J.', ','), (',', 'Wu'), ('Wu', ','), (',', 'Q.'), ('Q.', ','), (',', 'Ding'), ('Ding', ','), (',', 'G.'), ('G.', ','), (',', 'Xu'), ('Xu', ','), (',', 'Y.'), ('Y.', 'Feng'), ('Feng', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Qiu', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Wu'), (',', 'Wu', ','), ('Wu', ',', 'Q.'), (',', 'Q.', ','), ('Q.', ',', 'Ding'), (',', 'Ding', ','), ('Ding', ',', 'G.'), (',', 'G.', ','), ('G.', ',', 'Xu'), (',', 'Xu', ','), ('Xu', ',', 'Y.'), (',', 'Y.', 'Feng'), ('Y.', 'Feng', ','), ('Feng', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Qiu', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Wu', 'NNP'), (',', ','), ('Q.', 'NNP'), (',', ','), ('Ding', 'NNP'), (',', ','), ('G.', 'NNP'), (',', ','), ('Xu', 'NNP'), (',', ','), ('Y.', 'NNP'), ('Feng', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Qiu/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Wu/NNP)
  ,/,
  (NP Q./NNP)
  ,/,
  (NP Ding/NNP)
  ,/,
  (NP G./NNP)
  ,/,
  (NP Xu/NNP)
  ,/,
  (NP Y./NNP Feng/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Qiu', 'J.', 'Wu', 'Q.', 'Ding', 'G.', 'Xu', 'Y. Feng', 'S.']

>> Named Entities are: 
 [('GPE', 'Qiu'), ('GPE', 'Wu'), ('GPE', 'Ding'), ('GPE', 'Xu')] 

>> Stemming using Porter Stemmer: 
 [('Qiu', 'qiu'), (',', ','), ('J.', 'j.'), (',', ','), ('Wu', 'wu'), (',', ','), ('Q.', 'q.'), (',', ','), ('Ding', 'ding'), (',', ','), ('G.', 'g.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Y.', 'y.'), ('Feng', 'feng'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Qiu', 'qiu'), (',', ','), ('J.', 'j.'), (',', ','), ('Wu', 'wu'), (',', ','), ('Q.', 'q.'), (',', ','), ('Ding', 'ding'), (',', ','), ('G.', 'g.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Y.', 'y.'), ('Feng', 'feng'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Qiu', 'Qiu'), (',', ','), ('J.', 'J.'), (',', ','), ('Wu', 'Wu'), (',', ','), ('Q.', 'Q.'), (',', ','), ('Ding', 'Ding'), (',', ','), ('G.', 'G.'), (',', ','), ('Xu', 'Xu'), (',', ','), ('Y.', 'Y.'), ('Feng', 'Feng'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 928 =============================

A survey of machine learning for big data   processing. 


>> Tokens are: 
 ['A', 'survey', 'machine', 'learning', 'big', 'data', 'processing', '.']

>> Bigrams are: 
 [('A', 'survey'), ('survey', 'machine'), ('machine', 'learning'), ('learning', 'big'), ('big', 'data'), ('data', 'processing'), ('processing', '.')]

>> Trigrams are: 
 [('A', 'survey', 'machine'), ('survey', 'machine', 'learning'), ('machine', 'learning', 'big'), ('learning', 'big', 'data'), ('big', 'data', 'processing'), ('data', 'processing', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('survey', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('big', 'JJ'), ('data', 'NNS'), ('processing', 'NN'), ('.', '.')]

 (S
  (NP A/DT survey/NN machine/NN)
  learning/VBG
  (NP big/JJ data/NNS processing/NN)
  ./.) 


>> Noun Phrases are: 
 ['A survey machine', 'big data processing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('survey', 'survey'), ('machine', 'machin'), ('learning', 'learn'), ('big', 'big'), ('data', 'data'), ('processing', 'process'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('survey', 'survey'), ('machine', 'machine'), ('learning', 'learning'), ('big', 'big'), ('data', 'data'), ('processing', 'processing'), ('.', '.')]



============================ Sentence 929 =============================

EURASIP Journal on Advances in Signal Processing, p. 67. 


>> Tokens are: 
 ['EURASIP', 'Journal', 'Advances', 'Signal', 'Processing', ',', 'p.', '67', '.']

>> Bigrams are: 
 [('EURASIP', 'Journal'), ('Journal', 'Advances'), ('Advances', 'Signal'), ('Signal', 'Processing'), ('Processing', ','), (',', 'p.'), ('p.', '67'), ('67', '.')]

>> Trigrams are: 
 [('EURASIP', 'Journal', 'Advances'), ('Journal', 'Advances', 'Signal'), ('Advances', 'Signal', 'Processing'), ('Signal', 'Processing', ','), ('Processing', ',', 'p.'), (',', 'p.', '67'), ('p.', '67', '.')]

>> POS Tags are: 
 [('EURASIP', 'NNP'), ('Journal', 'NNP'), ('Advances', 'NNP'), ('Signal', 'NNP'), ('Processing', 'NNP'), (',', ','), ('p.', 'VBD'), ('67', 'CD'), ('.', '.')]

 (S
  (NP EURASIP/NNP Journal/NNP Advances/NNP Signal/NNP Processing/NNP)
  ,/,
  p./VBD
  67/CD
  ./.) 


>> Noun Phrases are: 
 ['EURASIP Journal Advances Signal Processing']

>> Named Entities are: 
 [('ORGANIZATION', 'EURASIP Journal Advances Signal')] 

>> Stemming using Porter Stemmer: 
 [('EURASIP', 'eurasip'), ('Journal', 'journal'), ('Advances', 'advanc'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('p.', 'p.'), ('67', '67'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('EURASIP', 'eurasip'), ('Journal', 'journal'), ('Advances', 'advanc'), ('Signal', 'signal'), ('Processing', 'process'), (',', ','), ('p.', 'p.'), ('67', '67'), ('.', '.')]

>> Lemmatization: 
 [('EURASIP', 'EURASIP'), ('Journal', 'Journal'), ('Advances', 'Advances'), ('Signal', 'Signal'), ('Processing', 'Processing'), (',', ','), ('p.', 'p.'), ('67', '67'), ('.', '.')]



============================ Sentence 930 =============================

Raghupathi, W. and Raghupathi, V., 2014. 


>> Tokens are: 
 ['Raghupathi', ',', 'W.', 'Raghupathi', ',', 'V.', ',', '2014', '.']

>> Bigrams are: 
 [('Raghupathi', ','), (',', 'W.'), ('W.', 'Raghupathi'), ('Raghupathi', ','), (',', 'V.'), ('V.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Raghupathi', ',', 'W.'), (',', 'W.', 'Raghupathi'), ('W.', 'Raghupathi', ','), ('Raghupathi', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Raghupathi', 'NNP'), (',', ','), ('W.', 'NNP'), ('Raghupathi', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Raghupathi/NNP)
  ,/,
  (NP W./NNP Raghupathi/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Raghupathi', 'W. Raghupathi', 'V.']

>> Named Entities are: 
 [('GPE', 'Raghupathi')] 

>> Stemming using Porter Stemmer: 
 [('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Raghupathi', 'raghupathi'), (',', ','), ('W.', 'w.'), ('Raghupathi', 'raghupathi'), (',', ','), ('V.', 'v.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Raghupathi', 'Raghupathi'), (',', ','), ('W.', 'W.'), ('Raghupathi', 'Raghupathi'), (',', ','), ('V.', 'V.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 931 =============================

Big data analytics in healthcare: promise and potential. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'healthcare', ':', 'promise', 'potential', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'healthcare'), ('healthcare', ':'), (':', 'promise'), ('promise', 'potential'), ('potential', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'healthcare'), ('analytics', 'healthcare', ':'), ('healthcare', ':', 'promise'), (':', 'promise', 'potential'), ('promise', 'potential', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('healthcare', 'NN'), (':', ':'), ('promise', 'NN'), ('potential', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS healthcare/NN)
  :/:
  (NP promise/NN potential/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics healthcare', 'promise potential']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), (':', ':'), ('promise', 'promis'), ('potential', 'potenti'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('healthcare', 'healthcar'), (':', ':'), ('promise', 'promis'), ('potential', 'potenti'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('healthcare', 'healthcare'), (':', ':'), ('promise', 'promise'), ('potential', 'potential'), ('.', '.')]



============================ Sentence 932 =============================

Health information science and systems, p. 3. 


>> Tokens are: 
 ['Health', 'information', 'science', 'systems', ',', 'p.', '3', '.']

>> Bigrams are: 
 [('Health', 'information'), ('information', 'science'), ('science', 'systems'), ('systems', ','), (',', 'p.'), ('p.', '3'), ('3', '.')]

>> Trigrams are: 
 [('Health', 'information', 'science'), ('information', 'science', 'systems'), ('science', 'systems', ','), ('systems', ',', 'p.'), (',', 'p.', '3'), ('p.', '3', '.')]

>> POS Tags are: 
 [('Health', 'NNP'), ('information', 'NN'), ('science', 'NN'), ('systems', 'NNS'), (',', ','), ('p.', 'JJ'), ('3', 'CD'), ('.', '.')]

 (S
  (NP Health/NNP information/NN science/NN systems/NNS)
  ,/,
  p./JJ
  3/CD
  ./.) 


>> Noun Phrases are: 
 ['Health information science systems']

>> Named Entities are: 
 [('GPE', 'Health')] 

>> Stemming using Porter Stemmer: 
 [('Health', 'health'), ('information', 'inform'), ('science', 'scienc'), ('systems', 'system'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Health', 'health'), ('information', 'inform'), ('science', 'scienc'), ('systems', 'system'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Health', 'Health'), ('information', 'information'), ('science', 'science'), ('systems', 'system'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]



============================ Sentence 933 =============================

Rana, S., 2019. 


>> Tokens are: 
 ['Rana', ',', 'S.', ',', '2019', '.']

>> Bigrams are: 
 [('Rana', ','), (',', 'S.'), ('S.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Rana', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Rana', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S (NP Rana/NNP) ,/, (NP S./NNP) ,/, 2019/CD ./.) 


>> Noun Phrases are: 
 ['Rana', 'S.']

>> Named Entities are: 
 [('GPE', 'Rana')] 

>> Stemming using Porter Stemmer: 
 [('Rana', 'rana'), (',', ','), ('S.', 's.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Rana', 'rana'), (',', ','), ('S.', 's.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Rana', 'Rana'), (',', ','), ('S.', 'S.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 934 =============================

Moving in the Realm of Big Data: Using Analytics in Management Research and   Practices.. SAGE journal, 8(1), pp. 


>> Tokens are: 
 ['Moving', 'Realm', 'Big', 'Data', ':', 'Using', 'Analytics', 'Management', 'Research', 'Practices', '..', 'SAGE', 'journal', ',', '8', '(', '1', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Moving', 'Realm'), ('Realm', 'Big'), ('Big', 'Data'), ('Data', ':'), (':', 'Using'), ('Using', 'Analytics'), ('Analytics', 'Management'), ('Management', 'Research'), ('Research', 'Practices'), ('Practices', '..'), ('..', 'SAGE'), ('SAGE', 'journal'), ('journal', ','), (',', '8'), ('8', '('), ('(', '1'), ('1', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Moving', 'Realm', 'Big'), ('Realm', 'Big', 'Data'), ('Big', 'Data', ':'), ('Data', ':', 'Using'), (':', 'Using', 'Analytics'), ('Using', 'Analytics', 'Management'), ('Analytics', 'Management', 'Research'), ('Management', 'Research', 'Practices'), ('Research', 'Practices', '..'), ('Practices', '..', 'SAGE'), ('..', 'SAGE', 'journal'), ('SAGE', 'journal', ','), ('journal', ',', '8'), (',', '8', '('), ('8', '(', '1'), ('(', '1', ')'), ('1', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Moving', 'VBG'), ('Realm', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (':', ':'), ('Using', 'NN'), ('Analytics', 'NNP'), ('Management', 'NNP'), ('Research', 'NNP'), ('Practices', 'NNPS'), ('..', 'NNP'), ('SAGE', 'NNP'), ('journal', 'NN'), (',', ','), ('8', 'CD'), ('(', '('), ('1', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  Moving/VBG
  (NP Realm/NNP Big/NNP Data/NNP)
  :/:
  (NP Using/NN Analytics/NNP Management/NNP Research/NNP)
  Practices/NNPS
  (NP ../NNP SAGE/NNP journal/NN)
  ,/,
  8/CD
  (/(
  1/CD
  )/)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Realm Big Data', 'Using Analytics Management Research', '.. SAGE journal', 'pp']

>> Named Entities are: 
 [('PERSON', 'Realm Big Data'), ('PERSON', 'Analytics Management Research')] 

>> Stemming using Porter Stemmer: 
 [('Moving', 'move'), ('Realm', 'realm'), ('Big', 'big'), ('Data', 'data'), (':', ':'), ('Using', 'use'), ('Analytics', 'analyt'), ('Management', 'manag'), ('Research', 'research'), ('Practices', 'practic'), ('..', '..'), ('SAGE', 'sage'), ('journal', 'journal'), (',', ','), ('8', '8'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Moving', 'move'), ('Realm', 'realm'), ('Big', 'big'), ('Data', 'data'), (':', ':'), ('Using', 'use'), ('Analytics', 'analyt'), ('Management', 'manag'), ('Research', 'research'), ('Practices', 'practic'), ('..', '..'), ('SAGE', 'sage'), ('journal', 'journal'), (',', ','), ('8', '8'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Moving', 'Moving'), ('Realm', 'Realm'), ('Big', 'Big'), ('Data', 'Data'), (':', ':'), ('Using', 'Using'), ('Analytics', 'Analytics'), ('Management', 'Management'), ('Research', 'Research'), ('Practices', 'Practices'), ('..', '..'), ('SAGE', 'SAGE'), ('journal', 'journal'), (',', ','), ('8', '8'), ('(', '('), ('1', '1'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 935 =============================

7-8. 


>> Tokens are: 
 ['7-8', '.']

>> Bigrams are: 
 [('7-8', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('7-8', 'JJ'), ('.', '.')]

 (S 7-8/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('7-8', '7-8'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('7-8', '7-8'), ('.', '.')]

>> Lemmatization: 
 [('7-8', '7-8'), ('.', '.')]



============================ Sentence 936 =============================

Ren, S., Zhang, Y., Liu, Y., Sakao, T., Huisingh, D., Almeida, C. M. V. B, 2019. 


>> Tokens are: 
 ['Ren', ',', 'S.', ',', 'Zhang', ',', 'Y.', ',', 'Liu', ',', 'Y.', ',', 'Sakao', ',', 'T.', ',', 'Huisingh', ',', 'D.', ',', 'Almeida', ',', 'C.', 'M.', 'V.', 'B', ',', '2019', '.']

>> Bigrams are: 
 [('Ren', ','), (',', 'S.'), ('S.', ','), (',', 'Zhang'), ('Zhang', ','), (',', 'Y.'), ('Y.', ','), (',', 'Liu'), ('Liu', ','), (',', 'Y.'), ('Y.', ','), (',', 'Sakao'), ('Sakao', ','), (',', 'T.'), ('T.', ','), (',', 'Huisingh'), ('Huisingh', ','), (',', 'D.'), ('D.', ','), (',', 'Almeida'), ('Almeida', ','), (',', 'C.'), ('C.', 'M.'), ('M.', 'V.'), ('V.', 'B'), ('B', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Ren', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Zhang'), (',', 'Zhang', ','), ('Zhang', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Liu'), (',', 'Liu', ','), ('Liu', ',', 'Y.'), (',', 'Y.', ','), ('Y.', ',', 'Sakao'), (',', 'Sakao', ','), ('Sakao', ',', 'T.'), (',', 'T.', ','), ('T.', ',', 'Huisingh'), (',', 'Huisingh', ','), ('Huisingh', ',', 'D.'), (',', 'D.', ','), ('D.', ',', 'Almeida'), (',', 'Almeida', ','), ('Almeida', ',', 'C.'), (',', 'C.', 'M.'), ('C.', 'M.', 'V.'), ('M.', 'V.', 'B'), ('V.', 'B', ','), ('B', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Ren', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Zhang', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Liu', 'NNP'), (',', ','), ('Y.', 'NNP'), (',', ','), ('Sakao', 'NNP'), (',', ','), ('T.', 'NNP'), (',', ','), ('Huisingh', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('Almeida', 'NNP'), (',', ','), ('C.', 'NNP'), ('M.', 'NNP'), ('V.', 'NNP'), ('B', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S
  (NP Ren/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Zhang/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Liu/NNP)
  ,/,
  (NP Y./NNP)
  ,/,
  (NP Sakao/NNP)
  ,/,
  (NP T./NNP)
  ,/,
  (NP Huisingh/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  (NP Almeida/NNP)
  ,/,
  (NP C./NNP M./NNP V./NNP B/NNP)
  ,/,
  2019/CD
  ./.) 


>> Noun Phrases are: 
 ['Ren', 'S.', 'Zhang', 'Y.', 'Liu', 'Y.', 'Sakao', 'T.', 'Huisingh', 'D.', 'Almeida', 'C. M. V. B']

>> Named Entities are: 
 [('PERSON', 'Ren'), ('PERSON', 'Zhang'), ('PERSON', 'Liu'), ('PERSON', 'Sakao'), ('PERSON', 'Huisingh'), ('GPE', 'Almeida')] 

>> Stemming using Porter Stemmer: 
 [('Ren', 'ren'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('Sakao', 'sakao'), (',', ','), ('T.', 't.'), (',', ','), ('Huisingh', 'huisingh'), (',', ','), ('D.', 'd.'), (',', ','), ('Almeida', 'almeida'), (',', ','), ('C.', 'c.'), ('M.', 'm.'), ('V.', 'v.'), ('B', 'b'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ren', 'ren'), (',', ','), ('S.', 's.'), (',', ','), ('Zhang', 'zhang'), (',', ','), ('Y.', 'y.'), (',', ','), ('Liu', 'liu'), (',', ','), ('Y.', 'y.'), (',', ','), ('Sakao', 'sakao'), (',', ','), ('T.', 't.'), (',', ','), ('Huisingh', 'huisingh'), (',', ','), ('D.', 'd.'), (',', ','), ('Almeida', 'almeida'), (',', ','), ('C.', 'c.'), ('M.', 'm.'), ('V.', 'v.'), ('B', 'b'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Ren', 'Ren'), (',', ','), ('S.', 'S.'), (',', ','), ('Zhang', 'Zhang'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Liu', 'Liu'), (',', ','), ('Y.', 'Y.'), (',', ','), ('Sakao', 'Sakao'), (',', ','), ('T.', 'T.'), (',', ','), ('Huisingh', 'Huisingh'), (',', ','), ('D.', 'D.'), (',', ','), ('Almeida', 'Almeida'), (',', ','), ('C.', 'C.'), ('M.', 'M.'), ('V.', 'V.'), ('B', 'B'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 937 =============================

A comprehensive   review of big data analytics throughout product lifecycle to support sustainable smart   manufacturing: A framework, challenges and future research direction.. Journal of Cleaner   Production, Volume 210, pp. 


>> Tokens are: 
 ['A', 'comprehensive', 'review', 'big', 'data', 'analytics', 'throughout', 'product', 'lifecycle', 'support', 'sustainable', 'smart', 'manufacturing', ':', 'A', 'framework', ',', 'challenges', 'future', 'research', 'direction', '..', 'Journal', 'Cleaner', 'Production', ',', 'Volume', '210', ',', 'pp', '.']

>> Bigrams are: 
 [('A', 'comprehensive'), ('comprehensive', 'review'), ('review', 'big'), ('big', 'data'), ('data', 'analytics'), ('analytics', 'throughout'), ('throughout', 'product'), ('product', 'lifecycle'), ('lifecycle', 'support'), ('support', 'sustainable'), ('sustainable', 'smart'), ('smart', 'manufacturing'), ('manufacturing', ':'), (':', 'A'), ('A', 'framework'), ('framework', ','), (',', 'challenges'), ('challenges', 'future'), ('future', 'research'), ('research', 'direction'), ('direction', '..'), ('..', 'Journal'), ('Journal', 'Cleaner'), ('Cleaner', 'Production'), ('Production', ','), (',', 'Volume'), ('Volume', '210'), ('210', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('A', 'comprehensive', 'review'), ('comprehensive', 'review', 'big'), ('review', 'big', 'data'), ('big', 'data', 'analytics'), ('data', 'analytics', 'throughout'), ('analytics', 'throughout', 'product'), ('throughout', 'product', 'lifecycle'), ('product', 'lifecycle', 'support'), ('lifecycle', 'support', 'sustainable'), ('support', 'sustainable', 'smart'), ('sustainable', 'smart', 'manufacturing'), ('smart', 'manufacturing', ':'), ('manufacturing', ':', 'A'), (':', 'A', 'framework'), ('A', 'framework', ','), ('framework', ',', 'challenges'), (',', 'challenges', 'future'), ('challenges', 'future', 'research'), ('future', 'research', 'direction'), ('research', 'direction', '..'), ('direction', '..', 'Journal'), ('..', 'Journal', 'Cleaner'), ('Journal', 'Cleaner', 'Production'), ('Cleaner', 'Production', ','), ('Production', ',', 'Volume'), (',', 'Volume', '210'), ('Volume', '210', ','), ('210', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('comprehensive', 'JJ'), ('review', 'NN'), ('big', 'JJ'), ('data', 'NN'), ('analytics', 'NNS'), ('throughout', 'IN'), ('product', 'NN'), ('lifecycle', 'NN'), ('support', 'NN'), ('sustainable', 'JJ'), ('smart', 'JJ'), ('manufacturing', 'NN'), (':', ':'), ('A', 'DT'), ('framework', 'NN'), (',', ','), ('challenges', 'VBZ'), ('future', 'JJ'), ('research', 'NN'), ('direction', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Cleaner', 'NNP'), ('Production', 'NNP'), (',', ','), ('Volume', 'NN'), ('210', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP A/DT comprehensive/JJ review/NN)
  (NP big/JJ data/NN analytics/NNS)
  throughout/IN
  (NP product/NN lifecycle/NN support/NN)
  (NP sustainable/JJ smart/JJ manufacturing/NN)
  :/:
  (NP A/DT framework/NN)
  ,/,
  challenges/VBZ
  (NP
    future/JJ
    research/NN
    direction/NN
    ../NNP
    Journal/NNP
    Cleaner/NNP
    Production/NNP)
  ,/,
  (NP Volume/NN)
  210/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['A comprehensive review', 'big data analytics', 'product lifecycle support', 'sustainable smart manufacturing', 'A framework', 'future research direction .. Journal Cleaner Production', 'Volume', 'pp']

>> Named Entities are: 
 [('PERSON', 'Cleaner Production'), ('ORGANIZATION', 'Volume 210')] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('comprehensive', 'comprehens'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('throughout', 'throughout'), ('product', 'product'), ('lifecycle', 'lifecycl'), ('support', 'support'), ('sustainable', 'sustain'), ('smart', 'smart'), ('manufacturing', 'manufactur'), (':', ':'), ('A', 'a'), ('framework', 'framework'), (',', ','), ('challenges', 'challeng'), ('future', 'futur'), ('research', 'research'), ('direction', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Cleaner', 'cleaner'), ('Production', 'product'), (',', ','), ('Volume', 'volum'), ('210', '210'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('comprehensive', 'comprehens'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('throughout', 'throughout'), ('product', 'product'), ('lifecycle', 'lifecycl'), ('support', 'support'), ('sustainable', 'sustain'), ('smart', 'smart'), ('manufacturing', 'manufactur'), (':', ':'), ('A', 'a'), ('framework', 'framework'), (',', ','), ('challenges', 'challeng'), ('future', 'futur'), ('research', 'research'), ('direction', 'direct'), ('..', '..'), ('Journal', 'journal'), ('Cleaner', 'cleaner'), ('Production', 'product'), (',', ','), ('Volume', 'volum'), ('210', '210'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('comprehensive', 'comprehensive'), ('review', 'review'), ('big', 'big'), ('data', 'data'), ('analytics', 'analytics'), ('throughout', 'throughout'), ('product', 'product'), ('lifecycle', 'lifecycle'), ('support', 'support'), ('sustainable', 'sustainable'), ('smart', 'smart'), ('manufacturing', 'manufacturing'), (':', ':'), ('A', 'A'), ('framework', 'framework'), (',', ','), ('challenges', 'challenge'), ('future', 'future'), ('research', 'research'), ('direction', 'direction'), ('..', '..'), ('Journal', 'Journal'), ('Cleaner', 'Cleaner'), ('Production', 'Production'), (',', ','), ('Volume', 'Volume'), ('210', '210'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 938 =============================

1343-1365. 


>> Tokens are: 
 ['1343-1365', '.']

>> Bigrams are: 
 [('1343-1365', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1343-1365', 'JJ'), ('.', '.')]

 (S 1343-1365/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1343-1365', '1343-1365'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1343-1365', '1343-1365'), ('.', '.')]

>> Lemmatization: 
 [('1343-1365', '1343-1365'), ('.', '.')]



============================ Sentence 939 =============================

Ristoski, P., Bizer, C. and Paulheim, H., 2015. 


>> Tokens are: 
 ['Ristoski', ',', 'P.', ',', 'Bizer', ',', 'C.', 'Paulheim', ',', 'H.', ',', '2015', '.']

>> Bigrams are: 
 [('Ristoski', ','), (',', 'P.'), ('P.', ','), (',', 'Bizer'), ('Bizer', ','), (',', 'C.'), ('C.', 'Paulheim'), ('Paulheim', ','), (',', 'H.'), ('H.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Ristoski', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Bizer'), (',', 'Bizer', ','), ('Bizer', ',', 'C.'), (',', 'C.', 'Paulheim'), ('C.', 'Paulheim', ','), ('Paulheim', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Ristoski', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Bizer', 'NNP'), (',', ','), ('C.', 'NNP'), ('Paulheim', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Ristoski/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  (NP Bizer/NNP)
  ,/,
  (NP C./NNP Paulheim/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Ristoski', 'P.', 'Bizer', 'C. Paulheim', 'H.']

>> Named Entities are: 
 [('GPE', 'Ristoski'), ('PERSON', 'Bizer')] 

>> Stemming using Porter Stemmer: 
 [('Ristoski', 'ristoski'), (',', ','), ('P.', 'p.'), (',', ','), ('Bizer', 'bizer'), (',', ','), ('C.', 'c.'), ('Paulheim', 'paulheim'), (',', ','), ('H.', 'h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Ristoski', 'ristoski'), (',', ','), ('P.', 'p.'), (',', ','), ('Bizer', 'bizer'), (',', ','), ('C.', 'c.'), ('Paulheim', 'paulheim'), (',', ','), ('H.', 'h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Ristoski', 'Ristoski'), (',', ','), ('P.', 'P.'), (',', ','), ('Bizer', 'Bizer'), (',', ','), ('C.', 'C.'), ('Paulheim', 'Paulheim'), (',', ','), ('H.', 'H.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 940 =============================

Mining the web of linked data with rapidminer.. 


>> Tokens are: 
 ['Mining', 'web', 'linked', 'data', 'rapidminer', '..']

>> Bigrams are: 
 [('Mining', 'web'), ('web', 'linked'), ('linked', 'data'), ('data', 'rapidminer'), ('rapidminer', '..')]

>> Trigrams are: 
 [('Mining', 'web', 'linked'), ('web', 'linked', 'data'), ('linked', 'data', 'rapidminer'), ('data', 'rapidminer', '..')]

>> POS Tags are: 
 [('Mining', 'VBG'), ('web', 'NN'), ('linked', 'VBN'), ('data', 'NNS'), ('rapidminer', 'NN'), ('..', 'NN')]

 (S
  Mining/VBG
  (NP web/NN)
  linked/VBN
  (NP data/NNS rapidminer/NN ../NN)) 


>> Noun Phrases are: 
 ['web', 'data rapidminer ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Mining', 'mine'), ('web', 'web'), ('linked', 'link'), ('data', 'data'), ('rapidminer', 'rapidmin'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Mining', 'mine'), ('web', 'web'), ('linked', 'link'), ('data', 'data'), ('rapidminer', 'rapidmin'), ('..', '..')]

>> Lemmatization: 
 [('Mining', 'Mining'), ('web', 'web'), ('linked', 'linked'), ('data', 'data'), ('rapidminer', 'rapidminer'), ('..', '..')]



============================ Sentence 941 =============================

Web Semantics: Science, Services and Agents on the World Wide Web, Volume 35, pp. 


>> Tokens are: 
 ['Web', 'Semantics', ':', 'Science', ',', 'Services', 'Agents', 'World', 'Wide', 'Web', ',', 'Volume', '35', ',', 'pp', '.']

>> Bigrams are: 
 [('Web', 'Semantics'), ('Semantics', ':'), (':', 'Science'), ('Science', ','), (',', 'Services'), ('Services', 'Agents'), ('Agents', 'World'), ('World', 'Wide'), ('Wide', 'Web'), ('Web', ','), (',', 'Volume'), ('Volume', '35'), ('35', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Web', 'Semantics', ':'), ('Semantics', ':', 'Science'), (':', 'Science', ','), ('Science', ',', 'Services'), (',', 'Services', 'Agents'), ('Services', 'Agents', 'World'), ('Agents', 'World', 'Wide'), ('World', 'Wide', 'Web'), ('Wide', 'Web', ','), ('Web', ',', 'Volume'), (',', 'Volume', '35'), ('Volume', '35', ','), ('35', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Web', 'JJ'), ('Semantics', 'NNS'), (':', ':'), ('Science', 'NN'), (',', ','), ('Services', 'NNPS'), ('Agents', 'NNP'), ('World', 'NNP'), ('Wide', 'NNP'), ('Web', 'NNP'), (',', ','), ('Volume', 'NN'), ('35', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Web/JJ Semantics/NNS)
  :/:
  (NP Science/NN)
  ,/,
  Services/NNPS
  (NP Agents/NNP World/NNP Wide/NNP Web/NNP)
  ,/,
  (NP Volume/NN)
  35/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Web Semantics', 'Science', 'Agents World Wide Web', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Services Agents'), ('ORGANIZATION', 'Volume 35')] 

>> Stemming using Porter Stemmer: 
 [('Web', 'web'), ('Semantics', 'semant'), (':', ':'), ('Science', 'scienc'), (',', ','), ('Services', 'servic'), ('Agents', 'agent'), ('World', 'world'), ('Wide', 'wide'), ('Web', 'web'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Web', 'web'), ('Semantics', 'semant'), (':', ':'), ('Science', 'scienc'), (',', ','), ('Services', 'servic'), ('Agents', 'agent'), ('World', 'world'), ('Wide', 'wide'), ('Web', 'web'), (',', ','), ('Volume', 'volum'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Web', 'Web'), ('Semantics', 'Semantics'), (':', ':'), ('Science', 'Science'), (',', ','), ('Services', 'Services'), ('Agents', 'Agents'), ('World', 'World'), ('Wide', 'Wide'), ('Web', 'Web'), (',', ','), ('Volume', 'Volume'), ('35', '35'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 942 =============================

142-151. 


>> Tokens are: 
 ['142-151', '.']

>> Bigrams are: 
 [('142-151', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('142-151', 'JJ'), ('.', '.')]

 (S 142-151/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('142-151', '142-151'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('142-151', '142-151'), ('.', '.')]

>> Lemmatization: 
 [('142-151', '142-151'), ('.', '.')]



============================ Sentence 943 =============================

Russom, P., 2011. 


>> Tokens are: 
 ['Russom', ',', 'P.', ',', '2011', '.']

>> Bigrams are: 
 [('Russom', ','), (',', 'P.'), ('P.', ','), (',', '2011'), ('2011', '.')]

>> Trigrams are: 
 [('Russom', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2011'), (',', '2011', '.')]

>> POS Tags are: 
 [('Russom', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2011', 'CD'), ('.', '.')]

 (S (NP Russom/NNP) ,/, (NP P./NNP) ,/, 2011/CD ./.) 


>> Noun Phrases are: 
 ['Russom', 'P.']

>> Named Entities are: 
 [('GPE', 'Russom')] 

>> Stemming using Porter Stemmer: 
 [('Russom', 'russom'), (',', ','), ('P.', 'p.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Russom', 'russom'), (',', ','), ('P.', 'p.'), (',', ','), ('2011', '2011'), ('.', '.')]

>> Lemmatization: 
 [('Russom', 'Russom'), (',', ','), ('P.', 'P.'), (',', ','), ('2011', '2011'), ('.', '.')]



============================ Sentence 944 =============================

Big data analytics, s.l. 


>> Tokens are: 
 ['Big', 'data', 'analytics', ',', 's.l', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', ','), ('analytics', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (',', ','), ('s.l', 'NN'), ('.', '.')]

 (S (NP Big/NNP data/NNS analytics/NNS) ,/, (NP s.l/NN) ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 's.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (',', ','), ('s.l', 's.l'), ('.', '.')]



============================ Sentence 945 =============================

: TDWI best practices report, fourth quarter. 


>> Tokens are: 
 [':', 'TDWI', 'best', 'practices', 'report', ',', 'fourth', 'quarter', '.']

>> Bigrams are: 
 [(':', 'TDWI'), ('TDWI', 'best'), ('best', 'practices'), ('practices', 'report'), ('report', ','), (',', 'fourth'), ('fourth', 'quarter'), ('quarter', '.')]

>> Trigrams are: 
 [(':', 'TDWI', 'best'), ('TDWI', 'best', 'practices'), ('best', 'practices', 'report'), ('practices', 'report', ','), ('report', ',', 'fourth'), (',', 'fourth', 'quarter'), ('fourth', 'quarter', '.')]

>> POS Tags are: 
 [(':', ':'), ('TDWI', 'NN'), ('best', 'JJS'), ('practices', 'NNS'), ('report', 'NN'), (',', ','), ('fourth', 'JJ'), ('quarter', 'NN'), ('.', '.')]

 (S
  :/:
  (NP TDWI/NN)
  best/JJS
  (NP practices/NNS report/NN)
  ,/,
  (NP fourth/JJ quarter/NN)
  ./.) 


>> Noun Phrases are: 
 ['TDWI', 'practices report', 'fourth quarter']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('TDWI', 'tdwi'), ('best', 'best'), ('practices', 'practic'), ('report', 'report'), (',', ','), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('TDWI', 'tdwi'), ('best', 'best'), ('practices', 'practic'), ('report', 'report'), (',', ','), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('TDWI', 'TDWI'), ('best', 'best'), ('practices', 'practice'), ('report', 'report'), (',', ','), ('fourth', 'fourth'), ('quarter', 'quarter'), ('.', '.')]



============================ Sentence 946 =============================

Sagiroglu, S. and Sinanc, D., 2013. 


>> Tokens are: 
 ['Sagiroglu', ',', 'S.', 'Sinanc', ',', 'D.', ',', '2013', '.']

>> Bigrams are: 
 [('Sagiroglu', ','), (',', 'S.'), ('S.', 'Sinanc'), ('Sinanc', ','), (',', 'D.'), ('D.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Sagiroglu', ',', 'S.'), (',', 'S.', 'Sinanc'), ('S.', 'Sinanc', ','), ('Sinanc', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Sagiroglu', 'NNP'), (',', ','), ('S.', 'NNP'), ('Sinanc', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Sagiroglu/NNP)
  ,/,
  (NP S./NNP Sinanc/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Sagiroglu', 'S. Sinanc', 'D.']

>> Named Entities are: 
 [('GPE', 'Sagiroglu')] 

>> Stemming using Porter Stemmer: 
 [('Sagiroglu', 'sagiroglu'), (',', ','), ('S.', 's.'), ('Sinanc', 'sinanc'), (',', ','), ('D.', 'd.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sagiroglu', 'sagiroglu'), (',', ','), ('S.', 's.'), ('Sinanc', 'sinanc'), (',', ','), ('D.', 'd.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Sagiroglu', 'Sagiroglu'), (',', ','), ('S.', 'S.'), ('Sinanc', 'Sinanc'), (',', ','), ('D.', 'D.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 947 =============================

Big data: A review. 


>> Tokens are: 
 ['Big', 'data', ':', 'A', 'review', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'A'), ('A', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'A'), (':', 'A', 'review'), ('A', 'review', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('A', 'DT'), ('review', 'NN'), ('.', '.')]

 (S (NP Big/JJ data/NNS) :/: (NP A/DT review/NN) ./.) 


>> Noun Phrases are: 
 ['Big data', 'A review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('A', 'a'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('A', 'A'), ('review', 'review'), ('.', '.')]



============================ Sentence 948 =============================

s.l., IEEE, pp. 


>> Tokens are: 
 ['s.l.', ',', 'IEEE', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 'IEEE'), ('IEEE', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 'IEEE'), (',', 'IEEE', ','), ('IEEE', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('IEEE', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP IEEE/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 'IEEE', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE')] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'ieee'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('IEEE', 'IEEE'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 949 =============================

42-47. 


>> Tokens are: 
 ['42-47', '.']

>> Bigrams are: 
 [('42-47', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('42-47', 'JJ'), ('.', '.')]

 (S 42-47/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('42-47', '42-47'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('42-47', '42-47'), ('.', '.')]

>> Lemmatization: 
 [('42-47', '42-47'), ('.', '.')]



============================ Sentence 950 =============================

Schelén, O., Elragal, A. and Haddara, M., 2015. 


>> Tokens are: 
 ['Schelén', ',', 'O.', ',', 'Elragal', ',', 'A.', 'Haddara', ',', 'M.', ',', '2015', '.']

>> Bigrams are: 
 [('Schelén', ','), (',', 'O.'), ('O.', ','), (',', 'Elragal'), ('Elragal', ','), (',', 'A.'), ('A.', 'Haddara'), ('Haddara', ','), (',', 'M.'), ('M.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Schelén', ',', 'O.'), (',', 'O.', ','), ('O.', ',', 'Elragal'), (',', 'Elragal', ','), ('Elragal', ',', 'A.'), (',', 'A.', 'Haddara'), ('A.', 'Haddara', ','), ('Haddara', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Schelén', 'NNP'), (',', ','), ('O.', 'NNP'), (',', ','), ('Elragal', 'NNP'), (',', ','), ('A.', 'NNP'), ('Haddara', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Schelén/NNP)
  ,/,
  (NP O./NNP)
  ,/,
  (NP Elragal/NNP)
  ,/,
  (NP A./NNP Haddara/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Schelén', 'O.', 'Elragal', 'A. Haddara', 'M.']

>> Named Entities are: 
 [('GPE', 'Schelén'), ('GPE', 'Elragal')] 

>> Stemming using Porter Stemmer: 
 [('Schelén', 'schelén'), (',', ','), ('O.', 'o.'), (',', ','), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Haddara', 'haddara'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Schelén', 'schelén'), (',', ','), ('O.', 'o.'), (',', ','), ('Elragal', 'elrag'), (',', ','), ('A.', 'a.'), ('Haddara', 'haddara'), (',', ','), ('M.', 'm.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Schelén', 'Schelén'), (',', ','), ('O.', 'O.'), (',', ','), ('Elragal', 'Elragal'), (',', ','), ('A.', 'A.'), ('Haddara', 'Haddara'), (',', ','), ('M.', 'M.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 951 =============================

A roadmap for big-data research and education.,   s.l. 


>> Tokens are: 
 ['A', 'roadmap', 'big-data', 'research', 'education.', ',', 's.l', '.']

>> Bigrams are: 
 [('A', 'roadmap'), ('roadmap', 'big-data'), ('big-data', 'research'), ('research', 'education.'), ('education.', ','), (',', 's.l'), ('s.l', '.')]

>> Trigrams are: 
 [('A', 'roadmap', 'big-data'), ('roadmap', 'big-data', 'research'), ('big-data', 'research', 'education.'), ('research', 'education.', ','), ('education.', ',', 's.l'), (',', 's.l', '.')]

>> POS Tags are: 
 [('A', 'DT'), ('roadmap', 'JJ'), ('big-data', 'JJ'), ('research', 'NN'), ('education.', 'NN'), (',', ','), ('s.l', 'NN'), ('.', '.')]

 (S
  (NP A/DT roadmap/JJ big-data/JJ research/NN education./NN)
  ,/,
  (NP s.l/NN)
  ./.) 


>> Noun Phrases are: 
 ['A roadmap big-data research education.', 's.l']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('A', 'a'), ('roadmap', 'roadmap'), ('big-data', 'big-data'), ('research', 'research'), ('education.', 'education.'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('A', 'a'), ('roadmap', 'roadmap'), ('big-data', 'big-data'), ('research', 'research'), ('education.', 'education.'), (',', ','), ('s.l', 's.l'), ('.', '.')]

>> Lemmatization: 
 [('A', 'A'), ('roadmap', 'roadmap'), ('big-data', 'big-data'), ('research', 'research'), ('education.', 'education.'), (',', ','), ('s.l', 's.l'), ('.', '.')]



============================ Sentence 952 =============================

: Luleå tekniska universitet. 


>> Tokens are: 
 [':', 'Luleå', 'tekniska', 'universitet', '.']

>> Bigrams are: 
 [(':', 'Luleå'), ('Luleå', 'tekniska'), ('tekniska', 'universitet'), ('universitet', '.')]

>> Trigrams are: 
 [(':', 'Luleå', 'tekniska'), ('Luleå', 'tekniska', 'universitet'), ('tekniska', 'universitet', '.')]

>> POS Tags are: 
 [(':', ':'), ('Luleå', 'NN'), ('tekniska', 'NN'), ('universitet', 'NN'), ('.', '.')]

 (S :/: (NP Luleå/NN tekniska/NN universitet/NN) ./.) 


>> Noun Phrases are: 
 ['Luleå tekniska universitet']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [(':', ':'), ('Luleå', 'luleå'), ('tekniska', 'tekniska'), ('universitet', 'universitet'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [(':', ':'), ('Luleå', 'luleå'), ('tekniska', 'tekniska'), ('universitet', 'universitet'), ('.', '.')]

>> Lemmatization: 
 [(':', ':'), ('Luleå', 'Luleå'), ('tekniska', 'tekniska'), ('universitet', 'universitet'), ('.', '.')]



============================ Sentence 953 =============================

Schulman, J., Levine, S., Abbeel, P., Jordan, M. and Moritz, P., 2015. 


>> Tokens are: 
 ['Schulman', ',', 'J.', ',', 'Levine', ',', 'S.', ',', 'Abbeel', ',', 'P.', ',', 'Jordan', ',', 'M.', 'Moritz', ',', 'P.', ',', '2015', '.']

>> Bigrams are: 
 [('Schulman', ','), (',', 'J.'), ('J.', ','), (',', 'Levine'), ('Levine', ','), (',', 'S.'), ('S.', ','), (',', 'Abbeel'), ('Abbeel', ','), (',', 'P.'), ('P.', ','), (',', 'Jordan'), ('Jordan', ','), (',', 'M.'), ('M.', 'Moritz'), ('Moritz', ','), (',', 'P.'), ('P.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Schulman', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Levine'), (',', 'Levine', ','), ('Levine', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Abbeel'), (',', 'Abbeel', ','), ('Abbeel', ',', 'P.'), (',', 'P.', ','), ('P.', ',', 'Jordan'), (',', 'Jordan', ','), ('Jordan', ',', 'M.'), (',', 'M.', 'Moritz'), ('M.', 'Moritz', ','), ('Moritz', ',', 'P.'), (',', 'P.', ','), ('P.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Schulman', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Levine', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Abbeel', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('Jordan', 'NNP'), (',', ','), ('M.', 'NNP'), ('Moritz', 'NNP'), (',', ','), ('P.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Schulman/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Levine/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Abbeel/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  (NP Jordan/NNP)
  ,/,
  (NP M./NNP Moritz/NNP)
  ,/,
  (NP P./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Schulman', 'J.', 'Levine', 'S.', 'Abbeel', 'P.', 'Jordan', 'M. Moritz', 'P.']

>> Named Entities are: 
 [('GPE', 'Schulman'), ('GPE', 'Levine'), ('GPE', 'Abbeel'), ('GPE', 'Jordan')] 

>> Stemming using Porter Stemmer: 
 [('Schulman', 'schulman'), (',', ','), ('J.', 'j.'), (',', ','), ('Levine', 'levin'), (',', ','), ('S.', 's.'), (',', ','), ('Abbeel', 'abbeel'), (',', ','), ('P.', 'p.'), (',', ','), ('Jordan', 'jordan'), (',', ','), ('M.', 'm.'), ('Moritz', 'moritz'), (',', ','), ('P.', 'p.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Schulman', 'schulman'), (',', ','), ('J.', 'j.'), (',', ','), ('Levine', 'levin'), (',', ','), ('S.', 's.'), (',', ','), ('Abbeel', 'abbeel'), (',', ','), ('P.', 'p.'), (',', ','), ('Jordan', 'jordan'), (',', ','), ('M.', 'm.'), ('Moritz', 'moritz'), (',', ','), ('P.', 'p.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Schulman', 'Schulman'), (',', ','), ('J.', 'J.'), (',', ','), ('Levine', 'Levine'), (',', ','), ('S.', 'S.'), (',', ','), ('Abbeel', 'Abbeel'), (',', ','), ('P.', 'P.'), (',', ','), ('Jordan', 'Jordan'), (',', ','), ('M.', 'M.'), ('Moritz', 'Moritz'), (',', ','), ('P.', 'P.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 954 =============================

Trust region policy   optimization. 


>> Tokens are: 
 ['Trust', 'region', 'policy', 'optimization', '.']

>> Bigrams are: 
 [('Trust', 'region'), ('region', 'policy'), ('policy', 'optimization'), ('optimization', '.')]

>> Trigrams are: 
 [('Trust', 'region', 'policy'), ('region', 'policy', 'optimization'), ('policy', 'optimization', '.')]

>> POS Tags are: 
 [('Trust', 'NNP'), ('region', 'NN'), ('policy', 'NN'), ('optimization', 'NN'), ('.', '.')]

 (S (NP Trust/NNP region/NN policy/NN optimization/NN) ./.) 


>> Noun Phrases are: 
 ['Trust region policy optimization']

>> Named Entities are: 
 [('GPE', 'Trust')] 

>> Stemming using Porter Stemmer: 
 [('Trust', 'trust'), ('region', 'region'), ('policy', 'polici'), ('optimization', 'optim'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Trust', 'trust'), ('region', 'region'), ('policy', 'polici'), ('optimization', 'optim'), ('.', '.')]

>> Lemmatization: 
 [('Trust', 'Trust'), ('region', 'region'), ('policy', 'policy'), ('optimization', 'optimization'), ('.', '.')]



============================ Sentence 955 =============================

s.l., s.n., pp. 


>> Tokens are: 
 ['s.l.', ',', 's.n.', ',', 'pp', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n.'), ('s.n.', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n.'), (',', 's.n.', ','), ('s.n.', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n.', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP s.n./NN) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 's.n.', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n.', 's.n.'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 956 =============================

1889-1897. 


>> Tokens are: 
 ['1889-1897', '.']

>> Bigrams are: 
 [('1889-1897', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('1889-1897', 'JJ'), ('.', '.')]

 (S 1889-1897/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('1889-1897', '1889-1897'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('1889-1897', '1889-1897'), ('.', '.')]

>> Lemmatization: 
 [('1889-1897', '1889-1897'), ('.', '.')]



============================ Sentence 957 =============================

Sharma, R., Mithas, S. and Kankanhalli, A., 2014. 


>> Tokens are: 
 ['Sharma', ',', 'R.', ',', 'Mithas', ',', 'S.', 'Kankanhalli', ',', 'A.', ',', '2014', '.']

>> Bigrams are: 
 [('Sharma', ','), (',', 'R.'), ('R.', ','), (',', 'Mithas'), ('Mithas', ','), (',', 'S.'), ('S.', 'Kankanhalli'), ('Kankanhalli', ','), (',', 'A.'), ('A.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Sharma', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Mithas'), (',', 'Mithas', ','), ('Mithas', ',', 'S.'), (',', 'S.', 'Kankanhalli'), ('S.', 'Kankanhalli', ','), ('Kankanhalli', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Sharma', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Mithas', 'NNP'), (',', ','), ('S.', 'NNP'), ('Kankanhalli', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Sharma/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Mithas/NNP)
  ,/,
  (NP S./NNP Kankanhalli/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Sharma', 'R.', 'Mithas', 'S. Kankanhalli', 'A.']

>> Named Entities are: 
 [('GPE', 'Sharma'), ('GPE', 'Mithas')] 

>> Stemming using Porter Stemmer: 
 [('Sharma', 'sharma'), (',', ','), ('R.', 'r.'), (',', ','), ('Mithas', 'mitha'), (',', ','), ('S.', 's.'), ('Kankanhalli', 'kankanh'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sharma', 'sharma'), (',', ','), ('R.', 'r.'), (',', ','), ('Mithas', 'mitha'), (',', ','), ('S.', 's.'), ('Kankanhalli', 'kankanh'), (',', ','), ('A.', 'a.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Sharma', 'Sharma'), (',', ','), ('R.', 'R.'), (',', ','), ('Mithas', 'Mithas'), (',', ','), ('S.', 'S.'), ('Kankanhalli', 'Kankanhalli'), (',', ','), ('A.', 'A.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 958 =============================

Transforming decision-making processes: a   research agenda for understanding the impact of business analytics on organisations.. European   Journal of Information Systems, Volume 23. 


>> Tokens are: 
 ['Transforming', 'decision-making', 'processes', ':', 'research', 'agenda', 'understanding', 'impact', 'business', 'analytics', 'organisations', '..', 'European', 'Journal', 'Information', 'Systems', ',', 'Volume', '23', '.']

>> Bigrams are: 
 [('Transforming', 'decision-making'), ('decision-making', 'processes'), ('processes', ':'), (':', 'research'), ('research', 'agenda'), ('agenda', 'understanding'), ('understanding', 'impact'), ('impact', 'business'), ('business', 'analytics'), ('analytics', 'organisations'), ('organisations', '..'), ('..', 'European'), ('European', 'Journal'), ('Journal', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'Volume'), ('Volume', '23'), ('23', '.')]

>> Trigrams are: 
 [('Transforming', 'decision-making', 'processes'), ('decision-making', 'processes', ':'), ('processes', ':', 'research'), (':', 'research', 'agenda'), ('research', 'agenda', 'understanding'), ('agenda', 'understanding', 'impact'), ('understanding', 'impact', 'business'), ('impact', 'business', 'analytics'), ('business', 'analytics', 'organisations'), ('analytics', 'organisations', '..'), ('organisations', '..', 'European'), ('..', 'European', 'Journal'), ('European', 'Journal', 'Information'), ('Journal', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'Volume'), (',', 'Volume', '23'), ('Volume', '23', '.')]

>> POS Tags are: 
 [('Transforming', 'VBG'), ('decision-making', 'JJ'), ('processes', 'NNS'), (':', ':'), ('research', 'NN'), ('agenda', 'NN'), ('understanding', 'JJ'), ('impact', 'NN'), ('business', 'NN'), ('analytics', 'NNS'), ('organisations', 'NNS'), ('..', 'VBP'), ('European', 'JJ'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Volume', 'NN'), ('23', 'CD'), ('.', '.')]

 (S
  Transforming/VBG
  (NP decision-making/JJ processes/NNS)
  :/:
  (NP research/NN agenda/NN)
  (NP
    understanding/JJ
    impact/NN
    business/NN
    analytics/NNS
    organisations/NNS)
  ../VBP
  (NP European/JJ Journal/NNP Information/NNP Systems/NNP)
  ,/,
  (NP Volume/NN)
  23/CD
  ./.) 


>> Noun Phrases are: 
 ['decision-making processes', 'research agenda', 'understanding impact business analytics organisations', 'European Journal Information Systems', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'European Journal Information Systems'), ('ORGANIZATION', 'Volume 23')] 

>> Stemming using Porter Stemmer: 
 [('Transforming', 'transform'), ('decision-making', 'decision-mak'), ('processes', 'process'), (':', ':'), ('research', 'research'), ('agenda', 'agenda'), ('understanding', 'understand'), ('impact', 'impact'), ('business', 'busi'), ('analytics', 'analyt'), ('organisations', 'organis'), ('..', '..'), ('European', 'european'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('23', '23'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Transforming', 'transform'), ('decision-making', 'decision-mak'), ('processes', 'process'), (':', ':'), ('research', 'research'), ('agenda', 'agenda'), ('understanding', 'understand'), ('impact', 'impact'), ('business', 'busi'), ('analytics', 'analyt'), ('organisations', 'organis'), ('..', '..'), ('European', 'european'), ('Journal', 'journal'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('23', '23'), ('.', '.')]

>> Lemmatization: 
 [('Transforming', 'Transforming'), ('decision-making', 'decision-making'), ('processes', 'process'), (':', ':'), ('research', 'research'), ('agenda', 'agenda'), ('understanding', 'understanding'), ('impact', 'impact'), ('business', 'business'), ('analytics', 'analytics'), ('organisations', 'organisation'), ('..', '..'), ('European', 'European'), ('Journal', 'Journal'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('Volume', 'Volume'), ('23', '23'), ('.', '.')]



============================ Sentence 959 =============================

Sarah Al-Shiakhli   53      Singh, J. and Singla, V., 2015. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '53', 'Singh', ',', 'J.', 'Singla', ',', 'V.', ',', '2015', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '53'), ('53', 'Singh'), ('Singh', ','), (',', 'J.'), ('J.', 'Singla'), ('Singla', ','), (',', 'V.'), ('V.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '53'), ('Al-Shiakhli', '53', 'Singh'), ('53', 'Singh', ','), ('Singh', ',', 'J.'), (',', 'J.', 'Singla'), ('J.', 'Singla', ','), ('Singla', ',', 'V.'), (',', 'V.', ','), ('V.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('53', 'CD'), ('Singh', 'NNP'), (',', ','), ('J.', 'NNP'), ('Singla', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  53/CD
  (NP Singh/NNP)
  ,/,
  (NP J./NNP Singla/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Singh', 'J. Singla', 'V.']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Singh'), ('PERSON', 'J. Singla')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('53', '53'), ('Singh', 'singh'), (',', ','), ('J.', 'j.'), ('Singla', 'singla'), (',', ','), ('V.', 'v.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('53', '53'), ('Singh', 'singh'), (',', ','), ('J.', 'j.'), ('Singla', 'singla'), (',', ','), ('V.', 'v.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('53', '53'), ('Singh', 'Singh'), (',', ','), ('J.', 'J.'), ('Singla', 'Singla'), (',', ','), ('V.', 'V.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 960 =============================

Big data: tools and technologies in big data.. International Journal   of Computer Applications., Volume 112. 


>> Tokens are: 
 ['Big', 'data', ':', 'tools', 'technologies', 'big', 'data', '..', 'International', 'Journal', 'Computer', 'Applications.', ',', 'Volume', '112', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'tools'), ('tools', 'technologies'), ('technologies', 'big'), ('big', 'data'), ('data', '..'), ('..', 'International'), ('International', 'Journal'), ('Journal', 'Computer'), ('Computer', 'Applications.'), ('Applications.', ','), (',', 'Volume'), ('Volume', '112'), ('112', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'tools'), (':', 'tools', 'technologies'), ('tools', 'technologies', 'big'), ('technologies', 'big', 'data'), ('big', 'data', '..'), ('data', '..', 'International'), ('..', 'International', 'Journal'), ('International', 'Journal', 'Computer'), ('Journal', 'Computer', 'Applications.'), ('Computer', 'Applications.', ','), ('Applications.', ',', 'Volume'), (',', 'Volume', '112'), ('Volume', '112', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('tools', 'NNS'), ('technologies', 'NNS'), ('big', 'JJ'), ('data', 'NNS'), ('..', 'VBP'), ('International', 'NNP'), ('Journal', 'NNP'), ('Computer', 'NNP'), ('Applications.', 'NNP'), (',', ','), ('Volume', 'NN'), ('112', 'CD'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  (NP tools/NNS technologies/NNS)
  (NP big/JJ data/NNS)
  ../VBP
  (NP International/NNP Journal/NNP Computer/NNP Applications./NNP)
  ,/,
  (NP Volume/NN)
  112/CD
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'tools technologies', 'big data', 'International Journal Computer Applications.', 'Volume']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Computer'), ('ORGANIZATION', 'Volume 112')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('tools', 'tool'), ('technologies', 'technolog'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Computer', 'comput'), ('Applications.', 'applications.'), (',', ','), ('Volume', 'volum'), ('112', '112'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('tools', 'tool'), ('technologies', 'technolog'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Computer', 'comput'), ('Applications.', 'applications.'), (',', ','), ('Volume', 'volum'), ('112', '112'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('tools', 'tool'), ('technologies', 'technology'), ('big', 'big'), ('data', 'data'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal'), ('Computer', 'Computer'), ('Applications.', 'Applications.'), (',', ','), ('Volume', 'Volume'), ('112', '112'), ('.', '.')]



============================ Sentence 961 =============================

Suthaharan, S., 2014. 


>> Tokens are: 
 ['Suthaharan', ',', 'S.', ',', '2014', '.']

>> Bigrams are: 
 [('Suthaharan', ','), (',', 'S.'), ('S.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Suthaharan', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Suthaharan', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Suthaharan/NNP) ,/, (NP S./NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Suthaharan', 'S.']

>> Named Entities are: 
 [('GPE', 'Suthaharan')] 

>> Stemming using Porter Stemmer: 
 [('Suthaharan', 'suthaharan'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Suthaharan', 'suthaharan'), (',', ','), ('S.', 's.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Suthaharan', 'Suthaharan'), (',', ','), ('S.', 'S.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 962 =============================

Big data classification: Problems and challenges in network intrusion   prediction with machine learning.. ACM SIGMETRICS Performance Evaluation Review, Volume   4, pp. 


>> Tokens are: 
 ['Big', 'data', 'classification', ':', 'Problems', 'challenges', 'network', 'intrusion', 'prediction', 'machine', 'learning', '..', 'ACM', 'SIGMETRICS', 'Performance', 'Evaluation', 'Review', ',', 'Volume', '4', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'classification'), ('classification', ':'), (':', 'Problems'), ('Problems', 'challenges'), ('challenges', 'network'), ('network', 'intrusion'), ('intrusion', 'prediction'), ('prediction', 'machine'), ('machine', 'learning'), ('learning', '..'), ('..', 'ACM'), ('ACM', 'SIGMETRICS'), ('SIGMETRICS', 'Performance'), ('Performance', 'Evaluation'), ('Evaluation', 'Review'), ('Review', ','), (',', 'Volume'), ('Volume', '4'), ('4', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'data', 'classification'), ('data', 'classification', ':'), ('classification', ':', 'Problems'), (':', 'Problems', 'challenges'), ('Problems', 'challenges', 'network'), ('challenges', 'network', 'intrusion'), ('network', 'intrusion', 'prediction'), ('intrusion', 'prediction', 'machine'), ('prediction', 'machine', 'learning'), ('machine', 'learning', '..'), ('learning', '..', 'ACM'), ('..', 'ACM', 'SIGMETRICS'), ('ACM', 'SIGMETRICS', 'Performance'), ('SIGMETRICS', 'Performance', 'Evaluation'), ('Performance', 'Evaluation', 'Review'), ('Evaluation', 'Review', ','), ('Review', ',', 'Volume'), (',', 'Volume', '4'), ('Volume', '4', ','), ('4', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('classification', 'NN'), (':', ':'), ('Problems', 'NNP'), ('challenges', 'VBZ'), ('network', 'NN'), ('intrusion', 'NN'), ('prediction', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('..', 'JJ'), ('ACM', 'NNP'), ('SIGMETRICS', 'NNP'), ('Performance', 'NNP'), ('Evaluation', 'NNP'), ('Review', 'NNP'), (',', ','), ('Volume', 'NN'), ('4', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS classification/NN)
  :/:
  (NP Problems/NNP)
  challenges/VBZ
  (NP network/NN intrusion/NN prediction/NN machine/NN)
  learning/VBG
  (NP
    ../JJ
    ACM/NNP
    SIGMETRICS/NNP
    Performance/NNP
    Evaluation/NNP
    Review/NNP)
  ,/,
  (NP Volume/NN)
  4/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data classification', 'Problems', 'network intrusion prediction machine', '.. ACM SIGMETRICS Performance Evaluation Review', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'ACM')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('classification', 'classif'), (':', ':'), ('Problems', 'problem'), ('challenges', 'challeng'), ('network', 'network'), ('intrusion', 'intrus'), ('prediction', 'predict'), ('machine', 'machin'), ('learning', 'learn'), ('..', '..'), ('ACM', 'acm'), ('SIGMETRICS', 'sigmetr'), ('Performance', 'perform'), ('Evaluation', 'evalu'), ('Review', 'review'), (',', ','), ('Volume', 'volum'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('classification', 'classif'), (':', ':'), ('Problems', 'problem'), ('challenges', 'challeng'), ('network', 'network'), ('intrusion', 'intrus'), ('prediction', 'predict'), ('machine', 'machin'), ('learning', 'learn'), ('..', '..'), ('ACM', 'acm'), ('SIGMETRICS', 'sigmetr'), ('Performance', 'perform'), ('Evaluation', 'evalu'), ('Review', 'review'), (',', ','), ('Volume', 'volum'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('classification', 'classification'), (':', ':'), ('Problems', 'Problems'), ('challenges', 'challenge'), ('network', 'network'), ('intrusion', 'intrusion'), ('prediction', 'prediction'), ('machine', 'machine'), ('learning', 'learning'), ('..', '..'), ('ACM', 'ACM'), ('SIGMETRICS', 'SIGMETRICS'), ('Performance', 'Performance'), ('Evaluation', 'Evaluation'), ('Review', 'Review'), (',', ','), ('Volume', 'Volume'), ('4', '4'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 963 =============================

70-73. 


>> Tokens are: 
 ['70-73', '.']

>> Bigrams are: 
 [('70-73', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('70-73', 'JJ'), ('.', '.')]

 (S 70-73/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('70-73', '70-73'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('70-73', '70-73'), ('.', '.')]

>> Lemmatization: 
 [('70-73', '70-73'), ('.', '.')]



============================ Sentence 964 =============================

Team, R.C., 2000. 


>> Tokens are: 
 ['Team', ',', 'R.C.', ',', '2000', '.']

>> Bigrams are: 
 [('Team', ','), (',', 'R.C.'), ('R.C.', ','), (',', '2000'), ('2000', '.')]

>> Trigrams are: 
 [('Team', ',', 'R.C.'), (',', 'R.C.', ','), ('R.C.', ',', '2000'), (',', '2000', '.')]

>> POS Tags are: 
 [('Team', 'NN'), (',', ','), ('R.C.', 'NNP'), (',', ','), ('2000', 'CD'), ('.', '.')]

 (S (NP Team/NN) ,/, (NP R.C./NNP) ,/, 2000/CD ./.) 


>> Noun Phrases are: 
 ['Team', 'R.C.']

>> Named Entities are: 
 [('GPE', 'Team')] 

>> Stemming using Porter Stemmer: 
 [('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Team', 'team'), (',', ','), ('R.C.', 'r.c.'), (',', ','), ('2000', '2000'), ('.', '.')]

>> Lemmatization: 
 [('Team', 'Team'), (',', ','), ('R.C.', 'R.C.'), (',', ','), ('2000', '2000'), ('.', '.')]



============================ Sentence 965 =============================

R language definition.. R foundation for statistical computing. 


>> Tokens are: 
 ['R', 'language', 'definition', '..', 'R', 'foundation', 'statistical', 'computing', '.']

>> Bigrams are: 
 [('R', 'language'), ('language', 'definition'), ('definition', '..'), ('..', 'R'), ('R', 'foundation'), ('foundation', 'statistical'), ('statistical', 'computing'), ('computing', '.')]

>> Trigrams are: 
 [('R', 'language', 'definition'), ('language', 'definition', '..'), ('definition', '..', 'R'), ('..', 'R', 'foundation'), ('R', 'foundation', 'statistical'), ('foundation', 'statistical', 'computing'), ('statistical', 'computing', '.')]

>> POS Tags are: 
 [('R', 'NNP'), ('language', 'NN'), ('definition', 'NN'), ('..', 'NNP'), ('R', 'NNP'), ('foundation', 'NN'), ('statistical', 'JJ'), ('computing', 'NN'), ('.', '.')]

 (S
  (NP R/NNP language/NN definition/NN ../NNP R/NNP foundation/NN)
  (NP statistical/JJ computing/NN)
  ./.) 


>> Noun Phrases are: 
 ['R language definition .. R foundation', 'statistical computing']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('R', 'r'), ('language', 'languag'), ('definition', 'definit'), ('..', '..'), ('R', 'r'), ('foundation', 'foundat'), ('statistical', 'statist'), ('computing', 'comput'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('R', 'r'), ('language', 'languag'), ('definition', 'definit'), ('..', '..'), ('R', 'r'), ('foundation', 'foundat'), ('statistical', 'statist'), ('computing', 'comput'), ('.', '.')]

>> Lemmatization: 
 [('R', 'R'), ('language', 'language'), ('definition', 'definition'), ('..', '..'), ('R', 'R'), ('foundation', 'foundation'), ('statistical', 'statistical'), ('computing', 'computing'), ('.', '.')]



============================ Sentence 966 =============================

Tien, J.M., 2013. 


>> Tokens are: 
 ['Tien', ',', 'J.M.', ',', '2013', '.']

>> Bigrams are: 
 [('Tien', ','), (',', 'J.M.'), ('J.M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Tien', ',', 'J.M.'), (',', 'J.M.', ','), ('J.M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Tien', 'NNP'), (',', ','), ('J.M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S (NP Tien/NNP) ,/, (NP J.M./NNP) ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 ['Tien', 'J.M.']

>> Named Entities are: 
 [('GPE', 'Tien')] 

>> Stemming using Porter Stemmer: 
 [('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tien', 'tien'), (',', ','), ('J.M.', 'j.m.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Tien', 'Tien'), (',', ','), ('J.M.', 'J.M.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 967 =============================

Big data: Unleashing information.. Journal of Systems Science and Systems   Engineering, 22(2), pp. 


>> Tokens are: 
 ['Big', 'data', ':', 'Unleashing', 'information', '..', 'Journal', 'Systems', 'Science', 'Systems', 'Engineering', ',', '22', '(', '2', ')', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'Unleashing'), ('Unleashing', 'information'), ('information', '..'), ('..', 'Journal'), ('Journal', 'Systems'), ('Systems', 'Science'), ('Science', 'Systems'), ('Systems', 'Engineering'), ('Engineering', ','), (',', '22'), ('22', '('), ('(', '2'), ('2', ')'), (')', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'Unleashing'), (':', 'Unleashing', 'information'), ('Unleashing', 'information', '..'), ('information', '..', 'Journal'), ('..', 'Journal', 'Systems'), ('Journal', 'Systems', 'Science'), ('Systems', 'Science', 'Systems'), ('Science', 'Systems', 'Engineering'), ('Systems', 'Engineering', ','), ('Engineering', ',', '22'), (',', '22', '('), ('22', '(', '2'), ('(', '2', ')'), ('2', ')', ','), (')', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('Unleashing', 'VBG'), ('information', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Systems', 'NNPS'), ('Science', 'NNP'), ('Systems', 'NNPS'), ('Engineering', 'NNP'), (',', ','), ('22', 'CD'), ('(', '('), ('2', 'CD'), (')', ')'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  Unleashing/VBG
  (NP information/NN ../NNP Journal/NNP)
  Systems/NNPS
  (NP Science/NNP)
  Systems/NNPS
  (NP Engineering/NNP)
  ,/,
  22/CD
  (/(
  2/CD
  )/)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'information .. Journal', 'Science', 'Engineering', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Science Systems Engineering')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('Unleashing', 'unleash'), ('information', 'inform'), ('..', '..'), ('Journal', 'journal'), ('Systems', 'system'), ('Science', 'scienc'), ('Systems', 'system'), ('Engineering', 'engin'), (',', ','), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('Unleashing', 'unleash'), ('information', 'inform'), ('..', '..'), ('Journal', 'journal'), ('Systems', 'system'), ('Science', 'scienc'), ('Systems', 'system'), ('Engineering', 'engin'), (',', ','), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('Unleashing', 'Unleashing'), ('information', 'information'), ('..', '..'), ('Journal', 'Journal'), ('Systems', 'Systems'), ('Science', 'Science'), ('Systems', 'Systems'), ('Engineering', 'Engineering'), (',', ','), ('22', '22'), ('(', '('), ('2', '2'), (')', ')'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 968 =============================

127-151.   ur Rehman, M.H., Chang, V., Batool, A. and Wah, T.Y., 2016. 


>> Tokens are: 
 ['127-151.', 'ur', 'Rehman', ',', 'M.H.', ',', 'Chang', ',', 'V.', ',', 'Batool', ',', 'A.', 'Wah', ',', 'T.Y.', ',', '2016', '.']

>> Bigrams are: 
 [('127-151.', 'ur'), ('ur', 'Rehman'), ('Rehman', ','), (',', 'M.H.'), ('M.H.', ','), (',', 'Chang'), ('Chang', ','), (',', 'V.'), ('V.', ','), (',', 'Batool'), ('Batool', ','), (',', 'A.'), ('A.', 'Wah'), ('Wah', ','), (',', 'T.Y.'), ('T.Y.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('127-151.', 'ur', 'Rehman'), ('ur', 'Rehman', ','), ('Rehman', ',', 'M.H.'), (',', 'M.H.', ','), ('M.H.', ',', 'Chang'), (',', 'Chang', ','), ('Chang', ',', 'V.'), (',', 'V.', ','), ('V.', ',', 'Batool'), (',', 'Batool', ','), ('Batool', ',', 'A.'), (',', 'A.', 'Wah'), ('A.', 'Wah', ','), ('Wah', ',', 'T.Y.'), (',', 'T.Y.', ','), ('T.Y.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('127-151.', 'JJ'), ('ur', 'JJ'), ('Rehman', 'NNP'), (',', ','), ('M.H.', 'NNP'), (',', ','), ('Chang', 'NNP'), (',', ','), ('V.', 'NNP'), (',', ','), ('Batool', 'NNP'), (',', ','), ('A.', 'NNP'), ('Wah', 'NNP'), (',', ','), ('T.Y.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP 127-151./JJ ur/JJ Rehman/NNP)
  ,/,
  (NP M.H./NNP)
  ,/,
  (NP Chang/NNP)
  ,/,
  (NP V./NNP)
  ,/,
  (NP Batool/NNP)
  ,/,
  (NP A./NNP Wah/NNP)
  ,/,
  (NP T.Y./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['127-151. ur Rehman', 'M.H.', 'Chang', 'V.', 'Batool', 'A. Wah', 'T.Y.']

>> Named Entities are: 
 [('PERSON', 'Rehman'), ('PERSON', 'Chang'), ('GPE', 'Batool')] 

>> Stemming using Porter Stemmer: 
 [('127-151.', '127-151.'), ('ur', 'ur'), ('Rehman', 'rehman'), (',', ','), ('M.H.', 'm.h.'), (',', ','), ('Chang', 'chang'), (',', ','), ('V.', 'v.'), (',', ','), ('Batool', 'batool'), (',', ','), ('A.', 'a.'), ('Wah', 'wah'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('127-151.', '127-151.'), ('ur', 'ur'), ('Rehman', 'rehman'), (',', ','), ('M.H.', 'm.h.'), (',', ','), ('Chang', 'chang'), (',', ','), ('V.', 'v.'), (',', ','), ('Batool', 'batool'), (',', ','), ('A.', 'a.'), ('Wah', 'wah'), (',', ','), ('T.Y.', 't.y.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('127-151.', '127-151.'), ('ur', 'ur'), ('Rehman', 'Rehman'), (',', ','), ('M.H.', 'M.H.'), (',', ','), ('Chang', 'Chang'), (',', ','), ('V.', 'V.'), (',', ','), ('Batool', 'Batool'), (',', ','), ('A.', 'A.'), ('Wah', 'Wah'), (',', ','), ('T.Y.', 'T.Y.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 969 =============================

Big data reduction framework for   value creation in sustainable enterprises. 


>> Tokens are: 
 ['Big', 'data', 'reduction', 'framework', 'value', 'creation', 'sustainable', 'enterprises', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'reduction'), ('reduction', 'framework'), ('framework', 'value'), ('value', 'creation'), ('creation', 'sustainable'), ('sustainable', 'enterprises'), ('enterprises', '.')]

>> Trigrams are: 
 [('Big', 'data', 'reduction'), ('data', 'reduction', 'framework'), ('reduction', 'framework', 'value'), ('framework', 'value', 'creation'), ('value', 'creation', 'sustainable'), ('creation', 'sustainable', 'enterprises'), ('sustainable', 'enterprises', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('reduction', 'NN'), ('framework', 'NN'), ('value', 'NN'), ('creation', 'NN'), ('sustainable', 'JJ'), ('enterprises', 'NNS'), ('.', '.')]

 (S
  (NP
    Big/NNP
    data/NNS
    reduction/NN
    framework/NN
    value/NN
    creation/NN)
  (NP sustainable/JJ enterprises/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data reduction framework value creation', 'sustainable enterprises']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('reduction', 'reduct'), ('framework', 'framework'), ('value', 'valu'), ('creation', 'creation'), ('sustainable', 'sustain'), ('enterprises', 'enterpris'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('reduction', 'reduct'), ('framework', 'framework'), ('value', 'valu'), ('creation', 'creation'), ('sustainable', 'sustain'), ('enterprises', 'enterpris'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('reduction', 'reduction'), ('framework', 'framework'), ('value', 'value'), ('creation', 'creation'), ('sustainable', 'sustainable'), ('enterprises', 'enterprise'), ('.', '.')]



============================ Sentence 970 =============================

International Journal of Information Management, 36(6),   pp.917-928.. International Journal of Information Management, Volume 36, pp. 


>> Tokens are: 
 ['International', 'Journal', 'Information', 'Management', ',', '36', '(', '6', ')', ',', 'pp.917-928', '..', 'International', 'Journal', 'Information', 'Management', ',', 'Volume', '36', ',', 'pp', '.']

>> Bigrams are: 
 [('International', 'Journal'), ('Journal', 'Information'), ('Information', 'Management'), ('Management', ','), (',', '36'), ('36', '('), ('(', '6'), ('6', ')'), (')', ','), (',', 'pp.917-928'), ('pp.917-928', '..'), ('..', 'International'), ('International', 'Journal'), ('Journal', 'Information'), ('Information', 'Management'), ('Management', ','), (',', 'Volume'), ('Volume', '36'), ('36', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('International', 'Journal', 'Information'), ('Journal', 'Information', 'Management'), ('Information', 'Management', ','), ('Management', ',', '36'), (',', '36', '('), ('36', '(', '6'), ('(', '6', ')'), ('6', ')', ','), (')', ',', 'pp.917-928'), (',', 'pp.917-928', '..'), ('pp.917-928', '..', 'International'), ('..', 'International', 'Journal'), ('International', 'Journal', 'Information'), ('Journal', 'Information', 'Management'), ('Information', 'Management', ','), ('Management', ',', 'Volume'), (',', 'Volume', '36'), ('Volume', '36', ','), ('36', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('International', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), (',', ','), ('36', 'CD'), ('(', '('), ('6', 'CD'), (')', ')'), (',', ','), ('pp.917-928', 'JJ'), ('..', 'NNP'), ('International', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Management', 'NNP'), (',', ','), ('Volume', 'NN'), ('36', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP International/NNP Journal/NNP Information/NNP Management/NNP)
  ,/,
  36/CD
  (/(
  6/CD
  )/)
  ,/,
  (NP
    pp.917-928/JJ
    ../NNP
    International/NNP
    Journal/NNP
    Information/NNP
    Management/NNP)
  ,/,
  (NP Volume/NN)
  36/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['International Journal Information Management', 'pp.917-928 .. International Journal Information Management', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'International Journal Information Management'), ('ORGANIZATION', 'Volume 36')] 

>> Stemming using Porter Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('36', '36'), ('(', '('), ('6', '6'), (')', ')'), (',', ','), ('pp.917-928', 'pp.917-928'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('36', '36'), ('(', '('), ('6', '6'), (')', ')'), (',', ','), ('pp.917-928', 'pp.917-928'), ('..', '..'), ('International', 'intern'), ('Journal', 'journal'), ('Information', 'inform'), ('Management', 'manag'), (',', ','), ('Volume', 'volum'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('International', 'International'), ('Journal', 'Journal'), ('Information', 'Information'), ('Management', 'Management'), (',', ','), ('36', '36'), ('(', '('), ('6', '6'), (')', ')'), (',', ','), ('pp.917-928', 'pp.917-928'), ('..', '..'), ('International', 'International'), ('Journal', 'Journal'), ('Information', 'Information'), ('Management', 'Management'), (',', ','), ('Volume', 'Volume'), ('36', '36'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 971 =============================

917-928. 


>> Tokens are: 
 ['917-928', '.']

>> Bigrams are: 
 [('917-928', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('917-928', 'CD'), ('.', '.')]

 (S 917-928/CD ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('917-928', '917-928'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('917-928', '917-928'), ('.', '.')]

>> Lemmatization: 
 [('917-928', '917-928'), ('.', '.')]



============================ Sentence 972 =============================

Van Hasselt, H., Guez, A. and Silver, D., 2016. 


>> Tokens are: 
 ['Van', 'Hasselt', ',', 'H.', ',', 'Guez', ',', 'A.', 'Silver', ',', 'D.', ',', '2016', '.']

>> Bigrams are: 
 [('Van', 'Hasselt'), ('Hasselt', ','), (',', 'H.'), ('H.', ','), (',', 'Guez'), ('Guez', ','), (',', 'A.'), ('A.', 'Silver'), ('Silver', ','), (',', 'D.'), ('D.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Van', 'Hasselt', ','), ('Hasselt', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Guez'), (',', 'Guez', ','), ('Guez', ',', 'A.'), (',', 'A.', 'Silver'), ('A.', 'Silver', ','), ('Silver', ',', 'D.'), (',', 'D.', ','), ('D.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Van', 'NNP'), ('Hasselt', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Guez', 'NNP'), (',', ','), ('A.', 'NNP'), ('Silver', 'NNP'), (',', ','), ('D.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Van/NNP Hasselt/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Guez/NNP)
  ,/,
  (NP A./NNP Silver/NNP)
  ,/,
  (NP D./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Van Hasselt', 'H.', 'Guez', 'A. Silver', 'D.']

>> Named Entities are: 
 [('PERSON', 'Van Hasselt'), ('GPE', 'Guez')] 

>> Stemming using Porter Stemmer: 
 [('Van', 'van'), ('Hasselt', 'hasselt'), (',', ','), ('H.', 'h.'), (',', ','), ('Guez', 'guez'), (',', ','), ('A.', 'a.'), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Van', 'van'), ('Hasselt', 'hasselt'), (',', ','), ('H.', 'h.'), (',', ','), ('Guez', 'guez'), (',', ','), ('A.', 'a.'), ('Silver', 'silver'), (',', ','), ('D.', 'd.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Van', 'Van'), ('Hasselt', 'Hasselt'), (',', ','), ('H.', 'H.'), (',', ','), ('Guez', 'Guez'), (',', ','), ('A.', 'A.'), ('Silver', 'Silver'), (',', ','), ('D.', 'D.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 973 =============================

Deep reinforcement learning with double q-  learning. 


>> Tokens are: 
 ['Deep', 'reinforcement', 'learning', 'double', 'q-', 'learning', '.']

>> Bigrams are: 
 [('Deep', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'double'), ('double', 'q-'), ('q-', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Deep', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'double'), ('learning', 'double', 'q-'), ('double', 'q-', 'learning'), ('q-', 'learning', '.')]

>> POS Tags are: 
 [('Deep', 'JJ'), ('reinforcement', 'NN'), ('learning', 'VBG'), ('double', 'JJ'), ('q-', 'JJ'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Deep/JJ reinforcement/NN)
  learning/VBG
  (NP double/JJ q-/JJ learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Deep reinforcement', 'double q- learning']

>> Named Entities are: 
 [('GPE', 'Deep')] 

>> Stemming using Porter Stemmer: 
 [('Deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('double', 'doubl'), ('q-', 'q-'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Deep', 'deep'), ('reinforcement', 'reinforc'), ('learning', 'learn'), ('double', 'doubl'), ('q-', 'q-'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Deep', 'Deep'), ('reinforcement', 'reinforcement'), ('learning', 'learning'), ('double', 'double'), ('q-', 'q-'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 974 =============================

s.l., s.n. 


>> Tokens are: 
 ['s.l.', ',', 's.n', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n'), ('s.n', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n'), (',', 's.n', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP s.n/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 's.n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]



============================ Sentence 975 =============================

Vom Brocke, J., Simons, A., Niehaves, B., Riemer, K., Plattfaut, R. and Cleven, A., 2009. 


>> Tokens are: 
 ['Vom', 'Brocke', ',', 'J.', ',', 'Simons', ',', 'A.', ',', 'Niehaves', ',', 'B.', ',', 'Riemer', ',', 'K.', ',', 'Plattfaut', ',', 'R.', 'Cleven', ',', 'A.', ',', '2009', '.']

>> Bigrams are: 
 [('Vom', 'Brocke'), ('Brocke', ','), (',', 'J.'), ('J.', ','), (',', 'Simons'), ('Simons', ','), (',', 'A.'), ('A.', ','), (',', 'Niehaves'), ('Niehaves', ','), (',', 'B.'), ('B.', ','), (',', 'Riemer'), ('Riemer', ','), (',', 'K.'), ('K.', ','), (',', 'Plattfaut'), ('Plattfaut', ','), (',', 'R.'), ('R.', 'Cleven'), ('Cleven', ','), (',', 'A.'), ('A.', ','), (',', '2009'), ('2009', '.')]

>> Trigrams are: 
 [('Vom', 'Brocke', ','), ('Brocke', ',', 'J.'), (',', 'J.', ','), ('J.', ',', 'Simons'), (',', 'Simons', ','), ('Simons', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Niehaves'), (',', 'Niehaves', ','), ('Niehaves', ',', 'B.'), (',', 'B.', ','), ('B.', ',', 'Riemer'), (',', 'Riemer', ','), ('Riemer', ',', 'K.'), (',', 'K.', ','), ('K.', ',', 'Plattfaut'), (',', 'Plattfaut', ','), ('Plattfaut', ',', 'R.'), (',', 'R.', 'Cleven'), ('R.', 'Cleven', ','), ('Cleven', ',', 'A.'), (',', 'A.', ','), ('A.', ',', '2009'), (',', '2009', '.')]

>> POS Tags are: 
 [('Vom', 'NNP'), ('Brocke', 'NNP'), (',', ','), ('J.', 'NNP'), (',', ','), ('Simons', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Niehaves', 'NNP'), (',', ','), ('B.', 'NNP'), (',', ','), ('Riemer', 'NNP'), (',', ','), ('K.', 'NNP'), (',', ','), ('Plattfaut', 'NNP'), (',', ','), ('R.', 'NNP'), ('Cleven', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('2009', 'CD'), ('.', '.')]

 (S
  (NP Vom/NNP Brocke/NNP)
  ,/,
  (NP J./NNP)
  ,/,
  (NP Simons/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Niehaves/NNP)
  ,/,
  (NP B./NNP)
  ,/,
  (NP Riemer/NNP)
  ,/,
  (NP K./NNP)
  ,/,
  (NP Plattfaut/NNP)
  ,/,
  (NP R./NNP Cleven/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  2009/CD
  ./.) 


>> Noun Phrases are: 
 ['Vom Brocke', 'J.', 'Simons', 'A.', 'Niehaves', 'B.', 'Riemer', 'K.', 'Plattfaut', 'R. Cleven', 'A.']

>> Named Entities are: 
 [('PERSON', 'Vom'), ('ORGANIZATION', 'Brocke'), ('GPE', 'Simons'), ('GPE', 'Niehaves'), ('GPE', 'Riemer'), ('PERSON', 'Plattfaut')] 

>> Stemming using Porter Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), (',', ','), ('Simons', 'simon'), (',', ','), ('A.', 'a.'), (',', ','), ('Niehaves', 'niehav'), (',', ','), ('B.', 'b.'), (',', ','), ('Riemer', 'riemer'), (',', ','), ('K.', 'k.'), (',', ','), ('Plattfaut', 'plattfaut'), (',', ','), ('R.', 'r.'), ('Cleven', 'cleven'), (',', ','), ('A.', 'a.'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Vom', 'vom'), ('Brocke', 'brock'), (',', ','), ('J.', 'j.'), (',', ','), ('Simons', 'simon'), (',', ','), ('A.', 'a.'), (',', ','), ('Niehaves', 'niehav'), (',', ','), ('B.', 'b.'), (',', ','), ('Riemer', 'riemer'), (',', ','), ('K.', 'k.'), (',', ','), ('Plattfaut', 'plattfaut'), (',', ','), ('R.', 'r.'), ('Cleven', 'cleven'), (',', ','), ('A.', 'a.'), (',', ','), ('2009', '2009'), ('.', '.')]

>> Lemmatization: 
 [('Vom', 'Vom'), ('Brocke', 'Brocke'), (',', ','), ('J.', 'J.'), (',', ','), ('Simons', 'Simons'), (',', ','), ('A.', 'A.'), (',', ','), ('Niehaves', 'Niehaves'), (',', ','), ('B.', 'B.'), (',', ','), ('Riemer', 'Riemer'), (',', ','), ('K.', 'K.'), (',', ','), ('Plattfaut', 'Plattfaut'), (',', ','), ('R.', 'R.'), ('Cleven', 'Cleven'), (',', ','), ('A.', 'A.'), (',', ','), ('2009', '2009'), ('.', '.')]



============================ Sentence 976 =============================

Reconstructing the giant: On the importance of rigour in documenting the literature search   process.. 


>> Tokens are: 
 ['Reconstructing', 'giant', ':', 'On', 'importance', 'rigour', 'documenting', 'literature', 'search', 'process', '..']

>> Bigrams are: 
 [('Reconstructing', 'giant'), ('giant', ':'), (':', 'On'), ('On', 'importance'), ('importance', 'rigour'), ('rigour', 'documenting'), ('documenting', 'literature'), ('literature', 'search'), ('search', 'process'), ('process', '..')]

>> Trigrams are: 
 [('Reconstructing', 'giant', ':'), ('giant', ':', 'On'), (':', 'On', 'importance'), ('On', 'importance', 'rigour'), ('importance', 'rigour', 'documenting'), ('rigour', 'documenting', 'literature'), ('documenting', 'literature', 'search'), ('literature', 'search', 'process'), ('search', 'process', '..')]

>> POS Tags are: 
 [('Reconstructing', 'VBG'), ('giant', 'NN'), (':', ':'), ('On', 'IN'), ('importance', 'NN'), ('rigour', 'NN'), ('documenting', 'VBG'), ('literature', 'JJ'), ('search', 'NN'), ('process', 'NN'), ('..', 'NN')]

 (S
  Reconstructing/VBG
  (NP giant/NN)
  :/:
  On/IN
  (NP importance/NN rigour/NN)
  documenting/VBG
  (NP literature/JJ search/NN process/NN ../NN)) 


>> Noun Phrases are: 
 ['giant', 'importance rigour', 'literature search process ..']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Reconstructing', 'reconstruct'), ('giant', 'giant'), (':', ':'), ('On', 'on'), ('importance', 'import'), ('rigour', 'rigour'), ('documenting', 'document'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('..', '..')]

>> Stemming using Snowball Stemmer: 
 [('Reconstructing', 'reconstruct'), ('giant', 'giant'), (':', ':'), ('On', 'on'), ('importance', 'import'), ('rigour', 'rigour'), ('documenting', 'document'), ('literature', 'literatur'), ('search', 'search'), ('process', 'process'), ('..', '..')]

>> Lemmatization: 
 [('Reconstructing', 'Reconstructing'), ('giant', 'giant'), (':', ':'), ('On', 'On'), ('importance', 'importance'), ('rigour', 'rigour'), ('documenting', 'documenting'), ('literature', 'literature'), ('search', 'search'), ('process', 'process'), ('..', '..')]



============================ Sentence 977 =============================

s.l., s.n. 


>> Tokens are: 
 ['s.l.', ',', 's.n', '.']

>> Bigrams are: 
 [('s.l.', ','), (',', 's.n'), ('s.n', '.')]

>> Trigrams are: 
 [('s.l.', ',', 's.n'), (',', 's.n', '.')]

>> POS Tags are: 
 [('s.l.', 'NN'), (',', ','), ('s.n', 'NN'), ('.', '.')]

 (S (NP s.l./NN) ,/, (NP s.n/NN) ./.) 


>> Noun Phrases are: 
 ['s.l.', 's.n']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]

>> Lemmatization: 
 [('s.l.', 's.l.'), (',', ','), ('s.n', 's.n'), ('.', '.')]



============================ Sentence 978 =============================

Waller, M.A. 


>> Tokens are: 
 ['Waller', ',', 'M.A', '.']

>> Bigrams are: 
 [('Waller', ','), (',', 'M.A'), ('M.A', '.')]

>> Trigrams are: 
 [('Waller', ',', 'M.A'), (',', 'M.A', '.')]

>> POS Tags are: 
 [('Waller', 'NNP'), (',', ','), ('M.A', 'NNP'), ('.', '.')]

 (S (NP Waller/NNP) ,/, (NP M.A/NNP) ./.) 


>> Noun Phrases are: 
 ['Waller', 'M.A']

>> Named Entities are: 
 [('GPE', 'Waller')] 

>> Stemming using Porter Stemmer: 
 [('Waller', 'waller'), (',', ','), ('M.A', 'm.a'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Waller', 'waller'), (',', ','), ('M.A', 'm.a'), ('.', '.')]

>> Lemmatization: 
 [('Waller', 'Waller'), (',', ','), ('M.A', 'M.A'), ('.', '.')]



============================ Sentence 979 =============================

and Fawcett, S.E., 2013. 


>> Tokens are: 
 ['Fawcett', ',', 'S.E.', ',', '2013', '.']

>> Bigrams are: 
 [('Fawcett', ','), (',', 'S.E.'), ('S.E.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Fawcett', ',', 'S.E.'), (',', 'S.E.', ','), ('S.E.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Fawcett', 'NNP'), (',', ','), ('S.E.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S (NP Fawcett/NNP) ,/, (NP S.E./NNP) ,/, 2013/CD ./.) 


>> Noun Phrases are: 
 ['Fawcett', 'S.E.']

>> Named Entities are: 
 [('GPE', 'Fawcett')] 

>> Stemming using Porter Stemmer: 
 [('Fawcett', 'fawcett'), (',', ','), ('S.E.', 's.e.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Fawcett', 'fawcett'), (',', ','), ('S.E.', 's.e.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Fawcett', 'Fawcett'), (',', ','), ('S.E.', 'S.E.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 980 =============================

Data science, predictive analytics, and big data: a revolution   that will transform supply chain design and management.. Journal of Business Logistics, Volume   34, pp. 


>> Tokens are: 
 ['Data', 'science', ',', 'predictive', 'analytics', ',', 'big', 'data', ':', 'revolution', 'transform', 'supply', 'chain', 'design', 'management', '..', 'Journal', 'Business', 'Logistics', ',', 'Volume', '34', ',', 'pp', '.']

>> Bigrams are: 
 [('Data', 'science'), ('science', ','), (',', 'predictive'), ('predictive', 'analytics'), ('analytics', ','), (',', 'big'), ('big', 'data'), ('data', ':'), (':', 'revolution'), ('revolution', 'transform'), ('transform', 'supply'), ('supply', 'chain'), ('chain', 'design'), ('design', 'management'), ('management', '..'), ('..', 'Journal'), ('Journal', 'Business'), ('Business', 'Logistics'), ('Logistics', ','), (',', 'Volume'), ('Volume', '34'), ('34', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Data', 'science', ','), ('science', ',', 'predictive'), (',', 'predictive', 'analytics'), ('predictive', 'analytics', ','), ('analytics', ',', 'big'), (',', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'revolution'), (':', 'revolution', 'transform'), ('revolution', 'transform', 'supply'), ('transform', 'supply', 'chain'), ('supply', 'chain', 'design'), ('chain', 'design', 'management'), ('design', 'management', '..'), ('management', '..', 'Journal'), ('..', 'Journal', 'Business'), ('Journal', 'Business', 'Logistics'), ('Business', 'Logistics', ','), ('Logistics', ',', 'Volume'), (',', 'Volume', '34'), ('Volume', '34', ','), ('34', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Data', 'NNP'), ('science', 'NN'), (',', ','), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('revolution', 'NN'), ('transform', 'NN'), ('supply', 'NN'), ('chain', 'NN'), ('design', 'NN'), ('management', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Business', 'NNP'), ('Logistics', 'NNP'), (',', ','), ('Volume', 'NN'), ('34', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Data/NNP science/NN)
  ,/,
  (NP predictive/JJ analytics/NNS)
  ,/,
  (NP big/JJ data/NNS)
  :/:
  (NP
    revolution/NN
    transform/NN
    supply/NN
    chain/NN
    design/NN
    management/NN
    ../NNP
    Journal/NNP
    Business/NNP
    Logistics/NNP)
  ,/,
  (NP Volume/NN)
  34/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Data science', 'predictive analytics', 'big data', 'revolution transform supply chain design management .. Journal Business Logistics', 'Volume', 'pp']

>> Named Entities are: 
 [('GPE', 'Data'), ('ORGANIZATION', 'Volume 34')] 

>> Stemming using Porter Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolut'), ('transform', 'transform'), ('supply', 'suppli'), ('chain', 'chain'), ('design', 'design'), ('management', 'manag'), ('..', '..'), ('Journal', 'journal'), ('Business', 'busi'), ('Logistics', 'logist'), (',', ','), ('Volume', 'volum'), ('34', '34'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Data', 'data'), ('science', 'scienc'), (',', ','), ('predictive', 'predict'), ('analytics', 'analyt'), (',', ','), ('big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolut'), ('transform', 'transform'), ('supply', 'suppli'), ('chain', 'chain'), ('design', 'design'), ('management', 'manag'), ('..', '..'), ('Journal', 'journal'), ('Business', 'busi'), ('Logistics', 'logist'), (',', ','), ('Volume', 'volum'), ('34', '34'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Data', 'Data'), ('science', 'science'), (',', ','), ('predictive', 'predictive'), ('analytics', 'analytics'), (',', ','), ('big', 'big'), ('data', 'data'), (':', ':'), ('revolution', 'revolution'), ('transform', 'transform'), ('supply', 'supply'), ('chain', 'chain'), ('design', 'design'), ('management', 'management'), ('..', '..'), ('Journal', 'Journal'), ('Business', 'Business'), ('Logistics', 'Logistics'), (',', ','), ('Volume', 'Volume'), ('34', '34'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 981 =============================

77-84. 


>> Tokens are: 
 ['77-84', '.']

>> Bigrams are: 
 [('77-84', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('77-84', 'JJ'), ('.', '.')]

 (S 77-84/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('77-84', '77-84'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('77-84', '77-84'), ('.', '.')]

>> Lemmatization: 
 [('77-84', '77-84'), ('.', '.')]



============================ Sentence 982 =============================

Wamba, S.F., Gunasekaran, A., Akter, S., Ren, S.J.F., Dubey, R. and Childe, S.J., 2017. 


>> Tokens are: 
 ['Wamba', ',', 'S.F.', ',', 'Gunasekaran', ',', 'A.', ',', 'Akter', ',', 'S.', ',', 'Ren', ',', 'S.J.F.', ',', 'Dubey', ',', 'R.', 'Childe', ',', 'S.J.', ',', '2017', '.']

>> Bigrams are: 
 [('Wamba', ','), (',', 'S.F.'), ('S.F.', ','), (',', 'Gunasekaran'), ('Gunasekaran', ','), (',', 'A.'), ('A.', ','), (',', 'Akter'), ('Akter', ','), (',', 'S.'), ('S.', ','), (',', 'Ren'), ('Ren', ','), (',', 'S.J.F.'), ('S.J.F.', ','), (',', 'Dubey'), ('Dubey', ','), (',', 'R.'), ('R.', 'Childe'), ('Childe', ','), (',', 'S.J.'), ('S.J.', ','), (',', '2017'), ('2017', '.')]

>> Trigrams are: 
 [('Wamba', ',', 'S.F.'), (',', 'S.F.', ','), ('S.F.', ',', 'Gunasekaran'), (',', 'Gunasekaran', ','), ('Gunasekaran', ',', 'A.'), (',', 'A.', ','), ('A.', ',', 'Akter'), (',', 'Akter', ','), ('Akter', ',', 'S.'), (',', 'S.', ','), ('S.', ',', 'Ren'), (',', 'Ren', ','), ('Ren', ',', 'S.J.F.'), (',', 'S.J.F.', ','), ('S.J.F.', ',', 'Dubey'), (',', 'Dubey', ','), ('Dubey', ',', 'R.'), (',', 'R.', 'Childe'), ('R.', 'Childe', ','), ('Childe', ',', 'S.J.'), (',', 'S.J.', ','), ('S.J.', ',', '2017'), (',', '2017', '.')]

>> POS Tags are: 
 [('Wamba', 'NNP'), (',', ','), ('S.F.', 'NNP'), (',', ','), ('Gunasekaran', 'NNP'), (',', ','), ('A.', 'NNP'), (',', ','), ('Akter', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('Ren', 'NNP'), (',', ','), ('S.J.F.', 'NNP'), (',', ','), ('Dubey', 'NNP'), (',', ','), ('R.', 'NNP'), ('Childe', 'NNP'), (',', ','), ('S.J.', 'NNP'), (',', ','), ('2017', 'CD'), ('.', '.')]

 (S
  (NP Wamba/NNP)
  ,/,
  (NP S.F./NNP)
  ,/,
  (NP Gunasekaran/NNP)
  ,/,
  (NP A./NNP)
  ,/,
  (NP Akter/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  (NP Ren/NNP)
  ,/,
  (NP S.J.F./NNP)
  ,/,
  (NP Dubey/NNP)
  ,/,
  (NP R./NNP Childe/NNP)
  ,/,
  (NP S.J./NNP)
  ,/,
  2017/CD
  ./.) 


>> Noun Phrases are: 
 ['Wamba', 'S.F.', 'Gunasekaran', 'A.', 'Akter', 'S.', 'Ren', 'S.J.F.', 'Dubey', 'R. Childe', 'S.J.']

>> Named Entities are: 
 [('GPE', 'Wamba'), ('GPE', 'Gunasekaran'), ('PERSON', 'Akter'), ('PERSON', 'Ren'), ('PERSON', 'Dubey')] 

>> Stemming using Porter Stemmer: 
 [('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Ren', 'ren'), (',', ','), ('S.J.F.', 's.j.f.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wamba', 'wamba'), (',', ','), ('S.F.', 's.f.'), (',', ','), ('Gunasekaran', 'gunasekaran'), (',', ','), ('A.', 'a.'), (',', ','), ('Akter', 'akter'), (',', ','), ('S.', 's.'), (',', ','), ('Ren', 'ren'), (',', ','), ('S.J.F.', 's.j.f.'), (',', ','), ('Dubey', 'dubey'), (',', ','), ('R.', 'r.'), ('Childe', 'child'), (',', ','), ('S.J.', 's.j.'), (',', ','), ('2017', '2017'), ('.', '.')]

>> Lemmatization: 
 [('Wamba', 'Wamba'), (',', ','), ('S.F.', 'S.F.'), (',', ','), ('Gunasekaran', 'Gunasekaran'), (',', ','), ('A.', 'A.'), (',', ','), ('Akter', 'Akter'), (',', ','), ('S.', 'S.'), (',', ','), ('Ren', 'Ren'), (',', ','), ('S.J.F.', 'S.J.F.'), (',', ','), ('Dubey', 'Dubey'), (',', ','), ('R.', 'R.'), ('Childe', 'Childe'), (',', ','), ('S.J.', 'S.J.'), (',', ','), ('2017', '2017'), ('.', '.')]



============================ Sentence 983 =============================

Big data   analytics and firm performance: Effects of dynamic capabilities. 


>> Tokens are: 
 ['Big', 'data', 'analytics', 'firm', 'performance', ':', 'Effects', 'dynamic', 'capabilities', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', 'analytics'), ('analytics', 'firm'), ('firm', 'performance'), ('performance', ':'), (':', 'Effects'), ('Effects', 'dynamic'), ('dynamic', 'capabilities'), ('capabilities', '.')]

>> Trigrams are: 
 [('Big', 'data', 'analytics'), ('data', 'analytics', 'firm'), ('analytics', 'firm', 'performance'), ('firm', 'performance', ':'), ('performance', ':', 'Effects'), (':', 'Effects', 'dynamic'), ('Effects', 'dynamic', 'capabilities'), ('dynamic', 'capabilities', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), ('firm', 'JJ'), ('performance', 'NN'), (':', ':'), ('Effects', 'NNS'), ('dynamic', 'JJ'), ('capabilities', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP data/NNS analytics/NNS)
  (NP firm/JJ performance/NN)
  :/:
  (NP Effects/NNS)
  (NP dynamic/JJ capabilities/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big data analytics', 'firm performance', 'Effects', 'dynamic capabilities']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('firm', 'firm'), ('performance', 'perform'), (':', ':'), ('Effects', 'effect'), ('dynamic', 'dynam'), ('capabilities', 'capabl'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), ('firm', 'firm'), ('performance', 'perform'), (':', ':'), ('Effects', 'effect'), ('dynamic', 'dynam'), ('capabilities', 'capabl'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), ('firm', 'firm'), ('performance', 'performance'), (':', ':'), ('Effects', 'Effects'), ('dynamic', 'dynamic'), ('capabilities', 'capability'), ('.', '.')]



============================ Sentence 984 =============================

Journal of Business Research,   pp. 


>> Tokens are: 
 ['Journal', 'Business', 'Research', ',', 'pp', '.']

>> Bigrams are: 
 [('Journal', 'Business'), ('Business', 'Research'), ('Research', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Journal', 'Business', 'Research'), ('Business', 'Research', ','), ('Research', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Journal', 'NNP'), ('Business', 'NNP'), ('Research', 'NNP'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP Journal/NNP Business/NNP Research/NNP) ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['Journal Business Research', 'pp']

>> Named Entities are: 
 [('PERSON', 'Journal'), ('ORGANIZATION', 'Business Research')] 

>> Stemming using Porter Stemmer: 
 [('Journal', 'journal'), ('Business', 'busi'), ('Research', 'research'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Journal', 'journal'), ('Business', 'busi'), ('Research', 'research'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Journal', 'Journal'), ('Business', 'Business'), ('Research', 'Research'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 985 =============================

356-365. 


>> Tokens are: 
 ['356-365', '.']

>> Bigrams are: 
 [('356-365', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('356-365', 'JJ'), ('.', '.')]

 (S 356-365/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('356-365', '356-365'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('356-365', '356-365'), ('.', '.')]

>> Lemmatization: 
 [('356-365', '356-365'), ('.', '.')]



============================ Sentence 986 =============================

Wang, H., Xu, Z., Fujita, H. and Liu, S., 2016. 


>> Tokens are: 
 ['Wang', ',', 'H.', ',', 'Xu', ',', 'Z.', ',', 'Fujita', ',', 'H.', 'Liu', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Wang', ','), (',', 'H.'), ('H.', ','), (',', 'Xu'), ('Xu', ','), (',', 'Z.'), ('Z.', ','), (',', 'Fujita'), ('Fujita', ','), (',', 'H.'), ('H.', 'Liu'), ('Liu', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Wang', ',', 'H.'), (',', 'H.', ','), ('H.', ',', 'Xu'), (',', 'Xu', ','), ('Xu', ',', 'Z.'), (',', 'Z.', ','), ('Z.', ',', 'Fujita'), (',', 'Fujita', ','), ('Fujita', ',', 'H.'), (',', 'H.', 'Liu'), ('H.', 'Liu', ','), ('Liu', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Wang', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('Xu', 'NNP'), (',', ','), ('Z.', 'NNP'), (',', ','), ('Fujita', 'NNP'), (',', ','), ('H.', 'NNP'), ('Liu', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S
  (NP Wang/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  (NP Xu/NNP)
  ,/,
  (NP Z./NNP)
  ,/,
  (NP Fujita/NNP)
  ,/,
  (NP H./NNP Liu/NNP)
  ,/,
  (NP S./NNP)
  ,/,
  2016/CD
  ./.) 


>> Noun Phrases are: 
 ['Wang', 'H.', 'Xu', 'Z.', 'Fujita', 'H. Liu', 'S.']

>> Named Entities are: 
 [('PERSON', 'Wang'), ('GPE', 'Xu'), ('GPE', 'Fujita')] 

>> Stemming using Porter Stemmer: 
 [('Wang', 'wang'), (',', ','), ('H.', 'h.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('Fujita', 'fujita'), (',', ','), ('H.', 'h.'), ('Liu', 'liu'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wang', 'wang'), (',', ','), ('H.', 'h.'), (',', ','), ('Xu', 'xu'), (',', ','), ('Z.', 'z.'), (',', ','), ('Fujita', 'fujita'), (',', ','), ('H.', 'h.'), ('Liu', 'liu'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Wang', 'Wang'), (',', ','), ('H.', 'H.'), (',', ','), ('Xu', 'Xu'), (',', ','), ('Z.', 'Z.'), (',', ','), ('Fujita', 'Fujita'), (',', ','), ('H.', 'H.'), ('Liu', 'Liu'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 987 =============================

Towards felicitous decision making: An overview   on challenges and trends of Big Data.. Information Sciences journal, Volume 367, pp. 


>> Tokens are: 
 ['Towards', 'felicitous', 'decision', 'making', ':', 'An', 'overview', 'challenges', 'trends', 'Big', 'Data', '..', 'Information', 'Sciences', 'journal', ',', 'Volume', '367', ',', 'pp', '.']

>> Bigrams are: 
 [('Towards', 'felicitous'), ('felicitous', 'decision'), ('decision', 'making'), ('making', ':'), (':', 'An'), ('An', 'overview'), ('overview', 'challenges'), ('challenges', 'trends'), ('trends', 'Big'), ('Big', 'Data'), ('Data', '..'), ('..', 'Information'), ('Information', 'Sciences'), ('Sciences', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '367'), ('367', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Towards', 'felicitous', 'decision'), ('felicitous', 'decision', 'making'), ('decision', 'making', ':'), ('making', ':', 'An'), (':', 'An', 'overview'), ('An', 'overview', 'challenges'), ('overview', 'challenges', 'trends'), ('challenges', 'trends', 'Big'), ('trends', 'Big', 'Data'), ('Big', 'Data', '..'), ('Data', '..', 'Information'), ('..', 'Information', 'Sciences'), ('Information', 'Sciences', 'journal'), ('Sciences', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '367'), ('Volume', '367', ','), ('367', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Towards', 'NNS'), ('felicitous', 'JJ'), ('decision', 'NN'), ('making', 'NN'), (':', ':'), ('An', 'DT'), ('overview', 'NN'), ('challenges', 'VBZ'), ('trends', 'NNS'), ('Big', 'NNP'), ('Data', 'NNP'), ('..', 'NNP'), ('Information', 'NNP'), ('Sciences', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('367', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Towards/NNS)
  (NP felicitous/JJ decision/NN making/NN)
  :/:
  (NP An/DT overview/NN)
  challenges/VBZ
  (NP
    trends/NNS
    Big/NNP
    Data/NNP
    ../NNP
    Information/NNP
    Sciences/NNP
    journal/NN)
  ,/,
  (NP Volume/NN)
  367/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Towards', 'felicitous decision making', 'An overview', 'trends Big Data .. Information Sciences journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 367')] 

>> Stemming using Porter Stemmer: 
 [('Towards', 'toward'), ('felicitous', 'felicit'), ('decision', 'decis'), ('making', 'make'), (':', ':'), ('An', 'an'), ('overview', 'overview'), ('challenges', 'challeng'), ('trends', 'trend'), ('Big', 'big'), ('Data', 'data'), ('..', '..'), ('Information', 'inform'), ('Sciences', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('367', '367'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Towards', 'toward'), ('felicitous', 'felicit'), ('decision', 'decis'), ('making', 'make'), (':', ':'), ('An', 'an'), ('overview', 'overview'), ('challenges', 'challeng'), ('trends', 'trend'), ('Big', 'big'), ('Data', 'data'), ('..', '..'), ('Information', 'inform'), ('Sciences', 'scienc'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('367', '367'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Towards', 'Towards'), ('felicitous', 'felicitous'), ('decision', 'decision'), ('making', 'making'), (':', ':'), ('An', 'An'), ('overview', 'overview'), ('challenges', 'challenge'), ('trends', 'trend'), ('Big', 'Big'), ('Data', 'Data'), ('..', '..'), ('Information', 'Information'), ('Sciences', 'Sciences'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('367', '367'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 988 =============================

747-765. 


>> Tokens are: 
 ['747-765', '.']

>> Bigrams are: 
 [('747-765', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('747-765', 'JJ'), ('.', '.')]

 (S 747-765/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('747-765', '747-765'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('747-765', '747-765'), ('.', '.')]

>> Lemmatization: 
 [('747-765', '747-765'), ('.', '.')]



============================ Sentence 989 =============================

Watson, H., 2014. 


>> Tokens are: 
 ['Watson', ',', 'H.', ',', '2014', '.']

>> Bigrams are: 
 [('Watson', ','), (',', 'H.'), ('H.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Watson', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Watson', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S (NP Watson/NNP) ,/, (NP H./NNP) ,/, 2014/CD ./.) 


>> Noun Phrases are: 
 ['Watson', 'H.']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Watson', 'Watson'), (',', ','), ('H.', 'H.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 990 =============================

Tutorial: Big data analytics: Concepts, technologies, and applications..   Communications of the Association for Information Systems CAIS, Volume 34, p. p.65. 


>> Tokens are: 
 ['Tutorial', ':', 'Big', 'data', 'analytics', ':', 'Concepts', ',', 'technologies', ',', 'applications', '..', 'Communications', 'Association', 'Information', 'Systems', 'CAIS', ',', 'Volume', '34', ',', 'p.', 'p.65', '.']

>> Bigrams are: 
 [('Tutorial', ':'), (':', 'Big'), ('Big', 'data'), ('data', 'analytics'), ('analytics', ':'), (':', 'Concepts'), ('Concepts', ','), (',', 'technologies'), ('technologies', ','), (',', 'applications'), ('applications', '..'), ('..', 'Communications'), ('Communications', 'Association'), ('Association', 'Information'), ('Information', 'Systems'), ('Systems', 'CAIS'), ('CAIS', ','), (',', 'Volume'), ('Volume', '34'), ('34', ','), (',', 'p.'), ('p.', 'p.65'), ('p.65', '.')]

>> Trigrams are: 
 [('Tutorial', ':', 'Big'), (':', 'Big', 'data'), ('Big', 'data', 'analytics'), ('data', 'analytics', ':'), ('analytics', ':', 'Concepts'), (':', 'Concepts', ','), ('Concepts', ',', 'technologies'), (',', 'technologies', ','), ('technologies', ',', 'applications'), (',', 'applications', '..'), ('applications', '..', 'Communications'), ('..', 'Communications', 'Association'), ('Communications', 'Association', 'Information'), ('Association', 'Information', 'Systems'), ('Information', 'Systems', 'CAIS'), ('Systems', 'CAIS', ','), ('CAIS', ',', 'Volume'), (',', 'Volume', '34'), ('Volume', '34', ','), ('34', ',', 'p.'), (',', 'p.', 'p.65'), ('p.', 'p.65', '.')]

>> POS Tags are: 
 [('Tutorial', 'NN'), (':', ':'), ('Big', 'NNP'), ('data', 'NNS'), ('analytics', 'NNS'), (':', ':'), ('Concepts', 'NNP'), (',', ','), ('technologies', 'NNS'), (',', ','), ('applications', 'NNS'), ('..', 'VBP'), ('Communications', 'NNP'), ('Association', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), ('CAIS', 'NNP'), (',', ','), ('Volume', 'NN'), ('34', 'CD'), (',', ','), ('p.', 'NN'), ('p.65', 'NN'), ('.', '.')]

 (S
  (NP Tutorial/NN)
  :/:
  (NP Big/NNP data/NNS analytics/NNS)
  :/:
  (NP Concepts/NNP)
  ,/,
  (NP technologies/NNS)
  ,/,
  (NP applications/NNS)
  ../VBP
  (NP
    Communications/NNP
    Association/NNP
    Information/NNP
    Systems/NNP
    CAIS/NNP)
  ,/,
  (NP Volume/NN)
  34/CD
  ,/,
  (NP p./NN p.65/NN)
  ./.) 


>> Noun Phrases are: 
 ['Tutorial', 'Big data analytics', 'Concepts', 'technologies', 'applications', 'Communications Association Information Systems CAIS', 'Volume', 'p. p.65']

>> Named Entities are: 
 [('GPE', 'Tutorial'), ('ORGANIZATION', 'Communications Association Information Systems'), ('ORGANIZATION', 'Volume 34')] 

>> Stemming using Porter Stemmer: 
 [('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), ('..', '..'), ('Communications', 'commun'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), ('CAIS', 'cai'), (',', ','), ('Volume', 'volum'), ('34', '34'), (',', ','), ('p.', 'p.'), ('p.65', 'p.65'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('data', 'data'), ('analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('technologies', 'technolog'), (',', ','), ('applications', 'applic'), ('..', '..'), ('Communications', 'communic'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), ('CAIS', 'cai'), (',', ','), ('Volume', 'volum'), ('34', '34'), (',', ','), ('p.', 'p.'), ('p.65', 'p.65'), ('.', '.')]

>> Lemmatization: 
 [('Tutorial', 'Tutorial'), (':', ':'), ('Big', 'Big'), ('data', 'data'), ('analytics', 'analytics'), (':', ':'), ('Concepts', 'Concepts'), (',', ','), ('technologies', 'technology'), (',', ','), ('applications', 'application'), ('..', '..'), ('Communications', 'Communications'), ('Association', 'Association'), ('Information', 'Information'), ('Systems', 'Systems'), ('CAIS', 'CAIS'), (',', ','), ('Volume', 'Volume'), ('34', '34'), (',', ','), ('p.', 'p.'), ('p.65', 'p.65'), ('.', '.')]



============================ Sentence 991 =============================

Watson, H., 2019. 


>> Tokens are: 
 ['Watson', ',', 'H.', ',', '2019', '.']

>> Bigrams are: 
 [('Watson', ','), (',', 'H.'), ('H.', ','), (',', '2019'), ('2019', '.')]

>> Trigrams are: 
 [('Watson', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2019'), (',', '2019', '.')]

>> POS Tags are: 
 [('Watson', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2019', 'CD'), ('.', '.')]

 (S (NP Watson/NNP) ,/, (NP H./NNP) ,/, 2019/CD ./.) 


>> Noun Phrases are: 
 ['Watson', 'H.']

>> Named Entities are: 
 [('GPE', 'Watson')] 

>> Stemming using Porter Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Watson', 'watson'), (',', ','), ('H.', 'h.'), (',', ','), ('2019', '2019'), ('.', '.')]

>> Lemmatization: 
 [('Watson', 'Watson'), (',', ','), ('H.', 'H.'), (',', ','), ('2019', '2019'), ('.', '.')]



============================ Sentence 992 =============================

Update Tutorial: Big Data Analytics: Concepts, Technology, and Applications..   Communications of the Association for Information Systems, Volume 44, p. 21. 


>> Tokens are: 
 ['Update', 'Tutorial', ':', 'Big', 'Data', 'Analytics', ':', 'Concepts', ',', 'Technology', ',', 'Applications', '..', 'Communications', 'Association', 'Information', 'Systems', ',', 'Volume', '44', ',', 'p.', '21', '.']

>> Bigrams are: 
 [('Update', 'Tutorial'), ('Tutorial', ':'), (':', 'Big'), ('Big', 'Data'), ('Data', 'Analytics'), ('Analytics', ':'), (':', 'Concepts'), ('Concepts', ','), (',', 'Technology'), ('Technology', ','), (',', 'Applications'), ('Applications', '..'), ('..', 'Communications'), ('Communications', 'Association'), ('Association', 'Information'), ('Information', 'Systems'), ('Systems', ','), (',', 'Volume'), ('Volume', '44'), ('44', ','), (',', 'p.'), ('p.', '21'), ('21', '.')]

>> Trigrams are: 
 [('Update', 'Tutorial', ':'), ('Tutorial', ':', 'Big'), (':', 'Big', 'Data'), ('Big', 'Data', 'Analytics'), ('Data', 'Analytics', ':'), ('Analytics', ':', 'Concepts'), (':', 'Concepts', ','), ('Concepts', ',', 'Technology'), (',', 'Technology', ','), ('Technology', ',', 'Applications'), (',', 'Applications', '..'), ('Applications', '..', 'Communications'), ('..', 'Communications', 'Association'), ('Communications', 'Association', 'Information'), ('Association', 'Information', 'Systems'), ('Information', 'Systems', ','), ('Systems', ',', 'Volume'), (',', 'Volume', '44'), ('Volume', '44', ','), ('44', ',', 'p.'), (',', 'p.', '21'), ('p.', '21', '.')]

>> POS Tags are: 
 [('Update', 'JJ'), ('Tutorial', 'NNP'), (':', ':'), ('Big', 'NNP'), ('Data', 'NNP'), ('Analytics', 'NNS'), (':', ':'), ('Concepts', 'NNP'), (',', ','), ('Technology', 'NNP'), (',', ','), ('Applications', 'NNP'), ('..', 'NNP'), ('Communications', 'NNP'), ('Association', 'NNP'), ('Information', 'NNP'), ('Systems', 'NNP'), (',', ','), ('Volume', 'NN'), ('44', 'CD'), (',', ','), ('p.', 'RB'), ('21', 'CD'), ('.', '.')]

 (S
  (NP Update/JJ Tutorial/NNP)
  :/:
  (NP Big/NNP Data/NNP Analytics/NNS)
  :/:
  (NP Concepts/NNP)
  ,/,
  (NP Technology/NNP)
  ,/,
  (NP
    Applications/NNP
    ../NNP
    Communications/NNP
    Association/NNP
    Information/NNP
    Systems/NNP)
  ,/,
  (NP Volume/NN)
  44/CD
  ,/,
  p./RB
  21/CD
  ./.) 


>> Noun Phrases are: 
 ['Update Tutorial', 'Big Data Analytics', 'Concepts', 'Technology', 'Applications .. Communications Association Information Systems', 'Volume']

>> Named Entities are: 
 [('GPE', 'Technology'), ('PERSON', 'Applications'), ('ORGANIZATION', 'Volume 44')] 

>> Stemming using Porter Stemmer: 
 [('Update', 'updat'), ('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('Technology', 'technolog'), (',', ','), ('Applications', 'applic'), ('..', '..'), ('Communications', 'commun'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('44', '44'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Update', 'updat'), ('Tutorial', 'tutori'), (':', ':'), ('Big', 'big'), ('Data', 'data'), ('Analytics', 'analyt'), (':', ':'), ('Concepts', 'concept'), (',', ','), ('Technology', 'technolog'), (',', ','), ('Applications', 'applic'), ('..', '..'), ('Communications', 'communic'), ('Association', 'associ'), ('Information', 'inform'), ('Systems', 'system'), (',', ','), ('Volume', 'volum'), ('44', '44'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]

>> Lemmatization: 
 [('Update', 'Update'), ('Tutorial', 'Tutorial'), (':', ':'), ('Big', 'Big'), ('Data', 'Data'), ('Analytics', 'Analytics'), (':', ':'), ('Concepts', 'Concepts'), (',', ','), ('Technology', 'Technology'), (',', ','), ('Applications', 'Applications'), ('..', '..'), ('Communications', 'Communications'), ('Association', 'Association'), ('Information', 'Information'), ('Systems', 'Systems'), (',', ','), ('Volume', 'Volume'), ('44', '44'), (',', ','), ('p.', 'p.'), ('21', '21'), ('.', '.')]



============================ Sentence 993 =============================

Webster, J. and Watson, R.T., 2002. 


>> Tokens are: 
 ['Webster', ',', 'J.', 'Watson', ',', 'R.T.', ',', '2002', '.']

>> Bigrams are: 
 [('Webster', ','), (',', 'J.'), ('J.', 'Watson'), ('Watson', ','), (',', 'R.T.'), ('R.T.', ','), (',', '2002'), ('2002', '.')]

>> Trigrams are: 
 [('Webster', ',', 'J.'), (',', 'J.', 'Watson'), ('J.', 'Watson', ','), ('Watson', ',', 'R.T.'), (',', 'R.T.', ','), ('R.T.', ',', '2002'), (',', '2002', '.')]

>> POS Tags are: 
 [('Webster', 'NNP'), (',', ','), ('J.', 'NNP'), ('Watson', 'NNP'), (',', ','), ('R.T.', 'NNP'), (',', ','), ('2002', 'CD'), ('.', '.')]

 (S
  (NP Webster/NNP)
  ,/,
  (NP J./NNP Watson/NNP)
  ,/,
  (NP R.T./NNP)
  ,/,
  2002/CD
  ./.) 


>> Noun Phrases are: 
 ['Webster', 'J. Watson', 'R.T.']

>> Named Entities are: 
 [('PERSON', 'J. Watson')] 

>> Stemming using Porter Stemmer: 
 [('Webster', 'webster'), (',', ','), ('J.', 'j.'), ('Watson', 'watson'), (',', ','), ('R.T.', 'r.t.'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Webster', 'webster'), (',', ','), ('J.', 'j.'), ('Watson', 'watson'), (',', ','), ('R.T.', 'r.t.'), (',', ','), ('2002', '2002'), ('.', '.')]

>> Lemmatization: 
 [('Webster', 'Webster'), (',', ','), ('J.', 'J.'), ('Watson', 'Watson'), (',', ','), ('R.T.', 'R.T.'), (',', ','), ('2002', '2002'), ('.', '.')]



============================ Sentence 994 =============================

Analyzing the past to prepare for the future: Writing a   literature review. 


>> Tokens are: 
 ['Analyzing', 'past', 'prepare', 'future', ':', 'Writing', 'literature', 'review', '.']

>> Bigrams are: 
 [('Analyzing', 'past'), ('past', 'prepare'), ('prepare', 'future'), ('future', ':'), (':', 'Writing'), ('Writing', 'literature'), ('literature', 'review'), ('review', '.')]

>> Trigrams are: 
 [('Analyzing', 'past', 'prepare'), ('past', 'prepare', 'future'), ('prepare', 'future', ':'), ('future', ':', 'Writing'), (':', 'Writing', 'literature'), ('Writing', 'literature', 'review'), ('literature', 'review', '.')]

>> POS Tags are: 
 [('Analyzing', 'VBG'), ('past', 'JJ'), ('prepare', 'JJ'), ('future', 'NN'), (':', ':'), ('Writing', 'JJ'), ('literature', 'NN'), ('review', 'NN'), ('.', '.')]

 (S
  Analyzing/VBG
  (NP past/JJ prepare/JJ future/NN)
  :/:
  (NP Writing/JJ literature/NN review/NN)
  ./.) 


>> Noun Phrases are: 
 ['past prepare future', 'Writing literature review']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Analyzing', 'analyz'), ('past', 'past'), ('prepare', 'prepar'), ('future', 'futur'), (':', ':'), ('Writing', 'write'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Analyzing', 'analyz'), ('past', 'past'), ('prepare', 'prepar'), ('future', 'futur'), (':', ':'), ('Writing', 'write'), ('literature', 'literatur'), ('review', 'review'), ('.', '.')]

>> Lemmatization: 
 [('Analyzing', 'Analyzing'), ('past', 'past'), ('prepare', 'prepare'), ('future', 'future'), (':', ':'), ('Writing', 'Writing'), ('literature', 'literature'), ('review', 'review'), ('.', '.')]



============================ Sentence 995 =============================

MIS quarterly, pp. 


>> Tokens are: 
 ['MIS', 'quarterly', ',', 'pp', '.']

>> Bigrams are: 
 [('MIS', 'quarterly'), ('quarterly', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('MIS', 'quarterly', ','), ('quarterly', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('MIS', 'NNP'), ('quarterly', 'RB'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S (NP MIS/NNP) quarterly/RB ,/, (NP pp/NN) ./.) 


>> Noun Phrases are: 
 ['MIS', 'pp']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('MIS', 'mi'), ('quarterly', 'quarterli'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIS', 'mis'), ('quarterly', 'quarter'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('MIS', 'MIS'), ('quarterly', 'quarterly'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 996 =============================

xiii-xxiii. 


>> Tokens are: 
 ['xiii-xxiii', '.']

>> Bigrams are: 
 [('xiii-xxiii', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('xiii-xxiii', 'NN'), ('.', '.')]

 (S (NP xiii-xxiii/NN) ./.) 


>> Noun Phrases are: 
 ['xiii-xxiii']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('xiii-xxiii', 'xiii-xxiii'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('xiii-xxiii', 'xiii-xxiii'), ('.', '.')]

>> Lemmatization: 
 [('xiii-xxiii', 'xiii-xxiii'), ('.', '.')]



============================ Sentence 997 =============================

Wixom, B.H., Yen, B. and Relich, M., 2013. 


>> Tokens are: 
 ['Wixom', ',', 'B.H.', ',', 'Yen', ',', 'B.', 'Relich', ',', 'M.', ',', '2013', '.']

>> Bigrams are: 
 [('Wixom', ','), (',', 'B.H.'), ('B.H.', ','), (',', 'Yen'), ('Yen', ','), (',', 'B.'), ('B.', 'Relich'), ('Relich', ','), (',', 'M.'), ('M.', ','), (',', '2013'), ('2013', '.')]

>> Trigrams are: 
 [('Wixom', ',', 'B.H.'), (',', 'B.H.', ','), ('B.H.', ',', 'Yen'), (',', 'Yen', ','), ('Yen', ',', 'B.'), (',', 'B.', 'Relich'), ('B.', 'Relich', ','), ('Relich', ',', 'M.'), (',', 'M.', ','), ('M.', ',', '2013'), (',', '2013', '.')]

>> POS Tags are: 
 [('Wixom', 'NNP'), (',', ','), ('B.H.', 'NNP'), (',', ','), ('Yen', 'NNP'), (',', ','), ('B.', 'NNP'), ('Relich', 'NNP'), (',', ','), ('M.', 'NNP'), (',', ','), ('2013', 'CD'), ('.', '.')]

 (S
  (NP Wixom/NNP)
  ,/,
  (NP B.H./NNP)
  ,/,
  (NP Yen/NNP)
  ,/,
  (NP B./NNP Relich/NNP)
  ,/,
  (NP M./NNP)
  ,/,
  2013/CD
  ./.) 


>> Noun Phrases are: 
 ['Wixom', 'B.H.', 'Yen', 'B. Relich', 'M.']

>> Named Entities are: 
 [('GPE', 'Wixom'), ('PERSON', 'Yen'), ('PERSON', 'Relich')] 

>> Stemming using Porter Stemmer: 
 [('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('Yen', 'yen'), (',', ','), ('B.', 'b.'), ('Relich', 'relich'), (',', ','), ('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('Yen', 'yen'), (',', ','), ('B.', 'b.'), ('Relich', 'relich'), (',', ','), ('M.', 'm.'), (',', ','), ('2013', '2013'), ('.', '.')]

>> Lemmatization: 
 [('Wixom', 'Wixom'), (',', ','), ('B.H.', 'B.H.'), (',', ','), ('Yen', 'Yen'), (',', ','), ('B.', 'B.'), ('Relich', 'Relich'), (',', ','), ('M.', 'M.'), (',', ','), ('2013', '2013'), ('.', '.')]



============================ Sentence 998 =============================

Maximizing Value from Business Analytics. 


>> Tokens are: 
 ['Maximizing', 'Value', 'Business', 'Analytics', '.']

>> Bigrams are: 
 [('Maximizing', 'Value'), ('Value', 'Business'), ('Business', 'Analytics'), ('Analytics', '.')]

>> Trigrams are: 
 [('Maximizing', 'Value', 'Business'), ('Value', 'Business', 'Analytics'), ('Business', 'Analytics', '.')]

>> POS Tags are: 
 [('Maximizing', 'VBG'), ('Value', 'NNP'), ('Business', 'NNP'), ('Analytics', 'NNPS'), ('.', '.')]

 (S Maximizing/VBG (NP Value/NNP Business/NNP) Analytics/NNPS ./.) 


>> Noun Phrases are: 
 ['Value Business']

>> Named Entities are: 
 [('PERSON', 'Value Business')] 

>> Stemming using Porter Stemmer: 
 [('Maximizing', 'maxim'), ('Value', 'valu'), ('Business', 'busi'), ('Analytics', 'analyt'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Maximizing', 'maxim'), ('Value', 'valu'), ('Business', 'busi'), ('Analytics', 'analyt'), ('.', '.')]

>> Lemmatization: 
 [('Maximizing', 'Maximizing'), ('Value', 'Value'), ('Business', 'Business'), ('Analytics', 'Analytics'), ('.', '.')]



============================ Sentence 999 =============================

MIS   Quarterly Executive. 


>> Tokens are: 
 ['MIS', 'Quarterly', 'Executive', '.']

>> Bigrams are: 
 [('MIS', 'Quarterly'), ('Quarterly', 'Executive'), ('Executive', '.')]

>> Trigrams are: 
 [('MIS', 'Quarterly', 'Executive'), ('Quarterly', 'Executive', '.')]

>> POS Tags are: 
 [('MIS', 'NNP'), ('Quarterly', 'NNP'), ('Executive', 'NNP'), ('.', '.')]

 (S (NP MIS/NNP Quarterly/NNP Executive/NNP) ./.) 


>> Noun Phrases are: 
 ['MIS Quarterly Executive']

>> Named Entities are: 
 [('ORGANIZATION', 'MIS'), ('PERSON', 'Quarterly Executive')] 

>> Stemming using Porter Stemmer: 
 [('MIS', 'mi'), ('Quarterly', 'quarterli'), ('Executive', 'execut'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('MIS', 'mis'), ('Quarterly', 'quarter'), ('Executive', 'execut'), ('.', '.')]

>> Lemmatization: 
 [('MIS', 'MIS'), ('Quarterly', 'Quarterly'), ('Executive', 'Executive'), ('.', '.')]



============================ Sentence 1000 =============================

Woerner, S.L., Wixom, B.H., 2015. 


>> Tokens are: 
 ['Woerner', ',', 'S.L.', ',', 'Wixom', ',', 'B.H.', ',', '2015', '.']

>> Bigrams are: 
 [('Woerner', ','), (',', 'S.L.'), ('S.L.', ','), (',', 'Wixom'), ('Wixom', ','), (',', 'B.H.'), ('B.H.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Woerner', ',', 'S.L.'), (',', 'S.L.', ','), ('S.L.', ',', 'Wixom'), (',', 'Wixom', ','), ('Wixom', ',', 'B.H.'), (',', 'B.H.', ','), ('B.H.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Woerner', 'NNP'), (',', ','), ('S.L.', 'NNP'), (',', ','), ('Wixom', 'NNP'), (',', ','), ('B.H.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S
  (NP Woerner/NNP)
  ,/,
  (NP S.L./NNP)
  ,/,
  (NP Wixom/NNP)
  ,/,
  (NP B.H./NNP)
  ,/,
  2015/CD
  ./.) 


>> Noun Phrases are: 
 ['Woerner', 'S.L.', 'Wixom', 'B.H.']

>> Named Entities are: 
 [('GPE', 'Woerner'), ('PERSON', 'Wixom')] 

>> Stemming using Porter Stemmer: 
 [('Woerner', 'woerner'), (',', ','), ('S.L.', 's.l.'), (',', ','), ('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Woerner', 'woerner'), (',', ','), ('S.L.', 's.l.'), (',', ','), ('Wixom', 'wixom'), (',', ','), ('B.H.', 'b.h.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Woerner', 'Woerner'), (',', ','), ('S.L.', 'S.L.'), (',', ','), ('Wixom', 'Wixom'), (',', ','), ('B.H.', 'B.H.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 1001 =============================

Big data: extending the business strategy toolbox.. Journal of   Information Technology, Volume 30, pp. 


>> Tokens are: 
 ['Big', 'data', ':', 'extending', 'business', 'strategy', 'toolbox', '..', 'Journal', 'Information', 'Technology', ',', 'Volume', '30', ',', 'pp', '.']

>> Bigrams are: 
 [('Big', 'data'), ('data', ':'), (':', 'extending'), ('extending', 'business'), ('business', 'strategy'), ('strategy', 'toolbox'), ('toolbox', '..'), ('..', 'Journal'), ('Journal', 'Information'), ('Information', 'Technology'), ('Technology', ','), (',', 'Volume'), ('Volume', '30'), ('30', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Big', 'data', ':'), ('data', ':', 'extending'), (':', 'extending', 'business'), ('extending', 'business', 'strategy'), ('business', 'strategy', 'toolbox'), ('strategy', 'toolbox', '..'), ('toolbox', '..', 'Journal'), ('..', 'Journal', 'Information'), ('Journal', 'Information', 'Technology'), ('Information', 'Technology', ','), ('Technology', ',', 'Volume'), (',', 'Volume', '30'), ('Volume', '30', ','), ('30', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Big', 'JJ'), ('data', 'NNS'), (':', ':'), ('extending', 'NN'), ('business', 'NN'), ('strategy', 'NN'), ('toolbox', 'NN'), ('..', 'NNP'), ('Journal', 'NNP'), ('Information', 'NNP'), ('Technology', 'NNP'), (',', ','), ('Volume', 'NN'), ('30', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Big/JJ data/NNS)
  :/:
  (NP
    extending/NN
    business/NN
    strategy/NN
    toolbox/NN
    ../NNP
    Journal/NNP
    Information/NNP
    Technology/NNP)
  ,/,
  (NP Volume/NN)
  30/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Big data', 'extending business strategy toolbox .. Journal Information Technology', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Volume 30')] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('extending', 'extend'), ('business', 'busi'), ('strategy', 'strategi'), ('toolbox', 'toolbox'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('data', 'data'), (':', ':'), ('extending', 'extend'), ('business', 'busi'), ('strategy', 'strategi'), ('toolbox', 'toolbox'), ('..', '..'), ('Journal', 'journal'), ('Information', 'inform'), ('Technology', 'technolog'), (',', ','), ('Volume', 'volum'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('data', 'data'), (':', ':'), ('extending', 'extending'), ('business', 'business'), ('strategy', 'strategy'), ('toolbox', 'toolbox'), ('..', '..'), ('Journal', 'Journal'), ('Information', 'Information'), ('Technology', 'Technology'), (',', ','), ('Volume', 'Volume'), ('30', '30'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 1002 =============================

60-62. 


>> Tokens are: 
 ['60-62', '.']

>> Bigrams are: 
 [('60-62', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('60-62', 'JJ'), ('.', '.')]

 (S 60-62/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('60-62', '60-62'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('60-62', '60-62'), ('.', '.')]

>> Lemmatization: 
 [('60-62', '60-62'), ('.', '.')]



============================ Sentence 1003 =============================

Wu, Celimuge and Yoshinaga, Tsutomu and Chen, Xianfu and Zhang, Lin and Ji, Yusheng, 2018. 


>> Tokens are: 
 ['Wu', ',', 'Celimuge', 'Yoshinaga', ',', 'Tsutomu', 'Chen', ',', 'Xianfu', 'Zhang', ',', 'Lin', 'Ji', ',', 'Yusheng', ',', '2018', '.']

>> Bigrams are: 
 [('Wu', ','), (',', 'Celimuge'), ('Celimuge', 'Yoshinaga'), ('Yoshinaga', ','), (',', 'Tsutomu'), ('Tsutomu', 'Chen'), ('Chen', ','), (',', 'Xianfu'), ('Xianfu', 'Zhang'), ('Zhang', ','), (',', 'Lin'), ('Lin', 'Ji'), ('Ji', ','), (',', 'Yusheng'), ('Yusheng', ','), (',', '2018'), ('2018', '.')]

>> Trigrams are: 
 [('Wu', ',', 'Celimuge'), (',', 'Celimuge', 'Yoshinaga'), ('Celimuge', 'Yoshinaga', ','), ('Yoshinaga', ',', 'Tsutomu'), (',', 'Tsutomu', 'Chen'), ('Tsutomu', 'Chen', ','), ('Chen', ',', 'Xianfu'), (',', 'Xianfu', 'Zhang'), ('Xianfu', 'Zhang', ','), ('Zhang', ',', 'Lin'), (',', 'Lin', 'Ji'), ('Lin', 'Ji', ','), ('Ji', ',', 'Yusheng'), (',', 'Yusheng', ','), ('Yusheng', ',', '2018'), (',', '2018', '.')]

>> POS Tags are: 
 [('Wu', 'NNP'), (',', ','), ('Celimuge', 'NNP'), ('Yoshinaga', 'NNP'), (',', ','), ('Tsutomu', 'NNP'), ('Chen', 'NNP'), (',', ','), ('Xianfu', 'NNP'), ('Zhang', 'NNP'), (',', ','), ('Lin', 'NNP'), ('Ji', 'NNP'), (',', ','), ('Yusheng', 'NNP'), (',', ','), ('2018', 'CD'), ('.', '.')]

 (S
  (NP Wu/NNP)
  ,/,
  (NP Celimuge/NNP Yoshinaga/NNP)
  ,/,
  (NP Tsutomu/NNP Chen/NNP)
  ,/,
  (NP Xianfu/NNP Zhang/NNP)
  ,/,
  (NP Lin/NNP Ji/NNP)
  ,/,
  (NP Yusheng/NNP)
  ,/,
  2018/CD
  ./.) 


>> Noun Phrases are: 
 ['Wu', 'Celimuge Yoshinaga', 'Tsutomu Chen', 'Xianfu Zhang', 'Lin Ji', 'Yusheng']

>> Named Entities are: 
 [('GPE', 'Wu'), ('PERSON', 'Celimuge Yoshinaga'), ('PERSON', 'Tsutomu Chen'), ('PERSON', 'Xianfu Zhang'), ('PERSON', 'Lin Ji'), ('PERSON', 'Yusheng')] 

>> Stemming using Porter Stemmer: 
 [('Wu', 'wu'), (',', ','), ('Celimuge', 'celimug'), ('Yoshinaga', 'yoshinaga'), (',', ','), ('Tsutomu', 'tsutomu'), ('Chen', 'chen'), (',', ','), ('Xianfu', 'xianfu'), ('Zhang', 'zhang'), (',', ','), ('Lin', 'lin'), ('Ji', 'ji'), (',', ','), ('Yusheng', 'yusheng'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wu', 'wu'), (',', ','), ('Celimuge', 'celimug'), ('Yoshinaga', 'yoshinaga'), (',', ','), ('Tsutomu', 'tsutomu'), ('Chen', 'chen'), (',', ','), ('Xianfu', 'xianfu'), ('Zhang', 'zhang'), (',', ','), ('Lin', 'lin'), ('Ji', 'ji'), (',', ','), ('Yusheng', 'yusheng'), (',', ','), ('2018', '2018'), ('.', '.')]

>> Lemmatization: 
 [('Wu', 'Wu'), (',', ','), ('Celimuge', 'Celimuge'), ('Yoshinaga', 'Yoshinaga'), (',', ','), ('Tsutomu', 'Tsutomu'), ('Chen', 'Chen'), (',', ','), ('Xianfu', 'Xianfu'), ('Zhang', 'Zhang'), (',', ','), ('Lin', 'Lin'), ('Ji', 'Ji'), (',', ','), ('Yusheng', 'Yusheng'), (',', ','), ('2018', '2018'), ('.', '.')]



============================ Sentence 1004 =============================

Cluster-based content distribution integrating LTE and IEEE 802.11 p with fuzzy logic and Q-  learning. 


>> Tokens are: 
 ['Cluster-based', 'content', 'distribution', 'integrating', 'LTE', 'IEEE', '802.11', 'p', 'fuzzy', 'logic', 'Q-', 'learning', '.']

>> Bigrams are: 
 [('Cluster-based', 'content'), ('content', 'distribution'), ('distribution', 'integrating'), ('integrating', 'LTE'), ('LTE', 'IEEE'), ('IEEE', '802.11'), ('802.11', 'p'), ('p', 'fuzzy'), ('fuzzy', 'logic'), ('logic', 'Q-'), ('Q-', 'learning'), ('learning', '.')]

>> Trigrams are: 
 [('Cluster-based', 'content', 'distribution'), ('content', 'distribution', 'integrating'), ('distribution', 'integrating', 'LTE'), ('integrating', 'LTE', 'IEEE'), ('LTE', 'IEEE', '802.11'), ('IEEE', '802.11', 'p'), ('802.11', 'p', 'fuzzy'), ('p', 'fuzzy', 'logic'), ('fuzzy', 'logic', 'Q-'), ('logic', 'Q-', 'learning'), ('Q-', 'learning', '.')]

>> POS Tags are: 
 [('Cluster-based', 'JJ'), ('content', 'NN'), ('distribution', 'NN'), ('integrating', 'VBG'), ('LTE', 'NNP'), ('IEEE', 'NNP'), ('802.11', 'CD'), ('p', 'NN'), ('fuzzy', 'JJ'), ('logic', 'JJ'), ('Q-', 'NNP'), ('learning', 'NN'), ('.', '.')]

 (S
  (NP Cluster-based/JJ content/NN distribution/NN)
  integrating/VBG
  (NP LTE/NNP IEEE/NNP)
  802.11/CD
  (NP p/NN)
  (NP fuzzy/JJ logic/JJ Q-/NNP learning/NN)
  ./.) 


>> Noun Phrases are: 
 ['Cluster-based content distribution', 'LTE IEEE', 'p', 'fuzzy logic Q- learning']

>> Named Entities are: 
 [('ORGANIZATION', 'LTE')] 

>> Stemming using Porter Stemmer: 
 [('Cluster-based', 'cluster-bas'), ('content', 'content'), ('distribution', 'distribut'), ('integrating', 'integr'), ('LTE', 'lte'), ('IEEE', 'ieee'), ('802.11', '802.11'), ('p', 'p'), ('fuzzy', 'fuzzi'), ('logic', 'logic'), ('Q-', 'q-'), ('learning', 'learn'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Cluster-based', 'cluster-bas'), ('content', 'content'), ('distribution', 'distribut'), ('integrating', 'integr'), ('LTE', 'lte'), ('IEEE', 'ieee'), ('802.11', '802.11'), ('p', 'p'), ('fuzzy', 'fuzzi'), ('logic', 'logic'), ('Q-', 'q-'), ('learning', 'learn'), ('.', '.')]

>> Lemmatization: 
 [('Cluster-based', 'Cluster-based'), ('content', 'content'), ('distribution', 'distribution'), ('integrating', 'integrating'), ('LTE', 'LTE'), ('IEEE', 'IEEE'), ('802.11', '802.11'), ('p', 'p'), ('fuzzy', 'fuzzy'), ('logic', 'logic'), ('Q-', 'Q-'), ('learning', 'learning'), ('.', '.')]



============================ Sentence 1005 =============================

ieee Computational intelligenCe magazine journal, pp. 


>> Tokens are: 
 ['ieee', 'Computational', 'intelligenCe', 'magazine', 'journal', ',', 'pp', '.']

>> Bigrams are: 
 [('ieee', 'Computational'), ('Computational', 'intelligenCe'), ('intelligenCe', 'magazine'), ('magazine', 'journal'), ('journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('ieee', 'Computational', 'intelligenCe'), ('Computational', 'intelligenCe', 'magazine'), ('intelligenCe', 'magazine', 'journal'), ('magazine', 'journal', ','), ('journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('ieee', 'JJ'), ('Computational', 'NNP'), ('intelligenCe', 'NN'), ('magazine', 'NN'), ('journal', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP
    ieee/JJ
    Computational/NNP
    intelligenCe/NN
    magazine/NN
    journal/NN)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['ieee Computational intelligenCe magazine journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Computational'), ('ORGANIZATION', 'intelligenCe')] 

>> Stemming using Porter Stemmer: 
 [('ieee', 'ieee'), ('Computational', 'comput'), ('intelligenCe', 'intellig'), ('magazine', 'magazin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('ieee', 'ieee'), ('Computational', 'comput'), ('intelligenCe', 'intellig'), ('magazine', 'magazin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('ieee', 'ieee'), ('Computational', 'Computational'), ('intelligenCe', 'intelligenCe'), ('magazine', 'magazine'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 1006 =============================

41-50. 


>> Tokens are: 
 ['41-50', '.']

>> Bigrams are: 
 [('41-50', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('41-50', 'JJ'), ('.', '.')]

 (S 41-50/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('41-50', '41-50'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('41-50', '41-50'), ('.', '.')]

>> Lemmatization: 
 [('41-50', '41-50'), ('.', '.')]



============================ Sentence 1007 =============================

Sarah Al-Shiakhli   54      Yi, X., Liu, F., Liu, J. and Jin, H., 2014. 


>> Tokens are: 
 ['Sarah', 'Al-Shiakhli', '54', 'Yi', ',', 'X.', ',', 'Liu', ',', 'F.', ',', 'Liu', ',', 'J.', 'Jin', ',', 'H.', ',', '2014', '.']

>> Bigrams are: 
 [('Sarah', 'Al-Shiakhli'), ('Al-Shiakhli', '54'), ('54', 'Yi'), ('Yi', ','), (',', 'X.'), ('X.', ','), (',', 'Liu'), ('Liu', ','), (',', 'F.'), ('F.', ','), (',', 'Liu'), ('Liu', ','), (',', 'J.'), ('J.', 'Jin'), ('Jin', ','), (',', 'H.'), ('H.', ','), (',', '2014'), ('2014', '.')]

>> Trigrams are: 
 [('Sarah', 'Al-Shiakhli', '54'), ('Al-Shiakhli', '54', 'Yi'), ('54', 'Yi', ','), ('Yi', ',', 'X.'), (',', 'X.', ','), ('X.', ',', 'Liu'), (',', 'Liu', ','), ('Liu', ',', 'F.'), (',', 'F.', ','), ('F.', ',', 'Liu'), (',', 'Liu', ','), ('Liu', ',', 'J.'), (',', 'J.', 'Jin'), ('J.', 'Jin', ','), ('Jin', ',', 'H.'), (',', 'H.', ','), ('H.', ',', '2014'), (',', '2014', '.')]

>> POS Tags are: 
 [('Sarah', 'NNP'), ('Al-Shiakhli', 'NNP'), ('54', 'CD'), ('Yi', 'NNP'), (',', ','), ('X.', 'NNP'), (',', ','), ('Liu', 'NNP'), (',', ','), ('F.', 'NNP'), (',', ','), ('Liu', 'NNP'), (',', ','), ('J.', 'NNP'), ('Jin', 'NNP'), (',', ','), ('H.', 'NNP'), (',', ','), ('2014', 'CD'), ('.', '.')]

 (S
  (NP Sarah/NNP Al-Shiakhli/NNP)
  54/CD
  (NP Yi/NNP)
  ,/,
  (NP X./NNP)
  ,/,
  (NP Liu/NNP)
  ,/,
  (NP F./NNP)
  ,/,
  (NP Liu/NNP)
  ,/,
  (NP J./NNP Jin/NNP)
  ,/,
  (NP H./NNP)
  ,/,
  2014/CD
  ./.) 


>> Noun Phrases are: 
 ['Sarah Al-Shiakhli', 'Yi', 'X.', 'Liu', 'F.', 'Liu', 'J. Jin', 'H.']

>> Named Entities are: 
 [('PERSON', 'Sarah'), ('PERSON', 'Liu'), ('PERSON', 'Liu'), ('PERSON', 'J. Jin')] 

>> Stemming using Porter Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakhli'), ('54', '54'), ('Yi', 'yi'), (',', ','), ('X.', 'x.'), (',', ','), ('Liu', 'liu'), (',', ','), ('F.', 'f.'), (',', ','), ('Liu', 'liu'), (',', ','), ('J.', 'j.'), ('Jin', 'jin'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Sarah', 'sarah'), ('Al-Shiakhli', 'al-shiakh'), ('54', '54'), ('Yi', 'yi'), (',', ','), ('X.', 'x.'), (',', ','), ('Liu', 'liu'), (',', ','), ('F.', 'f.'), (',', ','), ('Liu', 'liu'), (',', ','), ('J.', 'j.'), ('Jin', 'jin'), (',', ','), ('H.', 'h.'), (',', ','), ('2014', '2014'), ('.', '.')]

>> Lemmatization: 
 [('Sarah', 'Sarah'), ('Al-Shiakhli', 'Al-Shiakhli'), ('54', '54'), ('Yi', 'Yi'), (',', ','), ('X.', 'X.'), (',', ','), ('Liu', 'Liu'), (',', ','), ('F.', 'F.'), (',', ','), ('Liu', 'Liu'), (',', ','), ('J.', 'J.'), ('Jin', 'Jin'), (',', ','), ('H.', 'H.'), (',', ','), ('2014', '2014'), ('.', '.')]



============================ Sentence 1008 =============================

Building a network highway for big data: architecture and   challenges. 


>> Tokens are: 
 ['Building', 'network', 'highway', 'big', 'data', ':', 'architecture', 'challenges', '.']

>> Bigrams are: 
 [('Building', 'network'), ('network', 'highway'), ('highway', 'big'), ('big', 'data'), ('data', ':'), (':', 'architecture'), ('architecture', 'challenges'), ('challenges', '.')]

>> Trigrams are: 
 [('Building', 'network', 'highway'), ('network', 'highway', 'big'), ('highway', 'big', 'data'), ('big', 'data', ':'), ('data', ':', 'architecture'), (':', 'architecture', 'challenges'), ('architecture', 'challenges', '.')]

>> POS Tags are: 
 [('Building', 'NN'), ('network', 'NN'), ('highway', 'NN'), ('big', 'JJ'), ('data', 'NNS'), (':', ':'), ('architecture', 'NN'), ('challenges', 'NNS'), ('.', '.')]

 (S
  (NP Building/NN network/NN highway/NN)
  (NP big/JJ data/NNS)
  :/:
  (NP architecture/NN challenges/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Building network highway', 'big data', 'architecture challenges']

>> Named Entities are: 
 [('GPE', 'Building')] 

>> Stemming using Porter Stemmer: 
 [('Building', 'build'), ('network', 'network'), ('highway', 'highway'), ('big', 'big'), ('data', 'data'), (':', ':'), ('architecture', 'architectur'), ('challenges', 'challeng'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Building', 'build'), ('network', 'network'), ('highway', 'highway'), ('big', 'big'), ('data', 'data'), (':', ':'), ('architecture', 'architectur'), ('challenges', 'challeng'), ('.', '.')]

>> Lemmatization: 
 [('Building', 'Building'), ('network', 'network'), ('highway', 'highway'), ('big', 'big'), ('data', 'data'), (':', ':'), ('architecture', 'architecture'), ('challenges', 'challenge'), ('.', '.')]



============================ Sentence 1009 =============================

IEEE Network journal, Volume 28, pp. 


>> Tokens are: 
 ['IEEE', 'Network', 'journal', ',', 'Volume', '28', ',', 'pp', '.']

>> Bigrams are: 
 [('IEEE', 'Network'), ('Network', 'journal'), ('journal', ','), (',', 'Volume'), ('Volume', '28'), ('28', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('IEEE', 'Network', 'journal'), ('Network', 'journal', ','), ('journal', ',', 'Volume'), (',', 'Volume', '28'), ('Volume', '28', ','), ('28', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('IEEE', 'NNP'), ('Network', 'NNP'), ('journal', 'NN'), (',', ','), ('Volume', 'NN'), ('28', 'CD'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP IEEE/NNP Network/NNP journal/NN)
  ,/,
  (NP Volume/NN)
  28/CD
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['IEEE Network journal', 'Volume', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'IEEE Network'), ('ORGANIZATION', 'Volume 28')] 

>> Stemming using Porter Stemmer: 
 [('IEEE', 'ieee'), ('Network', 'network'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('28', '28'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('IEEE', 'ieee'), ('Network', 'network'), ('journal', 'journal'), (',', ','), ('Volume', 'volum'), ('28', '28'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('IEEE', 'IEEE'), ('Network', 'Network'), ('journal', 'journal'), (',', ','), ('Volume', 'Volume'), ('28', '28'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 1010 =============================

5-13. 


>> Tokens are: 
 ['5-13', '.']

>> Bigrams are: 
 [('5-13', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('5-13', 'JJ'), ('.', '.')]

 (S 5-13/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('5-13', '5-13'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('5-13', '5-13'), ('.', '.')]

>> Lemmatization: 
 [('5-13', '5-13'), ('.', '.')]



============================ Sentence 1011 =============================

Zhong, R.Y., Newman, S.T., Huang, G.Q. 


>> Tokens are: 
 ['Zhong', ',', 'R.Y.', ',', 'Newman', ',', 'S.T.', ',', 'Huang', ',', 'G.Q', '.']

>> Bigrams are: 
 [('Zhong', ','), (',', 'R.Y.'), ('R.Y.', ','), (',', 'Newman'), ('Newman', ','), (',', 'S.T.'), ('S.T.', ','), (',', 'Huang'), ('Huang', ','), (',', 'G.Q'), ('G.Q', '.')]

>> Trigrams are: 
 [('Zhong', ',', 'R.Y.'), (',', 'R.Y.', ','), ('R.Y.', ',', 'Newman'), (',', 'Newman', ','), ('Newman', ',', 'S.T.'), (',', 'S.T.', ','), ('S.T.', ',', 'Huang'), (',', 'Huang', ','), ('Huang', ',', 'G.Q'), (',', 'G.Q', '.')]

>> POS Tags are: 
 [('Zhong', 'NNP'), (',', ','), ('R.Y.', 'NNP'), (',', ','), ('Newman', 'NNP'), (',', ','), ('S.T.', 'NNP'), (',', ','), ('Huang', 'NNP'), (',', ','), ('G.Q', 'NNP'), ('.', '.')]

 (S
  (NP Zhong/NNP)
  ,/,
  (NP R.Y./NNP)
  ,/,
  (NP Newman/NNP)
  ,/,
  (NP S.T./NNP)
  ,/,
  (NP Huang/NNP)
  ,/,
  (NP G.Q/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Zhong', 'R.Y.', 'Newman', 'S.T.', 'Huang', 'G.Q']

>> Named Entities are: 
 [('GPE', 'Zhong'), ('GPE', 'Newman'), ('PERSON', 'Huang')] 

>> Stemming using Porter Stemmer: 
 [('Zhong', 'zhong'), (',', ','), ('R.Y.', 'r.y.'), (',', ','), ('Newman', 'newman'), (',', ','), ('S.T.', 's.t.'), (',', ','), ('Huang', 'huang'), (',', ','), ('G.Q', 'g.q'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zhong', 'zhong'), (',', ','), ('R.Y.', 'r.y.'), (',', ','), ('Newman', 'newman'), (',', ','), ('S.T.', 's.t.'), (',', ','), ('Huang', 'huang'), (',', ','), ('G.Q', 'g.q'), ('.', '.')]

>> Lemmatization: 
 [('Zhong', 'Zhong'), (',', ','), ('R.Y.', 'R.Y.'), (',', ','), ('Newman', 'Newman'), (',', ','), ('S.T.', 'S.T.'), (',', ','), ('Huang', 'Huang'), (',', ','), ('G.Q', 'G.Q'), ('.', '.')]



============================ Sentence 1012 =============================

and Lan, S., 2016. 


>> Tokens are: 
 ['Lan', ',', 'S.', ',', '2016', '.']

>> Bigrams are: 
 [('Lan', ','), (',', 'S.'), ('S.', ','), (',', '2016'), ('2016', '.')]

>> Trigrams are: 
 [('Lan', ',', 'S.'), (',', 'S.', ','), ('S.', ',', '2016'), (',', '2016', '.')]

>> POS Tags are: 
 [('Lan', 'NNP'), (',', ','), ('S.', 'NNP'), (',', ','), ('2016', 'CD'), ('.', '.')]

 (S (NP Lan/NNP) ,/, (NP S./NNP) ,/, 2016/CD ./.) 


>> Noun Phrases are: 
 ['Lan', 'S.']

>> Named Entities are: 
 [('GPE', 'Lan')] 

>> Stemming using Porter Stemmer: 
 [('Lan', 'lan'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Lan', 'lan'), (',', ','), ('S.', 's.'), (',', ','), ('2016', '2016'), ('.', '.')]

>> Lemmatization: 
 [('Lan', 'Lan'), (',', ','), ('S.', 'S.'), (',', ','), ('2016', '2016'), ('.', '.')]



============================ Sentence 1013 =============================

Big Data for supply chain   management in the service and manufacturing sectors: Challenges, opportunities, and future   perspectives. 


>> Tokens are: 
 ['Big', 'Data', 'supply', 'chain', 'management', 'service', 'manufacturing', 'sectors', ':', 'Challenges', ',', 'opportunities', ',', 'future', 'perspectives', '.']

>> Bigrams are: 
 [('Big', 'Data'), ('Data', 'supply'), ('supply', 'chain'), ('chain', 'management'), ('management', 'service'), ('service', 'manufacturing'), ('manufacturing', 'sectors'), ('sectors', ':'), (':', 'Challenges'), ('Challenges', ','), (',', 'opportunities'), ('opportunities', ','), (',', 'future'), ('future', 'perspectives'), ('perspectives', '.')]

>> Trigrams are: 
 [('Big', 'Data', 'supply'), ('Data', 'supply', 'chain'), ('supply', 'chain', 'management'), ('chain', 'management', 'service'), ('management', 'service', 'manufacturing'), ('service', 'manufacturing', 'sectors'), ('manufacturing', 'sectors', ':'), ('sectors', ':', 'Challenges'), (':', 'Challenges', ','), ('Challenges', ',', 'opportunities'), (',', 'opportunities', ','), ('opportunities', ',', 'future'), (',', 'future', 'perspectives'), ('future', 'perspectives', '.')]

>> POS Tags are: 
 [('Big', 'NNP'), ('Data', 'NNP'), ('supply', 'NN'), ('chain', 'NN'), ('management', 'NN'), ('service', 'NN'), ('manufacturing', 'VBG'), ('sectors', 'NNS'), (':', ':'), ('Challenges', 'NNS'), (',', ','), ('opportunities', 'NNS'), (',', ','), ('future', 'JJ'), ('perspectives', 'NNS'), ('.', '.')]

 (S
  (NP Big/NNP Data/NNP supply/NN chain/NN management/NN service/NN)
  manufacturing/VBG
  (NP sectors/NNS)
  :/:
  (NP Challenges/NNS)
  ,/,
  (NP opportunities/NNS)
  ,/,
  (NP future/JJ perspectives/NNS)
  ./.) 


>> Noun Phrases are: 
 ['Big Data supply chain management service', 'sectors', 'Challenges', 'opportunities', 'future perspectives']

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('supply', 'suppli'), ('chain', 'chain'), ('management', 'manag'), ('service', 'servic'), ('manufacturing', 'manufactur'), ('sectors', 'sector'), (':', ':'), ('Challenges', 'challeng'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('future', 'futur'), ('perspectives', 'perspect'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Big', 'big'), ('Data', 'data'), ('supply', 'suppli'), ('chain', 'chain'), ('management', 'manag'), ('service', 'servic'), ('manufacturing', 'manufactur'), ('sectors', 'sector'), (':', ':'), ('Challenges', 'challeng'), (',', ','), ('opportunities', 'opportun'), (',', ','), ('future', 'futur'), ('perspectives', 'perspect'), ('.', '.')]

>> Lemmatization: 
 [('Big', 'Big'), ('Data', 'Data'), ('supply', 'supply'), ('chain', 'chain'), ('management', 'management'), ('service', 'service'), ('manufacturing', 'manufacturing'), ('sectors', 'sector'), (':', ':'), ('Challenges', 'Challenges'), (',', ','), ('opportunities', 'opportunity'), (',', ','), ('future', 'future'), ('perspectives', 'perspective'), ('.', '.')]



============================ Sentence 1014 =============================

Computers & Industrial Engineering journal, pp. 


>> Tokens are: 
 ['Computers', '&', 'Industrial', 'Engineering', 'journal', ',', 'pp', '.']

>> Bigrams are: 
 [('Computers', '&'), ('&', 'Industrial'), ('Industrial', 'Engineering'), ('Engineering', 'journal'), ('journal', ','), (',', 'pp'), ('pp', '.')]

>> Trigrams are: 
 [('Computers', '&', 'Industrial'), ('&', 'Industrial', 'Engineering'), ('Industrial', 'Engineering', 'journal'), ('Engineering', 'journal', ','), ('journal', ',', 'pp'), (',', 'pp', '.')]

>> POS Tags are: 
 [('Computers', 'NNP'), ('&', 'CC'), ('Industrial', 'NNP'), ('Engineering', 'NNP'), ('journal', 'NN'), (',', ','), ('pp', 'NN'), ('.', '.')]

 (S
  (NP Computers/NNP)
  &/CC
  (NP Industrial/NNP Engineering/NNP journal/NN)
  ,/,
  (NP pp/NN)
  ./.) 


>> Noun Phrases are: 
 ['Computers', 'Industrial Engineering journal', 'pp']

>> Named Entities are: 
 [('ORGANIZATION', 'Computers'), ('ORGANIZATION', 'Industrial')] 

>> Stemming using Porter Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Computers', 'comput'), ('&', '&'), ('Industrial', 'industri'), ('Engineering', 'engin'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]

>> Lemmatization: 
 [('Computers', 'Computers'), ('&', '&'), ('Industrial', 'Industrial'), ('Engineering', 'Engineering'), ('journal', 'journal'), (',', ','), ('pp', 'pp'), ('.', '.')]



============================ Sentence 1015 =============================

572-591. 


>> Tokens are: 
 ['572-591', '.']

>> Bigrams are: 
 [('572-591', '.')]

>> Trigrams are: 
 []

>> POS Tags are: 
 [('572-591', 'JJ'), ('.', '.')]

 (S 572-591/JJ ./.) 


>> Noun Phrases are: 
 []

>> Named Entities are: 
 [] 

>> Stemming using Porter Stemmer: 
 [('572-591', '572-591'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('572-591', '572-591'), ('.', '.')]

>> Lemmatization: 
 [('572-591', '572-591'), ('.', '.')]



============================ Sentence 1016 =============================

Zuech, R., Khoshgoftaar, T.M. 


>> Tokens are: 
 ['Zuech', ',', 'R.', ',', 'Khoshgoftaar', ',', 'T.M', '.']

>> Bigrams are: 
 [('Zuech', ','), (',', 'R.'), ('R.', ','), (',', 'Khoshgoftaar'), ('Khoshgoftaar', ','), (',', 'T.M'), ('T.M', '.')]

>> Trigrams are: 
 [('Zuech', ',', 'R.'), (',', 'R.', ','), ('R.', ',', 'Khoshgoftaar'), (',', 'Khoshgoftaar', ','), ('Khoshgoftaar', ',', 'T.M'), (',', 'T.M', '.')]

>> POS Tags are: 
 [('Zuech', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('Khoshgoftaar', 'NNP'), (',', ','), ('T.M', 'NNP'), ('.', '.')]

 (S
  (NP Zuech/NNP)
  ,/,
  (NP R./NNP)
  ,/,
  (NP Khoshgoftaar/NNP)
  ,/,
  (NP T.M/NNP)
  ./.) 


>> Noun Phrases are: 
 ['Zuech', 'R.', 'Khoshgoftaar', 'T.M']

>> Named Entities are: 
 [('GPE', 'Zuech'), ('GPE', 'Khoshgoftaar')] 

>> Stemming using Porter Stemmer: 
 [('Zuech', 'zuech'), (',', ','), ('R.', 'r.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M', 't.m'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Zuech', 'zuech'), (',', ','), ('R.', 'r.'), (',', ','), ('Khoshgoftaar', 'khoshgoftaar'), (',', ','), ('T.M', 't.m'), ('.', '.')]

>> Lemmatization: 
 [('Zuech', 'Zuech'), (',', ','), ('R.', 'R.'), (',', ','), ('Khoshgoftaar', 'Khoshgoftaar'), (',', ','), ('T.M', 'T.M'), ('.', '.')]



============================ Sentence 1017 =============================

and Wald, R., 2015. 


>> Tokens are: 
 ['Wald', ',', 'R.', ',', '2015', '.']

>> Bigrams are: 
 [('Wald', ','), (',', 'R.'), ('R.', ','), (',', '2015'), ('2015', '.')]

>> Trigrams are: 
 [('Wald', ',', 'R.'), (',', 'R.', ','), ('R.', ',', '2015'), (',', '2015', '.')]

>> POS Tags are: 
 [('Wald', 'NNP'), (',', ','), ('R.', 'NNP'), (',', ','), ('2015', 'CD'), ('.', '.')]

 (S (NP Wald/NNP) ,/, (NP R./NNP) ,/, 2015/CD ./.) 


>> Noun Phrases are: 
 ['Wald', 'R.']

>> Named Entities are: 
 [('GPE', 'Wald')] 

>> Stemming using Porter Stemmer: 
 [('Wald', 'wald'), (',', ','), ('R.', 'r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Wald', 'wald'), (',', ','), ('R.', 'r.'), (',', ','), ('2015', '2015'), ('.', '.')]

>> Lemmatization: 
 [('Wald', 'Wald'), (',', ','), ('R.', 'R.'), (',', ','), ('2015', '2015'), ('.', '.')]



============================ Sentence 1018 =============================

Intrusion detection and big heterogeneous   data: a survey.. Journal of Big Data, p. 3. 


>> Tokens are: 
 ['Intrusion', 'detection', 'big', 'heterogeneous', 'data', ':', 'survey', '..', 'Journal', 'Big', 'Data', ',', 'p.', '3', '.']

>> Bigrams are: 
 [('Intrusion', 'detection'), ('detection', 'big'), ('big', 'heterogeneous'), ('heterogeneous', 'data'), ('data', ':'), (':', 'survey'), ('survey', '..'), ('..', 'Journal'), ('Journal', 'Big'), ('Big', 'Data'), ('Data', ','), (',', 'p.'), ('p.', '3'), ('3', '.')]

>> Trigrams are: 
 [('Intrusion', 'detection', 'big'), ('detection', 'big', 'heterogeneous'), ('big', 'heterogeneous', 'data'), ('heterogeneous', 'data', ':'), ('data', ':', 'survey'), (':', 'survey', '..'), ('survey', '..', 'Journal'), ('..', 'Journal', 'Big'), ('Journal', 'Big', 'Data'), ('Big', 'Data', ','), ('Data', ',', 'p.'), (',', 'p.', '3'), ('p.', '3', '.')]

>> POS Tags are: 
 [('Intrusion', 'NNP'), ('detection', 'NN'), ('big', 'JJ'), ('heterogeneous', 'JJ'), ('data', 'NNS'), (':', ':'), ('survey', 'NN'), ('..', 'VBZ'), ('Journal', 'NNP'), ('Big', 'NNP'), ('Data', 'NNP'), (',', ','), ('p.', 'NN'), ('3', 'CD'), ('.', '.')]

 (S
  (NP Intrusion/NNP detection/NN)
  (NP big/JJ heterogeneous/JJ data/NNS)
  :/:
  (NP survey/NN)
  ../VBZ
  (NP Journal/NNP Big/NNP Data/NNP)
  ,/,
  (NP p./NN)
  3/CD
  ./.) 


>> Noun Phrases are: 
 ['Intrusion detection', 'big heterogeneous data', 'survey', 'Journal Big Data', 'p.']

>> Named Entities are: 
 [('PERSON', 'Journal Big Data')] 

>> Stemming using Porter Stemmer: 
 [('Intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('heterogeneous', 'heterogen'), ('data', 'data'), (':', ':'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Stemming using Snowball Stemmer: 
 [('Intrusion', 'intrus'), ('detection', 'detect'), ('big', 'big'), ('heterogeneous', 'heterogen'), ('data', 'data'), (':', ':'), ('survey', 'survey'), ('..', '..'), ('Journal', 'journal'), ('Big', 'big'), ('Data', 'data'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

>> Lemmatization: 
 [('Intrusion', 'Intrusion'), ('detection', 'detection'), ('big', 'big'), ('heterogeneous', 'heterogeneous'), ('data', 'data'), (':', ':'), ('survey', 'survey'), ('..', '..'), ('Journal', 'Journal'), ('Big', 'Big'), ('Data', 'Data'), (',', ','), ('p.', 'p.'), ('3', '3'), ('.', '.')]

